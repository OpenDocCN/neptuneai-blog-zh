# 如何运行机器学习项目:最佳实践

> 原文：<https://web.archive.org/web/https://neptune.ai/blog/how-to-run-machine-learning-projects-best-practices>

ML 和数据科学发展迅速。在过去的几年里，在集成不同的技术和业务工作流方面已经取得了很大的进展。

如果你正在做一个商业 ML 项目，你可能会在打电话前后做很多事情。fit()和。预测()。在本文中，我们将讨论端到端项目的不同方面，通过一些简单的步骤，您可以增加项目成功的机会。

## 什么时候用 ML？

在创建模型之前，最好问问我们自己:

> “这个问题不用 ML 能解决吗？”

意思是，一个基于规则的系统能够很好地解决问题吗？

基于规则的方法具有独特的特征。规则是透明的，易于调试。你总是知道为什么预测会出错。当决策的解释和透明度至关重要时，这些信息就派上了用场。

然而，基于规则的系统很难维护。编写规则最初看起来很简单，但是随着产品的开发，它会变得很混乱。考虑规则的维护是至关重要的，而 ML 系统可以很容易地在新的数据集上重新训练。

例如，如果您正在构建发票解析软件，最初您可能会关注特定的发票模板。在那里很容易编写规则，因为文档结构几乎是一致的。然而，一旦您增加和处理更多的发票，基于 ML 的方法更有意义，因为它容易扩展。你只需要更多的数据和/或更复杂的模型，而不是更多的工程师来编写更多的规则。

## 启动 ML 项目前的清单

在你写第一行代码之前，你应该对你的进度有一个好的想法。这里有一个清单可能会有所帮助:

*   你的 ML 项目的目标是什么？为项目定义清晰的目标有助于集中注意力。例如，您可以构建一个 ML 模型来自动化信用卡审批。目的应该尽可能具体和透明。
*   你有数据吗？这一点我怎么强调都不为过！花更多时间收集高质量数据，而不是实施最先进的模型。实际上，每当您的模型表现不佳时，很可能是由于数据问题。你的公司可能没有任何数据，比如一些早期创业公司，所以你只能依靠第三方 ML 解决方案，直到你获得数据并训练你的模型。即使有了数据，也可能没有注释，注释需要一段时间。
*   **您将如何衡量模型性能？**当然，在训练您的模型时，您将跟踪准确性、精确度或任何其他感兴趣的指标。但是，请记住，这些数字并不是最终目标。您的业务度量来自项目目标。例如，网飞推荐引擎是一个 ML 模型，它增加了每个用户观看的*时间，或者减少了用户什么也没看* *并关闭网站*的*访问次数。有两个级别的指标，模型指标和业务指标。*
*   **基础设施真的到位了吗？**机器学习是 10%机器学习，90%工程。

如上图所示，实际的 ML 代码只是整个系统的一小部分。在 ML 代码之前，我们需要考虑数据过程。这不仅仅是收集数据并将其存储在一个地方。该系统必须具有高度的容错能力。例如，如果你正在使用云服务收集数据，而服务失败了，应该有一个救援机制来避免数据丢失。

此外，ML 模型需要根据用例频繁更新。让开发人员在每次更新上花费大量时间并不是好的做法。因此，拥有系统和工具来节省时间并在整个过程中更加透明是有益的。一种方法是使用一个好的模型注册中心，它允许我们存储和管理多个经过训练的模型。有像 MLflow 和 ModelDB 这样的开源模型注册中心。对于更复杂和协作的解决方案，请检查 neptune.ai(对个人开发者免费使用)。

从 MLOps 的角度来看，使用 Docker 将您的 ML 推理代码封装起来并使用 Kubernetes 进行部署是一个很好的实践。容器化应用程序使您不必担心如何设置合适的环境，并使您能够在云中的任何地方一致地运行您的应用程序。

*   **部署要求。**提前考虑部署策略通常是个好主意。云部署更好，还是边缘部署更好？延迟限制是什么？思考这些问题通常有助于决定您的模型应该有多大或多复杂。

糟糕的部署策略会降低用户体验。例如，如果你正在为一个用户生成餐馆推荐，在他/她打开应用程序的时候就这么做可能会花费很多时间。用户可能会退出应用程序。在这种情况下，当用户不活动时，可以在一夜之间生成推荐，并将它们缓存在他/她的设备上。

*   需要可解释性吗？任何模型背后的总体目标都是获得最佳指标。通常，这是以可解释性为代价的。越复杂，我们就越不知道模型内部发生了什么。然而，我们关心的是为什么模型在某些情况下做出了特定的预测。例如，在自动贷款申请系统中，申请人想要知道为什么他们的贷款申请被拒绝。在这种情况下，更简单的带有可解释参数的模型可能更好。

## 训练 ML 模型后的清单

你思考了上面几节的所有问题，训练了一个模型。那现在怎么办？你只是部署它吗？

没那么快。虽然您训练模型所依据的数据是经过仔细筛选的，但是您的模型还是有办法达到一个较高的指标。例如，考虑预测图像是熊猫还是北极熊的图像分类器。你以近乎完美的准确度训练了一个模型。

**模型预测(下图)–熊猫**

**模型预测(下图)——北极熊**

**模型预测(下图)——北极熊**

前两个预测有道理。第三个呢？应该是熊猫。

仔细查看模型后，发现该模型不是熊猫-北极熊分类器，而是雪草分类器。它经常在绿色的丛林中看到熊猫，在雪地里看到北极熊。

同样，NLP 中的数据泄漏也很常见。如果你正在构建一个情感分类器，确保模型是从代表情感的词中学习，而不是从停用词或任何其他不相关的词中学习。像 LIME 和 Shapley 这样的库有助于解释模型预测。

但是你如何评估一个无监督的模型呢？考虑一个句子嵌入模型。该模型的目标是为语义相似的句子生成高分，为不相似的句子生成低分，并在无监督或[自我监督的](/web/20221206013414/https://neptune.ai/blog/self-supervised-learning)设置中学习所有内容。在这种情况下，有一个定制的测试套件是很好的，就像手工策划的成对的正面(相似的)和负面(不相似的)例子。这些可以作为“单元测试”用于任何模型。设计多层次的测试。简单的检查模型健全性，例如:

(*很好的冰淇淋，政治领袖必须团结起来，0*

这是很好的冰淇淋，这甜点棒极了！，1

## A/B 测试

一旦你的模型准备好了并且正常了，就差不多是时候把它放到野外了。请记住，您的模型是在本地的受限环境中构建和测试的。但是在生产中事情可能会有所不同。因此，首先进行试运行，然后进行全面部署是至关重要的。

简而言之，A/B 测试用于评估随机设置中变量的两个选项。在我们的电影推荐示例中，我们会随机挑选几千个用户，并仅为这些用户部署新的 ML 模型。几天后，我们将新旧模型在推荐接受率、总花费时间等方面进行比较。如果新模型看起来性能更好，我们就为所有用户部署它。

根据测试的目的，一个好的 A/B 测试有许多设计考虑。

## 在野外测量模型性能

训练时你有标签。但是在真实环境中搅动模型预测又如何呢？很可能你看不到那里的标签。那么，你应该如何衡量一个活生生的模型的表现呢？

在进入 it 之前，我们为什么要在部署之后测量模型的性能呢？我们不是在一个采样良好的测试集上测试过吗？是的，我们确实这样做了。但是，训练数据分布可能与模型在真实环境中看到的分布有很大不同。例如，在 COVID 之前和 COVID 期间生成的推文可能在词汇、情感和主题方面有不同的分布。因此，这个模型肯定会在它没见过的数据上犯更多的错误。这被称为**数据漂移**。

您可以跟踪一些代理指标来显示特性分布是否发生了变化。由于训练的 ML 模型在预测中是确定性的，所以数据分布的变化通过特征分布的变化来反映。此外，预测标签分布的变化也可能是警报。如果定型数据标签看到的是 40-60 分布，而模型预测的标签是 20-80 分布，那么您可能需要检查模型。

在某些情况下，监管不力是有可能的。例如，在聊天机器人中，在一些系统生成的消息之后，系统可以询问对话是否对用户有帮助。过于频繁地要求这种验证会损害用户体验。类似地，在搜索或推荐中，通过点击接受结果可以反馈给系统。这种系统可以在线重新训练。

在您检测到模型质量下降后，下一步是通过对新数据进行重新训练来恢复其性能。但是在重新训练之前有一些考虑:

**您应该多久对模型进行一次再培训？**取决于你期望的数据移位频率。请记住，再培训是有成本的，尤其是在再培训大型模型的时候。

**应该只重新训练深度学习模型的最后几层还是整个模型？**您应该使用多少旧数据和多少新数据进行再培训？

这些选择主要取决于您的用例。

## 偏见和公平

现代深度学习模型是黑箱。我们不知道他们真正学到了什么。一个模型通常赋予一个特征更大的重要性，使其损失最小。当一个模型更加突出某些会引起系统性偏见的词或特征时，问题就出现了。

考虑 word2vec，它可能是为数不多的著名早期语言模型之一。单词向量可以用简单的向量代数来表示语言语义。例如:

***国王——男人+女人=王后***

同一模型也显示了这种关系。

***电脑程序员——男人+女人=家庭主妇***

你注意到偏见了吗？

不久前，在谷歌图片搜索中搜索“护士”时，出现了异常多的女性图片。

另一个臭名昭著的例子是亚马逊基于 ML 的招聘系统。亚马逊设计了一种算法，从数百份简历中挑出一份工作的前 5 份简历。人们发现，该制度对女性申请人有偏见，拒绝她们的情况比男性申请人多。

这种系统给公司带来了坏名声和巨大的经济损失。如果一家银行使用 ML 来接受或拒绝贷款申请，该模型可能会对某些种族产生系统性偏见。这显然意味着银行失去了潜在客户和它创造的收入。

### 偏倚治疗策略

机器学习可以用来消除机器学习模型中的偏差。这类方法分为两类——使用最大似然法去除有偏差的信号，以及使用最大似然法包含减少数据集中偏差的信号。如果在数据集中包括 **z** 改变了模型预测，则称 ML 模型相对于附加变量 **z** 有偏差。

有算法被设计来检测 ML 模型中的偏差。像 [IBM AI Fairness 360](https://web.archive.org/web/20221206013414/https://github.com/Trusted-AI/AIF360) 这样的包提供了这些算法的开源实现。此外，像莱姆和 SHAP 这样的可解释性方法也有助于理解 ML 模型的决策过程。

另一个名为 [FairML](https://web.archive.org/web/20221206013414/https://github.com/adebayoj/fairml) 的包使用了一个简单的想法，这个想法非常适合黑盒模型。由于模型采用特征的向量或矩阵并预测结果，如果改变特定的特征会彻底且一致地改变模型的结果，则该特征会引入一些偏差。FairML 评估输入特征的相对重要性，以检测输入数据中的偏差。根据该软件包的作者:

*"* *FairML 利用模型压缩和四种输入排序算法来量化模型对其输入的相对预测依赖性*

最近，去偏差模型的深度学习方法变得流行起来。在一种这样的方法中，为了从敏感变量 **z** 中消除分类器的偏差，要求模型预测任务标签 y 以及变量 **z** 。然而，在反向传播期间，相对于 **z** 的梯度被求反。因此，不是使用从 **z** 的梯度来减少损失，该模型现在学习更少地依赖 **z** 。

所以，这些问题是有解决办法的，你应该研究一下，以确保你的模型是公平的。

## 结论

总之，为业务用例开发 ML 解决方案是一个多变量的问题。

我们在本文中讨论的只是冰山一角。你的项目面临的挑战会根据你所解决的问题而有所不同。花点时间想想你的要求，然后着手执行。开始时，提前计划可能看起来很耗时，但将来会为你节省更多的时间。

### 参考

1.  [毫升偏差](https://web.archive.org/web/20221206013414/https://towardsdatascience.com/bias-in-machine-learning-algorithms-f36ddc2514c0)
2.  [亚马逊的招聘系统](https://web.archive.org/web/20221206013414/https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)