<html>
<head>
<title>Building a Search Engine With Pre-Trained Transformers: A Step By Step Guide </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>用预先训练好的变形金刚构建搜索引擎:一步一步指南</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/building-search-engine-with-pre-trained-transformers-guide#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/building-search-engine-with-pre-trained-transformers-guide#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>我们都用<a href="https://web.archive.org/web/20221206052553/https://serpact.com/8-machine-learning-principles-and-models-used-by-search-engines/" target="_blank" rel="noreferrer noopener nofollow">搜索引擎</a>。我们搜索关于最好的商品、一个好去处的信息，或者回答我们想知道的任何问题。</p>



<p>我们也非常依赖搜索来检查电子邮件、文件和金融交易。很多这样的搜索交互都是通过文本或语音转换成语音输入来实现的。这意味着大量的语言处理发生在搜索引擎上，所以NLP在现代搜索引擎中扮演着非常重要的角色</p>



<p>让我们快速看一下搜索时会发生什么。当您使用查询进行搜索时，搜索引擎会收集与该查询匹配的文档的排序列表。要做到这一点，首先应该为文档和其中使用的词汇构建一个“<strong>索引</strong>，然后用于搜索和排列结果。对文本数据进行索引和对搜索结果进行排名的一种流行形式是<a href="https://web.archive.org/web/20221206052553/https://en.wikipedia.org/wiki/Tf%E2%80%93idf" target="_blank" rel="noreferrer noopener nofollow"> TF-IDF </a>。</p>



<p>NLP的深度学习模型的最新发展可以用于此。例如，谷歌最近开始使用<a href="https://web.archive.org/web/20221206052553/https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html" target="_blank" rel="noreferrer noopener nofollow"> BERT </a>模型对搜索结果进行排名并显示片段。他们声称这提高了搜索结果的质量和相关性。</p>











<p>有两种类型的搜索引擎:</p>



<ul><li>通用搜索引擎，如Google和Bing，抓取网页，并通过不断寻找新网页来覆盖尽可能多的网页。</li><li><strong>企业搜索引擎</strong>，我们的搜索空间被限制在一个组织内已经存在的一个较小的文档集。</li></ul>



<p>第二种形式的搜索是你在任何工作场所都会遇到的最常见的用例。看下图就清楚了。</p>







<p>您可以在transformers中使用最先进的句子嵌入，并在下游任务中使用它们来实现语义文本的相似性。</p>



<p>在本文中，我们将探索如何构建一个基于向量的搜索引擎。</p>



<h2 id="h-why-would-you-need-a-vector-based-search-engine">为什么你需要一个基于矢量的搜索引擎？</h2>



<p>基于关键字搜索引擎面临以下问题:</p>



<ul><li>具有双重含义的复杂查询或单词。</li><li>长搜索查询。</li><li>不熟悉重要关键字的用户检索最佳结果。</li></ul>



<p>基于向量(也称为语义搜索)的搜索通过使用SOTA语言模型找到文本查询的数字表示来解决这些问题。然后，它在高维向量空间中对它们进行索引，并测量查询向量与索引文档的相似程度。</p>



<p>让我们看看预训练模型能提供什么:</p>



<ul><li>他们生产<strong>高质量的嵌入</strong>，因为他们在大量的文本数据上被训练。</li><li>他们不会强迫你创建一个自定义的记号赋予器，因为变形金刚有它们自己的方法。</li><li>它们<strong>非常简单方便</strong>来微调模型以适应你的下游任务。</li></ul>



<p>这些模型为文档中的每个标记生成一个固定大小的向量。</p>







<p>现在，让我们看看如何使用预训练的BERT模型来构建搜索引擎的特征提取器。</p>



<h2 id="h-step-1-load-the-pre-trained-model">步骤1:加载预先训练的模型</h2>



<pre class="hljs">!wget https://storage.googleapis.com/bert_models/<span class="hljs-number">2018</span>_10_18/uncased_L<span class="hljs-number">-12</span>_H<span class="hljs-number">-768</span>_A<span class="hljs-number">-12.</span>zip
!unzip uncased_L<span class="hljs-number">-12</span>_H<span class="hljs-number">-768</span>_A<span class="hljs-number">-12.</span>zip
!pip install bert-serving-server --no-deps</pre>



<p>对于这个实现，我将使用BERT uncased。还有其他可用的bert变体——BERT-as-a-service使用BERT作为句子编码器，并通过<a href="https://web.archive.org/web/20221206052553/https://zeromq.org/" target="_blank" rel="noreferrer noopener nofollow"> ZeroMQ </a>将其作为服务托管，让您只需两行代码就可以将句子映射为固定长度的表示。如果您希望避免客户端-服务器架构引入的额外延迟和潜在模式，这将非常有用。</p>



<h2 id="h-step-2-optimizing-the-inference-graph">步骤2:优化推理图</h2>



<p>为了修改模型图，我们需要一些低级的张量流编程。因为我们使用的是bert-as-a-service，所以我们可以使用一个简单的CLI界面来配置推断图。</p>



<p>(用于此实现的tensorflow版本是tensorflow==1.15.2)</p>



<pre class="hljs"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> tensorflow.compat.v1 <span class="hljs-keyword">as</span> tfc


sess = tfc.InteractiveSession()

<span class="hljs-keyword">from</span> bert_serving.server.graph <span class="hljs-keyword">import</span> optimize_graph
<span class="hljs-keyword">from</span> bert_serving.server.helper <span class="hljs-keyword">import</span> get_args_parser



MODEL_DIR = <span class="hljs-string">'/content/uncased_L-12_H-768_A-12'</span> 

GRAPH_DIR = <span class="hljs-string">'/content/graph/'</span> 

GRAPH_OUT = <span class="hljs-string">'extractor.pbtxt'</span> 

POOL_STRAT = <span class="hljs-string">'REDUCE_MEAN'</span> 
POOL_LAYER = <span class="hljs-string">'-2'</span> 
SEQ_LEN = <span class="hljs-string">'256'</span> 


tf.io.gfile.mkdir(GRAPH_DIR)


carg = get_args_parser().parse_args(args=[<span class="hljs-string">'-model_dir'</span>, MODEL_DIR,
                              <span class="hljs-string">'-graph_tmp_dir'</span>, GRAPH_DIR,
                              <span class="hljs-string">'-max_seq_len'</span>, str(SEQ_LEN),
                              <span class="hljs-string">'-pooling_layer'</span>, str(POOL_LAYER),
                              <span class="hljs-string">'-pooling_strategy'</span>, POOL_STRAT])

tmp_name, config = optimize_graph(carg)
graph_fout = os.path.join(GRAPH_DIR, GRAPH_OUT)

tf.gfile.Rename(
   tmp_name,
   graph_fout,
   overwrite=<span class="hljs-keyword">True</span>
)
print(<span class="hljs-string">"nSerialized graph to {}"</span>.format(graph_fout))</pre>



<p>看看上面代码片段中的几个参数。</p>



<p>对于每个文本样本，基于BERT的模型编码层输出形状为[ <strong> <em> sequence_len，encoder_dim </em> </strong> ]的张量，每个输入令牌一个向量。为了获得固定的表示，我们需要应用某种类型的池。</p>



<p><strong> POOL_STRAT </strong>参数定义了应用于编码器层数<strong> POOL_LAYER </strong>的池策略。默认值<strong>‘REDUCE _ MEAN’</strong>对序列中所有记号的向量进行平均。当模型没有微调时，这种特殊的策略最适合大多数句子级的任务。另一个选项是<strong> NONE </strong>，在这种情况下不应用池。</p>



<p><strong>SEQ _莱恩</strong>对模型处理的序列的最大长度有影响。如果想让模型推理速度几乎线性提升，可以给更小的值。</p>



<p>运行上面的代码片段会将模型图和权重放入一个<strong> GraphDef </strong>对象中，该对象将在<strong> GRAPH_OUT </strong>序列化为一个<strong> <em> pbtxt </em> </strong>文件。该文件通常比预训练模型小，因为训练所需的节点和变量将被移除。</p>







<p>让我们使用序列化的图来构建一个使用<a href="https://web.archive.org/web/20221206052553/https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator" target="_blank" rel="noreferrer noopener nofollow"> tf的特征提取器。估计器</a> API。我们需要定义2件事情:<strong>输入_fn </strong>和<strong>模型_fn </strong>。</p>



<p><strong> input_fn </strong>将数据获取到模型中。这包括执行整个文本预处理管道，并为BERT准备一个feed_dict。<br/>每个文本样本被转换成一个tf。示例实例，具有在<strong>输入名称</strong>中列出的必要特征。bert_tokenizer对象包含了<em>单词表</em>并执行文本处理。之后，示例在<em> feed_dict </em>中按照特性名称重新分组。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> logging
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-keyword">from</span> tensorflow.python.estimator.estimator <span class="hljs-keyword">import</span> Estimator
<span class="hljs-keyword">from</span> tensorflow.python.estimator.run_config <span class="hljs-keyword">import</span> RunConfig
<span class="hljs-keyword">from</span> tensorflow.python.estimator.model_fn <span class="hljs-keyword">import</span> EstimatorSpec
<span class="hljs-keyword">from</span> tensorflow.keras.utils <span class="hljs-keyword">import</span> Progbar

<span class="hljs-keyword">from</span> bert_serving.server.bert.tokenization <span class="hljs-keyword">import</span> FullTokenizer
<span class="hljs-keyword">from</span> bert_serving.server.bert.extract_features <span class="hljs-keyword">import</span> convert_lst_to_features

log = logging.getLogger(<span class="hljs-string">'tensorflow'</span>)
log.setLevel(logging.INFO)
log.handlers = []</pre>



<pre class="hljs">GRAPH_PATH = <span class="hljs-string">"/content/graph/extractor.pbtxt"</span> 
VOCAB_PATH = <span class="hljs-string">"/content/uncased_L-12_H-768_A-12/vocab.txt"</span> 

SEQ_LEN = <span class="hljs-number">256</span> </pre>



<pre class="hljs">INPUT_NAMES = [<span class="hljs-string">'input_ids'</span>, <span class="hljs-string">'input_mask'</span>, <span class="hljs-string">'input_type_ids'</span>]
bert_tokenizer = FullTokenizer(VOCAB_PATH)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_feed_dict</span><span class="hljs-params">(texts)</span>:</span>

   text_features = list(convert_lst_to_features(
       texts, SEQ_LEN, SEQ_LEN,
       bert_tokenizer, log, <span class="hljs-keyword">False</span>, <span class="hljs-keyword">False</span>))

   target_shape = (len(texts), <span class="hljs-number">-1</span>)

   feed_dict = {}
   <span class="hljs-keyword">for</span> iname <span class="hljs-keyword">in</span> INPUT_NAMES:
       features_i = np.array([getattr(f, iname) <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> text_features])
       features_i = features_i.reshape(target_shape).astype(<span class="hljs-string">"int32"</span>)
       feed_dict[iname] = features_i

   <span class="hljs-keyword">return</span> feed_dict</pre>



<p>tf。估算器有一个特性，使它们在每次调用predict函数时重建和重新初始化整个计算图。</p>



<p>因此，为了避免开销，我们将<strong>将生成器传递给预测函数</strong>，生成器将在一个永无止境的循环中为模型生成特征。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_input_fn</span><span class="hljs-params">(container)</span>:</span>

   <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen</span><span class="hljs-params">()</span>:</span>
       <span class="hljs-keyword">while</span> <span class="hljs-keyword">True</span>:
         <span class="hljs-keyword">try</span>:
           <span class="hljs-keyword">yield</span> build_feed_dict(container.get())
         <span class="hljs-keyword">except</span>:
           <span class="hljs-keyword">yield</span> build_feed_dict(container.get())

   <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">input_fn</span><span class="hljs-params">()</span>:</span>
       <span class="hljs-keyword">return</span> tf.data.Dataset.from_generator(
           gen,
           output_types={iname: tf.int32 <span class="hljs-keyword">for</span> iname <span class="hljs-keyword">in</span> INPUT_NAMES},
           output_shapes={iname: (<span class="hljs-keyword">None</span>, <span class="hljs-keyword">None</span>) <span class="hljs-keyword">for</span> iname <span class="hljs-keyword">in</span> INPUT_NAMES})
   <span class="hljs-keyword">return</span> input_fn

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DataContainer</span>:</span>
 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
   self._texts = <span class="hljs-keyword">None</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">set</span><span class="hljs-params">(self, texts)</span>:</span>
   <span class="hljs-keyword">if</span> type(texts) <span class="hljs-keyword">is</span> str:
     texts = [texts]
   self._texts = texts

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get</span><span class="hljs-params">(self)</span>:</span>
   <span class="hljs-keyword">return</span> self._texts</pre>



<p><strong> model_fn </strong>包含模型的规格。在我们的例子中，它是从我们在上一步中保存的<em> pbtxt </em>文件中加载的。这些特征通过<strong>输入映射</strong>明确映射到相应的输入节点。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">model_fn</span><span class="hljs-params">(features, mode)</span>:</span>
   <span class="hljs-keyword">with</span> tf.gfile.GFile(GRAPH_PATH, <span class="hljs-string">'rb'</span>) <span class="hljs-keyword">as</span> f:
       graph_def = tf.GraphDef()
       graph_def.ParseFromString(f.read())

   output = tf.import_graph_def(graph_def,
                                input_map={k + <span class="hljs-string">':0'</span>: features[k] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> INPUT_NAMES},
                                return_elements=[<span class="hljs-string">'final_encodes:0'</span>])

   <span class="hljs-keyword">return</span> EstimatorSpec(mode=mode, predictions={<span class="hljs-string">'output'</span>: output[<span class="hljs-number">0</span>]})

estimator = Estimator(model_fn=model_fn)
</pre>



<p>现在我们已经准备好了，我们需要进行推理。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">batch</span><span class="hljs-params">(iterable, n=<span class="hljs-number">1</span>)</span>:</span>
   l = len(iterable)
   <span class="hljs-keyword">for</span> ndx <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, l, n):
       <span class="hljs-keyword">yield</span> iterable[ndx:min(ndx + n, l)]

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_vectorizer</span><span class="hljs-params">(_estimator, _input_fn_builder, batch_size=<span class="hljs-number">128</span>)</span>:</span>
 container = DataContainer()
 predict_fn = _estimator.predict(_input_fn_builder(container), yield_single_examples=<span class="hljs-keyword">False</span>)
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">vectorize</span><span class="hljs-params">(text, verbose=False)</span>:</span>
   x = []
   bar = Progbar(len(text))
   <span class="hljs-keyword">for</span> text_batch <span class="hljs-keyword">in</span> batch(text, batch_size):
     container.set(text_batch)
     x.append(next(predict_fn)[<span class="hljs-string">'output'</span>])
     <span class="hljs-keyword">if</span> verbose:
       bar.add(len(text_batch))

   r = np.vstack(x)
   <span class="hljs-keyword">return</span> r
  <span class="hljs-keyword">return</span> vectorize
bert_vectorizer = build_vectorizer(estimator, build_input_fn)</pre>



<pre class="hljs">bert_vectorizer(<span class="hljs-number">64</span>*[<span class="hljs-string">'sample text'</span>]).shape
o/p: (<span class="hljs-number">64</span>, <span class="hljs-number">768</span>)
</pre>



<h2 id="h-step-4-exploring-vector-space-with-projector">第四步:用投影仪探索向量空间</h2>



<p>使用矢量器，我们将为来自<a href="https://web.archive.org/web/20221206052553/https://paperswithcode.com/dataset/reuters-21578" target="_blank" rel="noreferrer noopener nofollow"> Reuters-221578 </a>基准语料库的文章生成嵌入。</p>



<p>为了探索和可视化三维嵌入向量空间，我们将使用一种称为<a href="https://web.archive.org/web/20221206052553/https://distill.pub/2016/misread-tsne/" target="_blank" rel="noreferrer noopener nofollow"> T-SNE的降维技术。</a></p>



<p>首先让我们得到文章嵌入。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> reuters

<span class="hljs-keyword">import</span> nltk
nltk.download(<span class="hljs-string">"reuters"</span>)
nltk.download(<span class="hljs-string">"punkt"</span>)

max_samples = <span class="hljs-number">256</span>
categories = [<span class="hljs-string">'wheat'</span>, <span class="hljs-string">'tea'</span>, <span class="hljs-string">'strategic-metal'</span>,
             <span class="hljs-string">'housing'</span>, <span class="hljs-string">'money-supply'</span>, <span class="hljs-string">'fuel'</span>]

S, X, Y = [], [], []

<span class="hljs-keyword">for</span> category <span class="hljs-keyword">in</span> categories:
 print(category)
  sents = reuters.sents(categories=category)
 sents = [<span class="hljs-string">' '</span>.join(sent) <span class="hljs-keyword">for</span> sent <span class="hljs-keyword">in</span> sents][:max_samples]
 X.append(bert_vectorizer(sents, verbose=<span class="hljs-keyword">True</span>))
 Y += [category] * len(sents)
 S += sents
 X = np.vstack(X)
X.shape
</pre>



<p>运行上述代码后，如果你在collab中遇到任何问题，比如:"<strong> Resource reuters not found。请使用NLTK下载程序获取资源。</strong></p>



<p>…然后运行以下命令，其中-d后面的相对路径将给出文件解压缩的位置:</p>



<pre class="hljs">!unzip /root/nltk_data/corpora/reuters.zip -d /root/nltk_data/corpora
</pre>



<p>生成的嵌入的交互式可视化可在<a href="https://web.archive.org/web/20221206052553/https://projector.tensorflow.org/" target="_blank" rel="noreferrer noopener nofollow">嵌入投影仪</a>上获得。</p>



<p>通过链接，你可以自己运行<em> t-SNE </em>，或者使用右下角的书签加载一个检查点(加载在Chrome上有效)。</p>



<p>要重现用于该可视化的输入文件，请运行下面的代码片段。然后将文件下载到您的机器上，并上传到投影仪。</p>



<pre class="hljs"><span class="hljs-keyword">with</span> open(<span class="hljs-string">"embeddings.tsv"</span>, <span class="hljs-string">"w"</span>) <span class="hljs-keyword">as</span> fo:
 <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X.astype(<span class="hljs-string">'float'</span>):
   line = <span class="hljs-string">"t"</span>.join([str(v) <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> x])
   fo.write(line+<span class="hljs-string">'n'</span>)

<span class="hljs-keyword">with</span> open(<span class="hljs-string">'metadata.tsv'</span>, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> fo:
 fo.write(<span class="hljs-string">"LabeltSentencen"</span>)
 <span class="hljs-keyword">for</span> y, s <span class="hljs-keyword">in</span> zip(Y, S):
   fo.write(<span class="hljs-string">"{}t{}n"</span>.format(y, s))
</pre>



<p>这是我用投影仪捕捉到的。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> HTML

HTML(<span class="hljs-string">"""
&lt;video width="900" height="632" controls&gt;
 &lt;source src="https://storage.googleapis.com/bert_resourses/reuters_tsne_hd.mp4" type="video/mp4"&gt;
&lt;/video&gt;
"""</span>)
</pre>



<figure class="wp-block-video"><video controls="" src="https://web.archive.org/web/20221206052553im_/https://neptune.ai/wp-content/uploads/reuters_tsne_hd.mp4"/></figure>



<p>使用生成的特征构建监督模型非常简单:</p>



<pre class="hljs"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report
Xtr, Xts, Ytr, Yts = train_test_split(X, Y, random_state=<span class="hljs-number">34</span>)

mlp = LogisticRegression()
mlp.fit(Xtr, Ytr)

print(classification_report(Yts, mlp.predict(Xts)))
</pre>



<p id="separator-block_61af2b1c754d9" class="block-separator block-separator--10"> </p>



<div id="medium-table-block_61af2b23754da" class="block-medium-table c-table__outer-wrapper ">

    <table class="c-table">
                    <thead class="c-table__head">
            <tr>
                                    <td class="c-item">
                        <p class="c-item__inner">                                                      </p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">精确</p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">回忆</p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">f1-分数</p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">支持</p>
                    </td>
                            </tr>
            </thead>
        
        <tbody class="c-table__body">

                    
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

                    
        </tbody>
    </table>

</div>



<p id="separator-block_61af2b27754db" class="block-separator block-separator--20"> </p>



<h2 id="h-step-5-building-a-search-engine">步骤5:构建搜索引擎</h2>



<p>假设我们有一个50，000个文本样本的知识库，我们需要根据这些数据快速回答查询。如何从文本数据库中检索出与查询最相似的结果？答案之一可以是最近邻搜索。</p>



<p>我们在这里解决的搜索问题可以定义如下:</p>



<p>给定向量空间中的一组点<strong>S</strong>M<strong>T3】和一个查询点<strong>Q</strong>T6】∈</strong><strong><em>M，</em> </strong>求距离<strong> S </strong>到<strong> Q </strong>最近的点。在向量空间中有多种方法来定义<strong> <em>【最接近】</em></strong>——我们将使用<a href="https://web.archive.org/web/20221206052553/https://en.wikipedia.org/wiki/Euclidean_distance#:~:text=In%20mathematics%2C%20the%20Euclidean%20distance,being%20called%20the%20Pythagorean%20distance." target="_blank" rel="noreferrer noopener nofollow">欧几里德距离</a>。</p>



<p>要构建文本搜索引擎，我们将遵循以下步骤:</p>



<ol><li>对知识库中的所有样本进行矢量化——这就给出了<strong> S </strong>。</li><li>向量化查询——这给出了<strong> Q </strong>。</li><li>计算<strong> Q </strong>和<strong> S </strong>之间的欧几里德距离<strong> D </strong>。</li><li>按升序排序<strong>D</strong>-提供最相似样本的索引。</li><li>从知识库中检索所述样本的标签。</li></ol>



<p>我们可以为<strong> Q </strong>和<strong> S: </strong>创建占位符</p>



<pre class="hljs">graph = tf.Graph()

sess = tf.InteractiveSession(graph=graph)

dim = X.shape[<span class="hljs-number">1</span>]

Q = tf.placeholder(<span class="hljs-string">"float"</span>, [dim])
S = tf.placeholder(<span class="hljs-string">"float"</span>, [<span class="hljs-keyword">None</span>, dim])</pre>



<p>定义欧几里德距离计算:</p>



<pre class="hljs">squared_distance = tf.reduce_sum(tf.pow(Q - S, <span class="hljs-number">2</span>), reduction_indices=<span class="hljs-number">1</span>)
distance = tf.sqrt(squared_distance)
</pre>



<p>获取最相似的指数:</p>



<pre class="hljs">top_k = <span class="hljs-number">10</span>

top_neg_dists, top_indices = tf.math.top_k(tf.negative(distance), k=top_k)
top_dists = tf.negative(top_neg_dists)
</pre>



<pre class="hljs"><span class="hljs-keyword">from</span> sklearn.metrics.pairwise <span class="hljs-keyword">import</span> euclidean_distances

top_indices.eval({Q:X[<span class="hljs-number">0</span>], S:X})

np.argsort(euclidean_distances(X[:<span class="hljs-number">1</span>], X)[<span class="hljs-number">0</span>])[:<span class="hljs-number">10</span>]
</pre>



<h2 id="h-step-6-accelerating-search-with-math">第六步:用数学加速搜索</h2>



<p>在tensorflow中，这可以按如下方式完成:</p>



<pre class="hljs">Q = tf.placeholder(<span class="hljs-string">"float"</span>, [dim])
S = tf.placeholder(<span class="hljs-string">"float"</span>, [<span class="hljs-keyword">None</span>, dim])

Qr = tf.reshape(Q, (<span class="hljs-number">1</span>, <span class="hljs-number">-1</span>))

PP = tf.keras.backend.batch_dot(S, S, axes=<span class="hljs-number">1</span>)
QQ = tf.matmul(Qr, tf.transpose(Qr))
PQ = tf.matmul(S, tf.transpose(Qr))

distance = PP - <span class="hljs-number">2</span> * PQ + QQ
distance = tf.sqrt(tf.reshape(distance, (<span class="hljs-number">-1</span>,)))

top_neg_dists, top_indices = tf.math.top_k(tf.negative(distance), k=top_k)
</pre>



<p>上式<strong>中PP </strong>和<strong> QQ </strong>实际上是各自向量的平方<a href="https://web.archive.org/web/20221206052553/https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm" target="_blank" rel="noreferrer noopener nofollow"> L2范数</a>。如果两个向量都是L2归一化的，则:</p>



<p class="has-text-align-center"><strong><em>PP = QQ = 1</em>T3】</strong></p>



<p>进行L2归一化会丢弃关于矢量幅度的信息，这在很多情况下是你不想做的。</p>



<p>相反，我们可能会注意到，只要知识库保持不变——PP——其平方向量范数也保持不变。因此，我们可以只做一次，然后使用预先计算的结果，而不是每次都重新计算，从而进一步加快距离计算。</p>



<p>让我们一起努力。</p>



<pre class="hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">L2Retriever</span>:</span>
 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, dim, top_k=<span class="hljs-number">3</span>, use_norm=False, use_gpu=True)</span>:</span>
   self.dim = dim
   self.top_k = top_k
   self.use_norm = use_norm
   config = tf.ConfigProto(
       device_count = {<span class="hljs-string">'GPU'</span>: (<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> use_gpu <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)}
   )
   self.session = tf.Session(config=config)

   self.norm = <span class="hljs-keyword">None</span>
   self.query = tf.placeholder(<span class="hljs-string">"float"</span>, [self.dim])
   self.kbase = tf.placeholder(<span class="hljs-string">"float"</span>, [<span class="hljs-keyword">None</span>, self.dim])

   self.build_graph()

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_graph</span><span class="hljs-params">()</span>:</span>
   <span class="hljs-keyword">if</span> self.use_norm:
     self.norm = tf.placeholder(<span class="hljs-string">"float"</span>, [<span class="hljs-keyword">None</span>, <span class="hljs-number">1</span>])

   distance = dot_l2_distances(self.kbase, self.query, self.norm)
   top_neg_dists, top_indices = tf.math.top_k(tf.negative(distance), k=self.top_k)
   top_dists = tf.negative(top_neg_dists)

   self.top_distances = top_dists
   self.top_indices = top_indices

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span><span class="hljs-params">(self, kbase, query, norm=None)</span>:</span>
   query = np.squeeze(query)
   feed_dict = {self.query: query, self.kbase: kbase}
   <span class="hljs-keyword">if</span> self.use_norm:
     feed_dict[self.norm] = norm

   I, D = self.session.run([self.top_indices, self.top_distances],
                           feed_dict=feed_dict)
   <span class="hljs-keyword">return</span> I, D

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dot_l2_distances</span><span class="hljs-params">(kbase, query, norm=None)</span>:</span>
 query = tf.reshape(query, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))

 <span class="hljs-keyword">if</span> norm <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span>:
   XX = tf.keras.backend.batch_dot(kbase, kbase, axes=<span class="hljs-number">1</span>)
 <span class="hljs-keyword">else</span>:
   XX = norm
 YY = tf.matmul(query, tf.transpose(query))
 XY = tf.matmul(kbase, tf.transpose(query))

 distance = XX - <span class="hljs-number">2</span> * XY + YY
 distance = tf.sqrt(tf.reshape(distance, (<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>)))

 <span class="hljs-keyword">return</span> distance</pre>



<p>我们可以将这种实现用于任何矢量器模型，而不仅仅是BERT。它在最近邻检索方面非常有效，能够在双核colab CPU上每秒处理几十个请求。</p>



<p><strong>在构建机器学习应用时，你需要考虑一些额外的方面:</strong></p>



<ul><li>您如何确保解决方案的可扩展性？</li></ul>



<ul><li>选择正确的框架/语言。</li><li>使用正确的处理器。</li><li>收集和存储数据。</li><li>输入管道。</li><li>模特培训。</li><li>分布式系统。</li><li>其他优化。</li><li>资源利用和监控。</li><li>展开。</li></ul>



<ul><li>你如何训练、测试和部署你的产品模型？</li></ul>



<ul><li>创建一个可用于下载和处理数据的笔记本实例。</li><li>准备数据/预处理它，你需要训练你的ML模型，然后上传数据(例如:亚马逊S3)。</li><li>使用您的训练数据集来训练您的机器学习模型。</li><li>将模型部署到端点，重新格式化并加载csv数据，然后运行模型以创建预测。</li><li>评估ML模型的性能和准确性。</li></ul>







<h2 id="h-side-note-make-ml-easier-with-experiment-tracking">旁注–通过实验跟踪简化ML</h2>



<p>一个工具可以照顾你所有的<a href="/web/20221206052553/https://neptune.ai/experiment-tracking" target="_blank" rel="noreferrer noopener">实验跟踪</a>和协作需求——<a href="/web/20221206052553/https://neptune.ai/" target="_blank" rel="noreferrer noopener">Neptune . ai</a></p>



<p>Neptune记录您的整个实验过程——探索笔记本、模型训练运行、代码、超参数、指标、数据版本、结果、探索可视化等等。</p>



<p>这是MLOps的元数据存储，为进行大量实验的研究和生产团队而构建。专注于ML，把元数据管理留给Neptune。要开始使用Neptune，请访问他们广泛的<a href="https://web.archive.org/web/20221206052553/https://docs.neptune.ai/getting-started/hello-world" target="_blank" rel="noreferrer noopener">指南</a>。</p>



<p>像Neptune这样的ML元数据存储是MLOps栈的重要组成部分。在您构建模型时，它负责元数据管理。</p>



<p>它记录、存储、显示、组织、比较和查询ML模型生命周期中生成的所有元数据。</p>



<p>您可以使用ML metastore来跟踪、组织和比较您在ML实验中关心的一切。</p>







<p>Neptune集成了所有你喜欢的框架和工具——最流行的集成之一是直接通过<a href="https://web.archive.org/web/20221206052553/https://docs.neptune.ai/integrations-and-supported-tools/experiment-tracking/tensorboard" target="_blank" rel="noreferrer noopener"> TensorBoard </a>完成的<a href="https://web.archive.org/web/20221206052553/https://docs.neptune.ai/integrations-and-supported-tools/model-training/tensorflow-keras" target="_blank" rel="noreferrer noopener"> Tensorflow/Keras </a>。</p>



<h2 id="h-conclusion">结论</h2>



<p>使用BERT搜索的主要探索领域是<strong>相似性</strong>。文档的相似性、推荐的相似性以及查询和文档之间的相似性，用于返回和排列搜索结果。</p>



<p>如果你能使用相似性来解决这个问题，并得到非常精确的结果，那么你就能很好地搜索到你的产品或应用。</p>



<p>我希望你在这里学到了新东西。感谢阅读。不断学习。</p>
        </div>
        
    </div>    
</body>
</html>