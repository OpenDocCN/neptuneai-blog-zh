<html>
<head>
<title>Dive Into Football Analytics With TensorFlow Object Detection API </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>使用TensorFlow对象检测API深入足球分析</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/dive-into-football-analytics-with-tensorflow-object-detection-api#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/dive-into-football-analytics-with-tensorflow-object-detection-api#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>说到足球，看到一个球队如何能够战胜一个更强大的对手赢得比赛是令人惊讶的。有时，观众可以通过观察队员(他们的能力和实力)来预测比赛的比分。建立一个能够跟踪球场上团队球员的自动化机器学习模型，这样我们就可以预测球员的下一步行动，这难道不是很有趣吗？</p>



<p>为了进一步证明这一点，让我们来看看如何直观地应用对象检测/跟踪等计算机视觉技术来监控足球场上的团队球员。</p>



<p>这部作品的笔记本可以在这里找到<a href="https://web.archive.org/web/20221201165104/https://github.com/elishatofunmi/Computer-Vision/blob/master/football%20analytics/chealsea-mancity-liverpool%20analytics4.ipynb" target="_blank" rel="noreferrer noopener nofollow">。这项工作中实现的所有代码都是在colab上完成的。</a></p>



<p>下面是我们将要研究的内容的概要:</p>



<ol><li>数据来源</li><li>标签</li><li>数据准备(导出为张量流记录)</li><li>模型管道</li><li>建模、培训(和记录)</li><li>模型评估</li><li>结果和结论</li></ol>



<h2 id="h-data-sourcing">数据来源</h2>



<p>为了进行足球分析，需要有算法将从中学习的源数据。在这个项目中，源数据是从这里的<a href="https://web.archive.org/web/20221201165104/https://www.youtube.com/watch?v=EasWagnJvSI" target="_blank" rel="noreferrer noopener nofollow">得到的</a>。这里有一些你需要从比赛中了解的信息。这是一场切尔西(2)对曼城(1)的比赛。这个视频包含了真实足球比赛的精彩部分。切尔西能够在这场比赛中击败曼城，靠的是球员们一些独特的战术。</p>



<p>从视频中提取了152幅图像，并使用下面的代码进行了处理。</p>



<pre class="hljs">vidcap = cv2.VideoCapture(ChelseaManCity)
count = <span class="hljs-number">0</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getFrame</span><span class="hljs-params">(sec)</span>:</span>
   vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*<span class="hljs-number">1000</span>)
   hasFrames,image = vidcap.read()
   <span class="hljs-keyword">if</span> hasFrames:
       cv2.imwrite(<span class="hljs-string">"images/frame"</span>+str(count)+<span class="hljs-string">".jpg"</span>, image)     
   <span class="hljs-keyword">return</span> hasFrames
sec = <span class="hljs-number">2</span>
frameRate = <span class="hljs-number">2</span> 
count=<span class="hljs-number">88</span>
success = getFrame(sec)
<span class="hljs-keyword">while</span> success:
   count = count + <span class="hljs-number">1</span>
   sec = sec + frameRate
   sec = round(sec, <span class="hljs-number">2</span>)
   success = getFrame(sec)
</pre>



<p>生成的图像保存在一个文件夹中。由于目标是能够跟踪足球场上的各种队友(对象)，因此对数据进行标记非常重要，以便算法可以将正确的图像映射到实际目标。</p>



<p>机器学习标记是使算法直观地捕捉数据中呈现的信息的重要步骤。我们总是想把我们的问题作为监督学习问题(让机器从输入数据和目标标签中学习)呈现给一个算法；而不是无监督学习(让机器在输入数据中找出模式，没有目标标签)。</p>



<p>这样做的一个好处是，它减少了太多的计算，增强了学习，也使评估变得容易得多。因为我们正在处理图像数据或视频帧，所以需要利用好的注释工具箱来有效地检测足球场上存在的各种对象。在这个项目中，labelImg被用作标签工具包。</p>



<h2 id="h-labellmg">标签</h2>



<p>Labellmg是一个用于图像处理和注释的开源图形标签工具。本地使用它的源代码可以在<a href="https://web.archive.org/web/20221201165104/https://github.com/tzutalin/labelImg" target="_blank" rel="noreferrer noopener nofollow">这里</a>找到。在足球场上，我们确实有以下这些:</p>



<ol><li>来自两个对手球队的球员(在这种情况下，切尔西和曼城)，</li><li>裁判们，</li><li>守门员们，</li></ol>



<p>从上面可以看出，从视频中提取的152个图像中，我们有4个不同的类别要标记。我们可以训练并使算法跟踪所有4个类别并进行分类。为了简单起见，我决定分成3个类，这样我就有了:</p>



<ol><li>切尔西—0级</li><li>曼城—1级</li><li>裁判和守门员——2级</li></ol>



<p>所以我最后上了3节课。这是因为0级和1级的标签比裁判和守门员的标签多。由于在152帧中，裁判和守门员的标签都没有得到充分的代表，我们可以将他们作为一个单独的类别，称为<strong>‘未知’</strong>。</p>



<p>既然已经正确标记了帧中的所有类，我们可以继续使用名为<strong> efficientDet </strong>的对象检测架构进行建模。请注意，在我们建模之前，我们需要将这些带标签的数据以及生成的xml文件(为每一帧生成的文件，包含图像中每个标签的边界框)转换为TensorFlow记录。</p>







<h2 id="h-data-preparation-exporting-as-tensorflow-records">数据准备(导出为张量流记录)</h2>



<p>既然我们已经能够方便地标记数据，我们可以继续将数据导出为TensorFlow记录。为此，我们将使用roboflow.com平台。你需要做的就是遵循这些步骤:</p>



<ol><li>创建roboflow.com帐户后，继续点击创建数据集。</li><li>填写您的数据集详细信息，上传数据(图像和。xml文件)。确保在为计算机视觉建模选择数据类型时选择对象检测。</li><li>如果需要，您可以继续添加预处理步骤和增强步骤，最后，</li><li>上传后，点击右上角的生成张量流记录。继续选择“生成为代码”，这将为您提供一个链接，供您下载列车数据的张量流记录数据。</li></ol>



<h3><strong>模型管道</strong></h3>



<p>既然我们已经为训练和测试数据导出了张量流记录；下一步是使用EfficientDet建模。在使用EfficientDet建模之前，需要满足模型管道的某些先决条件，包括以下内容:</p>



<ol><li>安装TensorFlow对象检测API。</li><li>设置对象检测架构</li><li>设置配置文件。</li></ol>



<h3>TensorFlow对象检测API的安装</h3>



<p>以下信息和步骤演示了如何在Colab上进行培训时安装TensorFlow 2对象检测API。首先，使用下面的代码在GitHub上克隆TensorFlow模型库:</p>



<pre class="hljs"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> pathlib

<span class="hljs-keyword">if</span> <span class="hljs-string">"models"</span> <span class="hljs-keyword">in</span> pathlib.Path.cwd().parts:
 <span class="hljs-keyword">while</span> <span class="hljs-string">"models"</span> <span class="hljs-keyword">in</span> pathlib.Path.cwd().parts:
   os.chdir(<span class="hljs-string">'..'</span>)
<span class="hljs-keyword">elif</span> <span class="hljs-keyword">not</span> pathlib.Path(<span class="hljs-string">'models'</span>).exists():
 !git clone --depth <span class="hljs-number">1</span> https://github.com/tensorflow/models
</pre>



<p>接下来是使用以下命令安装TensorFlow对象检测API。</p>



<pre class="hljs">
%%bash
cd models/research/
protoc object_detection/protos/*.proto --python_out=.
cp object_detection/packages/tf2/setup.py .
python -m pip install .
</pre>



<p>安装了TensorFlow对象检测API后，下面的代码帮助我们确认已经安装了该API。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> matplotlib
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> io
<span class="hljs-keyword">import</span> imageio
<span class="hljs-keyword">import</span> glob
<span class="hljs-keyword">import</span> scipy.misc
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> six <span class="hljs-keyword">import</span> BytesIO
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image, ImageDraw, ImageFont
<span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> display, Javascript
<span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> Image <span class="hljs-keyword">as</span> IPyImage

<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-keyword">from</span> object_detection.utils <span class="hljs-keyword">import</span> label_map_util
<span class="hljs-keyword">from</span> object_detection.utils <span class="hljs-keyword">import</span> config_util
<span class="hljs-keyword">from</span> object_detection.utils <span class="hljs-keyword">import</span> visualization_utils <span class="hljs-keyword">as</span> viz_utils
<span class="hljs-keyword">from</span> object_detection.utils <span class="hljs-keyword">import</span> colab_utils
<span class="hljs-keyword">from</span> object_detection.builders <span class="hljs-keyword">import</span> model_builder

%matplotlib inline
</pre>



<p>既然API已经正确安装，我们可以继续训练数据，但是在此之前，让我们使用下面的代码构建模型测试器。model tester文件有助于确认任何对象检测问题的正确建模所需的库的安装和导入。为此，请尝试实现下面的代码。</p>



<pre class="hljs">
!python /content/models/research/object_detection/builders/model_builder_tf2_test.py
</pre>



<p>继续建模流程，在导入提议的架构之前，我们可以使用下面的代码从roboflow.com下载tfrecords格式的导出数据。</p>



<p>务必注意，在使用<a href="https://web.archive.org/web/20221201165104/http://roboflow.ai/" target="_blank" rel="noreferrer noopener nofollow">roboflow.com</a>平台生成tfrecords格式的数据时；数据可以导出为链接，下载到Colab中。将导出的链接插入下面的程序并运行，以便将数据下载到Colab中。</p>



<pre class="hljs">

%cd /content
!curl -L <span class="hljs-string">"[insert Link]"</span> &gt; roboflow.zip; unzip roboflow.zip; rm roboflow.zip</pre>



<p>如果你能走到这一步，这是迄今为止完成的伟大工作。在设置配置文件之前，还有一件事，我们需要指定训练和测试数据的目录(这在设置配置文件时是需要的)。</p>



<p>刚刚从roboflow.com下载的训练和测试数据的目录可以在当前目录中找到。您的目录应该如下所示:</p>



<pre class="hljs">train_record_fname = <span class="hljs-string">'/content/train/foot.tfrecord'</span>
test_record_fname = <span class="hljs-string">'/content/test/foot.tfrecord'</span>
label_map_pbtxt_fname = <span class="hljs-string">'/content/train/foot_label_map.pbtxt'</span>
</pre>



<p>恭喜你已经走了这么远，为顺利的训练做好了准备。现在，让我们继续在培训前设置配置文件。</p>







<h3>设置对象检测架构</h3>



<p>对于这个问题，期望的对象检测架构是EfficientDet。该架构有4个变体(D0、D1、D2和D3)。以下代码显示了D0-D3的模型配置，以及它们各自的模型名称和base_pipeline_file(配置文件)。</p>



<pre class="hljs">
MODELS_CONFIG = {
   <span class="hljs-string">'efficientdet-d0'</span>: {
       <span class="hljs-string">'model_name'</span>: <span class="hljs-string">'efficientdet_d0_coco17_tpu-32'</span>,
       <span class="hljs-string">'base_pipeline_file'</span>: <span class="hljs-string">'ssd_efficientdet_d0_512x512_coco17_tpu-8.config'</span>,
       <span class="hljs-string">'pretrained_checkpoint'</span>: <span class="hljs-string">'efficientdet_d0_coco17_tpu-32.tar.gz'</span>,
       <span class="hljs-string">'batch_size'</span>: <span class="hljs-number">16</span>
   },
   <span class="hljs-string">'efficientdet-d1'</span>: {
       <span class="hljs-string">'model_name'</span>: <span class="hljs-string">'efficientdet_d1_coco17_tpu-32'</span>,
       <span class="hljs-string">'base_pipeline_file'</span>: <span class="hljs-string">'ssd_efficientdet_d1_640x640_coco17_tpu-8.config'</span>,
       <span class="hljs-string">'pretrained_checkpoint'</span>: <span class="hljs-string">'efficientdet_d1_coco17_tpu-32.tar.gz'</span>,
       <span class="hljs-string">'batch_size'</span>: <span class="hljs-number">16</span>
   },
   <span class="hljs-string">'efficientdet-d2'</span>: {
       <span class="hljs-string">'model_name'</span>: <span class="hljs-string">'efficientdet_d2_coco17_tpu-32'</span>,
       <span class="hljs-string">'base_pipeline_file'</span>: <span class="hljs-string">'ssd_efficientdet_d2_768x768_coco17_tpu-8.config'</span>,
       <span class="hljs-string">'pretrained_checkpoint'</span>: <span class="hljs-string">'efficientdet_d2_coco17_tpu-32.tar.gz'</span>,
       <span class="hljs-string">'batch_size'</span>: <span class="hljs-number">16</span>
   },
       <span class="hljs-string">'efficientdet-d3'</span>: {
       <span class="hljs-string">'model_name'</span>: <span class="hljs-string">'efficientdet_d3_coco17_tpu-32'</span>,
       <span class="hljs-string">'base_pipeline_file'</span>: <span class="hljs-string">'ssd_efficientdet_d3_896x896_coco17_tpu-32.config'</span>,
       <span class="hljs-string">'pretrained_checkpoint'</span>: <span class="hljs-string">'efficientdet_d3_coco17_tpu-32.tar.gz'</span>,
       <span class="hljs-string">'batch_size'</span>: <span class="hljs-number">16</span>
   }
}
</pre>



<p>在本教程中，我们实现了轻量级、最小的艺术级EfficientDet模型(D0)。扩大到更高效的模型；你将需要更强的计算能力。对于训练，你可以从5000步开始(如果损失函数仍在下降，你可能想增加)。每步的评估次数也设置为500。这意味着，在500步之后执行评估。</p>



<p>下面的代码演示了上面的模型设置。</p>



<pre class="hljs">chosen_model = <span class="hljs-string">'efficientdet-d0'</span>
num_steps = <span class="hljs-number">5000</span> 
num_eval_steps = <span class="hljs-number">500</span> 
model_name = MODELS_CONFIG[chosen_model][<span class="hljs-string">'model_name'</span>]
pretrained_checkpoint = MODELS_CONFIG[chosen_model][<span class="hljs-string">'pretrained_checkpoint'</span>]
base_pipeline_file = MODELS_CONFIG[chosen_model][<span class="hljs-string">'base_pipeline_file'</span>]
batch_size = MODELS_CONFIG[chosen_model][<span class="hljs-string">'batch_size'</span>] 
</pre>



<p>完成这些后，让我们继续下载指定架构的预训练权重，如上面的代码所示(D0、D1、D2和D3)。下面的代码帮助我们做到这一点:</p>



<pre class="hljs">
%mkdir /content/models/research/deploy/
%cd /content/models/research/deploy/
<span class="hljs-keyword">import</span> tarfile
download_tar = <span class="hljs-string">'http://download.tensorflow.org/models/object_detection/tf2/20200711/'</span> + pretrained_checkpoint
!wget {download_tar}
tar = tarfile.open(pretrained_checkpoint)
tar.extractall()
tar.close()
</pre>



<p>让我们继续编写我们的自定义配置文件。</p>



<h3>设置配置文件</h3>



<p>配置文件是表示为. config的文件扩展名。该文件包含成功训练对象检测模型/架构所需的所有信息。这包括以下参数:</p>



<ol><li>训练的步数。</li><li>训练和label_maps数据集的目录。</li><li>微调检查点。</li><li>SSD模型参数，如锚点_生成器、图像_大小调整器、框_预测器、特征_提取器等。</li></ol>



<p>默认情况下，培训所需的每个期望的体系结构都有一个配置文件。那些配置文件中需要更新的是文件检查点、label_map、列车数据(在tfrecords中)和测试数据的目录。</p>



<p>为了实现上述目标，让我们采取以下步骤。首先，让我们使用下面的代码下载定制配置文件。</p>



<pre class="hljs">
%cd /content/models/research/deploy
download_config = <span class="hljs-string">'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/'</span> + base_pipeline_file
!wget {download_config}
</pre>



<p>完成以上工作后，我们可以继续设置管道文件名和模型检查点目录。下面的代码说明了这一点。此外，您可以使用函数get_num_classes确认从label_map_pbtxt文件中提取的类的数量，如下所示。</p>



<pre class="hljs">pipeline_fname = <span class="hljs-string">'/content/models/research/deploy/'</span> + base_pipeline_file
fine_tune_checkpoint = <span class="hljs-string">'/content/models/research/deploy/'</span> + model_name + <span class="hljs-string">'/checkpoint/ckpt-0'</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_num_classes</span><span class="hljs-params">(pbtxt_fname)</span>:</span>
   <span class="hljs-keyword">from</span> object_detection.utils <span class="hljs-keyword">import</span> label_map_util
   label_map = label_map_util.load_labelmap(pbtxt_fname)
   categories = label_map_util.convert_label_map_to_categories(
       label_map, max_num_classes=<span class="hljs-number">90</span>, use_display_name=<span class="hljs-keyword">True</span>)
   category_index = label_map_util.create_category_index(categories)
   <span class="hljs-keyword">return</span> len(category_index.keys())
num_classes = get_num_classes(label_map_pbtxt_fname)
</pre>



<p>对于这个问题，类的数量是3，即:</p>



<ol><li>切尔西-0级</li><li>人-城市-1级</li><li>未知(裁判、守门员和其他)-2级</li></ol>



<p>现在，让我们将以下信息写入自定义配置文件:</p>



<ol><li>列车方向，</li><li>测试方向。</li><li>标签图。</li><li>检查点文件目录。</li></ol>



<p>下面的代码帮助我们读取配置文件并将文件目录写入文件。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> re
%cd /content/models/research/deploy
print(<span class="hljs-string">'writing custom configuration file'</span>)
<span class="hljs-keyword">with</span> open(pipeline_fname) <span class="hljs-keyword">as</span> f:
   s = f.read()
<span class="hljs-keyword">with</span> open(<span class="hljs-string">'pipeline_file.config'</span>, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> f:
   
   s = re.sub(<span class="hljs-string">'fine_tune_checkpoint: ".*?"'</span>,
              <span class="hljs-string">'fine_tune_checkpoint: "{}"'</span>.format(fine_tune_checkpoint), s)
     
   s = re.sub(
       <span class="hljs-string">'(input_path: ".*?)(PATH_TO_BE_CONFIGURED/train)(.*?")'</span>, <span class="hljs-string">'input_path: "{}"'</span>.format(train_record_fname), s)
   s = re.sub(
       <span class="hljs-string">'(input_path: ".*?)(PATH_TO_BE_CONFIGURED/val)(.*?")'</span>, <span class="hljs-string">'input_path: "{}"'</span>.format(test_record_fname), s)
   
   s = re.sub(
       <span class="hljs-string">'label_map_path: ".*?"'</span>, <span class="hljs-string">'label_map_path: "{}"'</span>.format(label_map_pbtxt_fname), s)
   
   s = re.sub(<span class="hljs-string">'batch_size: [0-9]+'</span>,
              <span class="hljs-string">'batch_size: {}'</span>.format(batch_size), s)

   
   s = re.sub(<span class="hljs-string">'num_steps: [0-9]+'</span>,
              <span class="hljs-string">'num_steps: {}'</span>.format(num_steps), s)
   
   s = re.sub(<span class="hljs-string">'num_classes: [0-9]+'</span>,
              <span class="hljs-string">'num_classes: {}'</span>.format(num_classes), s)
     
   s = re.sub(
       <span class="hljs-string">'fine_tune_checkpoint_type: "classification"'</span>, <span class="hljs-string">'fine_tune_checkpoint_type: "{}"'</span>.format(<span class="hljs-string">'detection'</span>), s)

   f.write(s)
</pre>



<p>您可以通过运行下面的代码来确认dir已被写入文件:</p>



<pre class="hljs">%cat /content/models/research/deploy/pipeline_file.config
</pre>



<p>现在我们有了一个配置文件，让我们开始训练吧。但是在训练之前，让我们记下配置文件的目录以及保存所有训练参数的目录。它们应该是这样的:</p>



<pre class="hljs">pipeline_file = <span class="hljs-string">'/content/models/research/deploy/pipeline_file.config'</span>
model_dir = <span class="hljs-string">'/content/training/'</span>
</pre>







<h2 id="h-modelling-and-training">建模和培训</h2>



<p>在所有条件都相同的情况下，我们可以通过运行model_main_tf2.py文件来训练数据。此文件用于运行与TensorFlow 2相关的任何对象检测问题。要成功运行，您只需指定以下内容:</p>



<ol><li>管道配置路径。</li><li>型号目录。</li><li>训练步骤数。</li><li>评估步骤数。</li></ol>



<p>下面的代码帮助我们做到这一点。</p>



<pre class="hljs">!python /content/models/research/object_detection/model_main_tf2.py
   --pipeline_config_path={pipeline_file}
   --model_dir={model_dir}
   --alsologtostderr
   --num_train_steps={num_steps}
   --sample_1_of_n_eval_examples=<span class="hljs-number">1</span>
   --num_eval_steps={num_eval_steps}</pre>



<p>这样做了之后，我不得不通过改变训练步数来不断地跑，直到我得到想要的结果。在完成20000步训练后，当我确信我的训练不再减少时，我不得不停止。这需要大约5-6个小时的培训。</p>



<p>经过这么长时间的训练，这里有一个张量板来说明学习速度。</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/b51600356eb8e5d82e028136c95638f3.png" alt="football tensorboard training" class="wp-image-30879" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165104im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/football-tensorboard-training.png?ssl=1"/></figure>



<p>让我们通过运行这段代码来导出模型的训练推理图。</p>



<pre class="hljs">
%ls <span class="hljs-string">'/content/training/'</span>
</pre>



<p>下一步是运行一个转换脚本，导出模型参数作为推理，以便在实时预测需要时重新加载。</p>



<pre class="hljs">
<span class="hljs-keyword">import</span> re
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
output_directory = <span class="hljs-string">'/content/fine_tuned_model'</span>

last_model_path = <span class="hljs-string">'/content/training/'</span>
print(last_model_path)
!python /content/models/research/object_detection/exporter_main_v2.py
   --trained_checkpoint_dir {last_model_path}
   --output_directory {output_directory}
   --pipeline_config_path {pipeline_file}
</pre>



<h3><strong>模型评估</strong></h3>



<p>要评估该模型，需要实施以下步骤:</p>



<ol><li>训练后加载最后一个模型检查点。</li><li>读入视频帧。</li><li>识别每个帧中的对象(边界框和精确度)。</li><li>将视频帧转换为视频。</li></ol>



<p>若要在训练后加载最后一个模型检查点，请运行以下代码:</p>



<pre class="hljs">
pipeline_config = pipeline_file

model_dir = <span class="hljs-string">'/content/training/ckpt-6'</span>
configs = config_util.get_configs_from_pipeline_file(pipeline_config)
model_config = configs[<span class="hljs-string">'model'</span>]
detection_model = model_builder.build(
     model_config=model_config, is_training=<span class="hljs-keyword">False</span>)


ckpt = tf.compat.v2.train.Checkpoint(
     model=detection_model)
ckpt.restore(os.path.join(<span class="hljs-string">'/content/training/ckpt-6'</span>))


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_model_detection_function</span><span class="hljs-params">(model)</span>:</span>
 <span class="hljs-string">"""Get a tf.function for detection."""</span>

<span class="hljs-meta"> @tf.function</span>
 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">detect_fn</span><span class="hljs-params">(image)</span>:</span>
   <span class="hljs-string">"""Detect objects in image."""</span>

   image, shapes = model.preprocess(image)
   prediction_dict = model.predict(image, shapes)
   detections = model.postprocess(prediction_dict, shapes)

   <span class="hljs-keyword">return</span> detections, prediction_dict, tf.reshape(shapes, [<span class="hljs-number">-1</span>])

 <span class="hljs-keyword">return</span> detect_fn

detect_fn = get_model_detection_function(detection_model)
</pre>



<p>下一步是读入视频帧，并将其通过对象检测模型进行边界框识别和正确类别的预测。下面的代码帮助我们方便地做到这一点:</p>



<pre class="hljs">
label_map_path = configs[<span class="hljs-string">'eval_input_config'</span>].label_map_path
label_map = label_map_util.load_labelmap(label_map_path)
categories = label_map_util.convert_label_map_to_categories(
   label_map,
   max_num_classes=label_map_util.get_max_label_map_index(label_map),
   use_display_name=<span class="hljs-keyword">True</span>)
category_index = label_map_util.create_category_index(categories)
label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=<span class="hljs-keyword">True</span>)

<span class="hljs-keyword">import</span> random

TEST_IMAGE_PATHS = glob.glob(<span class="hljs-string">'/content/test/*.jpg'</span>)
image_path = random.choice(TEST_IMAGE_PATHS)
image_np = load_image_into_numpy_array(image_path)


input_tensor = tf.convert_to_tensor(
   np.expand_dims(image_np, <span class="hljs-number">0</span>), dtype=tf.float32)
detections, predictions_dict, shapes = detect_fn(input_tensor)

label_id_offset = <span class="hljs-number">1</span>
image_np_with_detections = image_np.copy()

viz_utils.visualize_boxes_and_labels_on_image_array(
     image_np_with_detections,
     detections[<span class="hljs-string">'detection_boxes'</span>][<span class="hljs-number">0</span>].numpy(),
     (detections[<span class="hljs-string">'detection_classes'</span>][<span class="hljs-number">0</span>].numpy() + label_id_offset).astype(int),
     detections[<span class="hljs-string">'detection_scores'</span>][<span class="hljs-number">0</span>].numpy(),
     category_index,
     use_normalized_coordinates=<span class="hljs-keyword">True</span>,
     max_boxes_to_draw=<span class="hljs-number">200</span>,
     min_score_thresh=<span class="hljs-number">.5</span>,
     agnostic_mode=<span class="hljs-keyword">False</span>,
)
</pre>







<h2 id="h-result-and-conclusion">结果和结论</h2>



<p>成功完成上述所有过程后，该模型能够识别来自同一支球队的球员，并将球场上的人归类为另一个称为“未知”的类别，即裁判或中场休息时来自支持队的人。下面是一个完整的视频演示对象检测架构的行动视频帧。</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><p class="wp-block-embed__wrapper"><iframe loading="lazy" title="Real time computer vision for football analytics - Chelsea 2-1 Manchester City" src="https://web.archive.org/web/20221201165104if_/https://www.youtube.com/embed/NiBL6K3jiJM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">视频</iframe></p></figure>



<p>总之，计算机视觉作为一个深度学习领域，在足球分析中有着可行的应用。可以做的更多事情包括:</p>



<ol><li>球跟踪，</li><li>用计算机视觉分析场上球员的情绪，</li><li>预测下一个接球的球员的强化学习，等等。</li></ol>



<p>如果这篇文章有助于你详细了解计算机视觉，请与朋友分享。感谢阅读！</p>



<h2 id="h-references">参考</h2>



<ol><li><a href="https://web.archive.org/web/20221201165104/http://roboflow.ai/" target="_blank" rel="noreferrer noopener nofollow">roboflow.com</a></li><li><a href="https://web.archive.org/web/20221201165104/https://heartbeat.fritz.ai/end-to-end-object-detection-using-efficientdet-on-raspberry-pi-3-part-2-bb5133646630" target="_blank" rel="noreferrer noopener nofollow">heart beat . fritz . ai/end-to-end-object-detection-using-efficient det-on-raspberry-pi-3-part-2-bb 5133646630</a></li><li><a href="https://web.archive.org/web/20221201165104/https://github.com/tzutalin/labelImg" target="_blank" rel="noreferrer noopener nofollow">github.com/tzutalin/labelImg</a></li><li><a href="https://web.archive.org/web/20221201165104/https://medium.com/@iKhushPatel/convert-video-to-images-images-to-video-using-opencv-python-db27a128a481" target="_blank" rel="noreferrer noopener nofollow">medium . com/@ iKhushPatel/convert-video-to-images-images-to-video-using-opencv-python-db27a 128 a 481</a></li><li><a href="https://web.archive.org/web/20221201165104/https://github.com/microsoft/VoTT" target="_blank" rel="noreferrer noopener nofollow">github.com/microsoft/VoTT</a></li><li><a href="https://web.archive.org/web/20221201165104/https://cvat.org/" target="_blank" rel="noreferrer noopener nofollow">cvat.org</a></li></ol>
        </div>
        
    </div>    
</body>
</html>