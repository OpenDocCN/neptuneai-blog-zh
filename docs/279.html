<html>
<head>
<title>Data Augmentation in Python: Everything You Need to Know </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Python中的数据扩充:您需要知道的一切</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/data-augmentation-in-python#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/data-augmentation-in-python#0001-01-01</a></blockquote><div><div class="article__content col-lg-10">
<p>在机器学习(<strong> ML </strong>)中，模型没有很好地从训练数据泛化到看不见的数据的情况被称为<strong>过拟合</strong>。你可能知道，这是应用机器学习中最棘手的障碍之一。</p>



<p>解决这个问题的第一步是真正知道你的模型<strong>过度拟合<em>。</em> </strong>这就是正确的<a href="/web/20220928201835/https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right" target="_blank" rel="noreferrer noopener">交叉验证</a>的用武之地。</p>



<p>识别问题后，您可以通过应用正则化或使用更多数据进行训练来防止问题发生。尽管如此，有时您可能没有额外的数据添加到您的初始数据集。获取和标记额外的数据点也可能是错误的途径。当然，在很多情况下，会有更好的效果，但在工作方面，往往费时费钱。</p>



<p>这就是<a href="https://web.archive.org/web/20220928201835/https://www.techopedia.com/definition/28033/data-augmentation" target="_blank" rel="noreferrer noopener nofollow"> <strong>数据增强</strong> </a> ( <strong> DA </strong>)的用武之地。</p>


<div class="table-of-contents">
        <h2>在本文中，我们将涵盖:</h2>
        
</div>


<h2 id="definition">什么是数据增强？</h2>



<p><strong>数据扩充</strong>是一种技术，可用于通过从现有数据创建修改后的数据来人为扩大训练集的规模。如果您想要防止<strong>过度拟合</strong>，或者初始数据集太小而无法训练，或者甚至您想要从您的模型中获得更好的性能，那么使用<strong> DA </strong>是一个很好的实践。</p>



<p>让我们明确一点，<strong>数据扩充</strong>不仅仅是用来防止<strong>过拟合</strong>。一般来说，拥有大型数据集对于<strong> ML </strong>和<strong>深度学习</strong> ( <strong> DL </strong>)模型的性能都至关重要。然而，我们可以通过增加现有的数据来提高模型的性能。这意味着<strong>数据扩充</strong>也有利于增强模型的性能。<br/> <br/>一般情况下，在建立<strong> DL </strong>模型时，经常使用<strong> DA </strong>。这就是为什么在整篇文章中，我们将主要讨论用各种<strong> DL </strong>框架来执行<strong>数据扩充</strong>。不过，你应该记住，你也可以为<strong> ML </strong>问题扩充数据。</p>



<p>您可以增加:</p>


<div class="custom-point-list">
<ol><li>声音的</li><li>文本</li><li>形象</li><li>任何其他类型的数据</li></ol>
</div>


<p>我们将重点放在图像增强，因为这些是最受欢迎的。尽管如此，增加其他类型的数据也同样有效和容易。这就是为什么最好记住一些可以用来扩充数据的常用技术。</p>



<h3>数据扩充技术</h3>



<p>我们可以对原始数据进行各种修改。例如，对于图像，我们可以使用:</p>


<div class="custom-point-list">
<ol><li><strong>几何变换</strong>–你可以随意翻转、裁剪、旋转或平移图像，而这只是冰山一角</li><li><strong>颜色空间转换</strong>–改变RGB颜色通道，增强任何颜色</li><li><strong>内核过滤器</strong>–锐化或模糊图像</li><li><strong>随机擦除</strong>–删除初始图像的一部分</li><li><strong>混合图像</strong>–基本上，将图像彼此混合。可能违反直觉，但它确实有效</li></ol>
</div>


<p>对于文本，有:</p>


<div class="custom-point-list">
<ol><li><strong>单词/句子混排</strong></li><li><strong>单词替换</strong>–用同义词替换单词</li><li><strong>语法树操作</strong>–使用相同的单词解释句子，使其语法正确</li><li>关于NLP 中的<a href="/web/20220928201835/https://neptune.ai/blog/data-augmentation-nlp" target="_blank" rel="noreferrer noopener">数据增强的其他描述</a></li></ol>
</div>


<p>对于音频增强，您可以使用:</p>


<div class="custom-point-list">
<ol><li><strong>噪声注入</strong></li><li><strong>换挡</strong></li><li><strong>改变磁带的速度</strong></li><li>还有更多</li></ol>
</div>


<p>此外，增强技术的最大优势是你可以一次使用所有这些技术。因此，您可能会从最初的样本中获得大量独特的数据样本。</p>





<h2 id="deep-learning">深度学习中的数据增强</h2>



<p>上面提到的<a href="https://web.archive.org/web/20220928201835/https://towardsdatascience.com/data-augmentation-for-deep-learning-4fe21d1a4eb9" target="_blank" rel="noreferrer noopener nofollow"> <strong>深度学习，</strong> <strong>数据增强</strong> </a>是常见的做法。因此，每个DL框架都有自己的增强方法，甚至是一个完整的库。例如，让我们看看如何使用TensorFlow (TF)和Keras、PyTorch和<strong> MxNet </strong>中的内置方法来应用图像增强。<br/></p>





<h3>TensorFlow和Keras中的数据扩充</h3>



<p>当使用<strong> TensorFlow </strong>或<strong> Keras </strong>作为我们的<strong> DL </strong>框架时，我们可以:</p>


<div class="custom-point-list">
<ul><li>使用<strong> tf.image </strong>编写我们自己的增强管道或层。</li><li>使用<strong> Keras </strong>预处理层</li><li>使用<strong>图像数据生成器</strong></li></ul>
</div>


<h4>Tf .图像</h4>



<p>让我们更仔细地看看第一种技术，定义一个可视化图像的函数，然后使用<strong> tf.image </strong>将翻转应用于该图像。您可以在下面看到代码和结果。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">visualize</span><span class="hljs-params">(original, augmented)</span>:</span>
    fig = plt.figure()
    plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)
    plt.title(<span class="hljs-string">'Original image'</span>)
    plt.imshow(original)

    plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)
    plt.title(<span class="hljs-string">'Augmented image'</span>)
    plt.imshow(augmented)
    flipped = tf.image.flip_left_right(image)
    visualize(image, flipped)</pre>







<p>为了更好的控制，你可以写你自己的增强管道。在大多数情况下，对整个数据集而不是单个图像应用增强是有用的。您可以如下实现它。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> tensorflow_datasets <span class="hljs-keyword">as</span> tfds 

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">augment</span><span class="hljs-params">(image, label)</span>:</span>
  image = tf.cast(image, tf.float32)
  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
  image = (image / <span class="hljs-number">255.0</span>)
  image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, <span class="hljs-number">3</span>])
  image = tf.image.random_brightness(image, max_delta=<span class="hljs-number">0.5</span>)
  <span class="hljs-keyword">return</span> image, label

(train_ds, val_ds, test_ds), metadata = tfds.load(
    <span class="hljs-string">'tf_flowers'</span>,
     split=[<span class="hljs-string">'train[:80%]'</span>, <span class="hljs-string">'train[80%:90%]'</span>, <span class="hljs-string">'train[90%:]'</span>],
     with_info=<span class="hljs-keyword">True</span>,
     as_supervised=<span class="hljs-keyword">True</span>,)

train_ds = train_ds
            .shuffle(<span class="hljs-number">1000</span>)
            .map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)
            .batch(batch_size)
            .prefetch(AUTOTUNE)</pre>



<p>当然，这只是冰山一角。<strong> TensorFlow </strong> API有大量的增强技术。如果你想了解更多关于这个话题的内容，请查看<a href="https://web.archive.org/web/20220928201835/https://www.tensorflow.org/tutorials/images/data_augmentation?hl=en" target="_blank" rel="noreferrer noopener nofollow">官方文件</a>或<a href="https://web.archive.org/web/20220928201835/https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/" target="_blank" rel="noreferrer noopener nofollow">其他文章</a>。</p>



<h4>Keras预处理</h4>



<p>如上所述，<strong> Keras </strong>有多种预处理层，可用于<strong>数据扩充</strong>。您可以按如下方式应用它们。</p>



<pre class="hljs">data_augmentation = tf.keras.Sequential([
     layers.experimental.preprocessing.RandomFlip(<span class="hljs-string">"horizontal_and_vertical"</span>),
     layers.experimental.preprocessing.RandomRotation(<span class="hljs-number">0.2</span>)])

image = tf.expand_dims(image, <span class="hljs-number">0</span>)
plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>))

<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">9</span>):
  augmented_image = data_augmentation(image)
  ax = plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, i + <span class="hljs-number">1</span>)
  plt.imshow(augmented_image[<span class="hljs-number">0</span>])
  plt.axis(<span class="hljs-string">"off"</span>)</pre>







<h4>Keras ImageDataGenerator</h4>



<p>此外，您可以使用<strong>imagedata generator</strong>(<strong>TF . keras . preprocessing . image . image data generator</strong>)，它可以使用实时<strong> DA </strong>生成批量张量图像。</p>



<pre class="hljs">datagen = ImageDataGenerator(rotation_range=<span class="hljs-number">90</span>)
datagen.fit(x_train)


<span class="hljs-keyword">for</span> X_batch, y_batch <span class="hljs-keyword">in</span> datagen.flow(x_train, y_train, batch_size=<span class="hljs-number">9</span>):
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, <span class="hljs-number">9</span>):
        pyplot.subplot(<span class="hljs-number">330</span> + <span class="hljs-number">1</span> + i)
        pyplot.imshow(X_batch[i].reshape(img_rows, img_cols, <span class="hljs-number">3</span>))
        pyplot.show()
    <span class="hljs-keyword">break</span>
</pre>












<h3>PyTorch和MxNet中的数据扩充</h3>



<h4>Pytorch中的变换</h4>



<p><strong> Transforms </strong> library是<strong> torchvision </strong>包的增强部分，该包由流行的数据集、模型架构和用于<strong>计算机视觉</strong>任务的常见图像转换组成。</p>



<p>要安装<strong>转换</strong>你只需要安装<strong>火炬视觉</strong>:</p>



<pre class="hljs">pip3 install torch torchvision
</pre>



<p><strong>转换</strong>库包含不同的图像转换，可以使用<strong>合成</strong>方法将它们链接在一起。在功能上，<strong> Transforms实现了多种增强技术</strong>。你可以通过使用<strong> Compose </strong>方法来组合它们。只需查看官方文档<a href="https://web.archive.org/web/20220928201835/https://pytorch.org/docs/stable/torchvision/transforms.html" target="_blank" rel="noreferrer noopener nofollow">就能找到任务的增强功能。</a></p>



<p>此外，还有<strong>torch vision . transforms . functional</strong>模块。它有各种功能转换，可以对转换进行细粒度的控制。如果您正在构建一个更复杂的增强管道，例如，在分段任务的情况下，这可能会非常有用。</p>



<p>除此之外，<strong>变换</strong>并没有什么独特的特性。它主要与<strong> PyTorch </strong>一起使用，因为它被认为是一个内置的增强库。</p>



<div id="blog-cta-intext-block_618e44e1035d0" class="blog-cta-intext">
  <h3 class="blog-cta-intext__title">更多关于PYTORCH闪电</h3>
  
  </div>


<p><strong>py torch变换的示例用法</strong></p>



<p>让我们看看如何使用<strong>变换</strong>来应用增强。你应该记住，<strong>变换</strong>只适用于<strong> PIL </strong>的图像。这就是为什么你要么阅读PIL格式的图像，要么对你的增强管道进行必要的转换。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms <span class="hljs-keyword">as</span> tr
<span class="hljs-keyword">from</span> torchvision.transfroms <span class="hljs-keyword">import</span> Compose

pipeline = Compose(
             [tr.RandomRotation(degrees = <span class="hljs-number">90</span>),
              tr.RandomRotation(degrees = <span class="hljs-number">270</span>)])

augmented_image = pipeline(img = img)</pre>



<p>有时你可能想为训练编写一个定制的<strong>数据加载器</strong>。让我们看看如何通过<strong>变换</strong>来应用增强，如果你这样做的话。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms
<span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Compose <span class="hljs-keyword">as</span> C

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">aug</span><span class="hljs-params">(p=<span class="hljs-number">0.5</span>)</span>:</span>
    <span class="hljs-keyword">return</span> C([transforms.RandomHorizontalFlip()], p=p)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Dataloader</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, train, csv, transform=None)</span>:</span>
        ...

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self, index)</span>:</span>
        ...
        img = aug()(**{<span class="hljs-string">'image'</span>: img})[<span class="hljs-string">'image'</span>]
        <span class="hljs-keyword">return</span> img, target

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">return</span> len(self.image_list)

trainset = Dataloader(train=<span class="hljs-keyword">True</span>, csv=<span class="hljs-string">'/path/to/file/'</span>, transform=aug)</pre>



<h4>MxNet中的转换</h4>



<p><strong> Mxnet </strong>还有一个内置的增强库叫做<strong>Transforms</strong>(<strong>Mxnet . gluon . data . vision . Transforms</strong>)。它非常类似于<strong> PyTorch转换</strong>库。几乎没有什么可补充的。如果您想找到关于这个主题的更多信息，请查看上面的<strong>转换</strong>部分。一般用法如下。</p>



<p><strong>MxNet转换的示例用法</strong></p>



<pre class="hljs">color_aug = transforms.RandomColorJitter(
                               brightness=<span class="hljs-number">0.5</span>,
                               contrast=<span class="hljs-number">0.5</span>,
                               saturation=<span class="hljs-number">0.5</span>,
                               hue=<span class="hljs-number">0.5</span>)
apply(example_image, color_aug)</pre>







<p>这些都是很好的例子，但是从我的经验来看，当您使用定制库时，<strong>数据扩充</strong>的真正威力就会显现出来:</p>


<div class="custom-point-list">
<ul><li>他们有更广泛的转换方法</li><li>它们允许您创建自定义增强</li><li>您可以将一个转换与另一个堆叠在一起。</li></ul>
</div>


<p>这就是为什么使用定制的<strong> DA </strong>库可能比使用内置库更有效。</p>





<h2 id="libraries">图像数据增强库</h2>



<p>在本节中，我们将讨论以下库:</p>


<div class="custom-point-list">
<ol><li>奥吉</li><li><strong>白蛋白</strong></li><li><strong>伊姆高格</strong></li><li><strong>自动增强(DeepAugment) </strong></li></ol>
</div>


<p>我们将查看安装、增强功能、增强过程并行化、自定义增强，并提供一个简单的示例。请记住，我们将侧重于图像增强，因为它是最常用的。</p>



<p>在我们开始之前，我有一些关于在不同的<strong> DL </strong>框架中使用定制增强库的一般说明。</p>



<p>一般来说，如果您在训练模型之前执行扩充，所有的库都可以用于所有的框架。<br/> <br/>重点是有些库和特定框架有预存的协同，比如<strong>albuminations</strong>和<strong> Pytorch </strong>。用这样的对子更方便。不过，如果您需要特定的函数或者您喜欢一个库胜过另一个库，您应该在开始训练模型之前执行<strong> DA </strong>，或者编写一个定制的数据加载器和训练过程。</p>



<p>第二个主题是在不同的增强库中使用定制的增强。例如，您想使用自己的CV2图像转换，并从<strong>albuminations</strong>库中进行特定的增强。</p>



<p>让我们弄清楚这一点，你可以对任何库这样做，但它可能比你想象的更复杂。一些图书馆在他们的官方文档中有如何做的指南，但是其他的没有。</p>



<p>如果没有向导，你基本上有两种方法:</p>


<div class="custom-point-list">
<ul><li>分别应用增强，例如，使用转换操作，然后使用管道。</li><li>检查一下Github 仓库，以防有人已经想出如何正确地将定制增强集成到管道中。</li></ul>
</div>


<p>好了，现在我们开始吧。</p>





<h3>奥吉先生</h3>



<p>继续谈库，<strong> Augmentor </strong>是一个Python包，它的目标是既是一个<strong>数据扩充</strong>工具，又是一个基本图像预处理函数库。</p>



<p>通过pip安装<strong>增强器</strong>非常容易:</p>



<pre class="hljs">pip install Augmentor</pre>



<p>如果你想从源代码编译这个包，请查阅<a href="https://web.archive.org/web/20220928201835/https://augmentor.readthedocs.io/en/master/userguide/install.html" target="_blank" rel="noreferrer noopener nofollow">官方文档</a>。</p>



<p>一般来说，<strong>增强器</strong>由许多标准图像变换函数的类组成，比如<strong>裁剪</strong>、<strong>旋转</strong>、<strong>翻转</strong>等等。</p>



<p><strong>增强器</strong>允许用户为每个变换操作选择一个概率参数。此参数控制操作的应用频率。因此，<strong>增强器</strong>允许形成一个增强管道，将大量随机应用的操作链接在一起。</p>



<p>这意味着每次图像通过管道时，都会返回完全不同的图像。根据流水线中的操作数量和概率参数，可以创建非常大量的新图像数据。基本上，这是最好的数据扩充。</p>



<p>使用<strong>增强器</strong>我们可以对图像做什么？<strong>增强器</strong>更侧重于<strong>几何变换</strong>虽然它也有其他增强。<strong>增强器</strong>组件的主要特点是:</p>


<div class="custom-point-list">
<ol><li><strong>透视倾斜</strong>–从不同的角度观看图像</li><li><strong>弹性变形</strong>–给图像添加变形</li><li><strong>旋转</strong>–简单地说，旋转图像</li><li><strong>剪切</strong>–沿着图像的一边倾斜图像</li><li><strong>裁剪</strong>–裁剪图像</li><li><strong>镜像</strong>–应用不同类型的翻转</li></ol>
</div>


<p><strong> Augmentor </strong>是一个组织严密的库。您可以将它与各种<strong> DL </strong>框架(<strong> TF、Keras、PyTorch、MxNet </strong>)一起使用，因为增强甚至可以在您建立模型之前应用。</p>



<p>此外，<strong>增强器</strong>允许您添加自定义增强。这可能有点棘手，因为它需要<a href="https://web.archive.org/web/20220928201835/https://augmentor.readthedocs.io/en/master/userguide/extend.html">编写</a>一个新的操作类，但是你可以做到。</p>



<p>不幸的是，Augmentor<strong>在功能上既不非常快也不灵活</strong>。有一些库提供了更多的转换函数，可以更快更有效地执行<strong> DA </strong>。这就是为什么<strong>增强器</strong>可能是最不受欢迎的<strong> DA </strong>库。</p>



<p><strong>增强器使用示例</strong></p>



<p>让我们检查一下<strong>增强器</strong>的简单用法:</p>


<div class="custom-point-list">
<ol><li>我们需要导入它。</li><li>我们创建一个空的扩充管道。</li><li>在那里添加一些操作</li><li>使用<strong>采样</strong>方法获得增强图像。</li></ol>
</div>


<p>请注意，当使用<strong>样本</strong>时，您需要指定您想要获得的增强图像的数量。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> Augmentor

p = Augmentor.Pipeline(<span class="hljs-string">"/path/to/images"</span>)
p.rotate(probability=<span class="hljs-number">0.7</span>, max_left_rotation=<span class="hljs-number">10</span>, max_right_rotation=<span class="hljs-number">10</span>)
p.zoom(probability=<span class="hljs-number">0.3</span>, min_factor=<span class="hljs-number">1.1</span>, max_factor=<span class="hljs-number">1.6</span>)
p.sample(<span class="hljs-number">10000</span>)</pre>





<h3>白蛋白</h3>



<p><strong>albuminations</strong>是一款计算机视觉工具，旨在执行快速灵活的图像放大。它似乎拥有所有图像增强库中最大的转换函数集。</p>



<p>让我们通过pip安装<strong>相册</strong>。如果你想以其他方式做这件事，检查官方文件。</p>



<pre class="hljs">pip install albumentations
</pre>



<p><strong>albuminations</strong>提供了一个简单的界面来处理不同的计算机视觉任务，如分类、分割、对象检测、姿态估计等。该库为最大速度和性能进行了<strong>优化，拥有大量不同的图像转换操作。</strong></p>



<p>如果我们谈论的是数据扩充，那么没有什么是<strong>白蛋白</strong>不能做的。说实话，<strong>albuminations</strong>是堆栈最多的库，因为它没有专注于图像转换的某个特定领域。你可以简单地检查官方文档，你会找到一个你需要的操作。</p>



<p>而且，<strong>albuminations</strong>与深度学习框架如<strong> PyTorch </strong>和<strong> Keras </strong>无缝集成。这个库是PyTorch生态系统的一部分，但是你也可以和TensorFlow一起使用。因此，<strong>albuminations</strong>是最常用的图像增强库。</p>



<p>另一方面，<strong>albuminations</strong>没有与<strong> MxNet </strong>集成，这意味着如果你使用<strong> MxNet </strong>作为<strong> DL </strong>框架，你应该编写一个定制的数据加载器或者使用另一个增强库。</p>



<p><br/>值得一提的是<strong>albuminations</strong>是一个开源库。如果你愿意，你可以很容易地检查原始的<a href="https://web.archive.org/web/20220928201835/https://github.com/albumentations-team/albumentations#benchmarking-results">代码</a>。</p>



<p><strong>白蛋白使用示例</strong></p>



<p>让我们看看如何使用<strong>相册</strong>来放大图像。您需要使用<strong> Compose </strong>方法定义管道(或者您可以使用单个增强)，向其传递一个图像，并获得增强的图像。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> albumentations <span class="hljs-keyword">as</span> A
<span class="hljs-keyword">import</span> cv2

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">visualize</span><span class="hljs-params">(image)</span>:</span>
    plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>))
    plt.axis(<span class="hljs-string">'off'</span>)
    plt.imshow(image)

image = cv2.imread(<span class="hljs-string">'/path/to/image'</span>)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

transform = A.Compose(
    [A.CLAHE(),
     A.RandomRotate90(),
     A.Transpose(),
     A.ShiftScaleRotate(shift_limit=<span class="hljs-number">0.0625</span>, scale_limit=<span class="hljs-number">0.50</span>,
                        rotate_limit=<span class="hljs-number">45</span>, p=<span class="hljs-number">.75</span>),
     A.Blur(blur_limit=<span class="hljs-number">3</span>),
     A.OpticalDistortion(),
     A.GridDistortion(),
     A.HueSaturationValue()])

augmented_image = transform(image=image)[<span class="hljs-string">'image'</span>]
visualize(augmented_image)
</pre>









<h3>伊姆高格</h3>



<p>现在，在阅读了<strong>增强器</strong>和<strong>相册</strong>之后，你可能会认为所有的图像增强库彼此都非常相似。</p>



<p>没错。在许多情况下，每个库的功能是可以互换的。然而，每一个都有自己的主要特点。</p>



<p>ImgAug也是一个图像增强库。它在功能上与增强器和缓冲区非常相似，但是官方文档中提到的主要特性是T4在多个CPU内核上执行增强的能力。如果你想这样做，你可能想检查下面的<a href="https://web.archive.org/web/20220928201835/https://nbviewer.jupyter.org/github/aleju/imgaug-doc/blob/master/notebooks/A03%20-%20Multicore%20Augmentation.ipynb" target="_blank" rel="noreferrer noopener nofollow">指南</a>。</p>



<p>正如你所看到的，这与<strong>增强师专注于几何</strong>变换或<strong> <em>融合</em> </strong> <strong>试图覆盖所有可能的增强</strong>截然不同。</p>



<p>然而，<strong> ImgAug的</strong>关键特性似乎有点奇怪，因为<strong>增强器</strong>和<strong>缓冲</strong>也可以在多个CPU内核上执行。总之<strong> ImgAug </strong>支持广泛的增强技术，就像白蛋白一样，并通过细粒度控制实现复杂的增强。</p>



<p><br/> <strong> ImgAug </strong>可通过pip或<a href="https://web.archive.org/web/20220928201835/https://imgaug.readthedocs.io/en/latest/source/installation.html" target="_blank" rel="noreferrer noopener nofollow"> conda </a>轻松安装。</p>



<pre class="hljs">pip install imgaug
</pre>



<p><strong>img aug的使用示例</strong></p>



<p>与其他图像增强库<strong> <em>，</em> ImgAug </strong>一样，使用起来也很方便。要定义一个扩充管道，使用<strong>顺序</strong>方法，然后像在其他库中一样简单地堆叠不同的转换操作。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> imgaug <span class="hljs-keyword">import</span> augmenters <span class="hljs-keyword">as</span> iaa

seq = iaa.Sequential([
    		iaa.Crop(px=(<span class="hljs-number">0</span>, <span class="hljs-number">16</span>)),
    		iaa.Fliplr(<span class="hljs-number">0.5</span>),
    		iaa.GaussianBlur(sigma=(<span class="hljs-number">0</span>, <span class="hljs-number">3.0</span>))])

<span class="hljs-keyword">for</span> batch_idx <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):
    		images = load_batch(batch_idx)
    		images_aug = seq(images=images)
</pre>





<h3>自动增强</h3>



<p>另一方面，自动增强更有趣。你可能知道，用<strong>机器学习</strong> ( <strong> ML </strong>)来提高<strong> ML </strong>的设计选择，已经到了<strong> DA </strong>的空间。</p>



<p>2018年，谷歌推出了自动增强<strong> </strong>算法，该算法是<strong>设计的，用于搜索最佳增强</strong>策略。<strong>自动增强帮助提高了最先进的模型在数据集上的性能</strong>，如<strong> CIFAR-10、CIFAR-100、ImageNet </strong>等。</p>



<p>然而，<strong> AutoAugment使用起来很棘手，因为它没有提供控制器模块，这阻止了用户为自己的数据集运行它。这就是为什么只有当我们计划训练的数据集和我们要完成的任务已经有了增强策略时，使用自动增强才是有意义的。</strong></p>



<p>因此，让我们更仔细地看看<strong> DeepAugment </strong>，它比<strong>自动增强</strong>更快、更灵活。<strong> DeepAugment </strong>与<strong> AutoAugment </strong>除了一般的想法之外没有什么强有力的联系，是由一群爱好者开发的。您可以通过pip安装它:</p>



<pre class="hljs">pip install deepaugment
</pre>



<p>知道如何使用<strong> DeepAugment </strong>为我们的图像获得最佳的增强策略对我们来说很重要。你可以按照下面的方法来做，或者查看<a href="https://web.archive.org/web/20220928201835/https://github.com/barisozmen/deepaugment" target="_blank" rel="noreferrer noopener nofollow">官方的Github库</a>。</p>



<p>请记住，<strong>当您使用优化方法时，您应该指定用于找到最佳增强策略的样本数量</strong>。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> deepaugment.deepaugment <span class="hljs-keyword">import</span> DeepAugment

deepaug = DeepAugment(my_images, my_labels)
best_policies = deepaug.optimize(<span class="hljs-number">300</span>)
</pre>



<p>总的来说，<strong>自动增强</strong>和<strong>深度增强</strong>都不常用。不过，如果您不知道哪种增强技术最适合您的数据，运行它们可能会非常有用。你只需要记住，这需要大量的时间，因为要训练多个模型。</p>



<p>值得一提的是，我们没有涵盖所有的自定义图像增强库，但我们已经涵盖了主要的。现在你知道什么库最受欢迎，它们有什么优点和缺点，以及如何使用它们。如果您需要，这些知识将帮助您找到任何其他信息。</p>





<h2 id="speed">图像数据增强库的速度比较</h2>



<p>您可能已经发现，增强过程在时间和计算上都非常昂贵。</p>



<p>执行<strong> DA </strong>所需的时间取决于我们需要转换的数据点的数量、整个扩充流水线的难度，甚至取决于您用来扩充数据的硬件。<br/> <br/>让我们进行一些实验，找出最快的增强库。我们将对<strong>增强器</strong>、<strong>白蛋白</strong>、<strong> ImgAug </strong>和<strong>转化</strong>进行这些实验。我们将使用来自Kaggle的一个<a href="https://web.archive.org/web/20220928201835/https://www.kaggle.com/alxmamaev/flowers-recognition" target="_blank" rel="noreferrer noopener nofollow">图像数据集</a>，它是为花朵识别而设计的，包含超过4000张图像。</p>



<p>在我们的第一个实验中，我们将创建一个只包含两个操作的扩充管道。这将是概率为0.4的<strong>水平翻转</strong>和概率为0.8的<strong>垂直翻转</strong>。让我们将管道应用于数据集中的每个图像，并测量时间。</p>


<p id="block_61ae6645931a6" class="separator separator-10"/>





<p id="block_61ae6651931a7" class="separator separator-25"/>



<p>正如我们所预料的，<strong> Augmentor的执行速度比其他库</strong>慢。尽管如此，<strong>albumation和Transforms都显示出良好的结果</strong>，因为它们被优化来执行快速增强。<br/> <br/>对于我们的第二个实验，我们将<strong>创建一个更复杂的管道，使用各种转换</strong>到<strong>，看看</strong>转换<strong>和</strong>缓冲<strong>是否停留在顶部</strong>。我们将更多的几何变换堆叠成一个流水线。因此，我们将能够使用所有库作为增强器，例如，没有太多的内核过滤操作。</p>



<p>你可以在我为你准备的笔记本中找到完整的流程<a href="https://web.archive.org/web/20220928201835/https://colab.research.google.com/drive/17R6PJRZkwjk7mYUxXCQVtR4o6JaCEVPQ?usp=sharing" target="_blank" rel="noreferrer noopener nofollow">。请随意试验和使用它。</a></p>


<p id="block_61ae6667931a8" class="separator separator-10"/>





<p id="block_6009c9c6d1939" class="separator separator-25"/>



<p>再一次<strong>变换和贴图位于顶部</strong>。</p>



<p>此外，如果我们检查通过<strong> Neptune </strong>获得的CPU使用图表，我们会发现<strong>缓冲和转换</strong>使用的CPU资源都不到60%。</p>







<p>另一方面，<strong>增强器和ImgAug </strong>使用超过80%。</p>







<p>你可能已经注意到了，<strong>转存和转换都非常快</strong>。这就是它们在现实生活中被广泛使用的原因。</p>





<h2 id="best-practices">最佳实践、提示和技巧</h2>



<p>值得一提的是，尽管<strong> DA </strong>是一个强大的工具，但你应该小心使用它。在应用增强时，您可能需要遵循一些通用规则:</p>


<div class="custom-point-list">
<ul><li>为你的任务选择适当的扩充。让我们想象一下，你正试图检测一张图像上的一张脸。你选择<strong>随机删除</strong>作为增强技术，突然你的模型甚至在训练中表现也不好。这是因为图像上没有人脸，因为它是通过增强技术随机擦除的。同样的事情也适用于声音检测和应用噪声注入到磁带作为一个增强。记住这些案例，在选择<strong> DA </strong>技术时要合乎逻辑。</li></ul>
</div>

<div class="custom-point-list">
<ul><li>不要在一个序列中使用太多的增强。你可能会简单地创建一个全新的观察，与你最初的训练(或测试数据)毫无共同之处</li><li>在笔记本中显示增强数据(图像和文本),并在开始训练之前聆听转换后的音频样本。当形成一个扩充管道时，很容易出错。这就是为什么复查结果总是更好的原因。</li></ul>
</div>




<p>此外，在创建自己的扩充管道之前，检查一下笔记本也是一个很好的做法。你可以在那里找到很多想法。试着为类似的任务找一个笔记本，检查作者是否应用了和你计划的一样的扩充。</p>





<h2>最后的想法</h2>



<p>在本文中，我们已经弄清楚了什么是<strong>数据扩充</strong>，有哪些<strong> DA </strong>技术，以及您可以使用哪些库来应用它们。</p>



<p>据我所知，最好的公共图书馆是图书室。这就是为什么如果你正在处理图像并且不使用<strong> MxNet </strong>或<strong> TensorFlow </strong>作为你的<strong> DL </strong>框架，你可能应该使用<strong>albuminations</strong>作为<strong> DA </strong>。</p>



<p>希望有了这些信息，你在为下一个机器学习项目设置<strong> DA </strong>时不会有任何问题。</p>





<h2>资源</h2>






<div id="author-box-new-format-block_60421a46c28a6" class="article__footer article__author">
  

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">弗拉基米尔·利亚申科</h3>
    
          <p class="article__authorContent-text">年轻的人工智能爱好者，对医学中的教育技术和计算机视觉充满热情。我想通过帮助其他人学习，探索新的机会，并通过先进的技术跟踪他们的健康状况，让世界变得更美好。</p>
    
          
    
  </div>
</div>


<div class="wp-container-1 wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator"/>



<p class="has-text-color"><strong>阅读下一篇</strong></p>



<h2>机器学习中模型评估和选择的最终指南</h2>



<p class="has-small-font-size">10分钟阅读|作者Samadrita Ghosh |年7月16日更新</p>


<p id="block_5ffc75def9f8e" class="separator separator-10"/>



<p>在高层次上，机器学习是统计和计算的结合。机器学习的关键围绕着算法或模型的概念，这些概念实际上是类固醇的统计估计。</p>



<p>然而，根据数据分布的不同，任何给定的模型都有一些限制。它们中没有一个是完全准确的，因为它们只是<strong> <em>(即使使用类固醇)</em> </strong>。这些限制俗称<strong> <em>偏差</em> </strong>和<strong> <em>方差</em> </strong>。</p>



<p>具有高偏差的<strong>模型会由于不太注意训练点而过于简化(例如:在线性回归中，不管数据分布如何，模型将总是假设线性关系)。</strong></p>



<p>具有高方差的<strong>模型将通过不对其之前未见过的测试点进行概括来将其自身限制于训练数据(例如:max_depth = None的随机森林)。</strong></p>



<p>当限制很微妙时，问题就出现了，比如当我们必须在随机森林算法和梯度推进算法之间进行选择，或者在同一决策树算法的两个变体之间进行选择。两者都趋向于具有高方差和低偏差。</p>



<p>这就是模型选择和模型评估发挥作用的地方！</p>



<p>在本文中，我们将讨论:</p>


<div class="custom-point-list">
<ul><li>什么是模型选择和模型评估？</li><li>有效的模型选择方法(重采样和概率方法)</li><li>流行的模型评估方法</li><li>重要的机器学习模型权衡</li></ul>
</div>

<a class="button continous-post blue-filled" href="/web/20220928201835/https://neptune.ai/blog/the-ultimate-guide-to-evaluation-and-selection-of-models-in-machine-learning" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator"/>
</div></div>
</div>
      </div>    
</body>
</html>