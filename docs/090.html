<html>
<head>
<title>Transformer Models for Textual Data Prediction </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>用于文本数据预测的转换器模型</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/transformer-models-for-textual-data-prediction#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/transformer-models-for-textual-data-prediction#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>诸如<a href="https://web.archive.org/web/20221206154022/https://en.wikipedia.org/wiki/BERT_(language_model)" target="_blank" rel="noreferrer noopener nofollow">谷歌的BERT </a>和<a href="https://web.archive.org/web/20221206154022/https://en.wikipedia.org/wiki/GPT-3" target="_blank" rel="noreferrer noopener nofollow"> Open AI的GPT3 </a>等变形金刚模型继续改变着我们对机器学习(ML)和自然语言处理(NLP)的看法。只要看看GitHub最近推出的一款名为<a href="https://web.archive.org/web/20221206154022/https://copilot.github.com/" target="_blank" rel="noreferrer noopener nofollow"> Copilot </a>的预测编程支持工具就知道了。它接受了数十亿行代码的训练，并声称理解“<em>你提供的上下文，并合成代码以匹配</em>”。你的虚拟搭档程序员伙伴！</p>



<p>我们已经在<a href="/web/20221206154022/https://neptune.ai/blog/bert-and-the-transformer-architecture-reshaping-the-ai-landscape" target="_blank" rel="noreferrer noopener">最近的文章</a>中写过这些模型和底层的变压器架构。我们还查看了<a href="/web/20221206154022/https://neptune.ai/blog/unmasking-bert-transformer-model-performance" target="_blank" rel="noreferrer noopener">最近对不同Transformer模型</a>的研究，以理解为什么BERT和GPT3的底层架构比其他模型更好地学习上下文。</p>



<p>现在，像Copilot一样，我们希望在现实生活中实现这些模型的一些功能。因此，在这篇文章中，我们将看看使用变形金刚预测文本不同特征的实用方法。在此之前，我们需要确定我们可以预测哪些类型的特征，并理解为什么预测文本不同于其他形式的预测。</p>



<h2 id="h-to-predict-or-not-to-predict">预测还是不预测？</h2>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" src="../Images/fc6beccadcd7d9f12cde702e85b5e60f.png" alt="The image shows a page full of definitions from the dictionary." class="wp-image-53029" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206154022im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/NLP-Guide-How-to-Predict-Textual-Data-With-Transformers_1.jpg?resize=512%2C348&amp;ssl=1"/><figcaption><meta http-equiv="content-type" content="text/html; charset=utf-8"/><em>How does predicting text differ from other forms of prediction? | <a href="https://web.archive.org/web/20221206154022/https://pixabay.com/photos/definition-word-dictionary-text-390785/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>预测文本数据不同于其他形式的预测。如果您想要预测某项资产(如股票或房屋)的价格，您可以向模型提供所有可用的数据，并预测您认为最能代表该资产的数字。价格是一个数字，虽然它可能是对的，也可能是错的，但它没有文本那么多潜在的“不确定性维度”。</p>



<p>以副驾驶为例。它预测代码片段，所以它可能拼错代码，使用错误的编码语言，使用不正确的变量名，等等。即使它做到了所有这些，代码本身也可能不起作用。</p>



<p>类似地，一个句子可能在语法上是正确的，但是在语义上是没有意义的。<a href="https://web.archive.org/web/20221206154022/https://en.wikipedia.org/wiki/Colorless_green_ideas_sleep_furiously#:~:text=Colorless%20green%20ideas%20sleep%20furiously%20is%20a%20sentence%20composed%20by,grammatically%20correct%2C%20but%20semantically%20nonsensical." target="_blank" rel="noreferrer noopener nofollow">诺姆·乔姆斯基</a>写了一句著名的句子“<em>无色的绿色想法疯狂地睡觉</em>”，以显示机器区分语法和语义的困难。</p>



<p>这就是我们所说的预测文本比价格有更多的“不确定性维度”的意思。与其他形式的数据(如资产价格)相比，文本在更多方面可能是“错误的”。为了控制这种程度的不确定性，我们试图识别我们想要预测的文本数据的特定特征。</p>



<p>这些特性在大多数以业务为中心的NLP管道中也应该是有用的。考虑到这一点，我们将在本帖中探讨以下特性:</p>



<ol><li>预测拼写错误:文本出错最简单的方法之一就是简单地拼错句子中的一个或多个单词。这个单词要么拼写正确，要么拼写错误。我们每天都在Gmail等应用程序的自动更正功能中看到这种情况，所以我们可以看看如何使用基于Transformer的模型轻松实现这样的功能。</li><li>预测语法错误:识别句子中的语法错误要稍微困难一些。我们可以使用基于Transformer的模型来预测一个句子是否包含语法错误吗？这可能是您在处理数据时使用的东西，以确定它是否需要更改或从您的管道中删除，因为它可能会增加系统中下游错误的可能性。</li><li><strong>预测转述句子</strong>:通常当我们查看文本数据时，我们试图理解某些句子是否相关。思考这个问题的一种方式是，我们是否能够预测一个句子何时会转述另一个句子。这项任务比简单地寻找拼写错误或语法错误有更多的细微差别。原因是它涉及到识别两个句子的上下文，并预测一个句子和另一个句子描述相同的意图是否合理。这在处理大量文本数据时很有用，并且您希望搜索或识别可能相关但不完全相同的文本。</li></ol>



<p>在研究这些特性的同时，我们还将研究一些不同的NLP库，它们使用转换器来执行一系列的NLP功能。您可以在NLP管道中使用这些库，它们也可以帮助您更好地理解如何将Transformers用于您的特定任务和用例。</p>



<p>这篇文章中描述的代码可以在相关的<a href="https://web.archive.org/web/20221206154022/https://github.com/choran/predicting_text" target="_blank" rel="noreferrer noopener nofollow"> Github </a> repo中找到。</p>



<h2 id="h-predicting-text-data-with-transformers">用转换器预测文本数据</h2>



<h3>数据集</h3>



<p>为了预测文本数据，我们希望使用一个表示“真实”查询和对话的数据集。我们所说的“真实”是指它包含了你在Slack或电子邮件中输入的所有混乱的东西。也就是说，它应该包含语法错误和拼写错误，使用缩写，以及所有其他我们可以找到的不太完美的方式来构建一个句子。</p>



<p>这类数据的一个重要来源是<a href="https://web.archive.org/web/20221206154022/http://jmcauley.ucsd.edu/data/amazon/qa/" target="_blank" rel="noreferrer noopener nofollow">亚马逊客户支持QA数据集</a>。具体来说，我们将使用问题的软件类别，因为我们想看看我们的方法是否可以识别相关领域内的主题。这个数据集很棒，因为:</p>



<ul><li>它包含<strong>真实问题</strong>，有我们想要的所有乱七八糟的问题，比如拼写错误、作为陈述的问题、有否定和无否定的问题，以及我们想以不同方式问同样问题的所有其他方式。</li><li>所有的<strong>问题都有关联的答案，</strong>有些是长答案，有些是简短的是/否答案。</li><li><strong>数据集被分成不同的类别</strong>。一些数据集包含各种不同主题的综合问题。这并不复制典型的业务客户数据集，该数据集将与特定的业务或技术领域相关。</li><li>它<strong>包含了关于如何最好地将其转换成不同格式的代码示例</strong>。作者提供了有用的代码片段来帮助将数据转换成您认为最有用的解析格式。</li></ul>



<p>按照数据集作者概述的步骤，我们最终得到一个熊猫数据框架，如下所示:</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/4aa1833159773e923b4c5daad11306ea.png" alt="The image shows Pandas DataFrame by the author." class="wp-image-53028" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206154022im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/NLP-Guide-How-to-Predict-Textual-Data-With-Transformers_2.png?ssl=1"/><figcaption><meta http-equiv="content-type" content="text/html; charset=utf-8"/><em><em>We use a DF here but you can transform your data into whatever data structure you find easiest to work with. | Source: Author</em></em></figcaption></figure></div>



<h3>预测拼写错误</h3>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/f632bb5eb03a921853f5258357b83da4.png" alt="The image shows a word made from scrabble letters." class="wp-image-53030" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206154022im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/NLP-Guide-How-to-Predict-Textual-Data-With-Transformers_11.jpg?resize=512%2C281&amp;ssl=1"/><figcaption><meta http-equiv="content-type" content="text/html; charset=utf-8"/><em>Can we use transformers to better predict when a word is misspelled? | <a href="https://web.archive.org/web/20221206154022/https://pxhere.com/en/photo/1520271" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>作为对我们预测技能的第一个测试，我们将尝试识别数据集中的拼写错误。我们现在在几乎每个应用程序中都经常看到这个特性，以至于我们可能认为这是一个简单的问题。然而，这里的关键区别在于，我们正在执行一项预测任务，而不仅仅是向操作员建议一个潜在的拼写。</p>



<p>例如，如果您有一个管道，在那里您正在做诸如清理新的或传入的数据之类的事情，那么您可能会有一个消耗该数据的下游任务。下游任务可以是将数据用于训练目的的模型，或者将数据用于聚类的模型，或者是问答类型的模型。在这些情况下，重要的是特定领域的数据或特定术语或俚语不会被错误地识别为拼写错误的单词并被更改。这可能会给你的下游任务带来严重的后果。</p>



<p>由于有了预先训练好的模型，Transformers使许多这类应用程序更容易实现。然而，尽管这些模型令人惊叹，您仍然需要关注您的特定用例。也许你不需要一个预先训练好的模型的所有附加功能，一个简单的拼写检查就可以了。或者，您可能想看看一些最新的transformer模型应用程序，看看它们是否为您的用例添加了任何新的和独特的价值。</p>



<p>这种方法的一个很好的例子是神经拼写校正库，<a href="https://web.archive.org/web/20221206154022/https://arxiv.org/pdf/2010.11085.pdf" target="_blank" rel="noreferrer noopener nofollow"> NeuSpell </a>。NeuSpell在神经网络上接受训练，通过使用相邻单词的上下文而不仅仅是字符扰动来学习拼写纠正。为了了解这种背景，他们使用ELMo和BERT等模型以及其他神经网络。你可以在这里找到github回购<a href="https://web.archive.org/web/20221206154022/https://arxiv.org/pdf/2010.11085.pdf" target="_blank" rel="noreferrer noopener nofollow">。</a></p>



<p>另一种方法是基于上下文的方法，就像spaCy通过他们的<a href="https://web.archive.org/web/20221206154022/https://spacy.io/universe/project/contextualSpellCheck" target="_blank" rel="noreferrer noopener nofollow">上下文拼写检查</a>提供的方法。这使用BERT来在识别错误或建议更正时利用单词的上下文。</p>



<p>让我们先来看一下这两种方法的一些例子，看看它们在实际中是怎样的。我们将从我们的测试集中抽取20个句子的样本，查看两个模型，看看他们认为什么是拼写错误。</p>



<pre class="hljs"><span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> original_queries:
    doc = nlp(q)
    spacy_misspell = doc._.performed_spellCheck
    print(f<span class="hljs-string">'='</span>*(len(q)))
    print(q)
    print(f<span class="hljs-string">'='</span>*(len(q)))
    print(f<span class="hljs-string">'-------- spaCy -------- '</span>)
    <span class="hljs-keyword">if</span> spacy_misspell:
        print(f<span class="hljs-string">'spaCy&gt; spelling error detected'</span>)
        print(doc._.suggestions_spellCheck)
        print(doc._.outcome_spellCheck)
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> doc._.score_spellCheck:
            print(i)
            <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> doc._.score_spellCheck[i]:
                print(s)
    <span class="hljs-keyword">else</span>:
        print(f<span class="hljs-string">'spaCy&gt; No spelling error detected'</span>)
    neuspell_res = checker.correct(q)
    print(f<span class="hljs-string">'-------- NeuSpell -------- '</span>)
    print(neuspell_res)</pre>



<p>在上面的代码中，您可以看到spaCy模型使我们能够检查在给定的字符串中是否确实检测到了拼写错误。您还可以查看最有可能的建议更正以及相应的分数。这些都是非常有用的功能，使您能够看到实际上是否有错误，以及模型对潜在的替代替换单词有多大的信心。</p>



<p>例如，查询“<em>do you need a proceser</em>”似乎有一个明显的拼写错误。然而，spaCy模型似乎认为这更像是一个上下文任务，而不是拼写错误:</p>



<pre class="hljs">do you need a procceser
=======================
spaCy: spelling error detected
-----------------------
{procceser: <span class="hljs-string">'coffee'</span>}
do you need a coffee
procceser
(<span class="hljs-string">'?'</span>, <span class="hljs-number">0.85842</span>)
(<span class="hljs-string">'.'</span>, <span class="hljs-number">0.04466</span>)
(<span class="hljs-string">'...'</span>, <span class="hljs-number">0.00479</span>)
(<span class="hljs-string">';'</span>, <span class="hljs-number">0.00453</span>)
(<span class="hljs-string">'-'</span>, <span class="hljs-number">0.00416</span>)
(<span class="hljs-string">'coffee'</span>, <span class="hljs-number">0.00275</span>)
(<span class="hljs-string">'!'</span>, <span class="hljs-number">0.00234</span>)
(<span class="hljs-string">'phone'</span>, <span class="hljs-number">0.00203</span>)
(<span class="hljs-string">'&gt;'</span>, <span class="hljs-number">0.00153</span>)
(<span class="hljs-string">'room'</span>, <span class="hljs-number">0.00138</span>)</pre>



<p>而NeuSpell模型确实识别了正确的拼写错误:</p>



<pre class="hljs">-----------------------
NeuSpell:
-----------------------
do you need a processor
</pre>



<p>spaCy模型还显示了更多与上下文相关的修正，例如:</p>



<pre class="hljs">Does this work well <span class="hljs-keyword">for</span> canada?
===============================
spaCy: spelling error detected
-------------------------------
{canada: <span class="hljs-string">'anyone'</span>}
Does this work well <span class="hljs-keyword">for</span> anyone?
canada
(<span class="hljs-string">'you'</span>, <span class="hljs-number">0.58046</span>)
(<span class="hljs-string">'him'</span>, <span class="hljs-number">0.11493</span>)
(<span class="hljs-string">'me'</span>, <span class="hljs-number">0.09218</span>)
(<span class="hljs-string">'her'</span>, <span class="hljs-number">0.06952</span>)
(<span class="hljs-string">'us'</span>, <span class="hljs-number">0.0262</span>)
(<span class="hljs-string">'them'</span>, <span class="hljs-number">0.02586</span>)
(<span class="hljs-string">'anyone'</span>, <span class="hljs-number">0.00408</span>)
(<span class="hljs-string">'everyone'</span>, <span class="hljs-number">0.00391</span>)
(<span class="hljs-string">'ya'</span>, <span class="hljs-number">0.00098</span>)
(<span class="hljs-string">'now'</span>, <span class="hljs-number">0.00094</span>)</pre>



<p>潜在的更正很有趣，因为它们看起来更像是与上下文相关的变化，而不是拼写错误。如果您将“加拿大”替换为大写的“C”，即“这对加拿大有用吗？”使用空间模型不会导致任何变化。即使使用加拿大的小写拼写，NeuSpell模型也不会更正原始句子。</p>



<p>您可以浏览数据集，查看更多关于这些模型如何相互比较的示例。即使粗略地看一下，这两种型号似乎都有问题。总的来说:</p>



<ol><li>spaCy模型似乎专注于上下文:spaCy模型有很多很好的特性，比如为潜在的替代者提供一个置信度得分。然而，它的建议更多的是基于上下文而不是拼写错误。在几个简单的例子中，如果我们的主要焦点是纠正潜在的拼写错误的话，它会产生一些看起来有问题的建议。这只是一个例子，可能有办法使用其他spaCy工具来调整它，或者改变它，使它更适合您的用例。但是现在，预测拼写错误的单词的纠正似乎没有用。</li><li><strong>neu spell模型不提供置信度得分</strong>:neu spell模型作为一个预测拼写错误单词纠正的模型，似乎表现得更好。它产生了比spaCy模型更合理的建议，所以你可以考虑使用它。它是否比其他标准(即非基于神经网络的)模型更好还有待商榷。此外，它似乎没有为其建议提供置信度得分的事实可能会限制其预测能力。如果能够查看置信度得分并选择是否接受建议，那就太好了。这将使NLP管道中的过程更容易自动化，并且确信您不是在“纠正”特定领域的术语，如产品名称。</li><li>传统的拼写检查可能更适合你的任务:看起来基于转换器的拼写检查可能不会比<a href="https://web.archive.org/web/20221206154022/https://norvig.com/spell-correct.html" target="_blank" rel="noreferrer noopener nofollow">传统类型的方法</a>提供更多的优势。但是，关注像这样的新应用总是好的，这些应用可能会通过像伯特或GPT这样的新NLP模型得到改进。</li></ol>







<h3>预测语法错误</h3>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/85612d18fdbd55d8e565add0b2bc1403.png" alt="The image shows a word made from scrabble letters." class="wp-image-53032" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206154022im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/NLP-Guide-How-to-Predict-Textual-Data-With-Transformers_14-scaled.jpg?resize=512%2C342&amp;ssl=1"/><figcaption><meta http-equiv="content-type" content="text/html; charset=utf-8"/><em>Do Transformer models like T5 make it easier to predict grammar errors in a sentence? | <a href="https://web.archive.org/web/20221206154022/https://www.photos-public-domain.com/2011/09/01/grammar/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>虽然我们的拼写模型可能没有取得巨大成功，但希望我们在识别数据集中的语法错误方面运气更好。同样，如果您想在下游任务中使用您的数据，这很有用。</p>



<p>或者你可能想用一个句子去找其他类似的句子。在这种情况下，知道原文是否是一个好的、干净的、结构良好的句子是很有用的。如果它确实包含一些语法错误，那么这可能是你在查看相似性匹配分数时要考虑的事情。</p>



<p>像谷歌的<a href="https://web.archive.org/web/20221206154022/https://github.com/google-research/text-to-text-transfer-transformer" target="_blank" rel="noreferrer noopener nofollow"> T5文本到文本转换器</a>，这是<a href="https://web.archive.org/web/20221206154022/https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html" target="_blank" rel="noreferrer noopener nofollow">在2020年</a>发布的，是基于转换器的模型的例子，可以执行多种任务，如识别正确或错误的语法。T5型号的有趣之处在于:</p>



<ul><li>它在许多自然语言处理任务上接受训练:该模型在广泛的自然语言处理任务上接受训练，从识别相似性、总结文本到识别语法错误。所有这些任务都使用相同的模型、损失函数和超参数。理论上，这类似于你或我学习语言的方式，即我们学习字母表，我们学习读写和拼写，回答问题，然后我们将所有这些知识结合起来，以便能够完成非常高级的语言任务。现在，我们并不是说这些模型理解语言的方式和我们一样，但它们已经开始在一些NLP任务中表现得接近或接近人类。</li><li>它使用文本进行输入和输出:这个模型的另一个关键点是，你只需通过文本告诉模型你想要它做什么，它提供的结果也总是文本格式的。这与像BERT这样的模型非常不同，在BERT模型中，输入可能是一个句子，但输出是一个实体，如大规模多维向量。相反，用T5，你通过文本告诉它，你想让它执行什么任务，提供这个任务的文本，它会用文本告诉你结果。就抽象而言，这是一个巨大的飞跃。想一想C或Java等编码语言和Python的区别。Python是一个如此高层次的抽象，它使得更多的人能够编程，并开辟了如此多的潜在用例。同样，当人们惊叹于<a href="https://web.archive.org/web/20221206154022/https://openai.com/blog/gpt-3-apps/" target="_blank" rel="noreferrer noopener nofollow"> GPT-3 </a>的强大时，我对它简单的界面印象深刻。真正的天才不在于无数的参数，而在于易用性，这使得人们能够生成文本、回答问题，并对他们所看到的感到惊讶，否则他们将无法测试基于transformer的高级模型。</li></ul>



<p>你可以直接通过其<a href="https://web.archive.org/web/20221206154022/https://github.com/google-research/text-to-text-transfer-transformer#installation" target="_blank" rel="noreferrer noopener nofollow"> github </a>页面或者从<a href="https://web.archive.org/web/20221206154022/https://huggingface.co/transformers/model_doc/t5.html" target="_blank" rel="noreferrer noopener nofollow"> HuggingFace库</a>使用T5。或者，也是我喜欢首先使用的方法，您可以尝试找到另一个库，其中包含一个抽象层，这样更容易使用。这样你可以快速测试模型，看看它是否适合你的用例。</p>



<p>如果是这样，那么您可以投入时间部署和测试“原始”模型，这可能使您能够在更加定制的基础上训练和调整它。最近，许多这种“抽象”类型库也允许您执行这些任务，所以您可能不需要做任何进一步的研究。</p>



<h4>识别有语法错误的句子</h4>



<p>如果你浏览我们的亚马逊数据集，你可以看到语法不正确的句子，例如“<em>用户下载时有问题吗？</em>”或者“<em>这样开餐厅好不好</em>”。</p>



<p>这是意料之中的，因为这是一个真实的数据集，我们都知道在网上聊天时很容易发生这类错误。正如我们前面提到的，如果您将客户数据用于下游任务，或者只是将清理数据作为最佳实践，那么您将需要识别句子中何时存在语法错误。结合拼写错误，您可以为您的管道创建一种质量分数，您可以在其中为您想到的任何下游任务排列更高质量的数据。</p>



<p>T5执行这些类型的任务，基于T5任务的一个很好的“抽象”库是<a href="https://web.archive.org/web/20221206154022/https://nlp.johnsnowlabs.com/analyze_spelling_grammar" target="_blank" rel="noreferrer noopener nofollow">约翰斯诺实验室</a> Spark NLP库<a href="https://web.archive.org/web/20221206154022/https://nlp.johnsnowlabs.com/analyze_spelling_grammar">。</a> <a href="https://web.archive.org/web/20221206154022/https://towardsdatascience.com/introduction-to-spark-nlp-foundations-and-basic-components-part-i-c83b7629ed59" target="_blank" rel="noreferrer noopener nofollow"> Spark NLP </a>是一个NLP库，类似于spaCy或NLTK这样的库，在一个屋檐下提供了一系列的NLP功能。John Snow Labs是一家为医疗保健等行业提供NLP服务的公司，它还提供一系列免费的NLP实用程序。不用说，这就是我们在这里看它们的原因。</p>



<p>要设置任务，您需要首先确定要使用的模型。约翰斯诺实验室提供其他模型，但现在我们将使用T5。</p>



<pre class="hljs">documentAssembler = DocumentAssembler()
    .setInputCol(<span class="hljs-string">"text"</span>)
    .setOutputCol(<span class="hljs-string">"document"</span>)


t5 = T5Transformer.pretrained(name=<span class="hljs-string">'t5_base'</span>,lang=<span class="hljs-string">'en'</span>)
    .setInputCols(<span class="hljs-string">'document'</span>)
    .setOutputCol(<span class="hljs-string">"T5"</span>)
</pre>



<p>然后你需要告诉它你要执行的任务。</p>



<pre class="hljs">
t5.setTask(<span class="hljs-string">'cola sentence:'</span>)


pipe_components = [documentAssembler,t5]
pipeline = Pipeline().setStages( pipe_components)
</pre>



<p>现在我们只需要测试数据中的一些例句。</p>



<pre class="hljs">
sentences = test_dataset_df[<span class="hljs-string">'question'</span>].sample(n=<span class="hljs-number">20</span>).tolist()

sentences = [[x] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> sentences <span class="hljs-keyword">if</span> len(x) &lt; <span class="hljs-number">90</span>]
df = spark.createDataFrame(sentences).toDF(<span class="hljs-string">"text"</span>)


model = pipeline.fit(df)
annotated_df = model.transform(df)
annotated_df.select([<span class="hljs-string">'text'</span>,<span class="hljs-string">'t5.result'</span>]).show(truncate=<span class="hljs-keyword">False</span>)
</pre>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/20d93a5a155fa1ff9315ef0f2875a993.png" alt="The image shows an example output from identifying which sentences are grammatically correct." class="wp-image-53025" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206154022im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/NLP-Guide-How-to-Predict-Textual-Data-With-Transformers_5.png?resize=840%2C445&amp;ssl=1"/><figcaption><meta http-equiv="content-type" content="text/html; charset=utf-8"/><em>This is the example output from identifying which sentences are grammatically correct | Source: Author</em></figcaption></figure></div>



<p>从上面的例子可以看出，它既识别了一个语法错误，也识别了一个拼写错误。我们可以将它与上面的拼写纠正库结合使用，看看我们需要对哪些句子进行拼写检查。这可能是解决我们之前提到的问题的另一种方法，当时我们没有一个单词拼写错误可能性的置信度得分。一旦我们知道有语法错误，我们就可以通过拼写检查，因为我们知道这个句子有问题。</p>



<p>再说一次，这是我们可以用来检查数据质量的另一个“引以为傲”的东西。你可以点击这里查看约翰斯诺图书馆提供的大量例子和演示。</p>



<p>您可以找到大量使用T5和其他transformer模型预测文本的其他示例。您还可以使用库管道结构来轻松创建自己的ML管道，以便按顺序执行所有这些任务。关于所有可用任务的列表，你可以阅读这篇<a href="https://web.archive.org/web/20221206154022/https://towardsdatascience.com/hands-on-googles-text-to-text-transfer-transformer-t5-with-spark-nlp-6f7db75cecff" target="_blank" rel="noreferrer noopener nofollow">介绍性文章</a>，它列出了所有T5任务和解释。</p>



<h3>预测转述句子</h3>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/554419a936d6a36620ed25de5767d3b8.png" alt="The image shows a pile of scrabble letters." class="wp-image-53038" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206154022im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/NLP-Guide-How-to-Predict-Textual-Data-With-Transformers_6.jpg?resize=600%2C450&amp;ssl=1"/><figcaption><meta http-equiv="content-type" content="text/html; charset=utf-8"/><em>Can BERT help us predict paraphrased sentences? | <a href="https://web.archive.org/web/20221206154022/https://unsplash.com/photos/7PYqjNzvrc4" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>到目前为止，我们试图预测我们的测试句子是否包含拼写错误的单词或语法错误。现在，假设我们将这些“检查”添加到我们的NLP管道中，其输出将是“干净”句子的预测器。这些“干净”的句子可以代表正确形成的客户询问。这一过程的最后一步可能是尝试并预测一个句子是否是数据集中已经存在的句子的意译。</p>



<p>这可能是一个有用的工具，看看你是否需要处理或分组任何新的句子。如果它们已经存在，那么你可能已经有了信息。如果您正在创建一个训练数据集，那么您可能需要相应地对句子进行分组和标记。以这种方式预测转述的句子有两个主要好处:</p>



<ol><li>很快:你可以找到相似的句子，而不是预测转述的句子。这需要将每个句子与其他句子进行比较，找出最相似的句子。如果您有大量数据，这可能会非常慢。</li><li>它可以使用预先训练好的模型:因为我们只寻找句子的释义版本，我们可以使用预先训练好的模型。或者，如果我们直接比较句子，我们可能需要对模型进行微调，以理解医学或法律术语之类的东西，如果我们在那个领域的话。当我们使用解释模型时，我们希望主要关注用不同的方式来表达问题。例如，想一个类似“<em>的句子，deefee要多少钱？</em>”。这是一个由一个词组成的句子，这个词没有任何意义，但这并不妨碍我们把它解释为:<ol><li>deefee的价格是多少？</li><li>参加deefee需要多少费用？</li><li>deefee的成本是多少？</li><li>段落免费吗？</li><li>段落免费吗？</li><li>deefee很贵吗？</li></ol></li></ol>



<p>*<em>deefee</em>–我通过一个叫做<a href="https://web.archive.org/web/20221206154022/https://l.thisworddoesnotexist.com/9btS" target="_blank" rel="noreferrer noopener nofollow">的酷网站生成了这个单词，这个单词并不存在</a>，它基于GPT2生成了不存在的单词，但它也生成了这些单词的定义。看到模型想出的东西很有趣。例如，它将deefee定义为“<em>一个赌博事件</em>”。</p>



<h4>用句子预测释义</h4>



<p>句子BERT是一个巨大的模型库，<a href="https://web.archive.org/web/20221206154022/https://arxiv.org/abs/1908.10084" target="_blank" rel="noreferrer noopener nofollow">最初开始使用BERT和一个暹罗网络来生成语义上有意义的句子嵌入，然后您可以使用它来进行分类或句子相似性等工作。它现在有一系列</a><a href="https://web.archive.org/web/20221206154022/https://www.sbert.net/docs/pretrained_models.html" target="_blank" rel="noreferrer noopener nofollow">不同的模型可用</a>，你可以用它来完成许多NLP任务，它现在也可以作为<a href="https://web.archive.org/web/20221206154022/https://huggingface.co/sentence-transformers" target="_blank" rel="noreferrer noopener nofollow"> HuggingFace </a>库的一部分。</p>







<p>我们将使用他们的<a href="https://web.archive.org/web/20221206154022/https://www.sbert.net/examples/applications/paraphrase-mining/README.html" target="_blank" rel="noreferrer noopener nofollow">转述模型</a>来识别亚马逊数据集中的转述句子。注意，你也可以通过<a href="https://web.archive.org/web/20221206154022/https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2" target="_blank" rel="noreferrer noopener nofollow"> HuggingFace </a>库或者作为<a href="https://web.archive.org/web/20221206154022/https://www.sbert.net/examples/applications/paraphrase-mining/README.html" target="_blank" rel="noreferrer noopener nofollow">句子转换器</a>库本身的一部分来使用这个模型。</p>



<p>我们首先需要下载模型，这很容易，因为它是HuggingFace的一部分:</p>



<pre class="hljs"><span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer
model = SentenceTransformer(<span class="hljs-string">'sentence-transformers/all-MiniLM-L6-v2'</span>)</pre>



<p>然后，我们需要从数据集中获取一个句子样本进行测试:</p>



<pre class="hljs">sentences = test_dataset_df[<span class="hljs-string">'question'</span>].sample(n=<span class="hljs-number">10</span>).tolist()
<span class="hljs-keyword">for</span> i, s <span class="hljs-keyword">in</span> enumerate(sentences, <span class="hljs-number">1</span>):
    print(f<span class="hljs-string">'{i}: {s}'</span>)</pre>



<pre class="hljs"><span class="hljs-number">1</span>: Will this work on a <span class="hljs-number">64</span>bit system?
<span class="hljs-number">2</span>: If I buy <span class="hljs-keyword">print</span> shop <span class="hljs-number">23</span> can I access my old files <span class="hljs-keyword">from</span> <span class="hljs-keyword">print</span> shop <span class="hljs-number">22</span>?
<span class="hljs-number">3</span>: does this work on a macbook mid <span class="hljs-number">2010</span> laptop??? (Macintosh HD OS X version <span class="hljs-number">10.9</span><span class="hljs-number">.4</span>)
<span class="hljs-number">4</span>: how can i play it on my mac <span class="hljs-number">0</span>s x?
<span class="hljs-number">5</span>: upgrade <span class="hljs-keyword">from</span> FMP <span class="hljs-number">6</span>? Will FMP <span class="hljs-number">10</span> upgrade <span class="hljs-keyword">from</span> FMP <span class="hljs-number">6</span>?
<span class="hljs-number">6</span>: Can you send me only the activation code?
<span class="hljs-number">7</span>: Can you use this to renew an existing subscription to McAfee Internet Security?
<span class="hljs-number">8</span>: What are options <span class="hljs-keyword">for</span> sound editing?
<span class="hljs-number">9</span>: Is this useful <span class="hljs-keyword">for</span> walking directions?
<span class="hljs-number">10</span>: does the instrumentation include a generous offering <span class="hljs-keyword">from</span> the indian orchestra plus the hammered dulcimer?</pre>



<p>这里看起来类似的句子不多，我们来看看模型是怎么想的。</p>



<pre class="hljs">paraphrases = util.paraphrase_mining(model, sentences, top_k=<span class="hljs-number">1</span>)
<span class="hljs-keyword">for</span> paraphrase <span class="hljs-keyword">in</span> paraphrases[<span class="hljs-number">0</span>:<span class="hljs-number">100</span>]:
    score, i, j = paraphrase
    para_list.append([round(score, <span class="hljs-number">2</span>), sentences[i], sentences[j]])
para_df = pd.DataFrame(para_list, columns=[<span class="hljs-string">'Paraphrase Likelihood'</span>, <span class="hljs-string">'Sentence 1'</span>, <span class="hljs-string">'Sentence 2'</span>])
para_df.index = np.arange(<span class="hljs-number">1</span>, len(para_df) + <span class="hljs-number">1</span>)
para_df.index.name = <span class="hljs-string">'Result'</span>
para_df</pre>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/a3161673189197bf0985f6cb1f2c3dc8.png" alt="The image shows how to predict textual data with transformers." class="wp-image-53023" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206154022im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/NLP-Guide-How-to-Predict-Textual-Data-With-Transformers_7.png?resize=897%2C298&amp;ssl=1"/><figcaption><em> Predicting paraphrasing with Sentence BERT | Source: Author</em></figcaption></figure></div>



<p>我们可以看到，这些例句中的一些是相互转述的可能性很低，42%是我们在这里看到的“<em>在2010年中期的macbook笔记本电脑上工作吗？？？</em> <em> (Macintosh HD OS X版本10.9.4) </em>【被转述】<em>如何在我的mac 0s x上播放？</em></p>



<p>这一点的美妙之处在于，我们可以很容易地将它应用到大量的例子中。在我们的亚马逊数据集中，我们有超过7500个例子。让我们看看我们可以预测哪些可能的释义。处理所有7，588个示例需要14秒多一点。这个时间可能会有所不同，取决于你在哪里运行你的笔记本电脑，但一般来说，这是很快考虑到它在引擎盖下做什么。</p>



<pre class="hljs">%%time
paraphrases = util.paraphrase_mining(model, all_sentences, top_k=<span class="hljs-number">1</span>)</pre>



<pre class="hljs">CPU times: user <span class="hljs-number">5</span>min <span class="hljs-number">34</span>s, sys: <span class="hljs-number">27.4</span> s, total: <span class="hljs-number">6</span>min <span class="hljs-number">2</span>s
Wall time: <span class="hljs-number">13.6</span> s</pre>



<p>我们的最佳结果是几乎相同的句子，所以它们并不是真正的相互转述。</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/3b36894df83e99aa06e6cfb4d33dd589.png" alt="The image shows how to predict textual data with transformers." class="wp-image-53022" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206154022im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/NLP-Guide-How-to-Predict-Textual-Data-With-Transformers_8.png?ssl=1"/><figcaption><meta http-equiv="content-type" content="text/html; charset=utf-8"/><em> Predicting paraphrasing with Sentence BERT | Source: Author</em></figcaption></figure></div>



<p>但是，如果我们看看一些较低的分数，我们可以看到它确实捕捉到了一些有趣的语言细微差别。</p>



<pre class="hljs">para_df.query(<span class="hljs-string">'0.75 &lt;= `Paraphrase Likelihood` &lt;= 0.85'</span>)</pre>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/538111e9dc54606d7ef071d068530625.png" alt="The image shows how to predict textual data with transformers." class="wp-image-53021" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206154022im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/NLP-Guide-How-to-Predict-Textual-Data-With-Transformers_9.png?ssl=1"/><figcaption><meta http-equiv="content-type" content="text/html; charset=utf-8"/><em> Predicting paraphrasing with Sentence BERT | Source: Author</em></figcaption></figure></div>



<p>为了更好地观察，让我们看一下随机抽样的结果。</p>



<pre class="hljs"><span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> sample_prar_df.sample(n=<span class="hljs-number">20</span>).itertuples():
    print(row[<span class="hljs-number">2</span>])
    print(f<span class="hljs-string">'------------------ {row[1]}------------------'</span>)
    print(row[<span class="hljs-number">3</span>])
    print(<span class="hljs-string">'='</span>*<span class="hljs-number">50</span>)</pre>



<pre class="hljs">Is this version a subscription product that has to be renewed every year?
------------------ <span class="hljs-number">0.82</span>------------------
Is this a subscription <span class="hljs-keyword">for</span> one year?
==================================================
Is it a renewal <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span>&amp;
------------------ <span class="hljs-number">0.77</span>------------------
Is this a <span class="hljs-number">1</span> yr renewal. It didn<span class="hljs-string">'t say anything on the listing. Thanks
==================================================
Is this original installation software or only an update? I do not have iLife on my computer.
------------------ 0.76------------------
Is ilife 9 a stand alone program or an upgrade of previous ilife software?
==================================================
Do you have to use Dragon with a microphone?
------------------ 0.75------------------
Can it work with Dragon Naturally Speaking?
==================================================
Can I transfer from Quicken for PC to quick book for Mac
------------------ 0.76------------------
Is this version of Quicken for Mac ok to buy
==================================================
can i use this on all three of my macs?
------------------ 0.83------------------
Can this be installed into 3 Macs?
==================================================
Will this version allow for 1 user/ 2 computers?
------------------ 0.81------------------
Can I install on two computers for 1 user?
==================================================
My MAC does not have a CD drive - can this be downloaded?
------------------ 0.78------------------
Does this come with a CD? Or is it a download? My new MacBook doesn'</span>t have a CD slot.
==================================================
you send me the codes via email?
------------------ <span class="hljs-number">0.76</span>------------------
<span class="hljs-keyword">if</span> i buy this one you will send the code to my e-mail ?
==================================================
can it be put on computer
------------------ <span class="hljs-number">0.75</span>------------------
can i install this on my computer can my sister put it on her computer also
==================================================
Better than Quicken? Is there something better than Quicken <span class="hljs-keyword">for</span> Mac?
------------------ <span class="hljs-number">0.81</span>------------------
Is this version of Quicken <span class="hljs-keyword">for</span> Mac ok to buy
==================================================
<span class="hljs-keyword">is</span> efile included? -- nothing <span class="hljs-keyword">is</span> specifically mentioned other <span class="hljs-keyword">in</span> the comparison of products
------------------ <span class="hljs-number">0.79</span>------------------
Does it include free efile
==================================================
Can I just simply rip DVDs, including those infused <span class="hljs-keyword">with</span> copy protection?
------------------ <span class="hljs-number">0.84</span>------------------
can I rip dvd<span class="hljs-string">'s, cd'</span>s <span class="hljs-keyword">with</span> this download?
==================================================
Can you please tell me <span class="hljs-keyword">if</span> this <span class="hljs-keyword">is</span> compatible <span class="hljs-keyword">with</span> Mac Mountain Lion <span class="hljs-keyword">or</span> Mavericks?
------------------ <span class="hljs-number">0.81</span>------------------
Will this version work <span class="hljs-keyword">with</span> mac Mavericks?
==================================================
Will this work on a windows <span class="hljs-number">8</span> tablet ?
------------------ <span class="hljs-number">0.83</span>------------------
will this work on Windows <span class="hljs-number">8</span>?
==================================================
what <span class="hljs-keyword">is</span> the license deal? What<span class="hljs-string">'s the deal here?
------------------ 0.76------------------
Can you be more specific about license specifications? Thanks for info
==================================================
Can I use this software on my macbook and if so how?
------------------ 0.83------------------
Can this software work on a Mac?
==================================================
can you do business cards and is there clipart
------------------ 0.82------------------
Can you make business cards?
==================================================
What are the main improvements of Manga Studio EX 5 to the previous EX version? Is it worth the upgrade?
------------------ 0.75------------------
What is the main difference between Manga Studio 5 and Manga Studio EX5?
==================================================
can I install it on my laptop?
------------------ 0.85------------------
Can I install it on my desktop and laptop?
</span></pre>



<p>这里有一些有趣的细微差别，因为人们用混乱而真实的方式表达问题，如“<em>什么是许可协议？</em>”。上面我们可以看到这样的措辞:</p>



<ul><li><em>什么是许可协议？这是怎么回事？</em></li><li>你能更具体地说明一下许可证的规格吗？感谢信息</li></ul>



<p>这些例子被看做是彼此的转述，得分0.76。这很好，因为句子的结构非常不同。你或我会知道它们是相似的，但很难编写规则来知道这些类型的句子是相似的。</p>



<p>同样，如果我们看这些例子:</p>



<ul><li>包含efile吗？—产品对比中未特别提及其他内容</li><li><em>是否包含免费文件</em></li></ul>



<p>我们认为这些被预测为得分为0.79的转述。同样，第一句话比第二句话长得多，包含的信息对于确定这些信息是否与同一主题相关并不真正有用，例如，声明产品中没有提到它是额外的信息，但不会改变问题的性质。查询答案"<em>是否包含免费efile？</em>”很可能是与第一个查询相同的答案。</p>



<p>在上面的例子中，我们预测了数据集中转述句子的最佳例子。换句话说，对于每一句话，该模型将在数据集中找到最佳的释义替代示例。我们可能希望找到不止一个例子，因为在这样的数据集中，很可能有多个潜在的释义例子。我们可以通过改变top_k参数来做到这一点。</p>



<pre class="hljs">paraphrases = util.paraphrase_mining(model, all_sentences, top_k=<span class="hljs-number">5</span>)
para_list = []



<span class="hljs-keyword">for</span> paraphrase <span class="hljs-keyword">in</span> sorted(paraphrases, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-keyword">True</span>):
    score, i, j = paraphrase
    para_list.append([round(score, <span class="hljs-number">2</span>), all_sentences[i], all_sentences[j]])
para_df = pd.DataFrame(para_list, columns=[<span class="hljs-string">'Paraphrase Likelihood'</span>, <span class="hljs-string">'Sentence 1'</span>, <span class="hljs-string">'Sentence 2'</span>])
para_df.index = np.arange(<span class="hljs-number">1</span>, len(para_df) + <span class="hljs-number">1</span>)
para_df.index.name = <span class="hljs-string">'Result'</span>
para_df</pre>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/63af71556451b8962cb031f1ba731098.png" alt="The image shows how to predict textual data with transformers." class="wp-image-53020" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206154022im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/NLP-Guide-How-to-Predict-Textual-Data-With-Transformers_10.png?ssl=1"/><figcaption><meta http-equiv="content-type" content="text/html; charset=utf-8"/><em> Predicting paraphrasing with Sentence BERT | Source: Author</em></figcaption></figure></div>



<h2 id="h-conclusion">结论</h2>



<p>在这篇文章中，我们看了一些基于transformer的模型被用来预测文本的不同特征的方法。我们研究了三个主要领域，从基于单词到基于语法，再到整个句子，这三个领域的复杂性都在增加。我们关注的主要领域是:</p>



<ol><li><strong>预测拼写错误</strong>:我们使用了许多库，如spaCy和NeuSpell，并展示了它们如何使用底层的transformer模型来尝试和预测拼写错误。最终，与传统算法相比，基于转换器的模型可能不会为纠正拼写错误增加太多价值。但这里的关键是，我们看了一些有用的库，现在更好地理解了这个问题，并可能使用这些库的一些其他功能，因为我们知道他们</li><li>预测语法错误:我们接着查看了约翰·斯诺实验室的NLP库，它提供了一系列漂亮的特性。我们使用语法错误特征来尝试和预测我们数据集中的一个句子在语法上是否正确。基于Transformer的模型似乎更适合这项任务，它似乎可以正确识别句子样本中的语法错误。在实现下一个NLP管道时，一定要牢记在心。</li><li>具有讽刺意味的是，随着我们任务的语言复杂性的增加，transformer模型似乎提供了更多的价值。我们使用句子转换器库在亚马逊数据集中查找句子，这些句子是数据集中其他句子的释义。这看起来非常有用，因为模型不知道我们的例子中使用的技术术语、版本和短语。这似乎是一个特性，您可以用它来识别一个新的客户查询实际上是否只是一个更常见的查询的重新表述。</li></ol>



<p>很明显，越来越多的应用程序建立在基于transformer的模型之上，这将更容易为您的特定用例找到和使用应用程序。理想情况下，您可以找到一个库来执行您需要的所有功能，但是正如我们在这里看到的，如果您不能在一个地方找到您需要的所有功能，您可以一起使用不同的库。</p>



<h3>参考</h3>



<p>下面是我们在这篇文章中使用的库的列表。您可以在这些库中找到更多的特性，所以一旦您开始使用它们，我鼓励您查看您认为可能对您的用例有用的任何其他特性:</p>



<ul><li>spaCy projects:spaCy projects是一个检查酷炫新车型的好地方。如果你愿意，你可以在这里<a href="https://web.archive.org/web/20221206154022/https://github.com/explosion/spaCy/blob/master/website/UNIVERSE.md" target="_blank" rel="noreferrer noopener nofollow">上传你自己的模型</a>！</li><li>我们用这个库做了一个不同的拼写检查的例子。</li><li>约翰·斯诺实验室:为了进行语法检查，我们使用了这个库中的例子。正如我所提到的，这里有这么多很酷的NLP特性和模型可以免费获得，你很可能会找到对你的用例有用的东西。</li><li><a href="https://web.archive.org/web/20221206154022/https://www.sbert.net/examples/applications/paraphrase-mining/README.html" target="_blank" rel="noreferrer noopener nofollow">句子变形金刚</a>:最后，为了释义，我们使用了句子变形金刚库。和约翰·斯诺实验室一样，在他们的网站上有很多基于变压器模型的不同应用的例子。</li></ul>
        </div>
        
    </div>    
</body>
</html>