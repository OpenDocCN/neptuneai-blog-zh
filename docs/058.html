<html>
<head>
<title>Deploying Computer Vision Models: Tools &amp; Best Practices </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>部署计算机视觉模型:工具和最佳实践</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/deploying-computer-vision-models#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/deploying-computer-vision-models#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>计算机视觉模型已经变得异常复杂，有各种各样的用例来提高业务效率、自动化关键决策系统等等。但是，如果一个有前途的模型在生产中表现不尽如人意，它可能会成为一个代价高昂的负担。话虽如此，我们如何开发和部署计算机视觉模型事关重大！</p>



<p>机器学习工程师正在他们的模型部署系统中慢慢接受DevOps实践，但这并没有结束！我们还需要考虑几个方面，比如代码版本、部署环境、持续培训/再培训、生产模型监控、数据漂移和质量、模型特性和超参数等等。但其中一些实践是特定于机器学习系统的。</p>



<p>在本文中，我们将了解如何在牢记上述方面的同时部署计算机视觉模型。</p>



<h2 id="h-computer-vision-model-lifecycle">计算机视觉模型生命周期</h2>



<p>考虑到只有少数开发的模型进入连续生产环境，部署计算机视觉模型或任何机器学习模型本身就是一个挑战。</p>



<p>CV模型生命周期从收集质量数据开始，到准备数据、训练和评估模型、部署模型、监控和重新训练模型。可以通过下图直观地看到这一点:</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" src="../Images/a7750dbdcdb5da66982967911d59b9d1.png" alt="Computer vision model lifecycle" class="wp-image-65849" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models6.png?resize=651%2C561&amp;ssl=1"/><figcaption><em>Computer vision model lifecycle | Source: Author</em></figcaption></figure></div>



<p>在本文中，我们将关注计算机视觉模型的部署阶段。您将学习模型部署的关键方面，包括<a href="/web/20221201165600/https://neptune.ai/blog/best-mlops-tools-for-computer-vision-project" target="_blank" rel="noreferrer noopener">工具</a>，最佳实践，以及部署计算机视觉模型时需要考虑的事项。</p>







<h2 id="h-cv-model-deployment-modes-platforms-ui">CV模型部署模式、平台和UI</h2>



<p>在这一节中，我们将深入探讨部署和服务计算机视觉模型的不同方式。这里需要考虑的关键因素是:</p>



<ul><li>部署模式(REST/RPC端点、边缘、混合)</li><li>如何提供给最终用户</li><li>易于访问硬件和部署平台的可扩展性</li></ul>



<h3>部署模式(REST/RPC端点、边缘、混合)</h3>



<p>托管在内部/云平台上的机器学习模型通常通过API端点来部署或访问。像<a href="https://web.archive.org/web/20221201165600/https://restfulapi.net/" target="_blank" rel="noreferrer noopener nofollow"> REST </a> / <a href="https://web.archive.org/web/20221201165600/https://en.wikipedia.org/wiki/Remote_procedure_call" target="_blank" rel="noreferrer noopener nofollow"> RPC </a>这样的API本质上为两个系统如何交互提供了语言和契约。</p>



<p>另一种模式是在边缘设备上部署模型，其中通过CV/认知应用的数据消费发生在起始点。通常，部署也可以是混合的，即API端点和边缘设备的组合。</p>



<h3>它们如何提供给最终用户</h3>



<p>根据最终用户使用模型的方式，界面会有所不同。模型可以通过简单的bash命令行界面提供给一些用户，而其他用户可以通过基于web或基于应用程序的交互式UI来使用它。在大多数情况下，模型可以通过API提供，下游应用程序使用结果。</p>



<h3>易于访问硬件和部署平台的可扩展性</h3>



<p>就像在UI/UX方面可用的选项一样，我们可以在平台或硬件上部署生产模型的大量选项也是可用的。这包括开发人员经常进行代码开发的笔记本电脑、远程机器、远程虚拟机、托管jupyter笔记本电脑的远程服务器、部署在云环境中的带有编排器的容器，等等。</p>



<p>以上提到的每一点都将在下面的章节中详细阐述。</p>



<h2 id="h-cv-deployment-through-api-rest-rpc-endpoints">通过API (REST/RPC)端点的CV部署</h2>



<p>REST代表“代表性状态转移”(作者<a href="https://web.archive.org/web/20221201165600/https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm" target="_blank" rel="noreferrer noopener nofollow">罗伊·菲尔丁</a>)。简而言之，REST是一种客户机-服务器关系，其中数据通过简单的格式可用/传输，比如JSON/XML。“RPC”部分代表“远程过程调用”，它通常类似于在JavaScript、Python等中调用函数。请阅读这篇文章以获得对<a href="https://web.archive.org/web/20221201165600/https://www.smashingmagazine.com/2016/09/understanding-rest-and-rpc-for-http-apis/" target="_blank" rel="noreferrer noopener nofollow"> REST/RPC </a>协议的详细理解。</p>



<p id="separator-block_627e493524943" class="block-separator block-separator--10"> </p>







<p>当ML部署API与另一个系统交互时，这种通信的接触点是通过REST/RPC端点发生的。对于API，端点通常由服务器或服务的URL组成。它就像一个软件中介，允许两个应用程序相互交换数据。它也是一组用于构建软件应用程序的例程、协议和工具。一些流行的预训练CV云服务完全在API端点上提供服务，例如，Google Vision API。</p>



<p>REST只是决定了API架构的外观。简单地说，这是开发人员在创建API时遵循的一组规则。</p>



<p>通常，每个URL被称为一个请求(API请求),而发送回您的数据(主要作为JSON)被称为一个响应。</p>



<p>一个<a href="https://web.archive.org/web/20221201165600/https://israelaminu.medium.com/deploying-ml-models-using-django-rest-api-part-1-da0370a07b90" target="_blank" rel="noreferrer noopener nofollow"> API请求</a>主要由四个部分组成:</p>



<ul><li>端点:端点有一个叫做URL的东西，它决定了你请求的资源或数据。在API的上下文中，这些URL或路径被称为端点。</li></ul>



<ul start="2"><li><strong>方法:</strong>方法是你发送给服务器的请求，比如GET、POST PUT、DELETE等。</li></ul>



<ul start="3"><li><strong>头:</strong>头携带请求和响应体、授权、缓存cookies等信息。</li></ul>



<ul start="4"><li><strong>数据:</strong>通常以JSON字符串和数据URL的形式出现。</li></ul>



<p>下面提到了一些我们可以用来创建Pythonic REST APIs的工具(假设我们使用Python作为ML后端代码)。本文的范围不是深入研究这些框架，而是给出它们的一个高层次的概述。</p>







<p><a href="https://web.archive.org/web/20221201165600/https://flask.palletsprojects.com/en/2.1.x/" target="_blank" rel="noreferrer noopener nofollow"> Flask </a>是用于构建web应用和REST APIs的Python微框架。Flask的主要工作是处理HTTP请求，并将它们路由到后端应用程序中的适当函数。</p>







<p>构建REST APIs的另一个流行选项是Django REST框架。构建API的模式通常被添加到Django web UI项目之上。</p>







<p>FastAPI是一个Python web框架，专门用于构建高效的API。它使用Python类型的提示，并内置了对异步操作的支持。FastAPI框架由于其易用性和多功能性，最近变得越来越流行。</p>



<p>通过python APIs部署计算机视觉应用就像部署任何机器学习模型一样。对于面向计算机视觉部署的API，重要的是您需要传递图像/视频进行处理，并作为后端部署的响应。可以通过下面讨论的一些方法发送图像/视频或其他数据文件</p>



<h4>分析器</h4>



<p>REST框架通常有内置的解析器，用来检测请求中的数据类型。其中有JSONParser、FormParser、MultiPartParser、FileUploadParser等等。在计算机视觉部署中，FileUploadParsers将在处理从后端到前端的数据传输中发挥主要作用。</p>



<p>下面显示了一个带有Flask框架的文件上传解析器(在我们的例子中，是一个图像/视频等)的样本片段。当然，代码结构随着Django和FastAPI框架的不同而不同。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, render_template, request, redirect, url_for

app = Flask(__name__)

<span class="hljs-meta">@app.route('/')</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">index</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-keyword">return</span> render_template(<span class="hljs-string">'index.html'</span>)

<span class="hljs-meta">@app.route('/', methods=['POST'])</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">upload_file</span><span class="hljs-params">()</span>:</span>
    uploaded_file = request.files[<span class="hljs-string">'file'</span>]
    <span class="hljs-keyword">if</span> uploaded_file.filename != <span class="hljs-string">''</span>:
        uploaded_file.save(uploaded_file.filename)
    <span class="hljs-keyword">return</span> redirect(url_for(<span class="hljs-string">'index'</span>))</pre>



<p class="has-text-align-center has-small-font-size"><em>代码片段| <a href="https://web.archive.org/web/20221201165600/https://blog.miguelgrinberg.com/post/handling-file-uploads-with-flask" target="_blank" rel="noreferrer noopener nofollow">来源</a> </em></p>



<p id="separator-block_627e495a24944" class="block-separator block-separator--15"> </p>



<p>对于python API创建的详细指南，这将是一篇很好的<a href="https://web.archive.org/web/20221201165600/https://realpython.com/api-integration-in-python/" target="_blank" rel="noreferrer noopener nofollow">文章</a>来通读。</p>



<p>在已部署的机器学习模型的上下文中，用户可以利用API端点和相关联的URL路径来与底层推理引擎传输数据、流程和事务，这意味着它可以来回传输图像、视频数据和命令。随着时间的推移，使用API端点来消费计算机视觉模型的情况必然会增加。</p>



<h3>计算机视觉API提供者</h3>



<p>有许多服务提供商提供可以直接与您的应用程序集成的计算机视觉API。下面将详细讨论其中的一些。有趣的是，您可以选择构建自己的用户界面，或者在这些API上使用默认的服务提供商用户界面。</p>



<h4>妮克丝</h4>



<p>Nyckel 正在提供计算机视觉API以及其他可以通过RESTful HTTPS请求访问的API。它们提供了许多预训练的CV专用用例，如无条形码扫描仪、质量检测系统、人类情感分析等。</p>



<p id="separator-block_627e49cb24946" class="block-separator block-separator--15"> </p>







<p class="has-text-align-center has-small-font-size"><em> Nyckel认知解决方案| <a href="https://web.archive.org/web/20221201165600/https://www.nyckel.com/" target="_blank" rel="noreferrer noopener nofollow">来源</a> </em></p>



<p id="separator-block_627e49a524945" class="block-separator block-separator--20"> </p>



<p>Nyckel通过https请求支持三种输入数据类型:文本、图像和表格。</p>



<p><strong> 1。Text </strong>:传递文本数据的请求和响应将作为JSON字符串处理。</p>



<p><strong> 2。Image </strong>:可以通过以下方式提供传递图像数据的请求:</p>



<ul><li>Raw image bytes</li><li>作为JSON请求中的数据URI</li></ul>



<p>传递图像数据的响应将以JSON字符串的形式提供，如下所示:</p>



<ul><li>指向图像的url</li><li>包含图像的数据URI。</li></ul>



<p><strong> 3。表格</strong>:它们作为<a href="https://web.archive.org/web/20221201165600/https://www.w3schools.com/js/js_json_syntax.asp" target="_blank" rel="noreferrer noopener nofollow"> JSON键值对</a>来处理。即请求和响应。它允许用户构建自定义ui，或者作为更大的应用程序管道中的中间API。</p>



<p>关于访问Nyckel API的完整文档可以通过web文档共享<a href="https://web.archive.org/web/20221201165600/https://www.nyckel.com/docs" target="_blank" rel="noreferrer noopener nofollow">这里</a>阅读。</p>



<h4>aws识别</h4>



<p>它是更广泛的<a href="https://web.archive.org/web/20221201165600/https://aws.amazon.com/" target="_blank" rel="noreferrer noopener nofollow"> AWS云解决方案套件</a>的一部分。该工具提供了预先训练和可定制的计算机视觉功能，可以从图片、视频等中提取信息。“Rekognition”非常适合初学者，因为它不需要深入了解与计算机视觉相关的理论。Rekognition的现成解决方案包括内容审核、面部识别、视频分析、文本识别、<a href="https://web.archive.org/web/20221201165600/https://docs.aws.amazon.com/rekognition/latest/dg/what-is.html" target="_blank" rel="noreferrer noopener nofollow">等</a>。</p>



<p>Amazon Rekognition提供了两个API集。<em>亚马逊Rekognition Image </em>用于分析图片，亚马逊Rekognition Video用于分析视频。需要分析的数据将被上传到<a href="https://web.archive.org/web/20221201165600/https://aws.amazon.com/s3/" target="_blank" rel="noreferrer noopener nofollow"> S3桶</a>中，可以通过<a href="https://web.archive.org/web/20221201165600/https://docs.aws.amazon.com/rekognition/latest/dg/setup-awscli-sdk.html" target="_blank" rel="noreferrer noopener nofollow">AWS CLI&amp;SDK</a>调用。</p>



<p>这两种API都可以分析图像和视频，为您的应用提供洞察。或者如前所述，您可以将其用作内部API，通过REST/RPC端点进行访问。</p>



<p id="separator-block_62826e5a546ed" class="block-separator block-separator--10">谷歌云视觉API</p>







<h4><a href="https://web.archive.org/web/20221201165600/https://cloud.google.com/vision/?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=japac-IN-all-en-dr-bkwsrmkt-all-super-trial-e-dr-1009882&amp;utm_content=text-ad-none-none-DEV_c-CRE_529584280042-ADGP_Hybrid%20%7C%20BKWS%20-%20EXA%20%7C%20Txt%20~%20AI%20%26%20ML%20~%20Vision%20AI_Vision-google%20cloud%20vision%20api-KWID_43700037527390326-aud-1644542956068%3Akwd-203288731207&amp;userloc_9040215-network_g&amp;utm_term=KW_google%20cloud%20vision%20api&amp;gclid=CjwKCAjw9-KTBhBcEiwAr19ig9cg52OrDA0cT8PZTIfl2twWFZr69nZaEwqZrej5OQ5gKz-whOq4QhoCv5AQAvD_BwE&amp;gclsrc=aw.ds" target="_blank" rel="noreferrer noopener nofollow"> Vision API </a>通过REST/RPC API提供强大的预训练机器学习模型。与亚马逊的Rekognition类似，它可以为图像分配标签，并快速将其归类到预定义的类别中。它可以检测物体和人脸，阅读印刷和手写文本。</h4>



<p>下面显示的部署架构是针对利用Google Cloud Vision API的OCR应用程序的。</p>



<p>使用Vision API的OCR(光学字符识别)应用程序中的数据流包括以下步骤:</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/330985937efd2d2336bfe54eae7c0765.png" alt="Google Cloud Vision API" class="wp-image-65868" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models25.png?resize=800%2C442&amp;ssl=1"/><figcaption><em>Google Cloud Vision API | <a href="https://web.archive.org/web/20221201165600/https://cloud.google.com/functions/docs/tutorials/ocr#functions_ocr_setup-python" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>The flow of data in the OCR (optical character recognition) application using Vision API involves steps shown below:</p>



<div id="case-study-numbered-list-block_62826eee546ef" class="block-case-study-numbered-list ">

    
    <h2 id="h-"><span class="c-list__counter"> 1 </span>上传了包含任何语言文本的图像</h2>

    <ul class="c-list">
                    <li class="c-list__item"><span class="c-list__counter"> 2 </span>触发视觉API提取文本并检测源语言</li>
                    <li class="c-list__item">如果目标语言与源语言不同，翻译会排队等候</li>
                    <li class="c-list__item"><span class="c-list__counter"> 4 </span>翻译API被触发，翻译翻译队列中的文本</li>
                    <li class="c-list__item"><span class="c-list__counter"> 5 </span>将翻译后的文本从结果队列保存到云存储中，供以后访问</li>
                    <li class="c-list__item">更多信息，请浏览谷歌云<a href="https://web.archive.org/web/20221201165600/https://cloud.google.com/functions/docs/tutorials/ocr#functions_ocr_setup-python" target="_blank" rel="noreferrer noopener nofollow"> OCR教程</a>。</li>
            </ul>
</div>



<p>Kairos人脸识别API</p>



<h4>Kairos人脸识别API使用计算机视觉算法来分析在图像和视频中发现的类似人类的人脸，并返回有关检测到的人脸的数据。这些数据可用于图像搜索、匹配和比较人脸，或者检测性别或年龄等特征。</h4>



<p> </p>



<p id="separator-block_6283845c546f7" class="block-separator block-separator--5">Kairos是一个相当容易实现的计算机视觉API，为定制业务用例提供基于云的面部识别服务。</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/a4f2701bea79e665796c3a6f7295459f.png" alt="Kairos face recognition API" class="wp-image-65876" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models33.png?resize=750%2C500&amp;ssl=1"/><figcaption><em>Kairos face recognition API | <a href="https://web.archive.org/web/20221201165600/https://viso.ai/deep-learning/face-detection-overview/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>CV模型的边缘部署</p>



<h2 id="h-edge-deployment-of-cv-models">在深入了解边缘部署的概念之前，了解什么是<a href="https://web.archive.org/web/20221201165600/https://www.ibm.com/in-en/cloud/edge-computing?utm_content=SRCWW&amp;p1=Search&amp;p4=43700055271017258&amp;p5=e&amp;gclid=CjwKCAjw9-KTBhBcEiwAr19ig_iJROYXYPGBKOS8DKib7i6Ds6juKgEZg5geQ9o9rxDWQyZ00kuBwhoCMxcQAvD_BwE&amp;gclsrc=aw.ds" target="_blank" rel="noreferrer noopener nofollow">边缘计算</a>非常重要。</h2>



<p>简而言之，边缘计算是一个在相同位置或靠近数据来源的位置进行计算的过程。</p>



<p>如今，企业被大量数据淹没，他们真的不知道如何处理这些数据。传统的分析方法是通过互联网传输生成的数据，用于其他地方的计算工作。但是，由于生成的数据量巨大，并且存在相关的延迟，这种模型已经变得不够用了。这些问题现在通过边缘计算系统来解决。下图显示了云与边缘云与边缘计算的直接对比。</p>



<p> </p>



<p id="separator-block_62826f72546f5" class="block-separator block-separator--10">在CV edge部署的上下文中，它指的是在云或内部基础架构中创建和训练并部署在边缘设备上的计算机视觉模型。最先进的基于计算机视觉的系统，如自主车辆、制造业中使用的工业机器人、自主无人机等。利用高级别的边缘计算/部署功能。</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/09f6ff7901b6b93cd0bab9be905651f6.png" alt="Compare edge cloud vs cloud computing vs edge computing" class="wp-image-65880" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models37.png?resize=785%2C707&amp;ssl=1"/><figcaption><em>Compare edge cloud vs cloud computing vs edge computing | <a href="https://web.archive.org/web/20221201165600/https://www.techtarget.com/searchdatacenter/definition/edge-computing#:~:text=Edge%20computing%20is%20the%20deployment,source%20at%20the%20network%20edge." target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>让我们来看看计算机视觉算法在边缘部署的一些经典用例。下面的示例简要介绍了边缘计算机视觉系统如何帮助零售商(如杂货店)监控现场活动，并及时采取措施优化销量。</p>



<p>现场安装的摄像机可以捕捉顾客在收银台排队、在特定区域拥挤、识别空货架、一段时间内顾客的购买模式、自助收银台发生的盗窃/欺诈等活动的实时视频。</p>



<p>下图显示了在超市环境中被识别和跟踪的对象。完整的论文可以通过这个<a href="https://web.archive.org/web/20221201165600/https://www.researchgate.net/figure/Object-detection-in-a-supermarket-setting_fig3_358501610/download" target="_blank" rel="noreferrer noopener nofollow">链接</a>访问。</p>



<p> </p>



<p id="separator-block_6283848e546f8" class="block-separator block-separator--5">CV模型的另一个应用领域是工业自动化。下图显示了一个在工业环境中对焊缝进行实时质量检测的例子。所示的机器人臂安装有照相机，该照相机识别焊接池中哪里出现问题，以便可以采取纠正措施。捕获的输入流被摄取到基于英特尔Edge AI处理器的系统中。该解决方案建立在基于计算机视觉的人工智能推理引擎上，可以检测焊接缺陷，并发送命令立即暂停机械臂，以便及时采取纠正措施。</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/537cbbaac7658eabe4ae1aad7a4651eb.png" alt="Object detection in a supermarket setting" class="wp-image-65872" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models29.png?resize=754%2C424&amp;ssl=1"/><figcaption><em>Object detection in a supermarket setting | <a href="https://web.archive.org/web/20221201165600/https://www.researchgate.net/figure/Object-detection-in-a-supermarket-setting_fig3_358501610/download" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/b0d912b2b153b2ad3296f6f4a6b2137a.png" alt="Object tracking in a supermarket setting" class="wp-image-65889" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models46.png?resize=754%2C272&amp;ssl=1"/><figcaption><em>Object tracking in a supermarket setting | <a href="https://web.archive.org/web/20221201165600/https://www.researchgate.net/figure/Object-tracking-in-a-supermarket-setting_fig6_358501610/download" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p> </p>



<p id="separator-block_6283849c546f9" class="block-separator block-separator--5">几乎所有流行的云服务提供商都提供边缘部署服务。下面讨论了其中的一些问题。</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/0d9f17d5dd6a27c87e3ea1bb130c9504.png" alt="Weld porosity detection system" class="wp-image-65852" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models9.jpg?ssl=1"/><figcaption><em>Weld porosity detection system | <a href="https://web.archive.org/web/20221201165600/https://www.manufacturingtomorrow.com/article/2021/10/ai-machine-vision-based-automated-weld-defect-detection-for-manufacturing-industry/17816" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p><a href="https://web.archive.org/web/20221201165600/https://www.ibm.com/cloud/edge-application-manager" target="_blank" rel="noreferrer noopener nofollow"> <strong> <em> IBM Edge应用管理器</em></strong></a><strong><em>(IEAM)</em></strong>是一个模型管理系统，可以在边缘设备上创建、部署和更新机器学习模型。这种特定的解决方案可以管理元数据，并跨多个边缘设备同步部署。在高层次上，该应用程序将有两个组件，一个在云中，另一个托管在边缘设备上，它们将在HTTPS连接的帮助下同步。<a href="https://web.archive.org/web/20221201165600/https://www.ibm.com/cloud/edge-application-manager" target="_blank" rel="noreferrer noopener nofollow"> IEAM </a>模型管理系统的代表图像如下图所示。</p>



<p> </p>



<p id="separator-block_628384ab546fa" class="block-separator block-separator--5">Azure的边缘部署解决方案</p>







<h3>使用<a href="https://web.archive.org/web/20221201165600/https://www.google.com/search?q=Azure+stack+edge&amp;oq=Azure+stack+edge&amp;aqs=chrome..69i57j0i22i30l9.413j0j4&amp;sourceid=chrome&amp;ie=UTF-8" target="_blank" rel="noreferrer noopener nofollow"> Azure stack edge </a>，可以将所有Azure功能(如计算、存储、网络和GPU加速的机器学习)带入任何边缘位置。</h3>



<p>边缘设备上的视频分析器的部署架构可能使用以下Azure服务:(仅列出了相关的少数服务，实际列表可能会因应用程序而异。)</p>



<p><strong> <a href="https://web.archive.org/web/20221201165600/https://azure.microsoft.com/en-us/services/machine-learning/" target="_blank" rel="noreferrer noopener nofollow"> Azure机器学习</a> : </strong>在基于云的环境中构建、训练、部署和管理ML模型。</p>



<ul><li><strong> <a href="https://web.archive.org/web/20221201165600/https://azure.microsoft.com/en-us/products/video-analyzer/" target="_blank" rel="noreferrer noopener nofollow"> Azure视频分析器</a> : </strong>使用您选择的AI构建智能视频应用。</li><li>Azure container registry:构建、存储和管理容器化的(Docker)计算机视觉/ML模型。</li><li>Azure stack edge:设计用于边缘的机器学习推理。数据在传输到Azure之前在边缘进行预处理，Azure是一种加速器硬件，可以提高边缘人工智能推理的性能。</li><li><strong> <a href="https://web.archive.org/web/20221201165600/https://azure.microsoft.com/en-us/services/iot-hub/" target="_blank" rel="noreferrer noopener nofollow"> Azure物联网中心</a> : </strong>一种基于云的托管服务，用于物联网设备和Azure之间的双向通信。</li><li><strong> <a href="https://web.archive.org/web/20221201165600/https://azure.microsoft.com/en-us/blog/storage-for-media-services/" target="_blank" rel="noreferrer noopener nofollow">媒体服务存储</a> : </strong>使用<a href="https://web.archive.org/web/20221201165600/https://azure.microsoft.com/en-us/product-categories/storage/" target="_blank" rel="noreferrer noopener nofollow"> Azure存储</a>存储大型媒体文件。</li><li><strong>本地数据:</strong>存储并用于机器学习模型的训练。</li><li>下面的示例图简要介绍了Azure如何帮助杂货店等零售商监控实时事件并采取及时行动。现场安装的摄像机可以捕捉顾客在收银台排队、顾客在特定区域拥挤、识别空货架、顾客在一段时间内的购买模式、自助收银台发生的盗窃或欺诈等活动的实时视频。</li></ul>



<p>下图是Azure edge部署为视频分析系统使用的代表性架构。您可以通过相同的链接详细了解部署架构。</p>



<p>AWS全景</p>



<p id="separator-block_628384b4546fb" class="block-separator block-separator--5"><a href="https://web.archive.org/web/20221201165600/https://aws.amazon.com/panorama/" target="_blank" rel="noreferrer noopener nofollow"> AWS Panorama </a>是亚马逊的一款机器学习(ML)设备和软件开发套件(SDK ),可将CV引入内部/边缘设备，尤其是IP摄像机。企业可以从他们现有的摄像机中访问许多视频资产，但这些数据仍然没有得到利用，主要是因为没有获得洞察力的正确工具。</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/13f42c79c0ae6f10b35feb023547083c.png" alt="Edge deployment solutions by Azure" class="wp-image-65883" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models40.png?resize=813%2C367&amp;ssl=1"/><figcaption><em>Edge deployment solutions by Azure | <a href="https://web.archive.org/web/20221201165600/https://docs.microsoft.com/en-us/azure/architecture/solution-ideas/media/video-analytics-architecture.png" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<h3>通过AWS Panorama，您可以将计算机视觉引入本地设备，同时降低延迟影响。它适用于边缘设备；因此，默认情况下，互联网带宽有限的情况可以顺利管理。此外，用户可以轻松地将定制的训练模型带到边缘，并构建与定制业务逻辑集成的应用程序</h3>



<p> </p>



<p>这里是使用AWS Panorama的停车场汽车计数器应用程序的实现的链接。</p>



<p id="separator-block_628384bf546fc" class="block-separator block-separator--5"> </p>







<p>类似于上面引用的例子，可能有过多的类似应用，例如计算购物中心的访客数量、计算任何给定时间的交通密度、改善餐馆运营等。</p>



<p id="separator-block_628384ca546fd" class="block-separator block-separator--5">CV模型部署UI</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/af5ca0c8d4591aa543862349f2b28c62.png" alt="Parking lot car counter using AWS Panorama" class="wp-image-65901" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models58.png?resize=821%2C461&amp;ssl=1"/><figcaption><em>Parking lot car counter using AWS Panorama | <a href="https://web.archive.org/web/20221201165600/https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2020/12/18/19-Parking-Lot.jpg" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>在讨论了API端点之后，我们讨论CV部署可用的流行UI选项的时机已经成熟。让我们探索一些流行且方便的UI选项。</p>



<h2 id="h-cv-model-deployment-ui">命令行界面</h2>



<p>命令行界面(CLI)是一种基于文本的用户界面(UI)，用于运行程序、管理计算机文件以及与计算机进行交互。CLI接受通过键盘输入的输入命令；在命令提示符下调用的命令然后由计算机运行。</p>



<h3><a href="https://web.archive.org/web/20221201165600/https://en.wikipedia.org/wiki/Bash_(Unix_shell)" target="_blank" rel="noreferrer noopener nofollow"> Bash </a>是Linux、Mac OS最常用的CLI，<a href="https://web.archive.org/web/20221201165600/https://docs.microsoft.com/en-us/powershell/scripting/overview" target="_blank" rel="noreferrer noopener nofollow">PowerShell</a>/Windows的命令提示符。</h3>



<p>这里的要求是CLI识别python文件，该文件包含CV代码和输入数据。结果会生成并存储在您以后可以访问的位置。但是如前所述，由于显而易见的原因，这种模型服务的方式通常对潜在用户不是很有吸引力。</p>



<p>带有Flask-REST API、HTML和CSS的Web应用程序</p>



<p>Flask是一个小型轻量级的Python web框架，它提供了有价值的工具和特性，使得用Python创建web应用程序和API变得更加容易。它允许我们创建轻量级的web应用程序，您可以用相当低的代码在本地机器、云环境或容器中运行。它还可以在浏览器上呈现HTML文本，允许您定制用于模型服务的UI。因此，如果我们能在使用HTML的同时使用CSS，这将变得更具视觉吸引力，与我们在网上冲浪时看到的网络应用程序相一致。</p>



<h3>下面显示了python使用Flask的代码片段:</h3>



<p>通过执行上面显示的代码片段，会发生以下情况:</p>



<p>导入Flask模块并创建Flask web服务器</p>



<pre class="hljs"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, render_template

app = Flask(__name__)

<span class="hljs-meta">@app.route("/")</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">home</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-keyword">return</span> render_template(<span class="hljs-string">"homePage.html"</span>)

<span class="hljs-meta">@app.route("/new_address")</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">salvador</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-keyword">return</span> <span class="hljs-string">"Hello, new_address!"</span>

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    app.run()</pre>



<p>__name__表示当前文件</p>



<ul><li>app . route(“/”)表示默认页面。当我们将浏览器连接到本地主机端口时，会弹出此消息</li><li>render_template呈现代码提供的HTML &amp; CSS文件；这使得用户界面更好！</li><li>来自浏览器的app.route("/new_address ")路由到代码片段中显示的下一个方法，该方法又打印出" Hello，new_address！"</li><li>有关更多信息和实际实施，请参考此<a href="https://web.archive.org/web/20221201165600/https://www.freecodecamp.org/news/how-to-build-a-web-application-using-flask-and-deploy-it-to-the-cloud-3551c985e492/" target="_blank" rel="noreferrer noopener nofollow">文章</a>。</li><li>下面显示了一个使用基于Flask的web应用程序的例子，该应用程序是为多类<a href="/web/20221201165600/https://neptune.ai/blog/image-classification-tips-and-tricks-from-13-kaggle-competitions" target="_blank" rel="noreferrer noopener">图像分类</a>定制的。</li></ul>



<p> </p>



<p>如果你想开发一个类似的应用并进一步阅读，请点击这个<a href="https://web.archive.org/web/20221201165600/https://www.youtube.com/redirect?event=video_description&amp;redir_token=QUFFLUhqbEtlSjQwVjVCcENXRjhjTm9jTWhBYWtYSzNFQXxBQ3Jtc0ttQ1ZCcndTblpZY1hoWVFOSGdUVVFzOG9ZZGZTRGxrMDBoZjYwNmg2OXBHc2gtanRvMjBralF1bEhlNWVJX2NBZ3RtOHlNdTVheUhfc1c5XzFMOGM1UFhrd0ZEZDQ5eUdwRUJHcS1oaklQc3lKSktxTQ&amp;q=https%3A%2F%2Fbuffml.com%2Fmulti-class-image-classification-flask-app-complete-project%2F" target="_blank" rel="noreferrer noopener nofollow">链接</a>。</p>



<p id="separator-block_628384db546fe" class="block-separator block-separator--5">使用Flask的模型部署非常适合本地部署，甚至是在有许多用户使用API的云服务器上。你可以使用`<a href="https://web.archive.org/web/20221201165600/https://docs.docker.com/compose/" target="_blank" rel="noreferrer noopener nofollow"> docker-compose </a>和<a href="https://web.archive.org/web/20221201165600/https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/" target="_blank" rel="noreferrer noopener nofollow"> Nginx负载均衡器</a>构建一个可伸缩的Flask应用程序，其中Nginx是一个开源的HTTP web服务器，也可以充当反向代理服务器。</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/f5b9cde9fcda511a68ae7e28dfa6e9cc.png" alt="Example of using Flask based web application tailored for multiclass image classification" class="wp-image-65860" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models17.jpg?resize=821%2C424&amp;ssl=1"/><figcaption><em>Example of using Flask based web application tailored for multiclass image classification | <a href="https://web.archive.org/web/20221201165600/https://www.youtube.com/watch?v=T8k8TOO4-xc" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>使用Docker-compose，您可以创建由Nginx负载平衡器提供服务的Flask应用程序的多个实例。您可以在这篇<a href="https://web.archive.org/web/20221201165600/https://www.linkedin.com/pulse/building-python-scalable-flask-application-using-nginx-itay-melamed/" target="_blank" rel="noreferrer noopener nofollow">文章</a>中浏览相同的详细实现。</p>



<p>带有Flask API(或任何Python API)和React FE、CSS的Web应用程序</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/9cd994e4f33053f39f1f925e6b7ddb3e.png" alt="Building a Python scalable Flask application using docker-compose and Nginx load balancer" class="wp-image-65859" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models16.png?resize=817%2C397&amp;ssl=1"/><figcaption><em>Building a Python scalable Flask application using docker-compose and Nginx load balancer | <a href="https://web.archive.org/web/20221201165600/https://www.linkedin.com/pulse/building-python-scalable-flask-application-using-nginx-itay-melamed/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>香草烧瓶并不总是用户友好的。自动用户界面更新、动态查询等并不总是有用的。</p>



<h3>此外，我们不能指望它能创造出像React或Angular那样酷的ui，除非你已经在其中嵌入了一些高级的JQuery表单提交技术。React Native 是目前最流行(也是最强大)的web UI工具之一。它支持一些最广泛使用的网络/移动应用程序和界面。</h3>



<p>作为一名熟悉Python的经验丰富的数据科学家，使用基于JavaScript的工具对您来说可能很困难。但是通过将React与Flask API &amp; python耦合用于后端，这就成为了为CV模型创建UI的最酷的方式之一。下面是使用React原生UI进行图像分类的截图。</p>



<p>这里有一个使用React和Tensorflow创建图像分类app的<a href="https://web.archive.org/web/20221201165600/https://www.youtube.com/watch?v=S_Lg1bVbqY4" target="_blank" rel="noreferrer noopener nofollow">链接</a>。部署到Heroku的React和Flask的另一个实现在这里显示为<a href="https://web.archive.org/web/20221201165600/https://www.youtube.com/watch?v=h96KP3JMX7Q" target="_blank" rel="noreferrer noopener nofollow"/>。</p>







<p>决定使用React for UI意味着雇佣一个专门的UI开发人员或者学习一个新的UI工具和脚本语言！。</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/3e3a8b72901bd15b5c300c78a1fdf97c.png" alt="React Native UI for image classification" class="wp-image-65873" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models30.jpg?resize=826%2C462&amp;ssl=1"/><figcaption><em>React Native UI for image classification | <a href="https://web.archive.org/web/20221201165600/https://www.youtube.com/watch?v=S_Lg1bVbqY4" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>使用细流服务web ui的模型</p>



<p>在我看来，<a href="https://web.archive.org/web/20221201165600/https://streamlit.io/" target="_blank" rel="noreferrer noopener nofollow"> Streamlit </a>可能是一位经验丰富的数据科学家创建web应用程序的最快方式，他对Python比对Javascript更熟悉(React主要基于Javascript)。开发人员可以创建一个web应用程序以及后端ML算法。所以与基于Flask/React的系统不同，它不需要单独的http/s路由来发送JSON数据。最好的部分是，它有内置的功能来呈现表格，图像，gif数据等。，放到网络屏幕上，而且也是开源的！你还需要什么？</p>



<h3>出于同样的原因，它正在成为服务于计算机视觉模型或者任何机器学习模型的最流行的方式之一。</h3>



<p>下面展示了一个Streamlit web UI有多酷的例子:(所有这些都使用了最少的python风格代码！)</p>



<p>CV模型服务平台</p>



<p>上面讨论的所有事情，不管是ML生命周期操作还是UI，都需要某种平台来操作。这些平台之间的选择通常主要基于:</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/fa8c478f24d00911fcddee789d48a1c5.png" alt="Model serving web UI with Streamlit" class="wp-image-65898" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models55.png?resize=832%2C506&amp;ssl=1"/><figcaption><em>Model serving web UI with Streamlit | <a href="https://web.archive.org/web/20221201165600/https://www.youtube.com/watch?v=1y1o4XoFIuA" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<h2 id="h-cv-model-serving-platforms">CV model serving platforms</h2>



<p><span class="c-list__counter"> 1 </span>涉及的费用</p>



<div id="case-study-numbered-list-block_6281f5f224947" class="block-case-study-numbered-list ">

    
    <h2 id="h-"><span class="c-list__counter"> 2 </span>组织对云提供商的选择</h2>

    <ul class="c-list">
                    <li class="c-list__item"><span class="c-list__counter"> 3 </span>可用的内部基础设施</li>
                    <li class="c-list__item"><span class="c-list__counter"> 4 </span>目标用户角色的技术成熟度</li>
                    <li class="c-list__item"><span class="c-list__counter"> 5 </span>目标用户量等。</li>
                    <li class="c-list__item">例如，用户通常希望在使用解决方案时，人工智能是不可见的。这意味着用户通常不想纠结于基于人工智能的复杂决策。</li>
                    <li class="c-list__item">对他们来说，部署在任何云平台上的web应用程序形式的UI就足够了。但是在某些情况下，用户需要足够的灵活性来修改算法&amp;需要定制的用户界面。你如何为你的模型服务将取决于上面提到的因素。</li>
            </ul>
</div>



<p>许多云服务提供商都有完全集成的机器学习平台。让我们来看看其中的几个。</p>



<p>aws pagemaker</p>



<p><a href="https://web.archive.org/web/20221201165600/https://aws.amazon.com/sagemaker/" target="_blank" rel="noreferrer noopener nofollow"> SageMaker </a>是AWS完全集成的机器学习平台。它具有图像注释平台、嵌入式Jupyter笔记本环境、实验跟踪、模型监控等功能。与Rekognition中给出的点击式解决方案相比，它还是一个开发需要仔细裁剪和定制的机器学习算法的优秀工具。</p>



<h3>该生态系统与所有其他AWS相关工具配合得非常好。因此，如果您的组织是AWS的客户，并计划构建复杂的计算机视觉或任何机器学习模型，Sagemaker将是现有套件的一个很好的补充。</h3>



<p>在<a href="https://web.archive.org/web/20221201165600/https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/imageclassification_caltech/Image-classification-fulltraining-highlevel.html" target="_blank" rel="noreferrer noopener nofollow">中给出了端到端多类图像分类的示例。该示例</a>具有通常的机器学习项目步骤:</p>



<p>The ecosystem works very well with all other AWS-related tools. Hence, if your organization is an AWS customer and plans to dive into building complex computer vision or any machine learning models, Sagemaker would be a great addition to the existing suite.</p>



<p><span class="c-list__counter"> 1 </span>预处理</p>



<div id="case-study-numbered-list-block_6281f69176828" class="block-case-study-numbered-list ">

    
    <h2 id="h-"><span class="c-list__counter"> 2 </span>数据准备<br/></h2>

    <ul class="c-list">
                    <li class="c-list__item"><span class="c-list__counter"> 3 </span>模特培训</li>
                    <li class="c-list__item"><span class="c-list__counter"> 4 </span>超参数调谐</li>
                    <li class="c-list__item"><span class="c-list__counter"> 5 </span>训练&amp;推论</li>
                    <li class="c-list__item">以上分享的文章里都有提到。</li>
                    <li class="c-list__item">除了图像分类，Sagemaker还提供了内置的注释工具，用于语义分割、实例分割、对象检测等。但是一些独立工具(本文前面已经讨论过)所提供的复杂程度可能会比这些通用注释服务更好。</li>
            </ul>
</div>



<p>下图显示了Sagemaker提供的一些注释选项。</p>



<p>下图显示了一个使用Sagemaker进行语义分段的例子。</p>



<p>Azure机器学习</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/44067ee52a132ba1ffd96f885e43874f.png" alt="Image annotation options using Sagemaker" class="wp-image-65867" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models24.jpg?resize=829%2C729&amp;ssl=1"/><figcaption><em>Image annotation options using Sagemaker | <a href="https://web.archive.org/web/20221201165600/https://www.youtube.com/watch?v=_FPI6KjDlCI" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>Azure ML是另一个基于云的环境，你可以用它来训练、自动化、部署和监控机器学习模型。</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/11f96dcbe07589aa969c7efe219c6307.png" alt="Semantic segmentation annotation using Sagemaker" class="wp-image-65881" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models38.jpg?resize=822%2C503&amp;ssl=1"/><figcaption><em>Semantic segmentation annotation using Sagemaker | <a href="https://web.archive.org/web/20221201165600/http://www.youtube.com/watch?v=z1g6m3AqNYM" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>







<h3>Azure中的自动化ML支持计算机视觉任务的模型训练，如图像分类、对象检测和实例分割。目前通过Azure机器学习Python SDK支持为计算机视觉任务创作AutoML模型。由此产生的实验运行、模型和输出可以从<a href="https://web.archive.org/web/20221201165600/https://studio.azureml.net/" target="_blank" rel="noreferrer noopener nofollow">Azure Machine Learning studio UI</a>访问。</h3>



<p>它内置了与流行的机器学习和深度学习库的集成，如<a href="https://web.archive.org/web/20221201165600/https://pytorch.org/" target="_blank" rel="noreferrer noopener nofollow"> Pytorch </a>、<a href="https://web.archive.org/web/20221201165600/https://www.tensorflow.org/" target="_blank" rel="noreferrer noopener nofollow"> TensorFlow </a>、<a href="https://web.archive.org/web/20221201165600/https://mlflow.org/" target="_blank" rel="noreferrer noopener nofollow"> MLflow </a>等。有趣的是，它有自己的开源MLOps环境。下面显示了使用Azure ML的ML管道的步骤，这对于使用计算机视觉的管道也是常见的:</p>



<p>Automated ML in Azure supports model training for computer vision tasks like image classification, object detection, and instance segmentation. Authoring AutoML models for computer vision tasks are currently supported via the Azure Machine Learning Python SDK. The resulting experimentation runs, models, and outputs are accessible from the <a href="https://web.archive.org/web/20221201165600/https://studio.azureml.net/" target="_blank" rel="noreferrer noopener nofollow">Azure Machine Learning studio UI</a>.</p>



<p><span class="c-list__counter"> 1 </span>任务类型选择</p>



<div id="case-study-numbered-list-block_6281ff697682f" class="block-case-study-numbered-list ">

    
    <h2 id="h-"><span class="c-list__counter"> 2 </span>数据消耗</h2>

    <ul class="c-list">
                    <li class="c-list__item"><span class="c-list__counter"> 3 </span>数据增强</li>
                    <li class="c-list__item"><span class="c-list__counter"> 4 </span>配置和运行实验</li>
                    <li class="c-list__item"><span class="c-list__counter"> 5 </span>评估指标的选择</li>
                    <li class="c-list__item"><span class="c-list__counter"> 6 </span>超参数优化</li>
                    <li class="c-list__item"><span class="c-list__counter"> 7 </span>注册和模型部署</li>
                    <li class="c-list__item">与AWS环境提供的功能类似，Azure AutoML支持图像分类、图像分类多标签、图像对象检测、图像实例分割等任务。</li>
                    <li class="c-list__item">右侧还显示了不同的内置注释工具。因此，带有相当简单注释的CV项目可以在Azure ML中轻松处理。</li>
            </ul>
</div>



<p> </p>



<p> </p>



<p id="separator-block_6283853c546ff" class="block-separator block-separator--5">下面的架构展示了如何在支持GPU的机器集群之间进行CV模型的分布式训练。该场景是图像分类，但是该解决方案可以推广到其他CV用例</p>



<p id="separator-block_628382b6546f6" class="block-separator block-separator--5">例如语义分割、对象检测等。</p>







<p> </p>



<p>使用Azure Kubernetes web服务可以轻松部署在Azure中端到端开发的CV模型。</p>



<p id="separator-block_6283854054700" class="block-separator block-separator--5">这里有一个<a href="https://web.archive.org/web/20221201165600/https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models" target="_blank" rel="noreferrer noopener nofollow">链接</a>设置AutoML用Python训练计算机视觉模型。如果您想进一步探索Azure ML的功能，请仔细阅读。</p>







<p>谷歌云人工智能平台</p>



<p>这个平台是谷歌的另一个相当先进的平台，具有许多支持机器学习生命周期管理的功能。谷歌在计算机视觉方面提供的旗舰产品有:</p>



<h3><strong> <a href="https://web.archive.org/web/20221201165600/https://cloud.google.com/vertex-ai?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=japac-IN-all-en-dr-bkws-all-all-trial-e-dr-1009882&amp;utm_content=text-ad-none-none-DEV_c-CRE_424314640471-ADGP_Hybrid%20%7C%20BKWS%20-%20EXA%20%7C%20Txt%20~%20AI%20%26%20ML%20~%20AI%20Platform_AI%20Platform-KWID_43700042852054351-aud-1589252136686%3Akwd-462879816162&amp;userloc_9040215-network_g&amp;utm_term=KW_google%20cloud%20ai%20platform&amp;gclid=CjwKCAjw9-KTBhBcEiwAr19ig273ax5Mx7h7j-NGJHBltXp0qrOeE8Kc2kYt035gbBgrc_KTn0Zn-hoCmOEQAvD_BwE&amp;gclsrc=aw.ds" target="_blank" rel="noreferrer noopener nofollow"> Vertex AI </a> : </strong>将所有的谷歌云服务，连同一个UI和一个API，集合在一个平台下。在Vertex AI中，您可以使用AutoML或自定义代码训练来训练和比较模型，并且您的所有模型都存储在一个中央模型库中。Google提供的所有MLOps工具都可以在一个平台上使用。</h3>



<p><strong> <a href="https://web.archive.org/web/20221201165600/https://cloud.google.com/vision/automl/docs" target="_blank" rel="noreferrer noopener nofollow"> AutoML Vision </a> : </strong>提供了一个易于使用的GUI来训练您自己的定制CV模型。AutoML Vision优化了模型的准确性、延迟和大小，并将它们导出到云或任何边缘设备。</p>



<ol><li>谷歌公司的另一个强大的解决方案是<a href="https://web.archive.org/web/20221201165600/https://cloud.google.com/solutions/visual-inspection-ai" target="_blank" rel="noreferrer noopener nofollow">视觉检测AI </a>。这直接应用于检测制造业中的产品缺陷。</li></ol>



<ol start="2"><li>一些应用包括机器人焊缝的视觉检查、PCB检查等。</li></ol>



<p> </p>



<p><em>目测AI | <a href="https://web.archive.org/web/20221201165600/https://cloud.google.com/solutions/visual-inspection-ai" target="_blank" rel="noreferrer noopener nofollow">来源</a> </em></p>



<p id="separator-block_6283855254701" class="block-separator block-separator--5"> </p>







<p class="has-text-align-center has-small-font-size">您将发现来自同一来源的易于学习的用例，以帮助您开始使用任何google cloud vision工具。无论需求是什么，谷歌云工具都有适合你的价格。它可以是按使用付费、按比例按月收费、按节点小时固定费率等。</p>



<p id="separator-block_6283855b54702" class="block-separator block-separator--5">Kubeflow</p>



<p><a href="https://web.archive.org/web/20221201165600/https://www.kubeflow.org/" target="_blank" rel="noreferrer noopener nofollow"> Kubeflow </a>是另一个开源的机器学习平台，与各大云平台无缝集成。</p>



<h3>Kubeflow旨在让机器学习(ML)工程师和数据科学家轻松利用云资产(公共或内部)来处理ML工作负载。通过Kubeflow，Jupyter笔记本电脑可以开发ML模型并创建Kubernetes资源，以便在任何平台(即内部、远程或云环境)上培训、封装和部署其模型。由于Kubeflow开发的初始阶段发生在谷歌，它已经具有与谷歌云平台(GKE-谷歌Kubernetes引擎)的出色集成能力。</h3>



<p>运行在Kubernetes之上的Kubeflow可以在云和内部平台上运行，但部署Kubernetes优化的机器学习模型是一项艰巨的工作。然而，开发人员一直在努力简化它的采用。</p>



<p>无论是哪种情况，Kubeflow都是部署计算机视觉模型以及云服务提供商甚至内部安装的绝佳平台。</p>











<p> </p>



<p>从计算机视觉模型部署的角度来看，当提供充足的资源(如RAM、存储空间和处理能力)时，Kubeflow可以创建可伸缩的CV部署。MLOps工程师在使用它时面临的一个问题是学习和掌握Kubeflow提供的功能的内在复杂性。</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/541e461c5d5c817d1d4719d287bfaa5c.png" alt="A diagrammatic workflow for deploying deep learning models using Kubeflow in Azure" class="wp-image-65855" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models12.png?resize=826%2C503&amp;ssl=1"/><figcaption><em>A diagrammatic workflow for deploying deep learning models using Kubeflow in Azure | <a href="https://web.archive.org/web/20221201165600/https://medium.com/microsoftazure/deploying-deep-learning-models-using-kubeflow-on-azure-d303c904c6db" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p id="separator-block_6283857a54703" class="block-separator block-separator--5">Neptune.ai</p>



<p>Neptune 是MLOps的元数据存储，为运行大量实验的团队而构建。它为您提供了一个单一的位置来记录、存储、显示、组织、比较和查询所有的模型构建元数据。</p>











<h3>海王星是一个理想的工具:</h3>



<p>说到数据版本控制，Neptune是一个可靠的轻量级解决方案。</p>



<p>从CV模型部署的角度来看，Neptune为每次实验运行中的每个模型性能参数提供了大量的见解。这为试验更多的超参数(如学习率、优化算法等)提供了足够的空间。因此，通过这些功能，为AI开发人员简化了生产部署的模型选择。</p>







<p>下图显示了与CV模型实验相关的跟踪仪表板。这是一个<a href="https://web.archive.org/web/20221201165600/https://docs.neptune.ai/you-should-know/displaying-metadata#how-to-create-a-custom-dashboard" target="_blank" rel="noreferrer noopener nofollow">定制仪表板</a>，任何人都可以在Neptune为ML项目创建它。</p>



<p> </p>



<p>工具<a href="/web/20221201165600/https://neptune.ai/integrations" target="_blank" rel="noreferrer noopener">将</a>与众多流行的机器学习库很好地集成在一起，如<a href="https://web.archive.org/web/20221201165600/https://docs.neptune.ai/integrations-and-supported-tools/model-training/sklearn" target="_blank" rel="noreferrer noopener"> Scikit learn </a>、<a href="https://web.archive.org/web/20221201165600/https://docs.neptune.ai/integrations-and-supported-tools/model-training/tensorflow-keras" target="_blank" rel="noreferrer noopener"> TensorFlow </a>、<a href="https://web.archive.org/web/20221201165600/https://docs.neptune.ai/integrations-and-supported-tools/model-training/pytorch" target="_blank" rel="noreferrer noopener"> Pytorch </a>、<a href="https://web.archive.org/web/20221201165600/https://docs.neptune.ai/integrations-and-supported-tools/model-training/xgboost" target="_blank" rel="noreferrer noopener"> XGBoost </a>、<a href="https://web.archive.org/web/20221201165600/https://docs.neptune.ai/integrations-and-supported-tools/model-training/lightgbm" target="_blank" rel="noreferrer noopener"> LightGBM </a>等等。</p>



<p id="separator-block_628385b554706" class="block-separator block-separator--5">随着计算机视觉中使用的PyTorch和TensorFlow等流行库的集成，Neptune将非常有能力处理基于这些库的CV模型。</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><a href="https://web.archive.org/web/20221201165600/https://neptune.ai/deploying-computer-vision-models28" target="_blank" rel="noopener"><img decoding="async" src="../Images/380b2012b5f898d3cefa313de76ea3e5.png" alt="Experiment tracking dashboard in Neptune" class="wp-image-65871" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models28.png?ssl=1"/></a><figcaption><em>Custom dashboard created for a Computer Vision project in Neptune | <a href="https://web.archive.org/web/20221201165600/https://app.neptune.ai/common/project-cv/e/PROJCV-103/dashboard/model-a72c0f5f-76e0-4386-b960-b186427a8b91" target="_blank" rel="noreferrer noopener">Source</a></em></figcaption></figure></div>



<p>MLflow</p>



<p>MLflow是一个管理ML生命周期的开源平台，包括实验、可复制性、部署和中央模型注册。MLflow提供了诸如实验跟踪、模型打包、模型注册等功能。MLflow集成了大多数流行的机器学习工具/库，如Scikit learn、Tensorflow、Pytorch、Spark等。此外，Docker &amp; Kubernetes等容器化工具以及与最流行的云平台的内置集成也是可用的。</p>



<h3>和其他ML项目一样，MLflow也可以支持计算机视觉相关的项目。这包括为实验模型、在每个实验中产生的工件等创建模型注册。下图显示了MLflow可以集成的一些流行库。实际列表比图表中显示的要大。Databricks内置了与MLflow的集成。</h3>



<p>MLflow易于与docker-compose代码集成，这也使它成为开源代码用户中一种流行的部署替代方案，用于快速的容器化部署。作为一个开源工具，MLflow在处理模型注册和元数据方面非常通用。因此，如果您的CV模型部署预算有限，这将是一个理想的平台。</p>



<p> </p>



<p>使用MLflow &amp; Redis AI制作计算机视觉模型的例子可以在这个<a href="https://web.archive.org/web/20221201165600/https://www.youtube.com/watch?v=ZIqHGjiSff4" target="_blank" rel="noreferrer noopener nofollow">链接</a>上看到。</p>



<p id="separator-block_628385c854708" class="block-separator block-separator--5">阿帕奇气流</p>







<p>这是一个主要用于数据工程管道的工作流管理平台。<a href="https://web.archive.org/web/20221201165600/https://airflow.apache.org/" target="_blank" rel="noreferrer noopener nofollow">气流</a>是用Python写的。因此，Airflow的一个关键优势是，您可以通过python脚本编排工作流。工作流被设计成大部分是静态的或缓慢变化的。预计气流工作流程在后续运行中看起来相似；这使得工作单元和连续性更加清晰。</p>







<h3> </h3>



<p>从计算机视觉的角度来看，气流可以用于对图像数据集、它们的版本化等执行某种流水线操作。一个有趣的用例是流入训练自动驾驶算法的图像/视频数据。新的数据集需要通过转换管道进行传递，以便持续进行模型再训练和数据漂移监控。</p>



<p id="separator-block_628385ee54709" class="block-separator block-separator--5">DVC</p>







<p><a href="https://web.archive.org/web/20221201165600/http://dvc.org/" target="_blank" rel="noreferrer noopener nofollow"> DVC </a>的建立是为了让ML模型可以共享和复制。它是专门为处理大型数据集、文件、ML模型、元数据以及代码而设计的。它是所有类型的ML部署的通用工具，而不仅仅是专门针对计算机视觉的。</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/8f65b9b44e5ed658e33de5d26d7eb4f0.png" alt="Object detection for self-driving cars" class="wp-image-65846" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models3.png?resize=840%2C459&amp;ssl=1"/><figcaption><em>Object detection for self-driving cars | <a href="https://web.archive.org/web/20221201165600/https://www.hackerearth.com/blog/developers/object-detection-for-self-driving-cars/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<h3> </h3>



<p>DVC提供以下功能:</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/2b3d76f06d0ee846b3b5b1d38ae82374.png" alt="DVC matches the right versions of data, code, and models" class="wp-image-65858" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models15.png?resize=794%2C501&amp;ssl=1"/><figcaption><em>DVC matches the right versions of data, code, and models | <a href="https://web.archive.org/web/20221201165600/https://dvc.org/doc/use-cases/versioning-data-and-model-files" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p id="separator-block_628386165470a" class="block-separator block-separator--5"><strong> <a href="https://web.archive.org/web/20221201165600/https://dvc.org/">数据版本控制</a> : </strong>允许您在Git提交中捕获数据和模型的版本，同时根据选择的存储硬件将它们存储在本地或云存储中。</p>



<p><strong> ML项目版本控制:</strong>即通过连接google云存储、Amazon s3 buckets等云存储，对ML模型和数据集&amp;元数据进行版本控制。</p>



<ol><li>ML实验跟踪:使用Git版本控制来跟踪实验。DVC在Git中做实验和关联分支一样快。</li><li>部署和协作:由于其固有的类似git的功能，生产部署也更加直观。此外，不同团队之间的强大协作是可能的，并且引入了高度的灵活性。</li><li>CV模型部署成熟度级别</li><li>ML部署的成功很大程度上取决于自动化水平。因此，这意味着在生产中维护模型所需的人工干预越少，它就变得越成熟。</li></ol>







<h2 id="h-cv-model-deployment-maturity-levels"> </h2>



<p>成熟度级别可以归因于下面显示的当前部署实践。你可以在<a href="https://web.archive.org/web/20221201165600/https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#devops_versus_mlops" target="_blank" rel="noreferrer noopener nofollow">谷歌云文档</a>页面阅读详细文章。本节不是专门针对计算机视觉的，而是针对所有ML模型部署的通用指南。</p>



<p id="separator-block_6283858254704" class="block-separator block-separator--5">手动过程</p>







<p>顾名思义，ML模型开发周期的每一步都是手工完成的。这个过程更具实验性和反复性。模型开发、验证等。，发生在iPython笔记本或类似的快速开发环境中。通常，每一个步骤都是相互分离的。然而，<a href="/web/20221201165600/https://neptune.ai/blog/ways-ml-teams-use-ci-cd-in-production" target="_blank" rel="noreferrer noopener"> CI/CD操作</a>在这一级不存在。当数据科学家/团队只处理很少的模型和数据集时，它特别适合，这些模型和数据集通常不会随时间而改变。</p>



<h3>与计算机视觉模型相关的典型步骤包括:</h3>



<p>通过网络搜集或开放数据集收集训练数据</p>



<p>使用注释工具</p>



<ul><li>使用笔记本进行代码/模型开发</li><li>模型训练和验证的迭代步骤</li><li>将模型交给工程团队进行API配置、测试和部署。</li><li>对于刚刚开始在用例中应用机器学习的企业来说，这种成熟度是常见的。但它也带来了各种挑战，例如模型无法适应输入数据的变化，或者在最坏的情况下，模型可能在生产中失败。CI/CD/CT等MLOps实践有助于应对这些挑战。</li><li>ML流水线自动化</li></ul>



<p>在这个自动化水平上，再培训和交付是自动进行的。这意味着，当大量新数据到达时，或者随着时间的推移，或者当观察到模型性能漂移时，就会触发重新训练。在参数空间中运行实验、记录生产模型、模型验证和生产模型的重新部署预计会在这个成熟度级别自动发生。</p>



<h3>这一级别的ML管道的一些特征是:</h3>



<p>快速实验</p>



<p>持续培训</p>



<ul><li>组件和管道的模块化和可重用代码。</li><li>连续发货等等。</li><li>在此阶段可以预期的一些附加组件有:</li><li>数据有效性</li></ul>



<p>在这一级，需要通过预先构建的数据管道来验证数据。这包括对数据质量、漂移、偏斜、稳健性等的检查。如果较新的数据不符合遗留模式，则应停止培训管道，并提醒数据科学团队缓解这些问题。</p>



<h4>模型验证</h4>



<p>自动化管道预计将针对较新的训练数据，针对现有的生产模型来评估新训练的模型的性能。例如，在计算机视觉对象检测模型的情况下，必须确保新训练的模型的所有对象类(或至少三分之二的对象类)的平均IoU ( <a href="https://web.archive.org/web/20221201165600/https://medium.com/analytics-vidhya/iou-intersection-over-union-705a39e7acef#:~:text=IOU(Intersection%20over%20Union)%20is,fits%20perfectly%20around%20an%20object." target="_blank" rel="noreferrer noopener nofollow">交集/并集</a>)的平均精度优于现有的生产模型。</p>



<h4>CI/CD/CT</h4>



<p>在这一级，模型部署升级到完全可扩展的架构。最常见的是具有健壮的web用户界面、负载平衡器、可伸缩数据库等的云部署。随着可训练数据的不断增加，基于并行和GPU的计算在这一阶段变得更加重要。模型性能参数被更详细地审查。</p>



<h3>它可以包括:</h3>



<p>源代码控制:跟踪和管理代码变更的实践</p>



<p>测试服务:评估和验证一个产品做了它应该做的事情的过程</p>



<ul><li><strong> <a href="/web/20221201165600/https://neptune.ai/blog/ml-model-registry" target="_blank" rel="noreferrer noopener">模型注册中心</a> : </strong>一个中央存储库，允许模型开发人员发布生产就绪的模型以便于访问</li><li><strong>特征库:</strong>一个集中的存储库，在这里可以标准化对用于训练&amp;服务的特征的访问。</li><li>元数据管理:关于实验、模型参数、时间戳、模型性能度量、模型工件等等的信息。</li><li><strong>可扩展的集装箱化部署</strong></li><li><strong>网络流量负载平衡器，数据库扩展</strong>等。</li><li>可扩展的MLOps设置保证了如下所示的几个组件:</li><li> </li></ul>



<p>令人惊讶的是，只有一小部分机器学习系统是由ML相关代码组成的。周围的组件使它变得复杂。</p>







<p id="separator-block_628385a754705" class="block-separator block-separator--5">因此，我们在DevOps(开发和操作大规模软件系统的流行实践)中遵循的一些步骤也经常在MLOps中使用。比如:</p>



<p>Surprisingly only a small fraction of Machine learning systems are composed of ML-related code. The surrounding components make it complex.</p>



<p><span class="c-list__counter"> 1 </span>持续集成</p>



<div id="case-study-numbered-list-block_62820b2376839" class="block-case-study-numbered-list ">

    
    <h2 id="h-"><span class="c-list__counter"> 2 </span>连续交货</h2>

    <ul class="c-list">
                    <li class="c-list__item"><span class="c-list__counter"> 3 </span>持续培训(MLOps独有)</li>
                    <li class="c-list__item">但是在MLOps的上下文中，CI不仅仅是关于代码测试和验证，还包括验证数据质量和模型特性。在CD环境中，还有额外的交付培训渠道和预测服务。</li>
                    <li class="c-list__item">计算机视觉模型部署的最佳实践</li>
            </ul>
</div>



<p>测试驱动的机器学习开发</p>







<h2 id="h-best-practices-in-computer-vision-models-deployment">这是从传统的<a href="https://web.archive.org/web/20221201165600/https://en.wikipedia.org/wiki/Test-driven_development" target="_blank" rel="noreferrer noopener nofollow">测试驱动软件开发</a>中借鉴来的另一种实践。</h2>



<h3><em>“测试驱动开发(Test-driven development，TDD)是一种软件开发过程，它依赖于在软件完全开发之前将软件需求转换为测试用例，并通过针对所有测试用例重复测试软件来跟踪所有软件开发。这与先开发软件，后创建测试用例的情况相反"</em></h3>



<p>因此，测试和代码不是一开始就开发一个成熟的解决方案，而是在以后的阶段进行测试，而是一次一个功能地迭代构建在一起。</p>



<blockquote class="wp-block-quote"><p>自动化测试和TDD在几个方面帮助了人工智能工程师。其中一些是:</p><cite><a href="https://web.archive.org/web/20221201165600/https://en.wikipedia.org/wiki/Test-driven_development" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></cite></blockquote>



<p><strong>提供及时反馈</strong>:即时了解代码是否符合规范，及早发现问题，进行增量调试。</p>



<p>迭代地解决挑战:就像通过小增量开发软件一样，类似的方法也可以在人工智能系统开发中使用。</p>



<ul><li>花费很少或没有浪费精力:只写实现需求所需的代码。</li><li>TDD使得组织代码和有效解决问题变得容易。这篇<a href="https://web.archive.org/web/20221201165600/https://www.ibm.com/garage/method/practices/reason/tdd-and-machine-learning/" target="_blank" rel="noreferrer noopener nofollow">文章</a>展示了一个<em>计算机视觉</em>网络应用的一步一步的测试驱动开发。你可以在<a href="https://web.archive.org/web/20221201165600/https://www.ibm.com/garage/method/practices/code/practice_test_driven_development/" target="_blank" rel="noreferrer noopener nofollow">这篇文章</a>中了解到一个更通用的适用于所有人工智能系统的TDD方法。</li><li> </li></ul>



<p>测试驱动开发的另一个很好的解释在这篇<a href="https://web.archive.org/web/20221201165600/https://www.xenonstack.com/blog/machine-learning-unit-testing" target="_blank" rel="noreferrer noopener nofollow">文章</a>中给出。ATDD代表验收测试驱动的开发。在开始开发之前，这项技术在循环中涉及到客户、测试人员和开发人员。验收标准是根据所有相关利益方的共识决定的。ATDD确保所有利益相关者与团队努力的目标一致。</p>



<p id="separator-block_6283862e5470b" class="block-separator block-separator--5">计算机视觉模型的单元测试</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/95731a230ace9c1383c7e575c86d3745.png" alt="Test-driven machine learning Procedures to reduce risks" class="wp-image-65892" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models49.png?resize=736%2C372&amp;ssl=1"/><figcaption><em>Test-driven machine learning procedures to reduce risks | <a href="https://web.archive.org/web/20221201165600/https://www.xenonstack.com/hubfs/test-driven-development-machine-learning-xenonstack.png" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>单元测试是测试驱动软件开发必不可少的便捷技术。单元测试包括测试源代码的各个部分，主要是函数和方法，以确定它们满足预期的行为/输出。</p>



<h3>单元测试通常是轻量级的，不需要太多的计算工作。特定的python库可以帮助您设置这些框架。CV模型管道中单元测试的一个例子是断言由数据加载器函数返回的图像或张量的大小。</h3>



<p>模型监控:确保CV模型部署保持相关性的方法！</p>



<p>在生产中，计算机视觉模型可能比生产中的NLP相关模型退化得更快。这完全是因为我们看到的事物变化的速度比我们使用语言的速度快得多。</p>



<h3> </h3>



<p>那么，我们需要监控哪些参数呢？嗯，它们就是我们首先用来测试模型性能的那些！。要监控的参数因型号而异。除了统计指标，我还建议在你考虑任何再培训之前进行人工干预。有时，性能衰减可能不会在指标中显示出来，但它在视觉上是可以辨别的。</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img decoding="async" loading="lazy" src="../Images/532a2a45f3c55c1e9324dcad6c6487c3.png" alt="" data-original-src="https://web.archive.org/web/20221201165600im_/https://lh4.googleusercontent.com/HLEJXf7Cx6ffb8vnr9SpBVlD7SwCcpGkA6QFOqPZNHNuwdzAL0Scfj5YuMLY1LQoQuLwbRPfg9pbCpgpgnycMuIoqMQwfpsyyIGn7j0EJ_xFGNmMslZeFCoeTbFssfbKlbWLX0sFIaXztTBPqg"/><figcaption><em>Model monitoring: the way you ensure the CV model deployment stays relevant | <a href="https://web.archive.org/web/20221201165600/https://deepchecks.com/wp-content/uploads/2021/03/2-1.png" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p id="separator-block_6283863e5470c" class="block-separator block-separator--5">在我们监控生产机器学习模型之前，我们需要有基础事实(标签)。这意味着目标标签是模型监控的黄金标准。嗯，这在很多情况下可能不可行。本节稍后将讨论如何在标签不可用的情况下进行监控。</p>



<p>下面讨论的指标主要基于这样的假设:对于较新的数据集，<strong> </strong>标签<strong>是可用的</strong>。</p>



<p>目标检测</p>



<p>在计算机视觉中，目标检测是帮助从图像中分类和定位目标的强大算法之一。</p>







<h4>您需要监控的主要对象检测指标有:</h4>



<p><strong>并集上的平均交集(IOU): </strong>它被定义为检测边界框和地面真实边界框的并集上高于评估阈值(比如0.5)的平均交集。IoU可以确定检测到的真阳性和假阳性的数量。其他相关参数有精度，回忆一下&amp; F1的成绩。想了解更多，请参考<a href="https://web.archive.org/web/20221201165600/https://www.kdnuggets.com/2020/08/metrics-evaluate-deep-learning-object-detectors.html" target="_blank" rel="noreferrer noopener nofollow">这里的</a>。</p>



<p> </p>



<ol><li><strong>平均精度(AP): </strong>平均精度可以定义为在各种IoU阈值下，单个对象类的精度/召回曲线下的面积。如果您的对象检测模型被分配为只查找一种特定的对象类型，那么跟踪此指标可能是有意义的。</li></ol>



<p id="separator-block_628386535470d" class="block-separator block-separator--5"><strong>平均精度(mAP): </strong>使用平均精度总体类(如上所述)和总体IoU阈值来计算mAP分数。</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/081652d5b01c84b1b51433c2f5c2bbba.png" alt="Average Intersection over Union (IOU)" class="wp-image-65890" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models47.png?resize=370%2C288&amp;ssl=1"/><figcaption><em>Average intersection over union (IOU) | Source: Author</em></figcaption></figure></div>



<ol start="2"><li>有了上面提到的指标，我们可以在更新的数据集上跟踪模型性能。可以用现有的模型性能值作为基准来决定是否需要重新训练。</li></ol>



<ol start="3"><li>语义分割</li></ol>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/9d2b959874f699939fe87775d69075b8.png" alt="The precision-recall curve for SSD model for four object classes, where IoU threshold is 0.5" class="wp-image-65875" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models32.png?resize=489%2C496&amp;ssl=1"/><figcaption><em>The precision-recall curve for SSD model for four object classes, </em><br/><em>where IoU threshold is 0.5 | <a href="https://web.archive.org/web/20221201165600/https://www.groundai.com/project/satellite-imagery-multiscale-rapid-detection-with-windowed-networks/1" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>语义分割中使用的主要监控指标是IoU。这与训练模型时用作损失函数的dice系数相同。与对象检测相比，语义分割中的IoU变得更加精细，即它是在像素级计算的。</p>







<h4>就像对象检测一样，IoU度量是为每个类计算的，以获得平均IoU分数，并且可以进行监控。</h4>



<p>另一个监控指标可以是<strong>像素精度</strong>，它计算正确分类的像素与图像总像素的比率。</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/5671aa77b4b54bf2b75ddbefd656a1cf.png" alt="Ground truth vs predicted pixels" class="wp-image-65863" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models20.png?resize=819%2C277&amp;ssl=1"/><figcaption><em>Ground truth vs predicted pixels | <a href="https://web.archive.org/web/20221201165600/https://www.jeremyjordan.me/content/images/2018/05/intersection_union.png" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p><strong>准确度= TP + TNTP + FP + TN + FN </strong></p>



<p> </p>



<p class="has-text-align-center">在监控过程中，这一指标有时会产生误导，因为随着时间的推移，输入数据会出现类别不平衡。</p>



<p id="separator-block_628386755470e" class="block-separator block-separator--5">实例分割</p>



<p>实例分段的监控度量与对象检测非常相似。但在这里，我们寻找的是遮罩的IoU，而不是边界框。与物体检测不同，在这种情况下，IoU是按像素计算的。</p>







<h4> </h4>



<p>好了，我们讨论了标签可用于监控模型的情况，如果标签不可用呢？</p>



<p id="separator-block_6283867f5470f" class="block-separator block-separator--5">是的，你没听错！有时标签不可用，也不能完全依赖。但是为什么呢？</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/71343407d00c327a72732885dfbcb4ac.png" alt="Instance segmentation" class="wp-image-65857" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models14.png?resize=820%2C615&amp;ssl=1"/><figcaption><em>Instance segmentation | <a href="https://web.archive.org/web/20221201165600/https://miro.medium.com/max/1400/1*-zw_Mh1e-8YncnokbAFWxg.png" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p><strong>预测和基础事实标签数据之间的长等待时间:</strong>在要预测的输入数据和它们的基础事实标签可用之间存在长滞后的可能性很大。一个例子可能是:今天生产的故障电路不会被标记，直到生产批次被检查，然后数据被传递给图像标记团队。这可能需要几天甚至几周的时间。</p>



<p><strong>人工标注</strong>:在大多数情况下，计算机视觉数据标注是一项耗费时间和资源的人工活动</p>



<ol><li><strong>模型干预:</strong>部署模型时，您可能会根据模型的预测采取行动，这可能会改变传入系统的数据。</li></ol>



<ol start="2"><li>在这些场景中，通过捕获不断变化的数据模式及其统计特征，在数据接收阶段进行监控和干预。关于数据漂移，下面将详细讨论这个概念。一个额外的阅读将是文章分享<a href="https://web.archive.org/web/20221201165600/https://towardsdatascience.com/monitoring-machine-learning-models-62d5833c7ecc" target="_blank" rel="noreferrer noopener nofollow">在这里</a>。</li></ol>



<ol start="3"><li>一些有用的工具有<a href="https://web.archive.org/web/20221201165600/https://prometheus.io/" target="_blank" rel="noreferrer noopener nofollow"> Prometheus </a>，它可以帮助存储时间序列，比如指标。Grafana帮助将存储在普罗米修斯中的数据可视化。两者都是开源工具，可用于模型参数监控/跟踪。</li></ol>



<p>计算机视觉应用中的数据漂移</p>



<p>在生产中，很可能会发生数据漂移，进而影响模型性能。一个典型的例子是，在室外背景上训练的对象检测模型突然被输入来自室内背景的数据。在这种情况下，模型性能可能会下降。</p>



<h3> </h3>



<p><em>计算机视觉应用中的数据漂移| <a href="https://web.archive.org/web/20221201165600/https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&amp;type=detection&amp;c=%2Fm%2F01940j&amp;id=b8c81a2e12abf68b" target="_blank" rel="noreferrer noopener nofollow">来源</a> </em></p>



<p id="separator-block_6283869054710" class="block-separator block-separator--5"> </p>







<p class="has-text-align-center has-small-font-size">在另一个例子中，仅在来自独特设备的图像上训练的模型暴露于来自不同环境的图像。一种典型的情况是来自不同设备的医学成像数据。在这些场景中，用更新的数据量化模型性能的变化。</p>



<p id="separator-block_6283895c54714" class="block-separator block-separator--0">解决这些类型的数据漂移的机制将有助于延长部署的计算机视觉模型的寿命。有一些工具可以用来监控这类问题。<a href="https://web.archive.org/web/20221201165600/https://www.arthur.ai/blog/introducing-monitoring-for-computer-vision-models" target="_blank" rel="noreferrer noopener nofollow"> Arthur </a>是一个漂移检测工具，它可以识别模型是否无法泛化，并提示您采取纠正措施。它们确保进入部署模型的数据看起来像预期的那样。在基于CV的系统中，这意味着输入的数据看起来类似于模型被训练的数据。他们的算法是基于这篇<a href="https://web.archive.org/web/20221201165600/https://arxiv.org/abs/2012.07421" target="_blank" rel="noreferrer noopener nofollow">论文</a>中使用的<strong> <em>非分布异常</em> </strong>算法。</p>



<p>下图显示了输入数据在不同地区以及随时间的变化情况。</p>



<p> </p>



<p>监控CV模型的算法偏差</p>



<p id="separator-block_628386a654711" class="block-separator block-separator--5">就像任何机器学习模型一样，偏见也可能蔓延到计算机视觉系统中。</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/30f4c35abaee25aac70ea8b1e82fadfa.png" alt="How the input data can vary across regions as well as with time" class="wp-image-65894" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models51.png?resize=817%2C367&amp;ssl=1"/><figcaption><em>How the input data can vary across regions as well as with time | <a href="https://web.archive.org/web/20221201165600/https://arxiv.org/pdf/2012.07421" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<h3>根据<a href="https://web.archive.org/web/20221201165600/https://www.techtarget.com/searchenterpriseai/definition/machine-learning-bias-algorithm-bias-or-AI-bias#:~:text=Machine%20learning%20bias%2C%20also%20sometimes,in%20the%20machine%20learning%20process." target="_blank" rel="noreferrer noopener nofollow">技术指标</a> <em> : </em></h3>



<p><em>“算法偏差(Algorithm bias)或AI偏差(AI bias)是一种现象，当一种算法产生的结果由于机器学习过程中的错误假设而具有系统性偏见</em>。</p>



<p>例如，人们发现，与白人相比，一些面部识别系统更偏向于有颜色的脸。这可能是由于缺乏对平衡数据集的接触。这些偏见通常是无意的，但它们会造成严重的后果，甚至是法律后果。为了避免这种情况，数据科学家应该充分了解数据集、它们的来源、多样性等。数据应该代表可能受到不利影响的不同种族、性别和文化。</p>



<blockquote class="wp-block-quote"><p>谷歌搜索“护士”显示大多是女护士。</p></blockquote>







<p>谷歌搜索医生显示大多是男医生。</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/c13e0ba58659b7825eaf43b09d7826c0.png" alt="Google search for “nurse” " class="wp-image-65886" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models43.png?resize=816%2C390&amp;ssl=1"/><figcaption><em>Google search for “nurse” | <a href="https://web.archive.org/web/20221201165600/https://www.google.com/search?q=nurse&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=2ahUKEwjXqYqRj-T3AhWZPewKHbWVClMQ_AUoAXoECAIQAw&amp;biw=1440&amp;bih=705&amp;dpr=2" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>这种偏差可能来自以下任何一种情况:</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/51b1f295ed135d927ca76ae9f501c4cc.png" alt="Google search for “doctor” " class="wp-image-65884" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models41.png?resize=809%2C391&amp;ssl=1"/><figcaption><em>Google search for “doctor” | <a href="https://web.archive.org/web/20221201165600/https://www.google.com/search?q=doctor&amp;tbm=isch&amp;ved=2ahUKEwim6YWSj-T3AhUIZhoKHYvJCiEQ2-cCegQIABAA&amp;oq=doctor&amp;gs_lcp=CgNpbWcQAzIECAAQQzIECAAQQzIECAAQQzIFCAAQgAQyBAgAEEMyBQgAEIAEMgUIABCABDIFCAAQgAQyBAgAEEMyBAgAEENQpQdYmBBgoRRoAHAAeACAAZ4BiAGhBZIBAzYuMZgBAKABAaoBC2d3cy13aXotaW1nwAEB&amp;sclient=img&amp;ei=l1CCYubBNYjMaYuTq4gC&amp;bih=705&amp;biw=1440" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p><strong>算法偏差</strong>:顾名思义，问题出在机器学习算法上。</p>



<p><strong>样本偏差</strong>:在这种情况下，训练数据集可能不够有代表性，或者不够大，不能给真实样本空间足够的表示。</p>



<ol><li><strong>偏见偏见</strong>:在这种情况下，制度反映了社会上现存的偏见/成见。一个例子是上面说明的现有性别刻板印象，例如训练数据集中出现的女护士和男医生。</li></ol>



<ol start="2"><li><strong>测量偏差</strong>:这种偏差是由数据的准确性以及如何测量或评估数据的潜在问题引起的。</li></ol>



<ol start="3"><li><strong>不平衡的类别</strong>:典型的场景可能包括面部特征识别算法，这些算法主要建立在西方白人努力理解典型亚洲面部特征的基础上。</li></ol>



<ol start="4"><li>虽然我们知道偏见可以通过许多方式蔓延到最先进的计算机视觉系统中，但意识和良好的治理可以防止这种情况。</li></ol>



<ol start="5"><li>这里可以采取一些步骤来解决这些问题:</li></ol>



<p>While we know there are many ways bias can creep even into the state of the art computer vision systems, awareness, and good governance can prevent this.</p>



<p><span class="c-list__counter"> 1 </span>选择具有充分代表性的训练数据</p>



<div id="case-study-numbered-list-block_6282512276843" class="block-case-study-numbered-list ">

    
    <h2 id="h-"><span class="c-list__counter"> 2 </span>在模型部署前进行单独的算法偏差测试</h2>

    <ul class="c-list">
                    <li class="c-list__item"><span class="c-list__counter"> 3 </span>随着输入数据的变化，积极监控偏差</li>
                    <li class="c-list__item">IBM的<a href="https://web.archive.org/web/20221201165600/https://aif360.mybluemix.net/" target="_blank" rel="noreferrer noopener nofollow"> AI fairness 360 </a>是一个开源工具包，可以帮助你在整个AI应用生命周期中检查、报告和减轻机器学习模型中的歧视和偏见。</li>
                    <li class="c-list__item">CV模型开发和部署需要考虑的事项</li>
            </ul>
</div>



<p>计算机视觉和数据质量</p>



<h2 id="h-things-to-consider-with-cv-model-development-deployment">训练数据的质量是制造健壮和高效的计算机视觉模型的关键因素。您可以考虑糟糕的数据质量可能导致不想要的结果的场景，例如在制造过程中犯下代价高昂的错误、自动驾驶系统造成的错误等。</h2>



<h3> </h3>



<p>人工智能开发人员面临的另一个挑战是转换海量数据，例如，通过创建视频注释。取决于帧速率，注释可能是高度劳动密集型的。典型的自动驾驶系统可能需要带注释的图像、视频、GPS数据、物联网传感器数据等。此外，生成和存储这些不同的数据点可能会很棘手。</p>



<p id="separator-block_628386c154712" class="block-separator block-separator--10">那么我们如何解决这些问题呢？</p>







<p>这是通过人员、流程和技术/工具的组合来实现的。</p>



<h4>人</h4>



<p>根据组织的规模和预算，注释工作人员可能是雇员、承包商、外包团队、众包人员等的混合。为了生成高质量的数据集，对所使用的工具和有针对性的CV应用的基本知识是必要的。令人惊讶的是，该项目的很大一部分成本可能仅仅在于数据准备方面。</p>



<h4>过程</h4>



<p>当你训练、验证和测试计算机视觉模型时，数据注释过程甚至可以发展。因此，这里重要的是团队应该是敏捷的。它们应该能够根据数据类型、注释类型、使用的工具等进行调整。</p>



<h4>技术/工具</h4>



<p>这些解决方案可以是基于云的、内部部署的，甚至是内部开发的。如果您的模型需要定制注释类型，开发内部注释工具将是一个好主意。由于大多数商业注释工具提供的功能比开源工具多得多，这里最重要的决定可能是内部构建还是购买。其他需要考虑的因素是集成平台的使用、数据安全性等。</p>



<h4>部署硬件</h4>



<p>有效的计算机视觉部署融合了硬件和底层软件。我们通常只考虑托管部署的本地硬件系统或云环境。但是大量其他应用包括在边缘设备上进行的部署。即使我们能够开发有效的算法，一些部署也可能是在边缘设备上，在那里您无法访问快速处理器，更不用说GPU了！。一些系统还与其他物联网设备集成，增加了更多复杂性。</p>



<h3>自主无人机是在这种情况下讨论的完美候选，即边缘设备的硬件要求。一些行业现在依靠自主无人机在短时间内完成更多工作。</h3>



<p>下图展示了世界各地的军队如何使用自主无人机进行主动监视。如今，许多无人驾驶侦察机都是自动化的、嵌入计算机视觉的边缘机器。</p>



<p>像<a href="https://web.archive.org/web/20221201165600/https://www.britannica.com/technology/unmanned-aerial-vehicle" target="_blank" rel="noreferrer noopener nofollow"> UAV </a>(无人机)这样的设备需要以合理的帧速率处理从摄像机流出的视频。作为一个处理工具，<a href="https://web.archive.org/web/20221201165600/https://opencv.org/" target="_blank" rel="noreferrer noopener nofollow"> OpenCV </a>或者<a href="https://web.archive.org/web/20221201165600/https://www.tensorflow.org/lite/guide" target="_blank" rel="noreferrer noopener nofollow"> Tensorflow Lite </a>会是不错的选择。另一个突出的例子可能是送货的自动化无人机。他们使用嵌入式视觉来帮助无人机识别他们“看到”的东西，就像无人机可以分辨物体是静止的还是移动的。</p>



<p>这篇<a href="https://web.archive.org/web/20221201165600/https://www.researchgate.net/publication/325201355_Deep_learning_for_vision-based_micro_aerial_vehicle_autonomous_landing" target="_blank" rel="noreferrer noopener nofollow">论文</a>很好地解释了基于视觉的自主无人机的硬件/部署架构。</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/baa4c26adfefce96ae04c0dc9092985b.png" alt="Autonomous drones used to carry out active surveillance" class="wp-image-65891" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models48.png?resize=685%2C394&amp;ssl=1"/><figcaption>Autonomous drones used to carry out active surveillance | <em><a href="https://web.archive.org/web/20221201165600/https://keymakr.com/blog/computer-vision-in-drone-technology/" target="_blank" rel="noreferrer noopener">S</a><a href="https://web.archive.org/web/20221201165600/https://keymakr.com/blog/computer-vision-in-drone-technology/" target="_blank" rel="noreferrer noopener nofollow">o</a><a href="https://web.archive.org/web/20221201165600/https://keymakr.com/blog/computer-vision-in-drone-technology/" target="_blank" rel="noreferrer noopener">urce</a></em></figcaption></figure></div>



<p>其他流行的edge设备都是基于Raspberry Pi的。Raspberry Pi 4，2GB RAM型号的起价仅为35美元，Raspberry Pi 4可以作为物联网设备的媒体中心、网络服务器或推理引擎。</p>



<p>来自Charmed Labs的Vizy 配备了一个Raspberry Pi 4，这是一个嵌入了高分辨率摄像头的智能设备，适用于那些开始使用基于计算机视觉的应用程序的人。Vizy利用Raspberry Pi 4的强大功能和一个高质量的摄像头，让学生或更高级的用户可以轻松构建计算机视觉项目或解决方案。</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/8119f81f96dc7f19f592d2cdb54153bd.png" alt="Sample hardware architecture of the vision-based autonomous drone navigation" class="wp-image-65864" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models21.png?resize=612%2C258&amp;ssl=1"/><figcaption><em>Sample hardware architecture of the vision-based autonomous drone navigation | <a href="https://web.archive.org/web/20221201165600/https://www.researchgate.net/publication/325201355_Deep_learning_for_vision-based_micro_aerial_vehicle_autonomous_landing" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/357d8e3adcdc6e2e80055b878f72b99a.png" alt="An autonomous drone: representative" class="wp-image-65874" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models31.png?resize=671%2C503&amp;ssl=1"/><figcaption><em>An autonomous drone: representative | <a href="https://web.archive.org/web/20221201165600/https://www.researchgate.net/publication/325201355_Deep_learning_for_vision-based_micro_aerial_vehicle_autonomous_landing" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>Vizy是通过网络界面控制的，而不是通过浏览器的HTTPS界面的桌面应用程序。在线编辑器和Charmed Labs的大量文档和<a href="https://web.archive.org/web/20221201165600/https://docs.vizycam.com/doku.php" target="_blank" rel="noreferrer noopener nofollow"> API参考</a>使得入门相对容易。电源板，一个GPIO附加板，有它的<a href="https://web.archive.org/web/20221201165600/https://docs.vizycam.com/doku.php?id=wiki:api_vizypowerboard" target="_blank" rel="noreferrer noopener nofollow"> API控制</a>，比如板载led，风扇控制器，IR遥控器等。</p>



<p>其他有趣的部署应用包括主要用于仓库/物流应用的AGV(自动导引车)。最近被称为vgv(视觉制导车辆)，它们是从AGV发展而来的。与AGV不同，它们不需要任何磁条或反射器。由于它们是基于地面的，不像无人机，它们可以负担更重的内置硬件。</p>



<div class="wp-block-image"><figure class="aligncenter size-full"><img decoding="async" src="../Images/d851b2297967513403780d37fa44fb08.png" alt="Vizy hardware specifications" class="wp-image-65870" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models27.png?ssl=1"/><figcaption><em>Vizy hardware specifications | <a href="https://web.archive.org/web/20221201165600/https://www.tomshardware.com/reviews/vizy-raspberry-pi-ai-camera" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/a406e8ef0c0bcedbd30478a929988a88.png" alt="Vizy- a Raspberry Pi-powered AI camera" class="wp-image-65899" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models56.png?resize=674%2C420&amp;ssl=1"/><figcaption><em>Vizy- a raspberry pi-powered AI camera | <a href="https://web.archive.org/web/20221201165600/https://cdn.mos.cms.futurecdn.net/BBuMTwYcEWZTQptrJ6GgXK-970-80.jpg.webp" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<p>在<a href="https://web.archive.org/web/20221201165600/https://www.waredock.com/magazine/what-is-amazon-robotic-fulfillment-center/" target="_blank" rel="noreferrer noopener nofollow">亚马逊机器人履行</a>中心使用的机器人是另一个具有边缘设备计算能力的计算机视觉模型部署的经典例子。但是，他们再次使用计算机视觉、物联网和传感器数据的组合来导航和执行他们的预期职责。</p>



<p>CV模型开发和部署的经济性和可行性</p>



<p>明确的业务目标对于部署成功的计算机视觉模型至关重要。比如:</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/54e86328b272551ecc9bd6501d293a2b.png" alt="Robots carrying inventory pods to warehouse" class="wp-image-65897" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201165600im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Deploying-computer-vision-models54.png?resize=684%2C427&amp;ssl=1"/><figcaption><em>Robots carrying inventory pods to warehouse I <a href="https://web.archive.org/web/20221201165600/https://www.waredock.com/wp-content/uploads/2019/08/Screenshot-2019-08-01-at-22.50.57.png" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>



<h3>是提高生产效率或盈利能力还是提高销量？</h3>



<p>它是否最大化/最小化了与业务目标相关的KPI？</p>



<ul><li>模型部署能够为您的组织带来什么样的货币价值？</li><li>从长远来看，收益是否大于成本？</li><li>在组建团队或选择部署工具时，成本效益分析非常有意义。每种工具都有各自的优缺点。一个昂贵的云原生集成平台可以节省大量的培训时间和资源以及数据ETL成本，但与此同时，订阅可能会很昂贵。与NLP或经典机器学习模型开发相比，计算机视觉模型开发可能会开发额外的工具开销，如专门的注释工具。</li><li>值得注意的是，近90%的ML模型从未投入生产；计算机视觉模型也是如此。在许多公司中，这背后的一些原因包括我们无法确保在小环境中工作的模型在其他地方也能工作，障碍可能来自数据不可用、云存储不足等形式。</li></ul>



<p>估算计算资源的数量和成本</p>



<p>对于熟练的人工智能开发人员来说，想出一个可行的算法不再是问题。他们已经存在了！挑战通常在于计算资源的可用性。领导者经常低估硬件需求，以及使用云服务时产生的成本。这通常导致他们将大部分预算花费在算法开发上，但是由于其估计成本(通常发生在后期阶段),因此无法进行充分的培训和测试。</p>



<h3>训练一个ML模型要多少钱？</h3>



<p>下面是AI21研究人员训练不同大小的BERT NLP模型的一些大概的标价成本。</p>



<p>两个数字被并列提及-一次训练运行的成本和典型的满载成本。</p>



<p><strong>$ 2.5k-$ 5万</strong>(1.1亿参数模型)</p>



<p><strong>$ 10k-$ 20万</strong>(3.4亿参数模型)</p>



<ul><li><strong>$ 80k-$ 160万</strong>(15亿参数模型)</li><li>好吧，你可能认为这只是NLP模型？。那么，看看最新的CNN建筑尺寸吧！</li><li>那里也一样！因此，为了了解所产生的成本，重要的是要知道深度学习模型的大小、训练批量大小、训练次数以及获得令人满意的训练模型所需进行的实验的预期数量。</li></ul>



<p>跨语言和工具支持问题</p>



<p>许多旧的计算机视觉模型都是用open CV构建的(主要是用C++构建的)。后来Python脚本的兴起，导致Pytorch、Caffe、Tensorflow等工具的广泛使用。最近，随着Tensorflow JS(基于Javascript)的到来，CV也嵌入到网络应用和边缘/移动设备中。这意味着您也可以将您的ML模型带入前端！。现在是<a href="https://web.archive.org/web/20221201165600/https://towardsdatascience.com/machine-learning-in-julia-5bca700e0348" target="_blank" rel="noreferrer noopener nofollow">朱丽亚</a>的黎明！</p>



<h3> </h3>



<p>由于每种语言都有独特的库和依赖集(甚至是硬件)，ML项目很快变得难以构建和维护，更不用说我们专门的计算机视觉模型了！一些管道使用Docker和Kubernetes的集装箱化，而其他管道可能不使用。一些管道需要使用专门的API，而另一些则不需要。</p>



<p id="separator-block_6283870a54713" class="block-separator block-separator--5">如前所述，一些部署工具能够解决这些不断发展的问题，但与传统软件行业相比，它仍然需要成熟。这就产生了一个独特的问题，对全栈、多语言人工智能工程师的需求。拥有这种技能的人很难找到，雇佣起来甚至更贵。</p>







<p>摘要</p>



<p>在本文中，我们涉及了各种主题，从注释、实验、UI、部署平台、监控、数据/模型验证、最佳实践等等。如果每个人都给予适当的关注，那么所有这些都是ML模型成功部署的秘诀。</p>



<h2 id="h-summary">MLOps是ML世界中一个著名的术语。但是，如果我们能够开始使用术语CVOps来表示与计算机视觉模型相关的部署活动，那就太好了。谁知道呢，这可能会成为一个常见的术语！</h2>



<p>如果你没有遵循这些步骤，我会说尝试一下！。即使是小型(概念验证)PoC或可扩展的高性能部署，上面提到的实践也是有价值的。</p>



<p>这篇文章不是路的尽头，所以继续学习吧！</p>



<p>参考</p>



<p><a href="https://web.archive.org/web/20221201165600/https://aws.amazon.com/blogs/machine-learning/building-and-deploying-an-object-detection-computer-vision-application-at-the-edge-with-aws-panorama/" target="_blank" rel="noreferrer noopener nofollow">使用AWS Panorama在边缘构建和部署对象检测计算机视觉应用</a></p>



<h3><a href="https://web.archive.org/web/20221201165600/https://cloud.google.com/vision/?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=japac-IN-all-en-dr-bkws-all-all-trial-b-dr-1009882&amp;utm_content=text-ad-none-none-DEV_c-CRE_529635525014-ADGP_Hybrid%20%7C%20BKWS%20-%20PHR%20%7C%20Txt%20~%20AI%20%26%20ML%20~%20Vision%20AI_Vision-General-KWID_43700065772057548-aud-1596662389094%3Akwd-1225059926329&amp;userloc_9040215-network_g&amp;utm_term=KW_gcp%20vision&amp;gclid=Cj0KCQjw_4-SBhCgARIsAAlegrVd1A92QzwZl06SaBqaGTUa6-aejg3wQrMO9naYfEtT4C_WZOXExBEaArjsEALw_wcB&amp;gclsrc=aw.ds" target="_blank" rel="noreferrer noopener nofollow">谷歌云视觉AI </a></h3>



<ol><li><a href="/web/20221201165600/https://neptune.ai/blog/best-mlops-tools-for-computer-vision-project" target="_blank" rel="noreferrer noopener">适合您的计算机视觉项目管道的最佳MLOps工具</a></li><li><a href="https://web.archive.org/web/20221201165600/https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning" target="_blank" rel="noreferrer noopener nofollow">https://cloud . Google . com/architecture/mlops-continuous-delivery-and-automation-pipeline-in-machine-learning</a></li><li><a href="https://web.archive.org/web/20221201165600/https://arxiv.org/abs/2012.07421" target="_blank" rel="noreferrer noopener nofollow">野生:野生分布变化的基准</a></li><li><a href="https://web.archive.org/web/20221201165600/https://medium.com/microsoftazure/deploying-deep-learning-models-using-kubeflow-on-azure-d303c904c6db" target="_blank" rel="noreferrer noopener nofollow">在Azure上使用Kubeflow部署深度学习模型</a></li><li><a href="https://web.archive.org/web/20221201165600/https://viso.ai/computer-vision/data-collection/" target="_blank" rel="noreferrer noopener nofollow">2022年计算机视觉数据收集指南</a></li><li><a href="https://web.archive.org/web/20221201165600/https://www.linkedin.com/pulse/building-python-scalable-flask-application-using-nginx-itay-melamed/" target="_blank" rel="noreferrer noopener nofollow">使用docker-compose和Nginx负载平衡器构建Python可扩展Flask应用</a></li><li><a href="https://web.archive.org/web/20221201165600/https://arthur.ai/" target="_blank" rel="noreferrer noopener nofollow">亚瑟。艾〔t1〕</a></li><li><a href="https://web.archive.org/web/20221201165600/https://www.techtarget.com/searchenterpriseai/definition/machine-learning-bias-algorithm-bias-or-AI-bias#:~:text=Machine%20learning%20bias%2C%20also%20sometimes,in%20the%20machine%20learning%20process." target="_blank" rel="noreferrer noopener nofollow">机器学习偏差(AI偏差)</a></li><li><a href="https://web.archive.org/web/20221201165600/https://www.researchgate.net/publication/358515919_When_AI_meets_store_layout_design_a_review" target="_blank" rel="noreferrer noopener nofollow">当人工智能遇到商店布局设计:回顾</a></li><li><a href="https://web.archive.org/web/20221201165600/https://www.manufacturingtomorrow.com/article/2021/10/ai-machine-vision-based-automated-weld-defect-detection-for-manufacturing-industry/17816" target="_blank" rel="noreferrer noopener nofollow"> AI &amp;基于机器视觉的制造业焊缝缺陷自动检测</a></li><li><a href="https://web.archive.org/web/20221201165600/https://realpython.com/api-integration-in-python/" target="_blank" rel="noreferrer noopener nofollow"> Python和REST APIs:与web服务交互</a></li><li><a href="https://web.archive.org/web/20221201165600/https://www.manufacturingtomorrow.com/article/2021/10/ai-machine-vision-based-automated-weld-defect-detection-for-manufacturing-industry/17816" target="_blank" rel="noreferrer noopener nofollow">AI &amp; machine vision based automated weld defect detection for manufacturing industry</a></li><li><a href="https://web.archive.org/web/20221201165600/https://realpython.com/api-integration-in-python/" target="_blank" rel="noreferrer noopener nofollow">Python and REST APIs: interacting with web services</a></li></ol>
        </div>
        
    </div>    
</body>
</html>