<html>
<head>
<title>Bayesian Neural Networks—Implementing, Training, Inference With the JAX Framework </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>贝叶斯神经网络——用JAX框架实现、训练和推理</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/bayesian-neural-networks-with-jax#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/bayesian-neural-networks-with-jax#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p><a href="https://web.archive.org/web/20221206064740/https://www.quora.com/What-is-the-difference-between-a-Bayesian-network-and-an-artificial-neural-network" target="_blank" rel="noreferrer noopener nofollow">贝叶斯神经网络(BNN)不同于人工神经网络(NN) </a>。主要区别——BNNs可以回答“我不确定”。这很有趣，但为什么你会希望神经网络告诉你它不知道你问题的答案？</p>



<p>为了向您展示网络说“我不确定”的重要性，我们需要考虑处理<strong>非分布数据</strong>。在人工智能安全中，<a href="https://web.archive.org/web/20221206064740/https://medium.com/analytics-vidhya/out-of-distribution-detection-in-deep-neural-networks-450da9ed7044" target="_blank" rel="noreferrer noopener nofollow">非分布检测</a>是当有人试图用并非来自数据集的例子愚弄网络时，网络如何感知的。</p>



<p>我们将探索BNNs背后的理论，然后用BNNs实现、训练和运行数字识别任务的推理。这很棘手，但是我会告诉你你需要做什么来让BNNs开始学习。我们将把它编码在新的、热门的JAX框架中(如果你不知道，我们将做一个快速介绍)。</p>



<p>在文章的最后，我们将向我们的神经网络输入字母而不是数字，看看它会做什么。我们开始吧！</p>



<h2 id="h-bayesian-perspective-on-artificial-neural-networks">人工神经网络的贝叶斯观点</h2>







<p>在我们开始之前，请注意这是一个复杂的话题。如果你觉得这个理论很难理解，那就直接跳到本文的编码部分。稍后，您还可以查看本文末尾链接的其他深入指南。</p>



<p>在非贝叶斯人工神经网络模型中(上图左侧)，我们训练网络参数的点估计。</p>



<p>在贝叶斯人工神经网络(上图右侧)中，我们用分布来表示我们对训练参数的信念，而不是点估计。代替变量，我们有随机变量，我们想从数据中推断。</p>



<h2 id="h-what-is-the-bayesian-neural-network">什么是贝叶斯神经网络？</h2>



<p>贝叶斯神经网络组件列表:</p>



<ul><li>数据集<em> <strong> D </strong> </em>带有预测器<strong> <em> X </em> </strong>(例如图像)和标签<strong><em/></strong>(例如类)。</li><li>可能性<strong> <em> P(D|θ) </em> </strong>或<strong> <em> P(Y |X，θ) </em> </strong>用由<strong> <em> θ </em> </strong>参数化的神经网络(NN)计算的逻辑上的分类softmax分布表示，例如softmax多层感知器。<ul><li>注意:到目前为止，它与非贝叶斯神经网络没有区别。</li><li>如果我们“正常地”训练它SGD使用交叉熵损失——那么我们可以说，我们得到了参数<strong><em/></strong>的最大似然点估计。参见“深度学习”，第5.5章:最大似然估计(<a href="https://web.archive.org/web/20221206064740/http://www.deeplearningbook.org/" target="_blank" rel="noreferrer noopener nofollow">“深度学习”。自适应计算和机器学习。”麻省理工学院出版社，2016 </a>)</li><li>然而，使用贝叶斯神经网络，参数来自它们的分布。进一步阅读！</li></ul></li><li>在神经网络参数之前，<strong><em/>【P(θ)】用正态分布来表示。</strong><ul><li>它编码了我们对参数值可能是什么的先验知识(或者说缺乏知识)。</li><li>然而，我们怀疑这些是零附近的一些小值。</li><li>这一假设来自我们的先验知识，即当我们将dnn的参数保持在0附近时，它们往往工作得很好。</li></ul></li><li>在看到数据之后，我们的NN参数的后验<strong><em>P(θ| D)</em></strong>—人们可以说是“在训练之后”。<ul><li>这是训练参数的分布。</li><li>我们将使用贝叶斯定理来计算它…</li><li>…或者至少我们会尝试这样做。</li></ul></li></ul>



<h3>贝叶斯定理</h3>



<p>从理论上讲，贝叶斯定理是我们应该用来根据先验和似然性计算神经网络参数的后验概率的工具。但是，有一个条件。</p>







<p>这个积分很难计算。只有在一些需要使用共轭先验的特殊情况下才容易处理。在“深度学习”，第5.6章:贝叶斯统计(<a href="https://web.archive.org/web/20221206064740/http://www.deeplearningbook.org/" target="_blank" rel="noreferrer noopener nofollow">“深度学习”中了解更多信息。自适应计算和机器学习。”麻省理工出版社，2016 </a>。在《走向数据科学》网站上还有一篇关于<a href="https://web.archive.org/web/20221206064740/https://towardsdatascience.com/conjugate-prior-explained-75957dc80bfb" target="_blank" rel="noreferrer noopener nofollow">共轭先验的精彩文章。</a></p>



<p>在我们的例子中，它很难处理，因为这个积分没有解析解。我们使用一个复杂的非线性函数，名为“人工神经网络”。这在计算上也很难处理，因为在分母中有指数数量的可能参数赋值需要评估和求和。</p>



<p>想象一个二元神经网络，它对N个参数分配了<strong>2<sup>N</sup>T3】个参数。对于N=272，就是<strong>2<sup>272</sup>T7】，已经比可见宇宙中的原子数量还要多。让我们同意，272个参数并不多，要知道现代CNN-s有数百万个参数。</strong></strong></p>



<h3>变分推理为救援！</h3>



<p>不会算？然后近似！</p>







<p>我们用一个分布Q来近似后验概率，称为变分分布，最小化它们之间的KL散度<strong><em><sub>KL</sub>(Q(θ)<strong>| |</strong>P(θ| D))</em></strong>。我们将找到与后验概率最接近的概率分布，它由一小组参数表示，如多元高斯分布的均值和方差，并且我们知道如何从中采样。</p>



<p>此外，我们必须能够通过它进行反向传播，并每次对分布的参数(即均值和方差)进行一点点修改，以查看最终的分布是否更接近我们想要计算的后验分布。</p>



<p>如果后验概率正是我们想要计算的，我们如何知道最终的分布是否更接近后验概率？就是这个想法！</p>



<p>从分布之间的KL散度，<strong><em>D<sub>KL</sub>(Q(θ)<strong>| |</strong>P(θ| D))</em></strong>，可以得到证据下界(ELBO)。</p>







<p>这就是所谓的变分推理。它把推理问题变成了优化问题。通过优化右侧，我们优化了从我们的变分分布NN参数<em><strong>【θ∾Q()</strong></em>中采样的经典最大似然分类损失(例如交叉熵损失)，减去正则化损失，对于高斯分布，正则化损失采用封闭形式，这意味着它是一个众所周知的方程，您将在一分钟内看到。</p>



<p>通过优化它，我们最大化证据——我们的数据集为真的概率——并最小化我们的变分分布、<strong><em>【Q(θ)</em></strong>和后验、<strong> <em> P(θ|D) </em> </strong>之间的差异。后路正是我们想要的，是我们的目标！</p>



<p>还有一个注意:它被称为证据下限，因为KL散度将总是正的。因此，右边是左边证据的下限。详见本教程:<a href="https://web.archive.org/web/20221206064740/http://arxiv.org/abs/1606.05908" target="_blank" rel="noreferrer noopener nofollow">多尔施，卡尔。变型自动编码器教程。</a></p>



<p>现在，正如所承诺的，我们有了NN参数上的分布，<strong><em>【Q(θ)</em></strong>，我们知道如何使用ELBO学习它。让我们跳到代码中来看看它的实践吧！</p>



<h2 id="h-what-is-jax">什么是JAX？</h2>



<p>正如我之前提到的，我们将使用JAX。</p>



<blockquote class="wp-block-quote"><p>“JAX<a href="https://web.archive.org/web/20221206064740/https://github.com/hips/autograd" target="_blank" rel="noreferrer noopener nofollow">亲笔签名</a>和<a href="https://web.archive.org/web/20221206064740/https://www.tensorflow.org/xla" target="_blank" rel="noreferrer noopener nofollow"> XLA </a>，聚在一起进行高性能数值计算和机器学习研究。它提供了Python+NumPy程序的可组合转换:区分、矢量化、并行化、实时编译到GPU/TPU，等等。”~ <a href="https://web.archive.org/web/20221206064740/https://jax.readthedocs.io/en/latest/" target="_blank" rel="noreferrer noopener nofollow"> JAX文档</a>。</p></blockquote>



<p>您可以查看JAX文档，但是您可能不需要它来理解下面的代码。正如作者所说，这就像机器学习和深度学习研究的NumPy。但是，我建议至少读一节，关于随机数的那一节。这可能不直观，因为通常在NumPy中你不必考虑伪随机数发生器的状态，但是在JAX中，你可以显式地将它传递给随机值采样函数。</p>



<h2 id="h-bayesian-neural-networks-for-digits-classification-using-jax">基于JAX的贝叶斯神经网络用于数字分类</h2>



<p>你可以<a href="https://web.archive.org/web/20221206064740/https://gitlab.com/awarelab/spin-up-with-variational-bayes" target="_blank" rel="noreferrer noopener nofollow">在这里</a>找到代码。README告诉您如何运行它。我鼓励你现在就去做，然后读完这篇文章。该回购包括:</p>



<ol><li>MNIST的mlp分类器(在JAX和俳句中)。</li><li>MNIST上的伯努利vae生成模型。</li><li>Bayes . py–MNIST上的变分Bayes NN分类器。</li></ol>



<p>今天，我们将做最后一个，变分贝叶斯神经网络分类器。我们将讨论代码中最重要的部分。</p>



<h3>关于HumbleSL(HSL包)的说明</h3>



<p>HumbleSL是我写的直接监督学习(SL) Python库。它提供了进行深度SL所需的所有样板代码:</p>



<ul><li>一个网络定义工厂，</li><li>度量和损失，</li><li>一种数据加载器，</li><li>火车环线，</li><li>等等。</li></ul>



<p>它得到了JAX图书馆和T2俳句框架的支持。它使用<a href="https://web.archive.org/web/20221206064740/https://www.tensorflow.org/datasets" target="_blank" rel="noreferrer noopener nofollow"> TensorFlow数据集</a>进行数据加载和预处理。</p>



<h3>培养</h3>



<h4>下载MNIST数据集</h4>



<p>第56-61行下载训练和测试数据集。</p>



<pre class="hljs">train_dataset = hsl.load_dataset(
     <span class="hljs-string">'mnist:3.*.*'</span>, <span class="hljs-string">'train'</span>, is_training=<span class="hljs-keyword">True</span>, batch_size=FLAGS.batch_size)
 train_eval_dataset = hsl.load_dataset(
     <span class="hljs-string">'mnist:3.*.*'</span>, <span class="hljs-string">'train'</span>, is_training=<span class="hljs-keyword">False</span>, batch_size=<span class="hljs-number">10000</span>)
 test_eval_dataset = hsl.load_dataset(
     <span class="hljs-string">'mnist:3.*.*'</span>, <span class="hljs-string">'test'</span>, is_training=<span class="hljs-keyword">False</span>, batch_size=<span class="hljs-number">10000</span>)</pre>



<p>train_dataset用于训练。train_eval_dataset用于对训练数据集进行性能评估。test_eval_dataset用于对测试数据集进行性能评估，你猜对了。</p>



<p>数据集是迭代器，您可以通过以下方式访问图像(和标签)的连续批次:</p>



<pre class="hljs">batch_image, batch_label = next(train_dataset)
</pre>



<h4>创建多层感知器(MLP)模型</h4>



<p>第71-74行创建了MLP模型。</p>



<pre class="hljs">net = hk.without_apply_rng(hk.transform(
     hsl.mlp_fn,
     apply_rng=<span class="hljs-keyword">True</span>  
 ))</pre>



<p>如果你对这个片段到底做了什么感兴趣，请查看<a href="https://web.archive.org/web/20221206064740/https://dm-haiku.readthedocs.io/en/latest/api.html" target="_blank" rel="noreferrer noopener nofollow">俳句基础</a>。所有你需要知道的是，它创建了“标准”的MLP与64个单位的两个隐藏层。</p>



<p>它在输入端接受一个28×28的图像，并返回对应于每个可能的类(数字)的10个值。net对象有两个函数:init和apply。</p>



<ul><li>params = net.init(next(rng)，batch_image)获取下一个随机生成器状态和图像批次，并返回初始模型参数。它需要随机发生器状态来采样参数。</li><li>logits = net.apply(params，batch_image)获取模型参数和图像批次，然后返回批次输出(10个数字的批次)。</li></ul>



<p>你可以把网络想象成一个典型的裸架构。你需要提供一些参数来预测它。</p>



<h4>初始化贝叶斯神经网络参数</h4>



<p>第79-85行获取MLP模型参数，并使用它来初始化贝叶斯神经网络参数。</p>



<pre class="hljs">prior = dict(
     
     
     mu=params,
     
     logvar=jax.tree_map(<span class="hljs-keyword">lambda</span> x: <span class="hljs-number">-7</span> * jnp.ones_like(x), params),
 )</pre>



<p>我们用平均场逼近后验概率。这意味着我们用以均值和方差(或对数方差)为参数的高斯分布来表示我们的变分分布，因为它可以采用任何值，而不仅仅是正值，这简化了训练。我们这样做是因为从高斯分布中取样很容易。</p>



<p>记住这里，后验概率是经过训练的MLP参数的分布。我们没有一套MLP参数来训练。我们训练近似后验的变分分布，并从中采样MLP参数。在代码中，对于变量名，我可能会交替使用aprx_posterior、posterior和prior来表示变分分布，我承认这不是100%正确，但在实践中，它们是一回事，或者我想强调训练参数的阶段(即prior是未训练的后验)。</p>



<h4>初始化优化程序</h4>



<p>第89-90行定义并初始化ADAM优化器。</p>



<pre class="hljs">opt = optix.adam(FLAGS.lr)
 opt_state = opt.init(prior)</pre>



<p>就这么简单。您传递学习率FLAGS.lr和初始参数prior。当然，优化器用于将梯度应用到参数上。与标准深度学习中的相同。</p>



<h4>定义目标</h4>



<p>第92-110行定义了ELBO目标。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">elbo</span><span class="hljs-params">(aprx_posterior, batch, rng)</span>:</span>
     <span class="hljs-string">"""Computes the Evidence Lower Bound."""</span>
     batch_image, batch_label = batch
     
     params = sample_params(aprx_posterior, rng)
     
     logits = net.apply(params, batch_image)
     
     log_likelihood = -hsl.softmax_cross_entropy_with_logits(
         logits, batch_label)
     
     kl_divergence = jax.tree_util.tree_reduce(
         <span class="hljs-keyword">lambda</span> a, b: a + b,
         jax.tree_multimap(hsl.gaussian_kl,
                           aprx_posterior[<span class="hljs-string">'mu'</span>],
                           aprx_posterior[<span class="hljs-string">'logvar'</span>]),
    )
     elbo_ = log_likelihood - FLAGS.beta * kl_divergence
     <span class="hljs-keyword">return</span> elbo_, log_likelihood, kl_divergence</pre>



<p>它获取一批图像(和标签)，对MLP参数进行采样，并对它们进行预测。然后，它计算logits和标签之间的交叉熵(分类损失)，并计算变分分布和正态分布之间的KL散度(正则化损失)。</p>



<p>hsl.gaussian_kl以封闭形式计算后者。由flagsβ加权的两者的组合产生ELBO。这与上面ELBO的数学表达式相匹配。损失是负面的ELBO:</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loss</span><span class="hljs-params">(params, batch, rng)</span>:</span>
     <span class="hljs-string">"""Computes the Evidence Lower Bound loss."""</span>
     <span class="hljs-keyword">return</span> -elbo(params, batch, rng)[<span class="hljs-number">0</span>]</pre>



<p>我们需要取反，因为JAX优化器只能做梯度下降。然而，我们需要最大化ELBO，而不是最小化它。</p>



<h4>训练循环</h4>



<p>第116-126行定义了SGD更新步骤。这是我们进行培训所需的最后一块。</p>



<pre class="hljs"><span class="hljs-meta">@jax.jit</span>
 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sgd_update</span><span class="hljs-params">(params, opt_state, batch, rng)</span>:</span>
     <span class="hljs-string">"""Learning rule (stochastic gradient descent)."""</span>
     
     
     grads = jax.grad(loss)(params, batch, rng)
     
     updates, opt_state = opt.update(grads, opt_state)
     
     posterior = optix.apply_updates(params, updates)
     <span class="hljs-keyword">return</span> posterior, opt_state</pre>



<p>此函数执行SGD更新的一个步骤。首先，它评估损失函数对于当前参数和该批数据的梯度。然后，计算更新并将其应用于参数。这个函数在一次更新后返回新的变分分布参数和优化器状态。之所以需要后者，是因为ADAM优化器存储并更新其自适应矩估计所需的状态。</p>



<p>现在，您只需在循环中运行这个函数，训练就会继续进行。我有一个助手函数:hsl.loop，它还负责检查点和定期评估训练和测试性能。</p>



<h3>估价</h3>



<p>第128-140行计算诊断。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">calculate_metrics</span><span class="hljs-params">(params, data)</span>:</span>
     <span class="hljs-string">"""Calculates metrics."""</span>
     images, labels = data
     probs = predict(net, params, images, next(rng), FLAGS.num_samples)[<span class="hljs-number">0</span>]
     elbo_, log_likelihood, kl_divergence = elbo(params, data, next(rng))
     mean_aprx_evidence = jnp.exp(elbo_ / FLAGS.num_classes)
     <span class="hljs-keyword">return</span> {
         <span class="hljs-string">'accuracy'</span>: hsl.accuracy(probs, labels),
         <span class="hljs-string">'elbo'</span>: elbo_,
         <span class="hljs-string">'log_likelihood'</span>: log_likelihood,
         <span class="hljs-string">'kl_divergence'</span>: kl_divergence,
         <span class="hljs-string">'mean_approximate_evidence'</span>: mean_aprx_evidence,
    }</pre>



<p>它从对提供的参数和数据运行预测开始。这不同于在ELBO物镜中简单地采样一组参数。下一小节将对此进行描述。这些预测与地面实况标注一起用于计算精度hsl.accuracy辅助函数。</p>



<p>接下来，我们计算ELBO、分类损失(log_likelihood)和正则化损失(kl_divergence)。ELBO用于计算近似证据，这直接来自ELBO的公式——它是证据下界，不是吗？这是在当前参数下数据的近似概率，即图像具有相应的标签。越高越好，因为这意味着我们的模型很好地拟合了数据-它为来自数据集的标签提供了高概率。</p>



<p>所有这些指标都放在一个字典中，并返回给调用者。在我们的例子中，hsl.loop辅助函数将不时地对来自训练和测试数据集的数据以及当前参数调用它。</p>



<h3>预言；预测；预告</h3>



<p>第41-49行运行预测。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span><span class="hljs-params">(net, prior, batch_image, rng, num_samples)</span>:</span>
     probs = []
     <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_samples):
         params_rng, rng = jax.random.split(rng)
         params = sample_params(prior, params_rng)
         logits = net.apply(params, batch_image)
         probs.append(jax.nn.softmax(logits))
     stack_probs = jnp.stack(probs)
     <span class="hljs-keyword">return</span> jnp.mean(stack_probs, axis=<span class="hljs-number">0</span>), jnp.std(stack_probs, axis=<span class="hljs-number">0</span>)</pre>



<p>这只是在样本数量_样本参数集上运行预测。然后，对预测进行平均，并计算这些预测的标准偏差作为不确定性的度量。</p>



<p>说到不确定性，现在我们已经有了所有的部分，让我们来玩一下贝叶斯神经网络。</p>



<h2 id="h-playing-with-bayesian-neural-networks">玩贝叶斯神经网络</h2>



<p>您运行代码并看到以下内容:</p>



<pre class="hljs">      <span class="hljs-number">0</span> | test/accuracy                       <span class="hljs-number">0.122</span>
      <span class="hljs-number">0</span> | test/elbo                         <span class="hljs-number">-94.269</span>
      <span class="hljs-number">0</span> | test/kl_divergence                 <span class="hljs-number">26.404</span>
      <span class="hljs-number">0</span> | test/log_likelihood               <span class="hljs-number">-67.865</span>
      <span class="hljs-number">0</span> | test/mean_approximate_evidence     <span class="hljs-number">0.000</span>
      <span class="hljs-number">0</span> | train/accuracy                     <span class="hljs-number">0.095</span>
      <span class="hljs-number">0</span> | train/elbo                       <span class="hljs-number">-176.826</span>
      <span class="hljs-number">0</span> | train/kl_divergence               <span class="hljs-number">26.404</span>
      <span class="hljs-number">0</span> | train/log_likelihood             <span class="hljs-number">-150.422</span>
      <span class="hljs-number">0</span> | train/mean_approximate_evidence     <span class="hljs-number">0.000</span>
</pre>



<p>这些是训练前的诊断，看起来没问题:</p>



<ul><li>精确度约为10%,对于随机初始化的神经网络来说是非常好的。这是随机猜测标签的准确性。</li><li>ELBO非常低，这在开始是没问题的，因为我们的变分分布远离真实的后验概率。</li><li>变分分布和正态分布之间的KL散度为正。它一定是正的，因为我们是以封闭形式计算的，而KL，因为它是距离的度量，不能取负值。</li><li>MLP模型返回的真实标签的对数似然或对数概率非常低。这意味着模型将低概率分配给真正的标签。如果我们还没有训练它，这是预料之中的。</li><li>平均近似证据为0。同样，我们还没有训练模型，所以它根本没有对数据集建模。</li></ul>



<p>让我们运行10k步，再次查看诊断结果:</p>



<pre class="hljs">  <span class="hljs-number">10000</span> | test/accuracy                       <span class="hljs-number">0.104</span>
  <span class="hljs-number">10000</span> | test/elbo                         <span class="hljs-number">-5.796</span>
  <span class="hljs-number">10000</span> | test/kl_divergence                 <span class="hljs-number">2.516</span>
  <span class="hljs-number">10000</span> | test/log_likelihood               <span class="hljs-number">-3.280</span>
  <span class="hljs-number">10000</span> | test/mean_approximate_evidence     <span class="hljs-number">0.560</span>
  <span class="hljs-number">10000</span> | train/accuracy                     <span class="hljs-number">0.093</span>
  <span class="hljs-number">10000</span> | train/elbo                         <span class="hljs-number">-5.610</span>
  <span class="hljs-number">10000</span> | train/kl_divergence                 <span class="hljs-number">2.516</span>
  <span class="hljs-number">10000</span> | train/log_likelihood               <span class="hljs-number">-3.095</span>
  <span class="hljs-number">10000</span> | train/mean_approximate_evidence     <span class="hljs-number">0.571</span>
</pre>



<p>这不好。真实标签的概率上升，log_likelihood和</p>



<p>均值近似证据上升，变分分布更接近正态分布，kl散度下降。</p>



<p>然而，采用返回概率的argmax来推断标签并将其与地面真实标签进行比较的准确度仍然比随机分类器好大约10%。这不是代码中的错误。诊断是正确的，我们需要两个技巧来训练它。继续读！</p>



<h3>训练贝叶斯神经网络的技巧</h3>



<h4>低β值</h4>



<p>β参数对分类损失和正则化损失进行加权。beta越高，正则化越强。太强的正则化会对模型有太多的约束，它将不能对任何知识进行编码。在上面的例子中，它被设置为flagsβ= 1。</p>



<p>这使得kl_divergance(正则化损失)大幅下降。但是，太强了！更好的值大约是FLAGS.beta = 0.001，这是我提供给你的代码中的默认值。</p>



<h4>低初始方差</h4>



<p>另一件事是变分分布的初始方差。太大了，网络很难开始训练和编码任何有用的知识。这是因为采样参数变化很大。在上面的例子中，它被设置为大约0.37。在代码中，默认情况下，它被设置为~0.001，这是一个更好的值。</p>



<h4>固定示例</h4>



<p>现在我们已经将超参数更改为正确的参数，让我们看看10k步后的诊断结果:</p>



<pre class="hljs">  <span class="hljs-number">10000</span> | test/accuracy                       <span class="hljs-number">0.979</span>
  <span class="hljs-number">10000</span> | test/elbo                         <span class="hljs-number">-0.421</span>
  <span class="hljs-number">10000</span> | test/kl_divergence               <span class="hljs-number">318.357</span>
  <span class="hljs-number">10000</span> | test/log_likelihood               <span class="hljs-number">-0.103</span>
  <span class="hljs-number">10000</span> | test/mean_approximate_evidence     <span class="hljs-number">0.959</span>
  <span class="hljs-number">10000</span> | train/accuracy                     <span class="hljs-number">0.995</span>
  <span class="hljs-number">10000</span> | train/elbo                         <span class="hljs-number">-0.341</span>
  <span class="hljs-number">10000</span> | train/kl_divergence               <span class="hljs-number">318.357</span>
  <span class="hljs-number">10000</span> | train/log_likelihood               <span class="hljs-number">-0.022</span>
  <span class="hljs-number">10000</span> | train/mean_approximate_evidence     <span class="hljs-number">0.966</span>
</pre>



<p>测试准确率为98%，我们可以同意它现在工作！注意正则化损失(kl_divergence)有多大。</p>



<p>是的，它离正态分布有那么远，但它需要如此。尽管如此，有了这个小测试，它仍然可以防止过度拟合。平均近似证据也非常高，这意味着我们的模型很好地预测了数据。注意ELBO也非常接近零(这是它的最大值)。</p>



<h3>查找不符合分布的示例</h3>







<p>我把训练好的模型放在上面的数字“3”和字母“B”上运行。以下是输出结果:</p>



<p id="separator-block_61af7af262f1a" class="block-separator block-separator--10"> </p>



<div id="medium-table-block_61af7af962f1b" class="block-medium-table c-table__outer-wrapper ">

    <table class="c-table">
                    <thead class="c-table__head">
            <tr>
                                    <td class="c-item">
                        <p class="c-item__inner">                                                      </p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">预言；预测；预告</p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">可能性</p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">Std。戴夫。(不确定性)</p>
                    </td>
                            </tr>
            </thead>
        
        <tbody class="c-table__body">

                    
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">
                            <p class="c-ceil__inner">                                                                     0                                                            </p>
                        </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

                    
        </tbody>
    </table>

</div>



<p id="separator-block_6149b6276e57e" class="block-separator block-separator--20"> </p>



<p>如你所见，它将数字“3”归类为3没有任何问题。然而，当我们给它喂食它在训练中没有看到的东西时，一件有趣的事情发生了。该模型将字母“B”分类为8。如果我们处理的是正常的神经网络，那就是了。</p>



<p>幸运的是，我们训练的贝叶斯神经网络也可以告诉我们它有多确定。</p>



<p>我们看到，在数字“3”的情况下，它是可信的——STD。戴夫。概率为0左右。对于字母“B ”,它返回的概率在任一方向上可以变化0，45 %!</p>



<p>这就像我们的模型告诉我们“如果我不得不猜，那么这是8，但它可能是任何东西——我以前没见过这个。”</p>



<p>这样，贝叶斯神经网络既可以对图像进行分类，也可以说“我不知道”。我们可以查出性病。戴夫。阈值，在该阈值之后，我们拒绝来自例如我们用来评估我们的模型的测试数据集的分类。</p>



<p>我简单地在整个测试数据集上运行模型，并观察std。戴夫。它的预测值。然后，我取第99个百分位数(99%的其他值较低的值)，在本例中为0.37。因此，我决定应该拒绝1%测试图像的分类。</p>



<p>我这样做是因为我知道MNIST数据集中有一些疯狂的图像，连我都无法正确分类。回到我们的例子，显然0.45 &gt; 0.37，所以我们应该拒绝字母“B”的分类。</p>



<h2 id="h-conclusion">结论</h2>



<p>就是这样！现在你可以训练一个不会让你愚弄它的神经网络。不确定性估计是人工智能安全中的一个大主题。我留给你们更多的阅读材料:</p>




        </div>
        
    </div>    
</body>
</html>