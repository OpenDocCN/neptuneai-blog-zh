<html>
<head>
<title>ARIMA vs Prophet vs LSTM for Time Series Prediction </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>ARIMA vs预言家vs LSTM进行时间序列预测</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/arima-vs-prophet-vs-lstm#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/arima-vs-prophet-vs-lstm#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>假设我们同意对时间和因果关系的线性理解，正如Sheldon Cooper <a href="https://web.archive.org/web/20221117203552/https://bigbangtheory.fandom.com/wiki/The_Financial_Permeability" target="_blank" rel="noreferrer noopener nofollow">博士所说</a>，那么将历史事件表示为随着时间的推移观察到的一系列值和特征，为从过去学习提供了基础。然而，<a href="/web/20221117203552/https://neptune.ai/blog/time-series-prediction-vs-machine-learning" target="_blank" rel="noreferrer noopener">时间序列与其他数据集</a>有些不同，包括像文本或DNA序列这样的序列数据。</p>



<p>时间组件提供了预测未来时有用的附加信息。因此，有许多专门为处理时间序列而设计的不同技术。这些技术从简单的可视化工具(显示趋势随时间演变或重复)到先进的机器学习模型(利用时间序列的特定结构)不等。</p>







<p>在本帖中，我们将讨论从时间序列数据中学习的三种流行方法:</p>



<div id="case-study-numbered-list-block_61d452cf7838a" class="block-case-study-numbered-list ">

    
    <h2 id="h-"/>

    <ul class="c-list">
                    <li class="c-list__item">用于时间序列预测的经典ARIMA框架</li>
                    <li class="c-list__item"><span class="c-list__counter"> 2 </span>脸书的内部模型Prophet，它是专门为从商业时间序列中学习而设计的</li>
                    <li class="c-list__item"><span class="c-list__counter">3</span>LSTM模型，这是一种强大的递归神经网络方法，已被用于在序列数据的许多问题上取得最著名的结果<br/></li>
            </ul>
</div>



<p>然后，我们将展示如何使用Neptune及其强大的功能来比较三个模型的结果。</p>



<p>我们先来简单概述一下这三种方法。</p>



<h2 id="h-overview-of-the-three-methods-arima-prophet-and-lstm">概述三种方法:ARIMA，先知和LSTM</h2>



<h3>ARIMA</h3>



<p>ARIMA是一类时间序列预测模型，名字是自回归综合移动平均的缩写。ARIMA的主干是一个数学模型，它使用时间序列的过去值来表示时间序列的值。该模型基于两个主要特征:</p>



<ol><li>过去的值:很明显，过去的行为可以很好地预测未来。唯一的问题是我们应该使用多少过去的值。该模型使用最后p个时间序列值作为特征。这里p是我们设计模型时需要确定的超参数。</li><li><strong>过去的错误:</strong>模型可以使用关于它在过去表现如何的信息。因此，我们将模型产生的最近的q错误添加为特征。同样，q是一个超参数。</li></ol>



<p>这里的一个重要方面是，时间序列需要标准化，以便模型独立于季节或临时趋势。对此的正式术语是，我们希望模型在一个<em>平稳的</em>时间序列上进行训练。从最直观的意义上来说，平稳性意味着生成时间序列的过程的统计特性不会随时间而改变。这并不意味着序列不会随着时间的推移而改变，只是它改变的方式本身不会随着时间的推移而改变。</p>



<p>有几种方法可以使时间序列平稳，最常用的是差分法。通过用n-1个差异替换系列中的n个值，我们迫使模型学习更高级的模式。当模型预测一个新值时，我们只需将最后一次观察到的值加进去，就可以得到最终的预测值。平稳性如果第一次遇到这个概念会有些混乱，可以参考这个<a href="https://web.archive.org/web/20221117203552/https://machinelearningmastery.com/remove-trends-seasonality-difference-transform-python/" target="_blank" rel="noreferrer noopener nofollow">教程</a>了解更多细节。</p>



<h4>因素</h4>



<p>形式上，ARIMA由描述模型三个主要组成部分的三个参数p、d和q定义。</p>



<ul><li><strong>综合</strong><strong>(ARIMA的I):</strong>达到平稳性所需的差数由参数d给出，设原特征为Y <sub> t </sub>其中t为序列中的索引。对于不同的d值，我们使用以下变换来创建一个平稳的时间序列。</li></ul>



<h5>对于d=0</h5>





<p>在这种情况下，级数已经是静止的，我们无事可做。</p>



<h5>对于d=1</h5>





<p>这是最典型的转型。</p>



<h5>对于d=2</h5>





<p>请注意，差分可以被视为微分的离散版本。对于d=1，新特征表示值如何变化。而对于d=2，新特征表示变化率<em>，就像微积分中的二阶导数一样。以上也可以推广到d &gt; 2，但这在实践中很少使用。</em></p>



<ul><li><strong>自回归(AR): </strong>参数p告诉我们，对于当前值的表达式，要考虑多少个过去的值。本质上，我们学习一个预测时间t的值的模型:</li></ul>





<ul><li><strong>移动平均线(MA): </strong>要考虑过去的预测误差有多少。新值计算如下:</li></ul>





<p>过去的预测误差:</p>





<p>这三个部分的组合给出了ARIMA(p，d，q)模型。更准确地说，我们首先对时间序列进行积分，然后我们将AR和MA模型相加，并学习相应的系数。</p>



<h3>先知</h3>



<p>Prophet FB是由脸书开发的一种算法，用于内部预测不同商业应用的时间序列值。因此，它是专门为预测商业时间序列而设计的。</p>



<p>这是一个附加模型，由四个部分组成:</p>





<p>让我们讨论一下每个组件的含义:</p>



<ol><li><strong> g(t): </strong>它代表<em>趋势</em>，目标是捕捉序列的总体趋势。例如，随着越来越多的人加入网络，脸书的广告浏览量可能会随着时间的推移而增加。但是增加的确切作用是什么呢？</li><li><strong> s(t): </strong> <em> </em>是<em>季节性</em>成分。广告浏览的数量也可能取决于季节。例如，在北半球的夏季，人们可能会花更多的时间在户外，花更少的时间在电脑前。对于不同的商业时间序列，这种季节性波动可能非常不同。因此，第二个组成部分是一个模拟季节性趋势的函数。</li><li><strong>h(t):</strong><em>节假日</em>成分。我们使用对大多数商业时间序列有明显影响的假期信息。请注意，不同的年份、不同的国家，假期是不同的。因此信息需要明确地提供给模型。</li><li><strong>误差项</strong> ε <sub> t </sub>代表模型无法解释的随机波动。通常，假设ε <sub> t </sub>遵循正态分布<em> N </em> (0，σ <sup> 2 </sup>)，均值为零，未知方差σ必须从数据中得出。</li></ol>



<h3>LSTM递归神经网络</h3>



<p>LSTM代表长期短期记忆。LSTM细胞用于递归神经网络，该网络学习从可变长度的序列预测未来。请注意，递归神经网络可以处理任何类型的序列数据，与ARIMA和预言家不同，它不限于时间序列。</p>



<p>LSTM细胞背后的主要思想是学习到目前为止看到的序列中的重要部分，忘记不太重要的部分。这通过所谓的门来实现，即具有不同学习目标的函数，例如:</p>



<ol><li>到目前为止看到的时间序列的紧凑表示</li><li>如何将新的输入与序列的过去表示相结合</li><li>忘记这个系列的什么</li><li>作为下一时间步的预测输出什么。</li></ol>



<p>更多细节见图1和维基百科文章。</p>







<p>设计基于LSTM的最佳模型可能是一项艰巨的任务，需要仔细调整超参数。以下是基于LSTM的模型需要考虑的最重要参数列表:</p>



<ul><li>用多少个LSTM单元来表示这个序列？请注意，每个LSTM单元将关注到目前为止处理的时间序列的特定方面。一些LSTM细胞不太可能捕获序列的结构，而太多的LSTM细胞可能导致过度拟合。</li><li>典型的是，首先，我们将输入序列转换成另一个序列，即值<em> h </em> <sub> t </sub>。这产生了一个新的表示，因为<em>h</em>T6】t状态捕获了到目前为止所处理的系列的结构。但是在某些时候，我们不需要所有的htvalues，而是只需要最后一个<em> h <sub> t </sub> </em>。这将允许我们将不同的<em>h</em>t<sub>t</sub>馈入完全连接的层，因为每个<em>h</em>t<sub>t</sub>对应于单个LSTM单元的最终输出。设计精确的架构可能需要仔细的微调和多次试验。</li></ul>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/c8e6091136eb519c0609a39f5193b3f8.png" alt="The structure of an LSTM cell" class="wp-image-60382" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_15.png?resize=803%2C550&amp;ssl=1"/><figcaption><em>Figure 1: the structure of an LSTM cell | <a href="https://web.archive.org/web/20221117203552/https://en.wikipedia.org/wiki/Long_short-term_memory" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>最后，我们想重申，递归神经网络是从序列数据中学习的一类通用方法，它们可以处理任意序列，如自然文本或音频。</p>



<h2 id="h-experimental-evaluation-arima-vs-prophet-vs-lstm">实验评测:ARIMA vs先知vs LSTM</h2>



<h3>资料组</h3>



<p>我们将使用Bajaj Finserv Ltd(一家印度金融服务公司)的股票交易数据来比较这三种模型。该数据集的时间跨度从2008年到2021年底。它包含每日股票价格(平均值、低值和高值)以及交易股票的总量和周转率。数据集的子样本如图2所示。</p>



<p id="separator-block_61d46d097838f" class="block-separator block-separator--10"> </p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/03f80bdacb67f44db01879ad3f4b102c.png" alt="The data used for evaluation" class="wp-image-60378" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_19.png?resize=840%2C216&amp;ssl=1"/><figcaption><em>Figure 2: the data used for evaluation | Source: Author</em></figcaption></figure></div>


<p id="separator-block_61d46d0f78390" class="block-separator block-separator--10"> </p>



<p>我们对预测每天结束时的成交量加权平均价格(VWAP)变量感兴趣。时间序列VWAP值的图表如图3所示。</p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/0e81818d808cc9ce999d871222686ba1.png" alt="The daily values of the VWAP variable" class="wp-image-60374" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_23.png?resize=568%2C350&amp;ssl=1"/><figcaption><em>Figure 3: the daily values of the VWAP variable | Source: Author</em></figcaption></figure></div>


<p>为了进行评估，我们将时间序列分为训练和测试时间序列，其中训练序列由截至2018年底的数据组成(见图4)。</p>



<p><strong>观察总数:</strong> 3201</p>



<p><strong>训练观察:</strong> 2624</p>



<p><strong>测试观察:</strong> 577</p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/78515399a126e9de67ceac027e5e0b88.png" alt="The train and test subsets of the VWAP time series" class="wp-image-60379" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_18.png?ssl=1"/><figcaption><em>Figure 4: the train and test subsets of the VWAP time series | Source: Author</em></figcaption></figure></div>


<h3>履行</h3>



<p>为了正常工作，机器学习模型需要良好的数据，为此，我们将做一点点<strong>特征工程</strong>。特征工程背后的目标是设计更强大的模型，利用数据中的不同模式。由于这三个模型学习了过去观察到的模式，我们创建了额外的特征来彻底描述股票运动的最近趋势。</p>







<p>特别是，我们跟踪3、7和30天内不同交易特征的移动平均线。此外，我们还考虑了月、周数和工作日等特性。因此，我们模型的输入是多维的。所用特征工程的一个小例子如下:</p>



<pre class="hljs">lag_features = [<span class="hljs-string">"High"</span>, <span class="hljs-string">"Low"</span>, <span class="hljs-string">"Volume"</span>, <span class="hljs-string">"Turnover"</span>, <span class="hljs-string">"Trades"</span>]
df_rolled_7d = df[lag_features].rolling(window=<span class="hljs-number">7</span>, min_periods=<span class="hljs-number">0</span>)
df_mean_7d = df_rolled_7d.mean().shift(<span class="hljs-number">1</span>).reset_index().astype(np.float32)</pre>



<p>上面的代码摘录显示了如何添加描述股票销售的几个特征在上周的移动平均值。总的来说，我们创建了一组外生特征:</p>





<p>现在，让我们从主要型号开始:</p>



<h4>ARIMA</h4>



<p>我们从公开可用的包<a href="https://web.archive.org/web/20221117203552/http://alkaline-ml.com/pmdarima/" target="_blank" rel="noreferrer noopener nofollow"> pmdarima </a>中实现了ARIMA版本。函数<a href="https://web.archive.org/web/20221117203552/http://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html#pmdarima.arima.auto_arima" target="_blank" rel="noreferrer noopener nofollow"> auto_arima </a>接受一列<em>外生</em>特征作为附加参数，其中我们提供了在特征工程步骤中创建的特征。auto_arima的主要优点是，它首先执行几个测试，以确定时间序列是否是平稳的。此外，它采用智能电网搜索策略来确定上一节中讨论的p、d和q的最佳参数。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> pmdarima <span class="hljs-keyword">import</span> auto_arima
model = auto_arima(
	df_train[<span class="hljs-string">"VWAP"</span>],
	exogenous=df_train[exogenous_features],
	trace=<span class="hljs-keyword">True</span>,
	error_action=<span class="hljs-string">"ignore"</span>,
	suppress_warnings=<span class="hljs-keyword">True</span>)</pre>



<p>参数p、d和q的不同值的网格搜索如下所示。最后，返回具有最小<a href="https://web.archive.org/web/20221117203552/https://en.wikipedia.org/wiki/Akaike_information_criterion" target="_blank" rel="noreferrer noopener nofollow"> AIC值</a>的模型。(AIC值是同时优化预测模型的准确性和复杂性的模型复杂性的度量。)</p>





<p>然后通过以下方式获得对测试集的预测</p>



<pre class="hljs">forecast = model.predict(n_periods=len(df_valid),  exogenous=df_valid[exogenous_features])</pre>



<h4>先知</h4>



<p>我们使用Prophet的公开可用的<a href="https://web.archive.org/web/20221117203552/https://facebook.github.io/prophet/docs/quick_start.html" target="_blank" rel="noreferrer noopener nofollow"> Python实现</a>。输入数据必须包含两个特定字段:</p>



<ol><li><strong>日期</strong>:应该是可以计算假期的有效日历日期</li><li><strong> Y </strong>:我们要预测的目标变量。</li></ol>



<p>我们将模型实例化为:</p>



<pre class="hljs"><span class="hljs-keyword">from</span> prophet <span class="hljs-keyword">import</span> Prophet
model = Prophet()</pre>



<p>必须将特征工程期间创建的特征明确添加到模型中，如下所示:</p>



<pre class="hljs"><span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> exogenous_features:
	model.add_regressor(feature)</pre>



<p>最后，我们拟合模型:</p>



<pre class="hljs">model.fit(df_train[[<span class="hljs-string">"Date"</span>, <span class="hljs-string">"VWAP"</span>] + exogenous_features].rename(columns={<span class="hljs-string">"Date"</span>: <span class="hljs-string">"ds"</span>, <span class="hljs-string">"VWAP"</span>: <span class="hljs-string">"y"</span>}))</pre>



<p>并且测试集的预测如下获得:</p>



<pre class="hljs">forecast = model.predict(df_test[[<span class="hljs-string">"Date"</span>, <span class="hljs-string">"VWAP"</span>] + exogenous_features].rename(columns={<span class="hljs-string">"Date"</span>: <span class="hljs-string">"ds"</span>}))</pre>



<h4>LSTM</h4>



<p>我们使用LSTMs的<a href="https://web.archive.org/web/20221117203552/https://keras.io/api/layers/recurrent_layers/lstm/" target="_blank" rel="noreferrer noopener nofollow"> Keras实现</a>:</p>



<pre class="hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Dropout
<span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dense
<span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> LSTM
<span class="hljs-keyword">from</span> tensorflow.keras.metrics <span class="hljs-keyword">import</span> RootMeanSquaredError, MeanAbsoluteError
<span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential</pre>



<p>该模型由以下函数定义。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_model</span><span class="hljs-params">(params, input_shape)</span>:</span>
	model = Sequential()
	model.add(LSTM(units=params[<span class="hljs-string">"lstm_units"</span>], return_sequences=<span class="hljs-keyword">True</span>, input_shape=(input_shape, <span class="hljs-number">1</span>)))
	model.add(Dropout(rate=params[<span class="hljs-string">"dropout"</span>]))

	model.add(LSTM(units=params[<span class="hljs-string">"lstm_units"</span>], return_sequences=<span class="hljs-keyword">True</span>))
	model.add(Dropout(rate=params[<span class="hljs-string">"dropout"</span>]))

	model.add(LSTM(units=params[<span class="hljs-string">"lstm_units"</span>], return_sequences=<span class="hljs-keyword">True</span>))
	model.add(Dropout(rate=params[<span class="hljs-string">"dropout"</span>]))

	model.add(LSTM(units=params[<span class="hljs-string">"lstm_units"</span>], return_sequences=<span class="hljs-keyword">False</span>))
	model.add(Dropout(rate=params[<span class="hljs-string">"dropout"</span>]))

	model.add(Dense(<span class="hljs-number">1</span>))

	model.compile(loss=params[<span class="hljs-string">"loss"</span>],
              	optimizer=params[<span class="hljs-string">"optimizer"</span>],
              	metrics=[RootMeanSquaredError(), MeanAbsoluteError()])

	<span class="hljs-keyword">return</span> model</pre>



<p>然后，我们用一组给定的参数实例化一个模型。我们使用时间序列中过去的90个观测值作为模型的输入序列。其他超参数描述了用于训练模型的架构和特定选择。</p>



<pre class="hljs">params = {
	<span class="hljs-string">"loss"</span>: <span class="hljs-string">"mean_squared_error"</span>,
	<span class="hljs-string">"optimizer"</span>: <span class="hljs-string">"adam"</span>,
	<span class="hljs-string">"dropout"</span>: <span class="hljs-number">0.2</span>,
	<span class="hljs-string">"lstm_units"</span>: <span class="hljs-number">90</span>,
	<span class="hljs-string">"epochs"</span>: <span class="hljs-number">30</span>,
	<span class="hljs-string">"batch_size"</span>: <span class="hljs-number">128</span>,
	<span class="hljs-string">"es_patience"</span> : <span class="hljs-number">10</span>
}

model = get_model(params=params, input_shape=x_train.shape[<span class="hljs-number">1</span>])</pre>



<p>以上结果产生了下面的Keras模型(参见图5):</p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/da15449e689b260c8ac649c4300cd28e.png" alt="A summary of the Keras LSTM model" class="wp-image-60371" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_26.png?ssl=1"/><figcaption><em>Figure 5: a summary of the Keras LSTM model | Source: Author</em></figcaption></figure></div>


<p>然后，我们创建一个回调来实现<a href="https://web.archive.org/web/20221117203552/https://en.wikipedia.org/wiki/Early_stopping" target="_blank" rel="noreferrer noopener nofollow">提前停止</a>，即，如果对于给定数量的时期(在我们的示例中为10个时期)验证数据集没有产生改进，则停止训练模型:</p>



<pre class="hljs">es_callback = tf.keras.callbacks.EarlyStopping(monitor=<span class="hljs-string">'val_root_mean_squared_error'</span>,
                                           	mode=<span class="hljs-string">'min'</span>,
patience=params[<span class="hljs-string">"es_patience"</span>])</pre>



<p>参数<em> es_patience </em>是指提前停止的次数。</p>



<p>最后，我们使用预定义的参数拟合模型:</p>



<pre class="hljs">model.fit(
	x_train,
	y_train,
	validation_data=(x_test, y_test),
	epochs=params[<span class="hljs-string">"epochs"</span>],
	batch_size=params[<span class="hljs-string">"batch_size"</span>],
	verbose=<span class="hljs-number">1</span>,
	callbacks=[neptune_callback, es_callback]
)</pre>



<h3>实验跟踪和模型比较</h3>



<p>因为在这篇博文中，我们想回答一个简单的问题，即哪个模型对测试数据集产生最准确的预测，我们需要看看这三个模型之间的差异。</p>



<p>有许多不同的方法用于<a href="https://web.archive.org/web/20221117203552/https://docs.neptune.ai/you-should-know/comparing-runs" target="_blank" rel="noreferrer noopener">模型比较</a>，例如创建记录不同指标评估的表格和图表，创建绘制测试集上预测值与真实值的图表，等等。然而，在这个练习中，我们将使用<strong>海王星。</strong></p>



<hr class="wp-block-separator has-css-opacity"/>



<h4>海王星是什么？</h4>



<p>Neptune是MLOps 的<a href="/web/20221117203552/https://neptune.ai/" target="_blank" rel="noreferrer noopener">元数据存储库，为运行大量实验的团队而构建。‌</a></p>



<p>它为您提供了一个记录、存储、显示、组织、比较和查询所有模型构建元数据的单一位置。</p>



<p>‌Neptune习惯了for:‌</p>



<ul><li><strong>实验跟踪</strong>:在一个地方记录、显示、组织和比较ML实验。</li><li><strong>模型注册</strong>:对训练好的模型进行版本化、存储、管理和查询，以及建模元数据。</li><li><strong>实时监控ML运行</strong>:实时记录和监控模型培训、评估或生产运行</li></ul>



<hr class="wp-block-separator has-css-opacity"/>



<p>如本教程中的<a href="https://web.archive.org/web/20221117203552/https://docs.neptune.ai/getting-started/hello-world" target="_blank" rel="noreferrer noopener">所述，我们首先创建一个Neptune项目，并记录我们帐户的API:</a></p>



<pre class="hljs">run = neptune.init(project=<span class="hljs-string">'&lt;YOUR_WORKSPACE/YOUR_PROJECT&gt;'</span>,
               	api_token=<span class="hljs-string">'&lt;YOUR_API_TOKEN&gt;'</span>) </pre>



<p>变量<em> run </em>可以看作一个文件夹，我们可以在其中创建包含不同信息的子文件夹。例如，我们可以创建一个名为model的子文件夹，并在其中记录模型的名称:</p>



<pre class="hljs">run[<span class="hljs-string">"model/name"</span>] = <span class="hljs-string">"Arima"</span></pre>



<p>我们将根据两个不同的指标来比较这些模型的准确性:</p>



<ol><li>均方根误差(RMSE)</li></ol>





<ol start="2"><li>平均绝对误差</li></ol>





<p>请注意，可以通过设置相应的值将这些值记录到Neptune中，例如，设置:</p>



<pre class="hljs">run[<span class="hljs-string">"test/mae"</span>] = mae
 run[<span class="hljs-string">"test/rmse"</span>] = mse</pre>



<p>三个模型的均方误差和平均误差可以在运行表中并排显示:</p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><a href="https://web.archive.org/web/20221117203552/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_16.png?ssl=1" target="_blank" rel="noopener"><img decoding="async" loading="lazy" src="../Images/31f9589958f846980c86ef2612105f57.png" alt="The mean square error and the mean average error for the three models can be seen next to each other. (The tags for each project are at the top.)" class="wp-image-60381" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_16.png?resize=840%2C270&amp;ssl=1"/></a><figcaption><em>Figure 6. the MSE and the MAE for the three models in the Neptune UI<br/>(the tags for each project are at the top) | <a href="https://web.archive.org/web/20221117203552/https://app.neptune.ai/kutzkov/TimeSeries/experiments?compare=IzBMBpnAWI&amp;split=tbl&amp;dash=leaderboard&amp;viewId=standard-view" target="_blank" rel="noreferrer noopener">Source</a></em></figcaption></figure></div>


<p>这三种算法的比较可以在Neptune中并排看到，如图7所示。</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><a href="https://web.archive.org/web/20221117203552/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/ARIMA-vs-Prophet-vs-LSTM.png?ssl=1"><img decoding="async" src="../Images/781d4ce608afc50414d4f3baef98373c.png" alt="Side by side comparison ARIMA Prophet LSTM" class="wp-image-60480" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/ARIMA-vs-Prophet-vs-LSTM.png?ssl=1"/></a><figcaption> <em>Figure 7: The mean square error and the mean average error for the three models can be seen next to each other </em><br/><em>(the tags for each project are at the top) | <a href="https://web.archive.org/web/20221117203552/https://app.neptune.ai/kutzkov/TimeSeries/experiments?compare=Iwg03I&amp;split=cmp&amp;dash=leaderboard&amp;viewId=standard-view" target="_blank" rel="noreferrer noopener">Source</a></em> </figcaption></figure></div>


<p>我们看到ARIMA产生了最好的性能，即它在测试集上实现了最小的均方误差和平均绝对误差。相比之下，LSTM神经网络在三个模型中表现最差。</p>



<p>根据真实值绘制的准确预测可以在下图中看到。我们观察到，所有三个模型都捕捉到了时间序列的总体趋势，但LSTM似乎落后于曲线，即它需要更多来调整自己以适应趋势的变化。和先知似乎失去了对ARIMA在最后几个月的考虑测试期间，它低估了真正的价值。</p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/b67066282935f39f4acbecd4498a58d8.png" alt="ARIMA predictions" class="wp-image-60375" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_22.png?ssl=1"/><figcaption><em>Figure 8: ARIMA predictions | Source: Author</em></figcaption></figure></div>

<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/cea112d1df59a6a88f79625470e30b6e.png" alt="Prophet predictions" class="wp-image-60372" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_25.png?ssl=1"/><figcaption><em>Figure 9: prophet predictions | Source: Author</em></figcaption></figure></div>

<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/e572c552414ef3c5f908fcbf2932dc16.png" alt="LSTM prediction" class="wp-image-60380" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_17.png?ssl=1"/><figcaption><em>Figure 10: LSTM prediction | Source: Author</em></figcaption></figure></div>


<h3>对模型性能的深入了解</h3>



<h4>ARIMA网格搜索</h4>



<p>当在ARIMA对p、d和q的不同值进行网格搜索时，我们可以绘制出各个值的均方误差。图11中的彩色点显示了不同ARIMA参数在验证集上的均方误差值。</p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><a href="https://web.archive.org/web/20221117203552/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_27.png?ssl=1"><img decoding="async" loading="lazy" src="../Images/c9e97ea832009952ba7e4ebff82fbae5.png" alt="Grid-search over the ARIMA parameters" class="wp-image-60370" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_27.png?resize=840%2C274&amp;ssl=1"/></a><figcaption><em>Figure 11: grid-search over the ARIMA parameters | <a href="https://web.archive.org/web/20221117203552/https://app.neptune.ai/kutzkov/TimeSeries/experiments?compare=OwJgNAjJ1bP3RDlNS9bNA&amp;split=cmp&amp;dash=charts&amp;viewId=standard-view&amp;query=((%60sys%2Ftags%60%3AstringSet%20CONTAINS%20%22grid-search%22)%20OR%20(%60sys%2Ftags%60%3AstringSet%20CONTAINS%20%22arima%22))&amp;sortBy=%5B%22sys%2Fcreation_time%22%5D&amp;sortFieldType=%5B%22datetime%22%5D&amp;sortFieldAggregationMode=%5B%22auto%22%5D&amp;sortDirection=%5B%22descending%22%5D&amp;suggestionsEnabled=true&amp;lbViewUnpacked=true&amp;chartFilter=mse" target="_blank" rel="noreferrer noopener">Source</a></em></figcaption></figure></div>


<h4>预言家的趋势</h4>



<p>我们在Neptune中收集参数、预测数据帧、残差诊断图表和其他元数据，同时使用Prophet训练模型。这是通过使用一个<a href="https://web.archive.org/web/20221117203552/https://docs.neptune.ai/integrations-and-supported-tools/model-training/prophet" target="_blank" rel="noreferrer noopener">单一函数来实现的，该函数捕获先知训练元数据</a>并将其自动记录到Neptune。</p>



<p>在图12中，我们展示了先知的不同组成部分的变化。我们观察到，趋势遵循线性增长，而季节性成分表现出波动。</p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><a href="https://web.archive.org/web/20221117203552/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_28.png?ssl=1"><img decoding="async" loading="lazy" src="../Images/503521bd1cd9cb64d97f2a71c3446d9d.png" alt="The change of values of the different components in the Prophet over time" class="wp-image-60369" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_28.png?resize=829%2C697&amp;ssl=1"/></a><figcaption><em>Figure 12: the change of values of the different components in the Prophet over time | Source: Author</em></figcaption></figure></div>


<h4>为什么LSTM表现最差？</h4>



<p>当在几个时期内训练LSTM模型时，我们在海王星中收集平均绝对误差。这是通过使用一个<a href="https://web.archive.org/web/20221117203552/https://docs.neptune.ai/api-reference/integrations/tensorflow-keras" target="_blank" rel="noreferrer noopener"> Neptune回调函数</a>来实现的，该回调函数捕获训练元数据并将其自动记录到Neptune。结果如图13所示。</p>



<p>观察到，虽然训练数据集上的误差在随后的时段中减小，但是验证集上的误差却不是这样，验证集上的误差在第二个时段中达到其最小值，然后波动。这表明，LSTM模型对于一个相当小的数据集来说过于先进，并且容易过度拟合。尽管增加了正则项，如辍学，我们仍然无法避免过度拟合。</p>




<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><a href="https://web.archive.org/web/20221117203552/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_29.png?ssl=1" target="_blank" rel="noopener"><img decoding="async" loading="lazy" src="../Images/cd7b3e0c4efb899ab653c64fb6c5a5b3.png" alt="The evolution of train and test error over different epochs of training the LSTM model" class="wp-image-60368" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221117203552im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Prophet-vs-ARIMA-vs-LSTM-for-Time-Series-Prediction_29.png?resize=840%2C396&amp;ssl=1"/></a><figcaption><em>Figure 13: the evolution of train and test error over different epochs of training the LSTM model | <a href="https://web.archive.org/web/20221117203552/https://app.neptune.ai/kutzkov/TimeSeries/e/TIM-117/charts" target="_blank" rel="noreferrer noopener">Source</a></em></figcaption></figure></div>


<h2 id="h-conclusions">结论</h2>



<p>在这篇博文中，我们展示并比较了三种不同的时间序列预测算法。正如所料，没有明确的赢家，每种算法都有自己的优势和局限性。下面我们总结了我们对每个算法的观察:</p>



<ol><li><strong> ARIMA </strong>是一个强大的模型，正如我们所见，它为股票数据取得了最好的结果。一个挑战是，它可能需要仔细的超参数调整和对数据的良好理解。</li><li><strong> Prophet </strong>是专门为商业时间序列预测而设计的。它在股票数据上取得了非常好的结果，但是，从轶事来看，它在其他领域的时间序列数据集上可能会失败。特别是，这适用于时间序列，其中<em>日历日期</em>的概念不适用，我们无法学习任何季节模式。Prophet的优势在于它需要较少的超参数调整，因为它是专门为检测业务时间序列中的模式而设计的。</li><li><strong>基于LSTM的递归神经网络</strong>可能是从序列数据中学习的最强大的方法，时间序列只是一个特例。当从大规模数据集学习时，我们可以检测复杂的模式，基于LSTM的模型的潜力就完全显现出来了。与ARIMA或Prophet不同，它们不依赖于关于数据的特定假设，如时间序列平稳性或日期字段的存在。一个缺点是LSTM的rnn很难解释，并且很难对它们的行为有直觉。此外，为了获得良好的结果，需要仔细调整超参数。</li></ol>



<h3>未来方向</h3>



<p>所以我希望你喜欢阅读这篇文章，现在你一定对我们在这里讨论的时间序列算法有了更好的理解。如果你想深入了解，这里有一些有用资源的链接。快乐实验！</p>



<ol><li>PMD·ARIMA。各个Python包的文档。</li><li><a href="https://web.archive.org/web/20221117203552/https://facebook.github.io/prophet/" target="_blank" rel="noreferrer noopener nofollow">先知</a>。脸书先知的文档和教程。</li><li>凯拉斯·LSTM。喀拉斯LSTM RNNs的文档和示例。</li><li><a href="https://web.archive.org/web/20221117203552/https://neptune.ai/" target="_blank" rel="noreferrer noopener">海王星</a>。有教程和文档的Neptune网站。</li><li>一篇关于用海王星跟踪ML实验的博客文章。</li><li>对ARIMA车型的更深入的了解。</li><li>关于用LSTM神经网络进行时间序列预测的教程。</li><li><a href="https://web.archive.org/web/20221117203552/https://peerj.com/preprints/3190.pdf" target="_blank" rel="noreferrer noopener nofollow">原先知研究</a>论文。</li></ol>
        </div>
        
    </div>    
</body>
</html>