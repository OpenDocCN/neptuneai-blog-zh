<html>
<head>
<title>Best Tools to Log and Manage ML Model Building Metadata </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>记录和管理ML模型构建元数据的最佳工具</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/best-tools-to-log-and-manage-ml-model-building-metadata#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/best-tools-to-log-and-manage-ml-model-building-metadata#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>当你在开发机器学习模型时，你绝对需要能够重现实验。如果你得到了一个结果很好的模型，但是你不能复制它，因为你没有记录实验，这将是非常不幸的。</p>



<p>你可以通过记录每一件事来使你的实验具有可重复性。有几个工具可以用来做这件事。在本文中，让我们看看一些最流行的工具，看看如何开始用它们记录实验的元数据。您将了解如何使用这些工具运行一个<a href="/web/20221206203026/https://neptune.ai/blog/how-to-organize-your-lightgbm-ml-model-development-process-examples-of-best-practices" target="_blank" rel="noreferrer noopener"> LightGBM实验</a>。</p>



<p>让我们开始吧。</p>



<h2 id="h-neptune">海王星</h2>



<p><a href="/web/20221206203026/https://neptune.ai/" target="_blank" rel="noreferrer noopener"> Neptune </a>是一个可以用来记录和管理ML建模元数据的平台。您可以用它来记录:</p>



<ul><li>型号版本，</li><li>数据版本，</li><li>模型超参数，</li><li>图表，</li><li>还有很多。</li></ul>



<p>海王星托管在云上，不需要任何设置，随时随地都可以访问你的实验。你可以在一个地方组织你所有的实验，并与你的团队合作。你可以邀请你的队友来观看和研究任何实验。</p>



<p>要开始使用Neptune，<a href="https://web.archive.org/web/20221206203026/https://docs.neptune.ai/getting-started/quick-starts/hello-world" target="_blank" rel="noreferrer noopener">你需要安装</a> `neptune-client`。你还需要在<a href="https://web.archive.org/web/20221206203026/https://neptune.ai/login" target="_blank" rel="noreferrer noopener">设立一个项目</a>。这是您将从Neptune的Python API中使用的项目。</p>







<p>Neptune 的一个<a href="/web/20221206203026/https://neptune.ai/blog/neptune-new" target="_blank" rel="noreferrer noopener">新版本刚刚发布。新版本支持更多的工作流，如离线模式、ML管道和恢复运行。然而，一些集成，如LightGBM one，仍将被移植到新版本中。因此，在本文中，我使用了一个旧版本。敬请关注</a><a href="https://web.archive.org/web/20221206203026/https://docs.neptune.ai/essentials/integrations/machine-learning-frameworks/lightgbm" target="_blank" rel="noreferrer noopener">这一页的新版本</a>。</p>



<p>下一步是初始化“neptune-client”来处理这个项目。除了项目，你还需要你的API密匙。你可以在你的个人资料图片下面得到这个，如下图。</p>







<p>有了这两件事，您现在可以初始化项目了。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> neptune
neptune.init(project_qualified_name=<span class="hljs-string">'mwitiderrick/LIGHTSAT'</span>, api_token=<span class="hljs-string">'YOUR_TOKEN'</span>)</pre>



<p>下一步是创建一个实验并命名它。这个实验的参数也在这个阶段传入。</p>



<pre class="hljs">params = {<span class="hljs-string">'boosting_type'</span>: <span class="hljs-string">'gbdt'</span>,
              <span class="hljs-string">'objective'</span>: <span class="hljs-string">'regression'</span>,
              <span class="hljs-string">'num_leaves'</span>: <span class="hljs-number">40</span>,
              <span class="hljs-string">'learning_rate'</span>: <span class="hljs-number">0.09</span>,
              <span class="hljs-string">'feature_fraction'</span>: <span class="hljs-number">0.8</span>
              }

exp = neptune.create_experiment(name=<span class="hljs-string">'LightGBM-training'</span>,params=param)</pre>







<p>现在，您将开始训练LightGBM模型。训练时，您将使用Neptune的LightGBM回调来记录训练过程。你需要安装“Neptune-contrib[监控]”。</p>



<p>接下来，您将导入“neptune_monitor”回调并将其传递给LightGBM的“train”方法。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> neptunecontrib.monitoring.lightgbm <span class="hljs-keyword">import</span> neptune_monitor
<span class="hljs-keyword">import</span> lightgbm <span class="hljs-keyword">as</span> lgb
lgb_train = lgb.Dataset(X_train, y_train)
lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)

gbm = lgb.train(params,
    lgb_train,
    num_boost_round=<span class="hljs-number">200</span>,
    valid_sets=[lgb_train, lgb_eval],
    valid_names=[<span class="hljs-string">'train'</span>,<span class="hljs-string">'valid'</span>],
    callbacks=[neptune_monitor()],
   )</pre>



<p>一旦训练过程结束，您可以回到Neptune web UI来查看实验并比较结果。</p>







<p>Neptune也记录模型度量。例如，让我们看看如何记录平均绝对误差、均方误差和均方根误差。您可以使用“log_metric”功能记录各种指标。</p>



<pre class="hljs">predictions = gbm.predict(X_test)
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error, mean_absolute_error
neptune.log_metric(<span class="hljs-string">'Root Mean Squared Error'</span>, np.sqrt(mean_squared_error(y_test, predictions)))
neptune.log_metric(<span class="hljs-string">'Mean Squarred Error'</span>, mean_squared_error(y_test, predictions))
neptune.log_metric(<span class="hljs-string">'Mean Absolute Error'</span>, mean_absolute_error(y_test, predictions))</pre>







<p>Neptune还自动记录训练和验证学习曲线。您可以在web用户界面的图表菜单下找到这些内容。</p>











<p>记录你训练好的模型是非常重要的。通过这种方式，您可以快速将其投入生产。您可以使用“log_artifact”功能记录所有模型。</p>



<pre class="hljs">gbm.save_model(<span class="hljs-string">'model.pkl'</span>)
neptune.log_artifact(<span class="hljs-string">'model.pkl'</span>)</pre>



<p>Neptune允许您访问这个实验并下载模型。使用“get_experiments”方法访问实验，并使用“download_artifact”功能下载模型。这个模型需要工件的名称以及您想要存储它的路径。</p>



<pre class="hljs">project = neptune.init(<span class="hljs-string">'mwitiderrick/LIGHTSAT'</span>,api_token=<span class="hljs-string">'YOUR_TOKEN'</span>)
experiment = project.get_experiments(id=<span class="hljs-string">'LIGHTSAT-5'</span>)[<span class="hljs-number">0</span>]
experiment.download_artifact(<span class="hljs-string">"model.pkl"</span>,<span class="hljs-string">"model"</span>)</pre>



<p>查看这款笔记本，了解Neptune的更多功能，并体验完整的LightGBM实验。</p>



<h2 id="h-mlflow">MLflow</h2>



<p><a href="https://web.archive.org/web/20221206203026/https://mlflow.org/docs/latest/quickstart.html" target="_blank" rel="noreferrer noopener nofollow"> MLflow </a>是一个开源平台，用于跟踪机器学习模型、记录和管理ML模型构建元数据。它还集成了流行的数据科学工具。让我们来看看LightGBM集成(这种集成在MLflow中仍处于试验阶段)。</p>



<p>使用MLflow运行实验时，我们要做的第一件事是启用参数和指标的自动记录。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> mlflow
mlflow.lightgbm.autolog()</pre>



<p>您也可以使用“log_param”功能手动记录参数。该方法记录当前运行下的参数。如果没有处于活动状态的管路，它将创建一个新管路。</p>



<pre class="hljs">params = {<span class="hljs-string">'boosting_type'</span>: <span class="hljs-string">'gbdt'</span>,
              <span class="hljs-string">'objective'</span>: regression,
              <span class="hljs-string">'num_leaves'</span>: <span class="hljs-number">67</span>,
              <span class="hljs-string">'learning_rate'</span>: <span class="hljs-number">0.01</span>,
              <span class="hljs-string">'feature_fraction'</span>: <span class="hljs-number">0.8</span>
              }

mlflow.log_param(<span class="hljs-string">"boosting_type"</span>, params[<span class="hljs-string">"boosting_type"</span>])
mlflow.log_param(<span class="hljs-string">"objective"</span>, params[<span class="hljs-string">"objective"</span>])
mlflow.log_param(<span class="hljs-string">"num_leaves"</span>, params[<span class="hljs-string">"num_leaves"</span>])
mlflow.log_param(<span class="hljs-string">"learning_rate"</span>, params[<span class="hljs-string">"learning_rate"</span>])
mlflow.log_param(<span class="hljs-string">"feature_fraction"</span>, params[<span class="hljs-string">"feature_fraction"</span>])</pre>



<p>也可以使用“log_model”功能手动记录经过训练的LightGBM模型。启用自动记录时，MFlow会自动记录此情况。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> mlflow.lightgbm <span class="hljs-keyword">import</span> log_model
log_model(artifact_path=<span class="hljs-string">'lightgbm-model'</span>,lgb_model=gbm)</pre>



<p>然后，您可以使用该模型对新数据进行预测。加载模型，并使用“预测”功能进行预测。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> mlflow
logged_model = <span class="hljs-string">'file:///Users/derrickmwiti/Downloads/mlruns/0/56cb6b76c6824ec0bc58d4426eb92b91/artifacts/lightgbm-model'</span>


loaded_model = mlflow.pyfunc.load_model(logged_model)


<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
loaded_model.predict(pd.DataFrame(data))</pre>



<p>如果你将模型作为<a href="https://web.archive.org/web/20221206203026/https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html" target="_blank" rel="noreferrer noopener nofollow">火花UDF </a>加载，你也可以在<a href="https://web.archive.org/web/20221206203026/https://neptune.ai/blog/apache-spark-tutorial" target="_blank" rel="noreferrer noopener nofollow">火花数据帧</a>上进行预测。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> mlflow
logged_model = <span class="hljs-string">'file:///Users/derrickmwiti/Downloads/mlruns/0/56cb6b76c6824ec0bc58d4426eb92b91/artifacts/lightgbm-model'</span>


loaded_model = mlflow.pyfunc.spark_udf(logged_model)


df.withColumn(loaded_model, <span class="hljs-string">'my_predictions'</span>)</pre>



<p>您可以使用“mlflow.end_run()”函数结束活动的MLflow运行。可以随时从网络用户界面查看跑步记录。您可以通过在终端上执行“mflow ui”来启动web UI。</p>







<p>网络用户界面使得比较不同的跑步变得容易。这将显示不同参数和指标的比较。</p>







<p>您还可以看到不同运行的训练和验证学习曲线的比较。</p>







<p>在artifacts部分，您将会找到记录的模型和图表。例如，下面是一次LightGBM训练运行的记录特征重要性。</p>







<p>点击查看完整的<a href="https://web.archive.org/web/20221206203026/https://colab.research.google.com/drive/1LwwJIsQ5Zb9ETngBjqagwhhsm6kufXQF?usp=sharing" target="_blank" rel="noreferrer noopener nofollow"> MLflow示例。</a></p>



<p>检查<a href="/web/20221206203026/https://neptune.ai/vs/mlflow" target="_blank" rel="noreferrer noopener"> MLflow与海王星</a>相比如何。</p>



<h2 id="h-weights-and-biases">权重和偏差</h2>



<p>Weights and Biases是一个平台，用于<a href="/web/20221206203026/https://neptune.ai/experiment-tracking" target="_blank" rel="noreferrer noopener">实验跟踪</a>、模型、数据集版本化以及管理ML模型构建元数据。要开始使用它，你必须<a href="https://web.archive.org/web/20221206203026/https://docs.wandb.ai/quickstart" target="_blank" rel="noreferrer noopener nofollow">创建一个账户和一个项目</a>。然后，您将在Python代码中初始化项目。</p>



<p>现在让我们导入‘wandb’并初始化一个项目。此时，您可以传递将用于LightGBM算法的参数。这些将被记录下来，您将在web用户界面上看到它们。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> wandb
params = {<span class="hljs-string">'boosting_type'</span>: <span class="hljs-string">'gbdt'</span>,
          <span class="hljs-string">'objective'</span>: <span class="hljs-string">'regression'</span>,
          <span class="hljs-string">'num_leaves'</span>: <span class="hljs-number">40</span>,
          <span class="hljs-string">'learning_rate'</span>: <span class="hljs-number">0.1</span>,
          <span class="hljs-string">'feature_fraction'</span>: <span class="hljs-number">0.9</span>
          }
run = wandb.init(config=params,project=<span class="hljs-string">'light'</span>, entity=<span class="hljs-string">'mwitiderrick'</span>, name=<span class="hljs-string">'light'</span>)</pre>







<p>下一步是使用来自“wandb”的LightGBM回调来可视化和记录模型的训练过程。将“wandb_callback”传递给LightGBM的“train”函数。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> wandb.lightgbm <span class="hljs-keyword">import</span> wandb_callback

gbm = lgb.train(params,
    lgb_train,
    num_boost_round=<span class="hljs-number">200</span>,
    valid_sets=[lgb_train, lgb_eval],
    valid_names=[<span class="hljs-string">'train'</span>,<span class="hljs-string">'valid'</span>],
    callbacks=[wandb_callback()],
   )</pre>



<p>权重和偏差日志标量，如准确性和回归度量。让我们看看如何记录每次LightGBM运行的回归指标。使用“wandb.log”功能。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error, mean_absolute_error
predictions = gbm.predict(X_test)
wandb.log({<span class="hljs-string">'Root Mean Squared Error'</span>: np.sqrt(mean_squared_error(y_test, predictions))})
wandb.log({<span class="hljs-string">'Mean Squared Error'</span>: mean_squared_error(y_test, predictions)})
wandb.log({<span class="hljs-string">'Mean Absolute Error'</span>: mean_absolute_error(y_test, predictions)})</pre>



<p>网络用户界面还会自动记录培训和验证学习计划。</p>







<p>您还可以从运行中快速创建报告。</p>







<p>您可以保存训练好的LightGBM模型，并在每次运行时将其记录到权重和偏差中。实例化一个空的“工件”实例，然后用它来记录模型。数据集可以类似地被记录。</p>



<pre class="hljs">gbm.save_model(<span class="hljs-string">'model.pkl'</span>)
artifact = wandb.Artifact(<span class="hljs-string">'model.pkl'</span>, type=<span class="hljs-string">'model'</span>)
artifact.add_file(<span class="hljs-string">'model.pkl'</span>)
run.log_artifact(artifact)</pre>



<p>您将在web UI的工件部分看到记录的模型。</p>







<p>您可以使用' wandb.finish()'来结束特定的实验。点击查看完整的<a href="https://web.archive.org/web/20221206203026/https://colab.research.google.com/drive/16aYcVYEG3yWn3f9hXHtfAz-KkVP_KRO8?usp=sharing" target="_blank" rel="noreferrer noopener nofollow">带重量和偏差的LightGBM示例。</a></p>



<p>检查<a href="/web/20221206203026/https://neptune.ai/vs/wandb" target="_blank" rel="noreferrer noopener">权重&amp;偏差与海王星</a>相比如何。</p>



<h2 id="h-sacred">神圣的</h2>



<p><a href="https://web.archive.org/web/20221206203026/https://github.com/IDSIA/sacred" target="_blank" rel="noreferrer noopener nofollow">神圣</a>是一个开源的机器学习实验工具。该工具还可以用于记录和管理ML模型构建元数据。使用神圣时，首先需要创建一个实验。如果你在Jupyter笔记本上运行实验，你需要通过“interactive=True”。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> sacred <span class="hljs-keyword">import</span> Experiment
ex = Experiment(<span class="hljs-string">'lightgbm'</span>,interactive=<span class="hljs-keyword">True</span>)</pre>



<p>接下来，使用` @ex.config `装饰器定义实验配置。该配置用于定义和记录算法的参数。</p>



<pre class="hljs"><span class="hljs-meta">@ex.config</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cfg</span><span class="hljs-params">()</span>:</span>
    params = {<span class="hljs-string">'boosting_type'</span>: <span class="hljs-string">'gbdt'</span>,
              <span class="hljs-string">'objective'</span>: <span class="hljs-string">'regression'</span>,
              <span class="hljs-string">'num_leaves'</span>: <span class="hljs-number">40</span>,
              <span class="hljs-string">'learning_rate'</span>: <span class="hljs-number">0.01</span>,
              <span class="hljs-string">'feature_fraction'</span>: <span class="hljs-number">0.9</span>
              }</pre>



<p>接下来，定义run函数。在交互模式下运行时，这个函数必须用` @ex.main `修饰。否则，使用` ex.automain`。这个修饰器负责计算主文件所在的文件名。带有这些装饰器的函数是在运行实验时执行的函数。对于这个实验，在“run”函数中会发生一些事情:</p>



<ul><li>LightGBM模型的训练，</li><li>保存模型，</li><li>使用该模型进行预测，</li><li>使用“log_scalar”方法记录回归度量，</li><li>使用“add_artifact”函数记录模型。</li></ul>



<p>您还可以使用“添加资源”功能记录资源，如Python文件。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> lightgbm <span class="hljs-keyword">as</span> lgb

<span class="hljs-meta">@ex.main</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(params)</span>:</span>
    lgb_train = lgb.Dataset(X_train, y_train)
    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)
    gbm = lgb.train(params,
        lgb_train,
        num_boost_round=<span class="hljs-number">200</span>,
        valid_sets=[lgb_train, lgb_eval],
        valid_names=[<span class="hljs-string">'train'</span>,<span class="hljs-string">'valid'</span>],
       )
    gbm.save_model(<span class="hljs-string">'model.pkl'</span>)
    predictions = gbm.predict(X_test)

    ex.log_scalar(<span class="hljs-string">'Root Mean Squared Error'</span>, np.sqrt(mean_squared_error(y_test, predictions)))
    ex.log_scalar(<span class="hljs-string">'Mean Squared Error'</span>, mean_squared_error(y_test, predictions))
    ex.log_scalar(<span class="hljs-string">'Mean Absolute Error'</span>, mean_absolute_error(y_test, predictions))
    ex.add_artifact(<span class="hljs-string">"model.pkl"</span>)
    ex.add_resource(<span class="hljs-string">"main.py"</span>)
</pre>



<p>下一步是进行实验。</p>



<pre class="hljs">r = ex.run()</pre>



<p>不幸的是，Sacred没有提供可以用来查看实验的网络用户界面。为此，您必须使用外部工具。这就把我们带到了下一个图书馆，Omniboard。</p>



<h2 id="h-omniboard">总括</h2>



<p>Omniboard是一个基于网络的神圣用户界面。该工具连接到神圣使用的MongoDB数据库。然后，它将为每个实验收集的指标和日志可视化。要查看神圣收集的所有信息，您必须创建一个观察者。“MongoObserver”是默认的观察者。它连接MongoDB数据库并创建一个包含所有这些信息的集合。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> sacred.observers <span class="hljs-keyword">import</span> MongoObserver
ex.observers.append(MongoObserver())</pre>



<p>准备就绪后，您可以从终端运行<a href="https://web.archive.org/web/20221206203026/https://vivekratnavel.github.io/omniboard/#/quick-start" target="_blank" rel="noreferrer noopener nofollow"> Omniboard </a>。</p>



<pre class="hljs">$ omniboard -m localhost:<span class="hljs-number">27017</span>:sacred</pre>



<p>然后，您可以通过127.0.0.1:9000访问web用户界面。</p>







<p>点击跑步将显示更多相关信息。例如度量标准。</p>







<p>您还可以看到在运行过程中记录的模型。</p>







<p>跑步者配置也在那里。</p>







<p>使用神圣+ Omniboard的<a href="https://web.archive.org/web/20221206203026/https://colab.research.google.com/drive/1hDQ9ypq_Nr6xP_LB5lDbHT1k6KltmXQY?usp=sharing" target="_blank" rel="noreferrer noopener nofollow">完整例子在这里</a>。你必须在服务器或你的本地机器上运行笔记本，这样你就可以<a href="https://web.archive.org/web/20221206203026/https://vivekratnavel.github.io/omniboard/#/quick-start" target="_blank" rel="noreferrer noopener nofollow">完成所有需要的设置</a>来运行Omniboard。</p>



<p>查查<a href="/web/20221206203026/https://neptune.ai/vs/sacred-omniboard" target="_blank" rel="noreferrer noopener">神圣+全能和海王星</a>相比如何。</p>



<h2 id="h-final-thoughts">最后的想法</h2>



<p>在本文中，我们使用各种实验跟踪工具运行了机器学习实验。您看到了如何:</p>



<ul><li>创建运行和实验，</li><li>日志模型和数据集，</li><li>捕获所有实验元数据，</li><li>比较不同的运行，</li><li>记录模型参数和度量。</li></ul>



<p>希望你学到了新东西。感谢阅读！</p>
        </div>
        
    </div>    
</body>
</html>