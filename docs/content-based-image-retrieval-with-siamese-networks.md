# 用 PyTorch 中的连体网络实现基于内容的图像检索

> 原文：<https://web.archive.org/web/https://neptune.ai/blog/content-based-image-retrieval-with-siamese-networks>

图像检索是寻找与给定查询相关的图像的任务。对于基于内容的图像检索，我们指的是找到包含一些属性的图像的任务，这些属性不在图像元数据中，但存在于其视觉内容中。

在本帖中，我们:

*   解释基于内容的图像检索背后的**理论概念**，
*   逐步展示如何用 PyTorch 构建一个基于内容的图像检索系统，解决一个特定的应用:寻找具有一组给定人脸属性(即男性、金发、微笑)的人脸图像。

![](img/165ebd365c68b3b23a3d1e2054f1ac03.png)

排序损失，对比损失，连体网，三联网，三联损失，图像检索

得益于 PyTorch + Neptune 集成，您可以如何跟踪您的模型训练。

## 基于内容的图像检索:如何在高层构建

为了找到最接近给定查询的图像，[图像检索](https://web.archive.org/web/20221206004822/https://www.sciencedirect.com/topics/computer-science/image-retrieval)系统需要:

*   计算测试集(通常称为检索集)中的所有图像与查询之间的相似性得分。
*   根据与查询的相似性对所有这些图像进行排序，
*   退回最上面的。

学习这些相似性的常见策略是学习图像和查询在同一向量空间(通常称为嵌入空间)中的表示(通常称为嵌入)。

在我们的例子中，这将是学习人脸图像的嵌入和在同一空间中编码人脸属性的向量。

神经网络用于学习上述嵌入。在我们的例子中，卷积神经网络(CNN)用于学习图像嵌入，多层感知器(MLP)是一组完全连接的层，用于学习属性向量嵌入。

这些网络以连体方式建立，并以排序损失(在我们的例子中是三联损失)进行训练。接下来我们将深入解释这些概念。

架构和损失

## **排名损失:三重损失**

### 排序损失旨在学习样本之间的相对 T2 距离，这项任务通常被称为 T4 度量学习。

为此，他们**计算样本表示之间的距离**(即欧几里德距离)，并优化模型以**最小化相似样本的距离，最大化不同样本的距离**。因此，模型最终会学习您定义为相似的样本的相似表示，以及您定义为不相似的样本的距离表示。

三重损失是最常用的排名损失。它处理三个一组的样本，包括:

锚样(三联体的参考样品)。

*   阳性样本(与锚相似)。
*   阴性样本(与锚不同)。
*   **三元组损失优化了模型，使得负样本和锚样本表示之间的距离比锚样本和正样本表示之间的距离大一个裕度。**

边缘的功能是当模型充分区分三个一组的阳性和阴性样本时，不浪费努力来扩大分离，以便它可以集中于更困难的三个一组。

换句话说:当给定三元组的网络性能已经是最佳时，余量建立。

三重态损耗正式定义为:

**L(a，p，n) = max(0，m + d(a，p)-d(a，n))**

> 其中:

d 是使用的距离函数(即欧几里德距离)，

*   m 是余量，
*   a、p 和 n 分别是锚、阳性和阴性样本的表示。
*   在我们面对按属性检索的例子中:

锚样本是一个**图像**，

*   正样本是编码其属性的向量，
*   负样本是一个属性不匹配的**向量**。
*   因此，该模型将被优化以在嵌入空间中靠近其属性向量嵌入该图像，而远离其他属性表示。在测试阶段，当您使用属性向量进行查询以检索包含这些属性向量的图像时，您将会发现嵌入在它附近的图像。

**简单、坚硬和半坚硬的三胞胎**

### 根据三元组样本之间的距离，在损失计算期间，我们可以有三种不同类型的[三元组](https://web.archive.org/web/20221206004822/https://omoindrot.github.io/triplet-loss):

**简单三联体**:与阳性样本相比，阴性样本与锚定样本的距离足够远。损失为 0，梯度也是。

*   **d(a，n) > (d(a，p) + m)**

**硬三元组**:负样本表示比正样本表示更接近锚样本表示。网络不能正确地区分这个三联体的阳性和阴性样本。

*   **d(a，n) < d(a，p)**

**半硬三连音**:负样本表示比正样本表示离锚更远，但距离之间的差异不大于边距。因此，网络必须把它们拉得更远。

*   **d(a，n) < (d(a，p) + m)**

**暹罗网**

### [分级损耗](https://web.archive.org/web/20221206004822/https://gombru.github.io/2019/04/03/ranking_loss/)通常用于连体网络架构。[暹罗网络](https://web.archive.org/web/20221206004822/https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18)是共享参数的神经网络，也就是共享权重。实际上，这意味着在训练过程中，我们优化单个神经网络，尽管它处理不同的样本。

在我们通过属性检索人脸图像的例子中，每个三元组包含一个图像(锚点)和两个属性向量(正面和负面)。

处理属性向量的网络将是连体的，这意味着我们将使用同一个网络来转发它们。这是因为我们想要为正负属性向量学习相同的特征提取器。

**py torch 中的三重态丢失**

### PyTorch 提供了三重损失的实现，称为三重边际损失，您可以在这里找到。

该文档使用与本文相同的术语。默认情况下，它使用欧几里德距离来计算输入张量之间的距离。你可以试着把它改成其他的距离，但是从我的经验来看，这并没有太大的区别。

您可以通过导入 Pytorch 神经网络库并设置边距来实例化它:

对于模型的收敛来说,**确切的差值并不重要。**

```py
import torch.nn as nn
criterion = nn.TripletMarginLoss(margin=0.1)
```

也就是说，您需要确保由损耗计算的距离差在您设置的值附近。一个好的做法是设置一个界限，使得在训练开始时，一半的三元组是随机正确的，而另一半是不正确的。常用的值是 0.1。

要在模型计算了三联体样本的表示后计算训练循环中的损失，您应该调用:

其中三元组样本表示总是按照该顺序。

```py
loss = criterion(anchor, positive, negative)
loss.backward()
```

利用 Pytorch 中的三重损失进行人脸图像检索

## **目标:找到具有某些属性的人脸图像**

### 本示例任务中的**目标**是找到具有特定属性的人脸图像。为了做到这一点，我们将使用一个带有注释二进制属性的人脸图像数据集。

使用的**数据集**是[大规模名人脸属性(CelebA)数据集](https://web.archive.org/web/20221206004822/http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)，它包含大约 200，000 张名人脸图像和 40 个带注释的二进制属性。属性被编码为 40 维多热点向量，其中包含 1 来指示正面的人脸图像属性，包含 0 来指示其余的属性。

为了让您对带注释的属性有所了解，让我列出几个:

眼袋

*   尖鼻子
*   髭
*   戴耳环
*   戴项链
*   鹅蛋脸
*   最终的图像检索系统旨在找到具有这些属性的给定组合的人脸图像。这里您可以看到数据集中的一些图像示例:

**如何创建训练三元组**

### 训练该系统在给定人脸属性的情况下检索人脸图像的三元组将包括:

一个图像(它是锚)，

1.  它的属性向量(正的)，
2.  和一个负属性向量(负的)。
3.  因此，要创建三元组的锚和正样本，只需加载一个图像及其属性，并将其放入张量中。

接下来，您需要为我们的三元组选择负面属性。**你可以**只是:

创建一个随机多热点 40 维向量，

*   检查与正向量不同的向量，
*   用它做反面。
*   但是**你最终会得到太多简单的三胞胎，**考虑到许多负面属性向量不太可能出现:例如(“女人”+“金发”+“有胡子”)。因此，模型很容易确定哪一个是正属性向量，并且它不会学习正确区分可能的属性向量。

保存数据集统计数据的**通用策略**是:

从训练数据中采样随机属性向量，

*   检查它是否不同于我们的正向量，
*   用它做反面。
*   如果`self.attribute_vectors`包含所有训练集属性:

一个**创建硬负**的策略，可以和上一个结合，就是从正属性向量中改变一些属性。举个例子:

```py
while True:
    att_negative = random.choice(self.attribute_vectors)
    if not np.array_equal(att_n, att_positive):
        break
```

用这些硬负三元组训练迫使模型区分除了 1、2 或 3 之外所有属性都相似的属性向量。

```py
num_changes = random.randint(1,3)
att_negative = np.copy(att_positive)

for c in range(0,num_changes):
   att_idx = random.randint(0,len(att_negative) - 1)
   if att_positive[att_idx] == 0:
      att_negative[att_idx] = 1
   else:
      att_negative[att_idx] = 0
```

**如何设计模型并训练它**

### 您需要一个神经网络架构，它可以在同一个向量空间(嵌入空间)中学习**图像和属性向量嵌入，这样我们就可以计算它们之间的距离和三元组损失。**

你需要做的第一件事是选择嵌入空间的维数。这取决于你想要学习的相似性的复杂程度，但是典型的维度范围是从 100 到 500。我们会选 300。

下图显示了我们将使用的架构:

为了学习**图像嵌入**，我们使用 CNN(即 ResNet-50)，其输出数量与嵌入空间维数相同。该 CNN 将图像张量(img_a，它是我们三元组的锚)[224x224x3]作为输入，并输出 300-D 向量(a)。

为了学习**属性向量嵌入**，我们使用了一个由两个 300-D 线性层组成的 [MLP](https://web.archive.org/web/20221206004822/https://medium.com/data-science-bootcamp/multilayer-perceptron-mlp-vs-convolutional-neural-network-in-deep-learning-c890f487a8f1) ，其具有批量标准化和 ReLU 激活。我们的三元组的正样本和负样本都是属性向量，我们将使用相同的层来处理它们，这就是所谓的连体架构(如图中黄色所示)。

一旦计算出图像和属性向量的嵌入，我们就对它们进行 L2 归一化，以确保它们具有相同的[欧几里德范数](https://web.archive.org/web/20221206004822/https://en.wikipedia.org/wiki/Norm_(mathematics))，并将它们输入到三元组损失中，以计算它们之间的距离。在 PyTorch 中，我们可以将训练循环写成:

注意`att_positive`和`att_negative`是由同一个 MLP 处理的:我们为它们使用了暹罗网络。

```py
anchor = self.CNN(img_anchor)
positive = self.MLP(att_positive)
negative = self.MLP(att_negative)
loss = criterion(anchor, anchor, negative)
optimizer.zero_grad()
loss.backward()
optimizer.step()
```

**如何监控培训**

### 当使用三元组损失来训练图像检索模型时，比在其他情况下更难监控训练，例如当训练用于图像分类的网络时。这是因为测试图像检索需要整个数据集的图像嵌入。

除了直接监控训练和验证损失(这当然会显示模型是否正确学习)之外，在训练和验证期间，监控每批正确三元组的数量也是有用的。

随着损失的减少，在学习期间，每批**的正确三联体(易否定)的百分比应该增加。此外，这个百分比给了你一个暗示，三胞胎上网有多难。**

如果很高比例的三元组已经是正确的，网络没有从他们那里学到任何东西，所以转发他们是一种**计算浪费**，也许你应该修改你的三元组创建管道来创建更难的三元组。

**使用训练好的模型进行图像检索**

### 一旦模型被训练，使用它进行图像检索是简单的。您应该:

计算所有检索集图像的嵌入，并将它们保存到磁盘。

1.  计算查询的嵌入(属性向量)
2.  计算查询嵌入和所有检索集图像之间的距离。
3.  找最近的。
4.  结果？

让我们看一下针对不同属性查询的建议模型的一些结果:

看起来相当不错！

如何评价一个图像检索模型

[基于内容的图像检索](https://web.archive.org/web/20221206004822/https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?referer=&httpsredir=1&article=3320&context=sis_research)系统通过检查它们针对一组查询检索的图像是否包含期望的属性来进行评估。

## 文献中使用了不同的指标，这取决于任务和您想要评估的系统特性。这可能会令人困惑，所以让我解释两个最常用的

Precision@K (P@K):它只考虑前 K 个(通常是 1、5、10 或 100 个)检索到的图像。当您只对正确检索有限数量的图像感兴趣时(推荐系统)，或者当检索集太大而无法评估所有排名时，可以使用它。如果检索到的图像包含查询属性，则认为它是正确的。

**P @ K = Top K/K 中的正确结果**

*   当报告一组查询的平均 P@K 时，这个指标有时被写成 AP@K。

平均精度(mAP):它考虑了所有检索集的排序。它为 k=1，2，…，N 计算 P@K，N 是具有查询属性的检索集图像的数量。然后，它平均所有的精度。这个度量的计算成本更高，也更不直观，但是它可以深入地评估一个检索系统。

*   什么可能出错:要避免的事情和最佳实践

一如既往，有太多的事情可能会出错，所以让我分享一下我的经验教训:

## **设置余量**:如果在训练开始时，损失减少，但正确的三胞胎数量没有增加，可能是您设置了过大的余量。一个好的做法是设置余量，这样当你开始训练时，一些三连音可能已经是正确的了。

**监控正确的三元组并使用硬否定**:如果你的批处理中的大多数三元组已经是正确的，修改你的三元组挖掘策略以使用更硬的否定，因为你的模型没有从它们那里学到任何东西。但是，请注意保留数据集的统计数据。
也许你只是想在你的批次中使用给定百分比的硬三元组:这高度依赖于你的问题，但如果你的三元组不现实，你可能最终会训练你的网络来区分你在任何现实场景中找不到的样本。

*   **在检索过程中计算距离**:确保您使用的距离函数与丢失时使用的距离函数相同。也就是说，如果损失使用欧几里德距离，您也应该在检索时使用它。

*   **检索效率**:如果您将检索集图像嵌入加载到您的 GPU 中，并使用 CUDA 中的查询计算距离，对于大型数据集，检索将会快得多。

*   最后的想法

*   **基于内容的图像检索**是通过图像的内容找到图像的任务。

## **排序损失**允许神经网络通过比较样本在向量空间中的表示来学习样本之间的距离。

*   **暹罗网络**是最常见的分级损失训练架构。在该架构中，不同的样本在每次迭代中通过相同的层转发。
*   所使用的**否定选择**策略对于高效训练和更好的表现非常重要。
*   监控每批正确三联体的**数量有助于确保模型被正确训练。**
*   额外资源
*   Monitoring the **number of correct triplets per batch** is helpful to ensure the model is being trained properly.

## Additional resources