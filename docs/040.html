<html>
<head>
<title>Building MLOps Pipeline for Time Series Prediction [Tutorial] </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>为时序预测构建MLOps管道[教程]</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/mlops-pipeline-for-time-series-prediction-tutorial#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/mlops-pipeline-for-time-series-prediction-tutorial#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>在本教程中，我们将展示一个基于时间序列的ML项目的简单示例，并为其构建一个MLOps管道。每一步都将按照MLOps的最佳实践来执行，整个项目将一步一步地解释。</p>



<p>这个时序项目是基于币安交易应用，但类似的逻辑也适用于其他ML项目。</p>



<p><strong>注意</strong>:这篇文章不是为了财务建议，它只是为了教育目的而写的。此外，本文的主要目的是介绍具有端到端ML项目流程的MLOps架构，而不是介绍有利可图的交易策略。</p>







<h2 id="h-mlops-101">MLOps 101</h2>



<p>MLOps代表机器学习操作，它是管理ML项目管道的过程。MLOps的作用是将ML项目的不同部分连接成一个结构，与其所有组件协调工作，并在将来保留该功能。为了实现最大的健壮性，MLOps应用了DevOps的一些实践，尤其是持续集成和持续交付(CI/CD):</p>



<ol>
<li><strong>持续集成</strong>确保每当一段代码或数据更新时，整个ML管道都能平稳运行。这是通过代码和数据版本化实现的，它允许代码在不同的团队之间共享和运行。重新运行可能包括培训和测试，但是拥有并运行代码测试以确保输入和输出数据遵循特定的格式并且一切按预期运行也是一个好的实践。</li>
</ol>



<ol start="2">
<li><strong>连续交付</strong>允许自动部署新的ML模型。通过CD流程，可以使用触发器在现有环境中部署新模型，例如新数据集上的重新训练模型、新超参数或新模型架构。</li>
</ol>



<p id="separator-block_c2fa3ac434962556cd5c0390a6b428d1" class="block-separator block-separator--20"> </p>





<p>总的来说，对于有编程经验的人来说，理解MLOps最简单的方法就是和DevOps对比。但在工具和流程上，它们并不完全相同。DevOps和MLOps都试图整合开发、测试和操作原则；然而，DevOps专注于常规软件开发，而MLOps只专注于ML项目。</p>



<p>在ML项目中，代码不是版本控制管理下的唯一组件。输入数据、超参数、元数据、日志和模型会随着时间而变化，因此需要控制和监控。另一个区别是传统软件不会退化，而ML模型会。一旦模型被部署到生产中，它就有可能开始产生错误和不准确的结果。这是因为输入数据随着时间的推移而变化，而模型保持不变，用旧数据进行训练。</p>



<p>因此，除了CI/CD之外，MLOps还包括:</p>



<ul>
<li><strong>持续培训(CT)</strong>-在生产中自动重新培训ML模型的过程。</li>



<li><strong>持续监控(CM)</strong>-持续监控生产中的数据和模型，以便注意潜在的数据漂移或模型过时。</li>
</ul>



<h3>MLOps阶段</h3>



<p>没有解决MLOps问题的独特方法或架构，尤其是现在有数百个与MLOps相关的工具和软件包。这是因为ML项目的多样性和MLOps的概念相当年轻的事实，我们可以提出一些步骤来帮助建立MLOps管道，但最有可能的是，它们可能不是详尽的。</p>



<p id="separator-block_338ce4aa3c1b35408ff75e2af9a746df" class="block-separator block-separator--15">设计和范围</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><a href="https://web.archive.org/web/20221206144902/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image12.png?ssl=1" target="_blank" rel="noreferrer noopener"><img decoding="async" loading="lazy" src="../Images/364bf62f8fe4c860a25f5b53be3a4389.png" alt="Some of the MLOps tools" class="wp-image-68994" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image12.png?resize=819%2C509&amp;ssl=1"/></a><figcaption class="wp-element-caption"><em>Some of the MLOps tools | </em><a href="https://web.archive.org/web/20221206144902/https://ml-ops.org/content/state-of-mlops" target="_blank" rel="noreferrer noopener nofollow"><em>Sour</em></a><em><a href="https://web.archive.org/web/20221206144902/https://ml-ops.org/content/state-of-mlops" target="_blank" rel="noreferrer noopener nofollow">ce</a></em></figcaption></figure></div>


<h4>在我们开始开发ML项目和编写代码之前，我们需要确保业务目标是明确的，并且我们有足够的能力解决问题。接下来是<strong>设计和范围</strong>的阶段。</h4>



<p>在这个阶段，我们需要确保理解项目的<strong>问题陈述和业务目标</strong>。此外，我们需要检查<strong>所有资源</strong>的可用性，例如合适的架构、计算资源、有能力的团队等等。</p>



<p>发展</p>



<h4>在设计和确定范围之后，是<strong>项目开发</strong>。它包括:</h4>



<p><strong>研究</strong>–收集关于潜在输入特征、数据预处理步骤、ML模型、新工具等的新信息。</p>



<ul>
<li><strong>数据工程</strong>——数据摄取、开发ETL管道、数据仓库、数据库工程等。</li>



<li><strong>探索性数据分析(EDA)</strong>–使用数据分析和可视化技术了解我们的数据。</li>



<li><strong>实验开发</strong>–可能包括数据预处理、特征工程、ML模型开发、超参数调整等。</li>



<li><strong>实验跟踪</strong>–最后，我们要比较所有实验并得出结论。</li>



<li>操作</li>
</ul>



<h4>在一个模型被开发出来并准备好投入生产后，就进入了<strong>运营</strong>阶段。运营的主要目标是使用一些<strong> MLOps实践</strong>将开发的模型投入生产，如测试、版本控制、CI/CD、监控等。</h4>



<p>时间序列101</p>



<h2 id="h-time-series-101">时间序列是按时间顺序排列的数据点序列。它是同一变量在不同时间点的一系列观察结果。时间序列数据通常表示为图表上的一条线，x轴表示时间，y轴表示每个数据点的值。此外，每个时间序列都由四个部分组成:</h2>



<p>A time series is a sequence of data points that are ordered in time. It is a series of observations of the same variable at different points in time. A time-series data is often presented as a line on a graph with time on the x-axis and the value of each data point on the y-axis. Also, every time series is composed of four components:</p>



<div id="case-study-numbered-list-block_736c6575bc7888617571650f7a919c40" class="block-case-study-numbered-list ">

    
    <h2 id="h-"><span class="c-list__counter"> 1 </span>趋势</h2>

    <ul class="c-list">
                    <li class="c-list__item"><span class="c-list__counter"> 2 </span>季节变化<br/></li>
                    <li class="c-list__item"><span class="c-list__counter"> 3 </span>周期性变化<br/></li>
                    <li class="c-list__item"><span class="c-list__counter"> 4 </span>不规则或随机变化</li>
                    <li class="c-list__item"> </li>
            </ul>
</div>



<p id="separator-block_338ce4aa3c1b35408ff75e2af9a746df" class="block-separator block-separator--15">时序项目示例</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/f52617b44b104fc02307569a2f0ef680.png" alt="Example of a time series " class="wp-image-68991" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image9.png?resize=800%2C349&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Example of a time</em> <em>series | </em><a href="/web/20221206144902/https://neptune.ai/blog/time-series-tools-packages-libraries" target="_blank" rel="noreferrer noopener"><em>Source</em></a></figcaption></figure></div>






<h3>时间序列在许多行业中都有表示，并且有大量时间序列项目的真实例子。这里，我们只提其中的一部分。</h3>



<p>网站流量预测</p>



<h4>主要思想是预测特定网站的流量，并在此基础上优化资源分配。它可能有助于负载平衡器将网络或应用程序流量分布到多个服务器上。除此之外，为了发现潜在的黑客攻击，有可能为web流量中的异常检测开发ML解决方案。</h4>



<p>许多组织，如脸书、亚马逊、易贝等，都使用类似的应用程序来预测和监控互联网流量。</p>



<p>医疗保健中的时间序列项目</p>



<h4>医疗保健中的时间序列数据，如电子健康记录(EHR)和注册表，代表了有关患者的有价值的信息来源，并可在许多方面用于患者福利。使用这些数据，可以开发ML模型，从而更深入地了解个体健康和疾病的轨迹，如癌症、阿尔茨海默病、心血管疾病、新冠肺炎和许多其他疾病。</h4>



<p>利用时间序列和ML模型，有可能发现未来死亡率、复发和并发症的风险，并推荐相同的处方和预防措施。</p>



<p>股票市场预测</p>



<p id="separator-block_338ce4aa3c1b35408ff75e2af9a746df" class="block-separator block-separator--15">股票市场预测是一项非常具有挑战性的任务，其主要目标是创建各种策略来预测未来的股票价格。由于许多因素，如全球经济、财务报告、政治和其他因素，股票市场具有非常不稳定和混乱的行为。</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/9774b044276406fd39b3424f1c218883.png" alt="Time series and ML in medicine" class="wp-image-68983" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image1-1.png?resize=828%2C397&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Time series and ML in medicine | </em><a href="https://web.archive.org/web/20221206144902/https://www.vanderschaar-lab.com/time-series-in-healthcare/" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></figcaption></figure></div>


<h4>一般来说，股市预测方法的应用方式有很多种。其中一些是趋势预测，长期价格预测，波动预测，每日，每小时，或高频交易，等等。</h4>



<p>其中大多数基于两种方法；基本面分析和技术面分析。基本面分析会考虑一些因素，如财务报告、行业趋势、通货膨胀率、GDP等。技术分析使用从历史股票数据中计算出来的技术指标，并在此基础上预测股票未来的表现。</p>



<p>比特币交易</p>



<p>比特币是一种数字资产，其价格由供需决定。同样，作为股票市场，它具有非常不稳定和混乱的行为，而比特币价格预测是一个复杂的挑战。众所周知，比特币与一些科技公司的股票相关，因此可以使用许多股市预测技术。</p>



<h4>在本文中，我们将使用比特币价格交易作为时间序列项目的示例。这篇文章不是金融建议，它是为教育目的而写的，重点是时间序列和MLOps架构。因此，使用Python只能开发简单的交易策略。</h4>



<p>为了编写一个能够自动下订单的Python程序，我们将使用币安交易所和币安API及其自己的包装包<a href="https://web.archive.org/web/20221206144902/https://github.com/sammchardy/python-binance" target="_blank" rel="noreferrer noopener nofollow">Python-币安</a>。此外，币安提供了一个模拟账户，允许交易者在模拟环境中用“纸币”进行交易。关于这一点的更多内容将在下面的文章中介绍。</p>



<p><a href="https://web.archive.org/web/20221206144902/https://medium.com/insiderfinance/introduction-to-crypto-bitcoin-trading-with-python-and-binance-743916258e5f" target="_blank" rel="noreferrer noopener nofollow">使用Python和币安进行加密比特币交易简介</a></p>



<p>时间序列预测的MLOps流水线:设计和范围</p>



<p class="c-box">前面提到和简要描述的所有阶段将在下面使用我们的比特币交易示例一步一步地实际实现。</p>



<h2 id="h-mlops-pipeline-for-time-series-prediction-design-and-scope">问题陈述</h2>



<p>首先，我们需要确定我们清楚这个问题。在这种特殊的情况下，我们不需要与客户或利益相关者等外部因素进行沟通。为了更简单，我们将尝试预测每小时的比特币走势。意味着我们要预测比特币接下来一个小时是涨还是跌，这说明这是一个分类问题。基于这一预测，我们将建立多头或空头头寸(买入或卖出特定数量的比特币)。</p>



<h3>例如，如果我们预测比特币的价格将在接下来的一个小时内上涨，如果它从100美元涨到105美元，我们的利润将是5美元。否则，如果价格从100美元降到95美元，我们将损失5美元。</h3>



<p>粗略地说，预测将使用XGBoost模型，整个ML项目将遵循最佳MLOps实践。</p>



<p>在此阶段，我们可以大致提出MLOps结构的蓝图如下:</p>



<p>商业目标</p>



<p>这里的商业目标很明确，那就是盈利。这是一个非常投机的策略；除此之外，我们还需要定义我们可以处理什么样的损失。例如，在任何时候，如果该策略的累计回报率低于-20%，交易将被暂停。</p>



<p id="separator-block_338ce4aa3c1b35408ff75e2af9a746df" class="block-separator block-separator--15">可利用的资源</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/8cd1926d41e02edcd3bed91b6d82a283.png" alt="Proposed MLOps architecture" class="wp-image-68996" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image14.png?resize=831%2C434&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Proposed MLOps architecture | Source: Author</em></figcaption></figure></div>


<h3>由于我们的项目很小，而且本质上是实验性的，很可能我们不需要在工具上花任何钱。此外，不会投入实际资金，因为该项目将部署到币安模拟环境。</h3>



<p>用于功能工程和培训的所有历史比特币价格数据将从AWS S3的币安下载。由于历史数据不是很大，我们也将它下载到本地，模型开发也将在本地完成。</p>



<h3>最后，我们需要获得所有将在我们的项目中使用的工具，这将在途中完成。</h3>



<p>时间序列预测的MLOps管道:模型开发</p>



<p>研究</p>



<p>正如我们之前提到的，ML项目开发的一个好的实践是从研究开始。在我们的例子中，我们可以简单地谷歌一些与我们的项目相关的术语，如“机器学习比特币交易python”或“比特币技术指标”。此外，youtube是一个很好的信息来源，尤其是在一些更复杂的概念需要解释的时候。</p>



<h2 id="h-mlops-pipeline-for-time-series-prediction-model-development">一些高质量的资源可能不容易通过谷歌搜索获得。例如，来自<a href="https://web.archive.org/web/20221206144902/https://www.kaggle.com/" target="_blank" rel="noreferrer noopener nofollow"> Kaggle </a>的笔记本很少出现在顶级搜索结果中。此外，一些特定领域的高级课程可能会出现在<a href="https://web.archive.org/web/20221206144902/https://www.udemy.com/" target="_blank" rel="noreferrer noopener nofollow"> Udemy </a>、<a href="https://web.archive.org/web/20221206144902/https://www.udacity.com/" target="_blank" rel="noreferrer noopener nofollow"> Udacity </a>或<a href="https://web.archive.org/web/20221206144902/https://www.coursera.org/" target="_blank" rel="noreferrer noopener nofollow"> Coursera </a>上。</h2>



<h3>有一些流行的ML网站，像<a href="https://web.archive.org/web/20221206144902/https://machinelearningmastery.com/blog/" target="_blank" rel="noreferrer noopener nofollow">机器学习大师</a>、<a href="https://web.archive.org/web/20221206144902/https://medium.com/" target="_blank" rel="noreferrer noopener nofollow">中级</a>和<a href="https://web.archive.org/web/20221206144902/https://towardsdatascience.com/" target="_blank" rel="noreferrer noopener nofollow">走向数据科学</a>。高质量的MLOps内容搜索的一个好地方肯定是Neptune.ai博客。Slack上还有MLOps社区，这是一个超级活跃的从业者讨论和分享知识的团体。<a href="https://web.archive.org/web/20221206144902/https://go.mlops.community/slack" target="_blank" rel="noreferrer noopener nofollow">你可以在这里加入</a>(如果你真的加入了，就来#neptune-ai频道说说MLOps，这篇文章，或者只是打个招呼！).</h3>



<p>最后，对于一些最先进的解决方案，我们可以搜索<a href="https://web.archive.org/web/20221206144902/https://scholar.google.com/" target="_blank" rel="noreferrer noopener nofollow">谷歌学术</a>或<a href="https://web.archive.org/web/20221206144902/https://www.researchgate.net/" target="_blank" rel="noreferrer noopener nofollow">研究之门</a>。</p>



<p>数据工程</p>



<p>在我们的例子中，输入数据的唯一来源是币安。使用python-finance包，可以用现有的方法直接获得数据。此外，还有一种获取历史价格并直接保存的替代方法。每月整理的csv文件。</p>



<p>为此，我们需要使用币安公共数据库。下载压缩文件。csv文件，我们使用命令:</p>



<h3>其中“download-kline.py”是“python”目录中的脚本。关于这个python脚本及其参数的更多信息可以在<a href="https://web.archive.org/web/20221206144902/https://github.com/binance/binance-public-data/tree/master/python" target="_blank" rel="noreferrer noopener nofollow">这里</a>找到。</h3>



<p>由于我们将使用AWS云架构，数据将被摄取到<a href="https://web.archive.org/web/20221206144902/https://aws.amazon.com/s3/" target="_blank" rel="noreferrer noopener nofollow"> S3存储</a>中。新的AWS帐户可以免费获得12个月的5GB S3存储空间。为了上传数据，我们需要创建一个bucket，它是存储在S3上的对象的容器。如何创建一个桶并在桶中上传一个文件在<a href="https://web.archive.org/web/20221206144902/https://www.youtube.com/watch?v=i4YFFWcyeFM" target="_blank" rel="noreferrer noopener nofollow">这个视频</a>中有解释。</p>



<p>除了使用AWS web控制台上传数据之外，还可以从<a href="https://web.archive.org/web/20221206144902/https://aws.amazon.com/ec2/" target="_blank" rel="noreferrer noopener nofollow"> AWS EC2 </a>实例上传数据。基本上，使用EC2可以创建一个实例或虚拟机，我们可以从那里下载数据，并使用一个简单的命令直接复制到S3存储桶:</p>



<pre class="hljs">`python download-kline.py -s BTCUSDT -i <span class="hljs-number">1</span>h -startDate <span class="hljs-number">2017</span><span class="hljs-number">-08</span><span class="hljs-number">-01</span> -endDate <span class="hljs-number">2022</span><span class="hljs-number">-06</span><span class="hljs-number">-01</span>`</pre>



<p>有了一个新的AWS帐户，就有可能每月获得750小时的小实例，12个月免费。此外，我们还将在EC2实例上部署我们的项目。</p>



<p>对于更复杂的项目，AWS上有几个其他的数据工程服务，一些最常用的服务在<a href="https://web.archive.org/web/20221206144902/https://www.youtube.com/watch?v=tykcCf-Zz1M" target="_blank" rel="noreferrer noopener nofollow">视频</a>中解释。</p>



<p>ML模型开发</p>



<pre class="hljs">`aws s3 cp LOCAL_DIRECTORY/ s3://BUCKET_NAME/DIRECTORY/ --recursive`</pre>



<p>现在，当数据准备好了，我们可以开始探索性数据分析(EDA)。EDA的主要目标是探索和可视化数据，以发现一些见解，并计划如何开发模型。通常，EDA是使用<a href="https://web.archive.org/web/20221206144902/https://jupyter.org/" target="_blank" rel="noreferrer noopener nofollow"> Jupyter notebook </a>和一些用于数据操作和分析的包来完成的，例如<a href="https://web.archive.org/web/20221206144902/https://pandas.pydata.org/" target="_blank" rel="noreferrer noopener nofollow">熊猫</a>、<a href="https://web.archive.org/web/20221206144902/https://numpy.org/" target="_blank" rel="noreferrer noopener nofollow"> numpy </a>、<a href="https://web.archive.org/web/20221206144902/https://matplotlib.org/" target="_blank" rel="noreferrer noopener nofollow"> matplotlib </a>等等。</p>



<p>接下来，我们可以从特征工程开始。出于本教程的考虑，我们将使用9个技术指标作为特征(5、10和20小时的移动平均线，7、14和21小时的RSI和MFI)。所有技术指标将使用<a href="https://web.archive.org/web/20221206144902/http://mrjbq7.github.io/ta-lib/" target="_blank" rel="noreferrer noopener nofollow"> TA-Lib </a>进行计算，它们大多与金融时间序列相关，但一般来说，软件包<a href="https://web.archive.org/web/20221206144902/https://tsfresh.readthedocs.io/en/latest/" target="_blank" rel="noreferrer noopener nofollow"> tsfresh </a>是计算时间序列特征的一个好选择。</p>



<p id="separator-block_338ce4aa3c1b35408ff75e2af9a746df" class="block-separator block-separator--15">对于ML模型，我们将尝试使用<a href="https://web.archive.org/web/20221206144902/https://xgboost.readthedocs.io/en/stable/" target="_blank" rel="noreferrer noopener nofollow"> XGBoost </a>和<a href="https://web.archive.org/web/20221206144902/https://optuna.org/" target="_blank" rel="noreferrer noopener nofollow"> Optuna </a>来优化超参数。默认情况下，Optuna使用树形结构的Parzen估计器算法，但也有更多的算法可供选择。优化算法将尝试最大化我们策略的累积回报。</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/cbf4f2188535ac3960e07d8dd284a22c.png" alt="Top AWS data engineering services" class="wp-image-69007" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image25.png?ssl=1"/><figcaption class="wp-element-caption"><em>Top AWS data engineering services | </em><a href="https://web.archive.org/web/20221206144902/https://www.youtube.com/watch?v=tykcCf-Zz1M" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></figcaption></figure></div>


<h3>数据集将分为两部分:</h3>



<p><strong>样本内</strong>(从2018-01-01到2021-12-31，用于超参数搜索和回测)</p>



<p><strong>样本外</strong>(从2022年1月1日到2022年5月31日，用于复查选择策略，以确保我们没有过度拟合模型)</p>



<p>回测将使用固定滑动窗口的时间序列交叉验证来完成，因为我们希望在每次迭代中保持我们的训练集大小相同。</p>



<p>实验跟踪</p>



<ul>
<li>实验跟踪将使用<a href="https://web.archive.org/web/20221206144902/https://docs.neptune.ai/integrations-and-supported-tools/hyperparameter-optimization/optuna" target="_blank" rel="noreferrer noopener"> neptune.ai对Optuna </a>的集成来完成。这是一个非常方便的集成，让您只需几行代码，通过几个图就可以跟踪来自模型训练的所有元数据。</li>



<li>在我们的例子中，我们将使用Neptune-Optuna集成来记录和监控XGBoost模型的Optuna超参数调优。通常，与一些卷积神经网络相比，时间序列模型并不大，并且作为输入，具有几百或几千个数值，因此模型训练得相当快。</li>
</ul>



<p>对于金融时间序列，有一种方便的方法来跟踪模型超参数尤其重要，因为我们需要运行许多不同的实验。这是因为金融中的时间序列往往具有非常混乱的运动，需要大量的调整。</p>



<p id="separator-block_338ce4aa3c1b35408ff75e2af9a746df" class="block-separator block-separator--15">通过使用合适的超参数跟踪工具，我们将能够通过观察<strong>优化历史图</strong>来识别优化是如何进行的。除了<strong>运行时间和硬件消耗日志</strong>之外，我们将能够断定我们是否需要增加优化试验(迭代)。</p>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/f72aab00bfd2151df65c95da2bd389a4.png" alt="Time series cross validation with sliding window" class="wp-image-68998" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image16.png?resize=753%2C393&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Time series cross validation with sliding window | </em><a href="https://web.archive.org/web/20221206144902/https://www.kaggle.com/code/cworsnup/backtesting-cross-validation-for-timeseries/notebook" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></figcaption></figure></div>


<h3>Neptune-Optuna集成提供了对<strong>超参数重要性</strong>、<strong>平行坐标图</strong>的可视化，显示了不同超参数值和目标函数值之间的关系，以及许多更有用的功能。</h3>



<p>为此，首先，我们将在主类中定义“objective”方法:</p>



<p>其中“trial”是Optuna中使用的参数，“apply_strategy”准备数据并训练模型，而“get_score”在我们的情况下返回累积回报，作为我们想要优化的度量。之后，我们需要连接Optuna和neptune.ai</p>



<p>更多信息，请遵循这个<a href="https://web.archive.org/web/20221206144902/https://docs.neptune.ai/integrations-and-supported-tools/hyperparameter-optimization/optuna" target="_blank" rel="noreferrer noopener">海王星-Optuna整合指南</a>。</p>



<p> </p>



<p>用于时间序列预测的MLOps流水线:自动化测试</p>



<p>在模型开发期间，我们将使用<a href="https://web.archive.org/web/20221206144902/https://github.com/" target="_blank" rel="noreferrer noopener nofollow"> GitHub </a>作为源代码管理工具。此外，基于一个项目及其需求，实现一些自动化测试是一个很好的实践。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">objective</span><span class="hljs-params">(self, trial)</span>:</span>

    params = {
        <span class="hljs-string">'n_estimators'</span>: trial.suggest_int(<span class="hljs-string">'n_estimators'</span>, <span class="hljs-number">350</span>, <span class="hljs-number">1000</span>),
        <span class="hljs-string">'max_depth'</span>: trial.suggest_int(<span class="hljs-string">'max_depth'</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>),
        <span class="hljs-string">'learning_rate'</span>: trial.suggest_uniform(<span class="hljs-string">'learning_rate'</span>, <span class="hljs-number">0.01</span>, <span class="hljs-number">0.10</span>),
        <span class="hljs-string">'subsample'</span>: trial.suggest_uniform(<span class="hljs-string">'subsample'</span>, <span class="hljs-number">0.50</span>, <span class="hljs-number">0.90</span>),
        <span class="hljs-string">'colsample_bytree'</span>: trial.suggest_uniform(<span class="hljs-string">'colsample_bytree'</span>, <span class="hljs-number">0.50</span>, <span class="hljs-number">0.90</span>),
        <span class="hljs-string">'gamma'</span>: trial.suggest_int(<span class="hljs-string">'gamma'</span>, <span class="hljs-number">0</span>, <span class="hljs-number">20</span>),
    }
    look_back = trial.suggest_int(<span class="hljs-string">'look_back'</span>, <span class="hljs-number">30</span>, <span class="hljs-number">180</span>)
    self.apply_strategy(params)

    <span class="hljs-keyword">return</span> self.get_score()
</pre>



<p>作为自动化测试的一个例子，我们将创建一个简单的冒烟测试，使用<a href="https://web.archive.org/web/20221206144902/https://github.com/features/actions" target="_blank" rel="noreferrer noopener nofollow"> GitHub actions </a>运行整个项目。这是一个简单的自动化测试，检查我们的主要python脚本是否可以成功运行。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> optuna
<span class="hljs-keyword">import</span> neptune.new <span class="hljs-keyword">as</span> neptune
<span class="hljs-keyword">import</span> neptune.new.integrations.optuna <span class="hljs-keyword">as</span> optuna_utils

run = neptune.init(
	project=<span class="hljs-string">"enes.zvornicanin/optuna-test"</span>,
	api_token=<span class="hljs-string">"YOUR_API_TOKEN"</span>,
)

neptune_callback = optuna_utils.NeptuneCallback(run)


hb = HourlyBacktester(dt.data, trader_config)
n_trials = <span class="hljs-number">20</span>

study = optuna.create_study(direction=<span class="hljs-string">"maximize"</span>)
study.optimize(hb.objective, n_trials=n_trials, callbacks=[neptune_callback])
</pre>



<p>为了测试这个项目，在我们的“main.py”脚本中，除了main函数之外，我们还将创建一个名称相同但前缀为“test_”的函数:</p>



<p id="separator-block_338ce4aa3c1b35408ff75e2af9a746df" class="block-separator block-separator--15">这样，如果我们以“pytest main.py”的形式运行“main.py”和<a href="https://web.archive.org/web/20221206144902/https://docs.pytest.org/" target="_blank" rel="noreferrer noopener nofollow"> Pytest </a>，Pytest将自动运行所有带有“test_”前缀的函数。在“test_main”函数中，我们提供了一个“debug”参数，该参数控制我们是使用真实数据还是仅用于测试的虚拟数据。此外，当“debug=True”时，程序不登录币安帐户，而是创建一个模拟币安客户对象的一个方法的<a href="https://web.archive.org/web/20221206144902/https://realpython.com/python-mock-library/" target="_blank" rel="noreferrer noopener nofollow">模拟对象</a>:</p>





<h2 id="h-mlops-pipeline-for-time-series-prediction-automated-testing">其中client.create_order将在代码的后面使用。</h2>



<p>接下来，我们将设置GitHub，使它在每次推送到存储库后自动在Ubuntu虚拟机上运行我们的测试。第一步是在目录“. github/workflows”中创建一个. yml文件，或者直接在github存储库中创建，方法是:</p>







<p>操作-&gt;新建工作流-&gt;自行设置工作流:</p>



<p> </p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>:</span>
	pt = PaperTrader(config)
	pt.execute_trade()

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_main</span><span class="hljs-params">()</span>:</span>
	pt = PaperTrader(config, debug=<span class="hljs-keyword">True</span>)
	pt.test_execute_trade()

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
	main()
</pre>



<p> </p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">log_in</span><span class="hljs-params">(self)</span>:</span>

    	<span class="hljs-keyword">if</span> self.debug:
        	self.client = Mock()
        	self.client.create_order = <span class="hljs-keyword">lambda</span> symbol, side, type, quantity:{
            	<span class="hljs-string">"executedQty"</span>:<span class="hljs-number">1</span>,
            	<span class="hljs-string">"cummulativeQuoteQty"</span>:np.random.rand()+<span class="hljs-number">1</span>
        	}
        	<span class="hljs-keyword">return</span>

    	self.client = Client(api_key = os.environ.get(<span class="hljs-string">'BINANCE_TESTNET_API'</span>),
                         	api_secret = os.environ.get(<span class="hljs-string">'BINANCE_TESTNET_SECRET'</span>),
                         	tld = <span class="hljs-string">'com'</span>,
                         	testnet = <span class="hljs-keyword">True</span>)</pre>



<p>之后，将出现一个新的工作流模板，其中包含一些基本命令:</p>



<p> </p>



<p> </p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">更新的。为我们的用例创建的yml文件在<a href="https://web.archive.org/web/20221206144902/https://github.com/eneszv/binance-trading-neptune/blob/production/.github/workflows/main.yml" target="_blank" rel="noreferrer noopener nofollow">存储库</a>中可用，它看起来像这样:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/617a2b545bcbde9784e35e1d35e3c09a.png" alt="Setting up workflow" class="wp-image-68984" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image2-1.png?ssl=1"/><figcaption class="wp-element-caption"><em>Setting up workflow | Source: Author</em></figcaption></figure></div>


<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5"> </p>



<p>这将使名为“Tests”的GitHub操作使用“master”分支在push上运行下面的命令。该工作流将在Ubuntu机器上运行，前两个步骤在大多数项目中都很常见，与检出存储库和python的设置相关。之后，它安装需求和需要特殊安装的包talib(用于技术指标)。最后，它运行我们的测试。</p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">如果操作成功完成所有步骤，操作选项卡下将出现绿色标志:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/f5d912f004c4ff71aab89397ba14d6e0.png" alt="New workflow template" class="wp-image-69005" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image23.png?ssl=1"/><figcaption class="wp-element-caption"><em>New workflow template | Source: Author</em></figcaption></figure></div>


<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5"> </p>



<p>用于时间序列预测的MLOps管道:部署和连续交付</p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">将使用<a href="https://web.archive.org/web/20221206144902/https://github.com/features/actions" target="_blank" rel="noreferrer noopener nofollow"> GitHub actions </a>、<a href="https://web.archive.org/web/20221206144902/https://www.docker.com/" target="_blank" rel="noreferrer noopener nofollow"> Docker </a>和<a href="https://web.archive.org/web/20221206144902/https://aws.amazon.com/ecs/" target="_blank" rel="noreferrer noopener nofollow"> AWS ECS </a>按照CI/CD实践进行部署。弹性容器服务(ECS)是一种容器编排服务，可以轻松部署、管理和扩展容器化的应用程序。在我们的例子中，我们将把它用作CI/CD服务，它将托管docker将在其中运行的<a href="https://web.archive.org/web/20221206144902/https://aws.amazon.com/ec2/" target="_blank" rel="noreferrer noopener nofollow"> EC2 </a>实例。</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/0868d4e6e3c1900517ea8074fb889c18.png" alt="The updated .yml file " class="wp-image-68986" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image4-1.png?ssl=1"/><figcaption class="wp-element-caption"><em>The updated .yml file | Source: Author</em></figcaption></figure></div>


<p>将使用<a href="https://web.archive.org/web/20221206144902/https://aws.amazon.com/iam/" target="_blank" rel="noreferrer noopener nofollow"> AWS身份和访问管理(IAM) </a>服务提供对AWS服务的访问。此外，在部署之前，我们将在<a href="https://web.archive.org/web/20221206144902/https://aws.amazon.com/s3/" target="_blank" rel="noreferrer noopener nofollow"> AWS S3 </a>上接收输入数据。</p>



<p>简而言之，部署步骤如下:</p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">当代码被推送到一个定义的分支时，GitHub动作激活并启动CD进程。首先，操作配置AWS凭证，以便访问服务。</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/f9399f51c72bd982cb4fb74ac28c659d.png" alt="Completed action" class="wp-image-68989" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image7.png?ssl=1"/><figcaption class="wp-element-caption"><em>Completed action | Source: Author</em></figcaption></figure></div>


<h2 id="h-mlops-pipeline-for-time-series-prediction-deployment-and-continuous-delivery">动作建立Docker图像并将其推送到<a href="https://web.archive.org/web/20221206144902/https://aws.amazon.com/ecr/" target="_blank" rel="noreferrer noopener nofollow"> AWS ECR </a>上。Elastic Container Registry是一个容器图像的存储库，其中的图像可以很容易地通过其他AWS服务进行推送、访问和分发。</h2>



<p>操作在ECS服务上部署定义的映像。</p>



<p>ECS服务将操作一个EC2实例，其中将部署一个Docker容器。在Docker容器中，cron作业将使用Miniconda环境，每小时运行一次我们的主python脚本。</p>







<p>输出数据将存储在<a href="https://web.archive.org/web/20221206144902/https://aws.amazon.com/s3/" target="_blank" rel="noreferrer noopener nofollow"> AWS S3 </a>上。此外，一些输出结果和元数据将作为监控服务存储在<a href="https://web.archive.org/web/20221206144902/https://neptune.ai/" target="_blank" rel="noreferrer noopener"> neptune.ai </a>上。</p>



<ul>
<li>我和S3</li>



<li>创建IAM用户的步骤</li>



<li>1.AWS -&gt; IAM -&gt;用户-&gt;添加用户</li>



<li> </li>



<li>2.填写用户名，并在AWS访问类型下选择“访问密钥-编程访问”,然后单击权限选项卡旁边的。</li>
</ul>



<p id="separator-block_338ce4aa3c1b35408ff75e2af9a746df" class="block-separator block-separator--15">3.选择以下策略:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/91862c7b13fb4897d8583b9eb3a28d94.png" alt="Production set-up" class="wp-image-69006" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image24.png?resize=753%2C614&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Production set-up | Source: Author</em></figcaption></figure></div>


<h3>AmazonS3FullAccess</h3>



<h4>亚马逊C2FullAccess</h4>



<p>amazone C2 containerregistryfull access</p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">AmazonECS_FullAccess</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/dd729ca0e5b81d50e05c9ad1f59b6b6c.png" alt="Adding a user" class="wp-image-69004" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image22.png?ssl=1"/><figcaption class="wp-element-caption"><em>Adding a user | Source: Author</em></figcaption></figure></div>


<p>EC 2 instanceprofileforimagebuilderecrcontainerbuilds</p>



<p> </p>



<ul>
<li>4.单击“下一步”按钮两次，然后单击“创建用户”。现在，用户凭证将会出现，<strong>请确保下载并保存它们</strong>，因为您将无法再次看到它们。</li>



<li>创建S3存储桶的步骤</li>



<li>1.转到AWS -&gt;亚马逊S3 -&gt;桶-&gt;创建桶</li>



<li>2.写入存储桶名称，并可选地启用存储桶版本控制。单击create bucket，它应该已经创建好了。</li>



<li>3.现在点击你的桶名，试着从你的电脑上传一个文件。</li>
</ul>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">ECR和ECS</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/3a1b3fabc858ffbc7780eaddb29d2901.png" alt="Polices to select" class="wp-image-69000" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image18.png?ssl=1"/><figcaption class="wp-element-caption"><em>Selecting policies | Source: Author</em></figcaption></figure></div>


<p>创建ECR存储库的步骤</p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">1.转到AWS ECR -&gt;入门(创建存储库)</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/f53646ffe778ab71b07bd9156838e88f.png" alt="Download and save user credentials" class="wp-image-68993" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image11.png?ssl=1"/><figcaption class="wp-element-caption"><em>Download and save user credentials | Source: Author</em></figcaption></figure></div>


<h4>2.在可见性设置中，选择私有。</h4>



<p>3.定义存储库名称。</p>



<p>4.单击创建存储库。</p>



<p>对于ECS服务，我们需要创建:</p>



<p id="separator-block_8fa70a2b14d62fe3b357023a454ebfec" class="block-separator block-separator--0"><strong>任务定义</strong>(需要在Amazon ECS中运行Docker容器)</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/2352f7d4ceef6d507ba63a250e57eaf0.png" alt="Creating the S3 bucket" class="wp-image-68988" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image6.png?ssl=1"/><figcaption class="wp-element-caption"><em>Creating S3 bucket | Source: Author</em></figcaption></figure></div>


<h3><strong>集群</strong>(定义Docker将运行的基础设施)</h3>



<h4>创建ECS任务定义的步骤</h4>



<p>1.转到AWS ECS -&gt;任务定义-&gt;创建新任务定义</p>



<p>2.为启动类型兼容性选择EC2。</p>



<p>3.指定任务定义的名称。</p>



<p>4.在容器定义下，单击添加容器按钮。</p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">5.对于容器名称，添加先前定义的ECR repo名称。</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/2023f52430a53f35b92706c6a6a58046.png" alt="Creating ECR repository" class="wp-image-69009" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image27.png?ssl=1"/><figcaption class="wp-element-caption"><em>Creating ECR repository | Source: Author</em></figcaption></figure></div>


<p>6.为映像添加ECR repo URI链接(可以在ECR服务中找到，在存储库名称旁边)。内存限制和端口映射如下图所示。单击添加，然后单击创建按钮。</p>



<ul>
<li> </li>



<li>创建ECS群集的步骤</li>
</ul>



<h4>1.转到AWS ECS -&gt;集群-&gt;创建集群</h4>



<p>2.选择EC2 Linux +网络，然后单击下一步。</p>



<p>3.定义一个集群名称，选择EC2实例类型(t2.micro符合免费层的条件)并创建一个密钥对(或选择现有的密钥对)。点击创建按钮。</p>



<p> </p>



<p>4.创建群集后，单击群集名称，然后在“Services”选项卡下，单击“Create”按钮。</p>



<p> </p>



<p>5.选择EC2作为启动类型，定义服务名称和任务数(1)。</p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">6.几次单击下一步，然后单击“创建服务”按钮完成。<br/></p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/f3427e95ab3b2b20e337cf49ecf1a155.png" alt="Creating ECS task definition" class="wp-image-68995" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image13.png?ssl=1"/><figcaption class="wp-element-caption"><em>Creating ECS task definition | Source: Author</em></figcaption></figure></div>


<h4>Dockerfile</h4>



<p><a href="https://web.archive.org/web/20221206144902/https://github.com/eneszv/binance-trading-neptune/blob/production/Dockerfile" target="_blank" rel="noreferrer noopener nofollow"> Dockerfile </a>可以在<a href="https://web.archive.org/web/20221206144902/https://github.com/eneszv/binance-trading-neptune/tree/production" target="_blank" rel="noreferrer noopener nofollow">这个资源库</a>中找到，我们在这里简单解释一下。</p>



<p> </p>



<p>对于Docker容器，我们将使用Ubuntu 22.10映像。我们为miniconda设置了环境变量PATH、python脚本将使用的环境变量，并为Ubuntu安装了一些包。之后，我们下载、安装并创建一个名为“env”的miniconda python环境。</p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">命令收到。币安_贸易/`复制我们项目的所有文件到Docker“币安_贸易”目录。下一组命令与<a href="https://web.archive.org/web/20221206144902/https://blog.quantinsti.com/install-ta-lib-python/" target="_blank" rel="noreferrer noopener nofollow">安装Ta-Lib Python包</a>有关，我们用它来表示技术指标。之后，我们安装requirements.txt文件中的所有其他包。</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/e3939633e5a5ce0566d2e14fded12211.png" alt="Creating ECS cluster" class="wp-image-69010" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image28.png?ssl=1"/><figcaption class="wp-element-caption"><em>Creating ECS cluster | Source: Author</em></figcaption></figure></div>


<p>接下来的几个命令与在Docker 中配置cron作业的<a href="https://web.archive.org/web/20221206144902/https://stackoverflow.com/questions/37458287/how-to-run-a-cron-job-inside-a-docker-container" target="_blank" rel="noreferrer noopener nofollow">相关。为此，我们需要在存储库中有一个“cron-job”文件，我们将把它复制到Docker容器中。容器启动时将被激活的最后一个命令将环境变量重定向到/etc/environment文件中，以便对cron作业可见。此外，它还会激活cron作业。</a></p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">Cron作业文件是在我们的存储库中定义的，它应该每小时运行一次我们的主脚本。</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/a88ae5effb24883e2f4a8ae90ff3a335.png" alt="Creating ECS cluster" class="wp-image-68999" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image17.png?ssl=1"/><figcaption class="wp-element-caption"><em>Creating ECS cluster | Source: Author</em></figcaption></figure></div>


<p>GitHub操作</p>



<p>接下来，我们将解释如何将我们的项目作为持续部署(CD)工作流的一部分部署到ECS。为此，我们将使用GitHub动作。定义这个过程的Yaml文件可以在资源库中找到，在这里我们将一步一步地解释它。</p>



<h3><a href="https://web.archive.org/web/20221206144902/https://docs.github.com/en/actions/deployment/deploying-to-your-cloud-provider/deploying-to-amazon-elastic-container-service" target="_blank" rel="noreferrer noopener nofollow">我们将遵循GitHub文档中可用的框架</a>。该操作将在推送到主分支时被激活。</h3>



<p>1.首先，我们定义一些稍后将会用到的环境变量。其中一些如存储库、服务、集群和容器名称是在前面的步骤中定义的。AWS区域与AWS配置文件相关。</p>



<p id="separator-block_579779d8a0a823a1af56d482b04d32f7" class="block-separator block-separator--10">2.ECS任务定义可以存储为。json文件，位于ECS -&gt;任务定义-&gt;您的定义名称-&gt; JSON选项卡下</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/f2884f39bf2745f529db67d3dcbb29ed.png" alt="Dockerfile" class="wp-image-69011" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image29.png?ssl=1"/><figcaption class="wp-element-caption"><em>Dockerfile | Source: Author</em></figcaption></figure></div>


<ul>
<li>之后，在yaml文件中，我们定义了将在最新的Ubuntu操作系统上运行的步骤，第一步是检查存储库。</li>
</ul>



<ul>
<li>4.接下来，我们需要配置AWS凭证。我们在IAM用户下创建了它们。此外，它们将被存储为动作秘密，我们可以在GitHub存储库中定义它们，位于:设置选项卡-&gt;秘密-&gt;动作-&gt;新存储库秘密</li>
</ul>



<ul>
<li>所有机密都可以使用$ { { secrets }访问。变量名称}}符号。</li>
</ul>



<ul>
<li>5.登录Amazon ECR后，我们构建Docker映像并将其推送到ECR存储库。这里我们从秘密中定义局部环境变量。其中一些在构建命令期间作为构建参数被处理到Docker容器中。这样，我们的python脚本就能够使用方法访问它们。</li>
</ul>







<h3>6.最后，我们在任务定义中填充一个新的映像ID，并将其部署在ECS上。</h3>



<p>现在，如果我们在我们的存储库中推送更改，GitHub actions将启动这个过程。下面是一个成功运行的例子:</p>



<p>用于时间序列预测的MLOps管道:监控</p>



<p>我们可以使用neptune.ai轻松获得相同的功能，而不是建立一个Flask或Fast API web服务器来显示我们的结果、元数据和图表。这个想法是在每次脚本运行后，即每次交易后，我们在neptune.ai项目上上传带有图表的结果。通过几行代码和两分钟的工作，我们将能够存储和跟踪我们的Matplotlib图表和。neptune.ai项目中的csv结果文件。</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/6e2259d96f8b7e3fc945364c26785b12.png" alt="Defining environment variables" class="wp-image-69002" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image20.png?ssl=1"/><figcaption class="wp-element-caption"><em> Defining environment variables | Source: Author</em></figcaption></figure></div>


<p>要开始监控性能指标，请运行以下代码:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/008a7ad43ce81af4c07a8892a8a6a9c0.png" alt="ECS task definition" class="wp-image-68992" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image10.png?ssl=1"/><figcaption class="wp-element-caption"><em>ECS task definition | Source: Author</em></figcaption></figure></div>


<ol start="3">
<li>定义matplotlib图:</li>
</ol>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/ded63b44417415d18a3802e14aebaffb.png" alt="Checking repository" class="wp-image-68985" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image3-1.png?ssl=1"/><figcaption class="wp-element-caption"><em>Checking repository | Source: Author</em></figcaption></figure></div>


<p>并将其作为静态或交互式图像上传到项目中:</p>



<p>为了上传包含结果的pandas数据框，请再添加一行代码:</p>



<p>在这种情况下，这将自动记录元数据和结果的过程。同时，您还可以根据定义的指标，在不同的实验运行之间进行比较，如下一个屏幕截图所示。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> os
aws_access_key_id = os.environ.get(<span class="hljs-string">'AWS_ACCESS_KEY_ID'</span>)
</pre>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/ab28098327c476605ec79c9aa38addcf.png" alt="Building and pushing the Docker image to the ECR repository" class="wp-image-68990" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image8.png?ssl=1"/><figcaption class="wp-element-caption"><em>Building and pushing the Docker image to the ECR repository | Source: Author</em></figcaption></figure></div>


<p> </p>



<p>除了简单地跟踪我们的结果以便向我们的同事和客户展示之外，为ML项目建立监控系统还有更多好处:</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/e02a6c8e4998065e316db021460c85a7.png" alt="Successful run" class="wp-image-68987" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221206144902im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image5.png?ssl=1"/><figcaption class="wp-element-caption"><em>Successful run | Source: Author </em></figcaption></figure></div>






<h2 id="h-mlops-pipeline-for-time-series-prediction-monitoring">例如，<strong>模型陈旧</strong>是金融时间序列中的常见问题。虽然在这个项目中，模型再训练的逻辑是在代码中实现的，并且在模型开始表现不佳时会被触发，但是直接监控模型的陈旧性可能是有用的。</h2>



<p>类似地，<strong>数据漂移</strong>可以是监控的对象，可以创建仪表板，显示每个模型预测的实时生产数据的统计数据。</p>



<p>除了Neptune之外，还有一些更专用于ML监控的工具。例如，<a href="https://web.archive.org/web/20221206144902/https://arize.com/" target="_blank" rel="noreferrer noopener nofollow"> Arize AI </a>通过帮助理解机器学习模型在现实世界中部署时的行为方式，使ML从业者能够更好地检测和诊断模型问题。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> neptune.new <span class="hljs-keyword">as</span> neptune
run = neptune.init(
        	project=os.environ.get(<span class="hljs-string">'NEPTUNE_PROJECT'</span>),
        	api_token=os.environ.get(<span class="hljs-string">'NEPTUNE_API_TOKEN'</span>),
    	)</pre>



<p>类似地，<a href="https://web.archive.org/web/20221206144902/https://whylabs.ai/" target="_blank" rel="noreferrer noopener nofollow"> WhyLabs </a>是一个模型监控工具，帮助ML团队监控数据管道和ML应用程序。更多关于ML监控工具的信息可以在本文中找到:<a href="/web/20221206144902/https://neptune.ai/blog/ml-model-monitoring-best-tools" target="_blank" rel="noreferrer noopener">做ML模型监控的最佳工具</a>。</p>



<pre class="hljs">fig = plt.figure(figsize =(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>))</pre>



<p>结论</p>



<pre class="hljs">run[<span class="hljs-string">"static-img"</span>].upload(neptune.types.File.as_image(fig))
run[<span class="hljs-string">"interactive-img"</span>].upload(neptune.types.File.as_html(fig))
</pre>



<p>在本教程中，我们介绍了一个简单的端到端ML时间序列项目，遵循MLOps实践。</p>



<pre class="hljs">run[<span class="hljs-string">'data/results'</span>].upload(neptune.types.File.as_html(df_results))</pre>





<p>我们的项目位于<a href="https://web.archive.org/web/20221206144902/https://github.com/eneszv/binance-trading-neptune" target="_blank" rel="noreferrer noopener nofollow"> github库</a>上，定义了在代码推送时触发的冒烟测试。这是<strong> CI实践</strong>的一个简单例子。除此之外，<strong> CD功能</strong>是通过GitHub actions、Docker和AWS服务实现的。<strong> CM示例</strong>是使用neptune.ai简单提供的，而<strong> CT逻辑</strong>集成在python代码本身中，如果最后N次运行的结果低于T阈值，模型将被重新训练和优化。</p>



<p id="separator-block_8cf0505a2319810193554005f94fc238" class="block-separator block-separator--5">关于这个项目的任何其他问题，请随时联系我。</p>





<p>参考</p>



<ul>
<li>For instance, <strong>model staleness</strong> is a common issue in financial time series. Although in this project, the logic for model retraining is implemented in the code and will be triggered if the model starts to perform badly, it might be useful to monitor model staleness directly.</li>
</ul>



<ul>
<li>Similarly, <strong>data drift</strong> can be a subject for monitoring, where it’s possible to create dashboards that will show some statistics about real-time production data at every model prediction.</li>
</ul>



<p>Besides Neptune, there are a few more tools that are more specialized for ML monitoring. For example, <a href="https://web.archive.org/web/20221206144902/https://arize.com/" target="_blank" rel="noreferrer noopener nofollow">Arize AI</a> enables ML practitioners to better detect and diagnose model issues by helping understand why a machine learning model behaves the way it does when deployed in the real world.</p>



<p>Similarly, <a href="https://web.archive.org/web/20221206144902/https://whylabs.ai/" target="_blank" rel="noreferrer noopener nofollow">WhyLabs</a> is a model monitoring tool that helps ML teams with monitoring data pipelines and ML applications. More about ML monitoring tools can be found in this article: <a href="/web/20221206144902/https://neptune.ai/blog/ml-model-monitoring-best-tools" target="_blank" rel="noreferrer noopener">Best Tools to Do ML Model Monitoring</a>.</p>



<h2 id="h-conclusion">Conclusion</h2>



<p>In this tutorial, we’ve presented a simple end-to-end ML time series project following MLOps practices. </p>



<p>Our project is located on the <a href="https://web.archive.org/web/20221206144902/https://github.com/eneszv/binance-trading-neptune" target="_blank" rel="noreferrer noopener nofollow">github repository</a> with defined smoke tests which are triggered on code push. That is a simple example of <strong>CI practices</strong>. In addition to that, <strong>CD functionality</strong> is implemented with GitHub actions, Docker, and AWS service. <strong>CM example</strong> is simply provided using neptune.ai and <strong>CT logic</strong> is integrated in the python code itself, where the model will be retrained and optimized if the results of the last N runs are below the T threshold.</p>



<p>For any additional questions regarding this project, feel free to reach out to me on Linkedin.</p>



<h3>References</h3>




        </div>
        
    </div>    
</body>
</html>