# 最佳顶点 ML 元数据替代方案

> 原文：<https://web.archive.org/web/https://neptune.ai/blog/vertex-ml-metadata-alternatives>

去年，谷歌宣布了 [Vertex AI](https://web.archive.org/web/20221201180901/https://cloud.google.com/vertex-ai) ，这是一个新的托管机器学习平台，旨在让开发者更容易部署和维护人工智能模型。那么，Vertex AI 有什么好处和坏处呢？在本文中，我们将讨论 Vertex AI，并看看它的替代品，但首先，让我们看看为什么需要这样一个工具？

表征数据集、计算环境和模型的信息称为元数据。简单来说，这是一个一站式商店，提供您构建和部署机器学习模型所需的所有信息。这对 [ML 再现性](/web/20221201180901/https://neptune.ai/blog/how-to-solve-reproducibility-in-ml)至关重要；没有元数据存储，如果您不记录和保存信息，您将无法重新创建测试。ML 元数据存储将帮助您:

*   **[跟踪所有实验](/web/20221201180901/https://neptune.ai/experiment-tracking)** 和模型元数据。
*   提供工具**可视化和比较实验**。
*   **记录所有可能相关的元数据**。
*   获取有关代码、数据、参数和环境版本的信息。
*   **分析、监控并提醒**您是否检测到模型输入/输出分布的任何意外变化。

[数据和工件谱系](/web/20221201180901/https://neptune.ai/blog/data-lineage-in-machine-learning)、再现性和可比性都是通过收集关于每个 ML 管道运行的数据来辅助的。当项目从开发过渡到生产时，再现性确保了数据的一致性和错误的减少。它也有助于调查故障和异常。通常，ML 元数据存储将记录以下元数据:

*   使用的管道和组件的版本。
*   开始和结束日期，以及管道完成每个阶段所需的时间。
*   作为参数提供给管道的参数。
*   在模型评估过程中为训练集和测试集生成的模型评估度量。在模型验证过程中，这些指标允许您将新训练的模型的性能与先前模型的性能进行比较。
*   在模型评估过程中为训练集和测试集生成的模型评估度量。

![Basic Workflow of Metadata Store](img/d98dd9437083df452523c00eef0581f9.png)

*Basic workflow of Metadata Store | Image by author*

## 顶点人工智能

谷歌推出了 [Vertex AI，](https://web.archive.org/web/20221201180901/https://cloud.google.com/vertex-ai)这是一个新的统一机器学习平台，使用谷歌的人工智能技术来帮助你更快地部署模型。 **Vertex AI 将用于机器学习开发的谷歌云服务结合到单一的 UI 和 API 中。** Vertex AI 允许您使用 AutoML 或自定义代码轻松训练和比较模型，并且您的所有模型都保存在单个模型库中。

![Vertex AI Dashboard](img/9e499e0035841b7652d7f9392d56e6ee.png)

*Vertex AI Dashboard | Screenshot by Author *

### 顶点人工智能的特点

有了 Vertex AI，作为最终用户，您现在拥有了一个单一的工作流，它包含了从实验到部署的整个开发生命周期。以下是 vertex AI 的一些功能:

*   支持所有流行的开源框架。

它通过定制的训练和预测容器支持几乎所有的 ML 框架。这允许您以同样的方式对待所有的模型，不管它们是定制的还是用 AutoML 创建的。

您可以获得针对视觉、视频等内容的预训练 API，这不仅是为了简化流程，也是为了提高效率。您可以简单地将它们集成到您现有的应用程序中，或者使用它们创建一个新的应用程序。因此，您可能不需要寻找额外的 AI API 平台来完成您的任务。

*   **数据到人工智能的无缝集成**

BigQueryML 被广泛用于开发和执行使用 SQL 查询的机器学习模型，这并不奇怪。您将能够访问它并将数据集导出到平台中，以便使用 Vertex AI 将其与流程连接起来。因此，您将拥有端到端的集成。

*   **简化的机器学习过程**

您将能够利用 AutoML、Explainable、Edge Manager 等工具来处理 ML 模型。把所有东西都放在一个地方应该会改变游戏规则。您还可以使用自定义代码进行训练，同时将所有内容保存在一个地方。

**Vertix AI 提供的工具有:**

*   模型监控
*   匹配引擎
*   **ML 元数据**
*   张量板
*   管道和更多的东西。

Vertex AI 使用 [MLMD](https://web.archive.org/web/20221201180901/https://www.tensorflow.org/tfx/guide/mlmd) 原理来存储元数据。它将元数据呈现为一个可导航的图形，节点代表执行和工件，边连接它们(如下图所示)。执行和对象由上下文进一步连接，上下文由子图表示。顶点 ML 元数据将有助于运行分析、ML 实验和 ML 工件的跟踪等。让我们看一下用来记录元数据的一些最重要的实体。

*   史前古器物
*   实行
*   事件
*   内容

[![Vertex AI: example lineage graph ](img/7302d9f8b33954dd950e1214053a754b.png)](https://web.archive.org/web/20221201180901/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Vertex-AI-example-lineage-graph.png?ssl=1)

*Vertex AI: example lineage graph | [Source](https://web.archive.org/web/20221201180901/https://codelabs.developers.google.com/vertex-mlmd-pipelines#5)*

### 顶点人工智能的局限性

Vertex AI 提供了许多好的特性，但它仍然有一些缺点，这可能是许多人担心的原因:

顶点元数据基于 ML 元数据，而 ML 元数据没有客户端 python SDK，而客户端 python SDK 是临时训练操作(例如在笔记本中)所必需的。通过使用临时操作，组织可以节省时间、金钱并减少 IT 工作量。它目前缺乏诸如自动化调试、模型注册、模型工件编译和 Kubernetes 支持等特性，这可能是一些用户的障碍。它也缺乏同步在线和离线功能的能力。

作为新用户，你将有几个月的免费等级，但之后，你将不得不按需付费。与其他解决方案相比，Vertax AI 相对昂贵，随着客户使用更多服务，价格可能会大幅上涨。你必须为其他用于模型监控的谷歌云产品付费，比如 BigQuery storage 或者 Batch Explain。Vertex ML 元数据存储费用从每月 10 美元每吉字节(GiB)开始，如果您使用其他功能，费用可能会增加。你可以在这里找到完整的价格信息。

顶点人工智能元数据目前只能在生产管道中使用。它允许您将 GPU 加速器链接到现有的 CPU 实例，但是它还不支持 A100 实例类型。

*   **文档&开发者指南**

尽管 Vertex AI 已经推出了一段时间，但很难在网上或开发者社区网站上找到解决方案。由于该产品不是为中小型企业设计的，团队需要可靠的文档和教程来开始。

无论您是有一个成长中的团队，打算扩展和升级现有的解决方案，还是想要向您的产品线添加额外的 ML 解决方案，元数据存储都是实现速度、自动化和智能洞察的理想方式。元数据在机器学习中非常重要，因为它可以帮助您:

*   伪像跟踪
*   对模型审计试验的法律遵从性
*   热身训练
*   跟踪模型签署
*   从以前的错误中学习

以下是您在选择 Vertex ML 元数据替代或任何元数据存储时应该考虑的事项。

1.**跟踪能力**

您将跟踪超参数、模型、代码、资源、见解等等。元数据存储应该提供各种各样的跟踪功能，包括数据版本控制、跟踪数据和模型血统、源代码版本控制，甚至是测试和生产环境的版本控制。因此，请确保您选择的工具包含项目所需的所有追踪功能。

2.**集成**

为了捕获在管道的每个阶段创建的生活元素，理想的元数据存储应该能够与所有主要或最重要的工具和框架集成。

3.**轻松协作**

为了设计一个成功的 ML 解决方案，开发团队、运营团队，甚至商业团队都需要协作。元数据存储应该是可靠的，并允许团队成员之间的简单协作。对于团队在 ML 实验中的合作，你使用的工具应该提供这样的条款。

4.**详细见解**

虽然元数据存储在不同阶段收集数据，但它也应该提供智能见解，从而加快测试并增强报告。理想的元数据存储平台应该能够为开发人员提供动态可视化，他们可以定制这些可视化来说明管道数据的独特重点领域。

5.**可视化**

一个像样的视觉表现将使其更容易评估结果。它简化了复杂的概念，并允许您向利益相关者传达可视化的结果。它还可以帮助您执行错误分析，并确定需要改进的地方。

由于上面讨论的所有原因，Vertex AI 可能并不完全适合所有人。因此，让我们来看看目前市场上一些具有吸引力功能的顶级解决方案:

Neptune 是一个元数据存储库。它是一个连接 [MLOps](/web/20221201180901/https://neptune.ai/blog/mlops) 工作流的几个组件的工具，比如数据版本化、实验跟踪、模型注册和监控。它简化了模型开发过程中创建的所有信息的存储、管理、可视化和比较

Neptune 提供了一个 Python 客户端库,让用户[在他们的 ML 实验中记录并跟踪任何元数据类型](https://web.archive.org/web/20221201180901/https://docs.neptune.ai/you-should-know/what-can-you-log-and-display),无论这些是在 Python 脚本、Jupyter 笔记本、Amazon SageMaker 笔记本还是 Google Colab 中运行的。

[![Metadata-dashboard-experiments](img/746379c1f2153afe91b731293e51aa7a.png)](https://web.archive.org/web/20221201180901/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Metadata-dashboard-experiments.png?ssl=1)

*Example dashboard with logged metadata | *[*Source*](https://web.archive.org/web/20221201180901/https://app.neptune.ai/o/common/org/project-cv/e/PROJCV-103/dashboard/variety-metadata-d78dd5d4-dc58-4488-baa0-0bbe1017ceec)

#### 海王星摘要

Neptune 增强了团队对机器学习项目的管理。它的**易于使用的界面**让您可以汇总跑步记录，保存自定义仪表板视图，并快速与您的团队分享。

*   **记录并显示所有元数据类型**，包括参数、模型权重和媒体文件。
*   用户界面易于使用，并为**分组运行提供了多种选项。**
*   **比较见解**和参数。
*   **自动记录**代码、环境、参数、模型二进制文件等等。
*   **跟踪在脚本、笔记本和任何基础设施上执行的实验**。
*   广泛的实验跟踪和**可视化功能。**
*   您可以监控硬件，让您的实验自动运行。**检查您的模型训练运行消耗的 GPU/CPU** 和内存量。

*   Neptune 提供了一个 Python 客户端库。
*   它提供了一个非常直观和灵活的用户界面，允许用户以他们选择的方式查看和排列数据。
*   Neptune 保存了大部分元数据及其版本，使用户更容易重新创建模型。
*   它允许与超过 25 种不同的工具顺利集成。
*   性价比高。

TensorFlow 的 ML 元数据(MLMD)是 TensorFlow Extended (TFX)的一部分，后者是一个用于部署机器学习解决方案的端到端框架。每次运行生产 ML 管道时，都会生成元数据，其中包含有关管道组件、它们的执行(例如，训练运行)以及所生成的工件(例如，训练模型)的信息。

MLMD 建筑由三样东西组成，

*   **驱动**，为执行程序提供所需的元数据。
*   **执行器**是组件功能编码的地方。
*   结果由**发布者**存储在元数据中。

#### MLMD 摘要

*   跟踪管道中组件之间的元数据流动。
*   **支持多个存储**后端。
*   您可以通过加载相同类型的两个工件来比较它们。
*   它存储关于管道组件血统的元数据
*   它列出了特定类型的所有工件。
*   存储有关管道执行的信息。
*   它有用于存储和检索元数据的 API。
*   存储后端是可扩展和可插拔的。
*   它记录和查询工作流运行的上下文。

这篇教程将帮助你更好地了解 MLMD。

#### 最大似然元数据(MLMD)与顶点最大似然元数据

*   Vertex ML 元数据和 MLMD 都是以相同的方式构建的，尽管它们在 API、工作流和其他方面存在一些差异。
*   顶点人工智能是一个企业级人工智能平台，而 MLMD 是一个用于记录和检索机器学习应用相关信息的库。
*   MLMD 是一个强大的开源模型调试库。
*   与模型优先视图相比，它优先考虑管道视图。

MLflow 是一个开源的 ML 生命周期管理工具。它帮助数据科学家和 ML 工程师进行实验、部署和模型注册。它可以与各种 ML 库和工具一起使用。它也是一个开源的模型优先的机器学习元数据存储，您可以使用它来监控您的实验或为生产打包模型。

![MLflow example view](img/6bd9fcca24e6517a8b412e4933f72339.png)

*MLflow example dashboard | [Source](https://web.archive.org/web/20221201180901/https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.htmlhttps://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html)*

#### MLFlow 摘要

*   它可以与**任何机器学习库**、语言或任何现有代码一起工作。它在任何云中都以同样的方式运行。
*   它以标准化的格式打包了一个 ML 模型，可以被下游工具使用。
*   MLflow 的四个主要组件是 MLflow 跟踪、MLflow 项目、MLflow 模型和 MLflow 注册表。
*   您可以使用 MLflow tracking 来**存储和查询您的代码**和数据实验。
*   MLFlow tracking 让您**记录工件、度量、参数、来源、时间等等。**
*   MLflow projects 是一个数据科学包，其中包含可重用和可复制的代码。它还带有一个 API 和一个命令行工具，用于 ML 和数据科学任务。
*   **不同类型的 ML 模型**可使用 MLflow 模型进行部署。每个模型都存储为包含任意数量文件的目录。

#### ML 流与顶点 ML 元数据

*   它是一个开源平台。
*   MLflow 是高度可定制的。
*   提供实时实验跟踪。
*   MLflow 可以与任何云服务提供商合作。

Kubeflow 是一款面向 Kubernetes 的机器学习工具，是开源的。Kubeflow 将数据科学过程中的各个阶段转化为 Kubernetes 任务，为您的机器学习库、框架、管道和笔记本提供云原生接口。

默认情况下，Kubeflow 包含一个元数据组件，用于存储和提供元数据。在管道运行期间，它会自动记录元数据。这使您可以跟踪管道版本、上次更新时间和元数据等信息，以便分析管道运行。

#### Kubeflow 摘要

*   部署在各种基础设施上是可重复和可移植的。
*   **支持多种框架**和平台。
*   特别是 [kubeflow pipeline](https://web.archive.org/web/20221201180901/https://www.kubeflow.org/docs/components/pipelines/overview/quickstart/) 自动记录关于运行的信息，包括工作流工件、执行和沿袭。
*   Kubernetes 用户会发现 Kubeflow 非常适合。
*   除了自动跟踪之外，您还可以手动写入元数据服务器以收集其他元数据。
*   **它是可扩展的**，并提供了广泛的超参数调谐选项。

从 [Kubeflow 文档中了解更多信息。](https://web.archive.org/web/20221201180901/https://www.kubeflow.org/docs/about/kubeflow/)

#### Kubeflow 与顶点 ML 元数据

*   它是一个开源平台。
*   即使是中小型企业也能从其可扩展性中受益。
*   对于管理和跟踪模型实验、任务和运行，它提供了一个优秀的用户界面。
*   Kubeflow 允许用户快速连接到其他平台，如果需要，用户可以轻松地迁移到另一个平台。

Valohai 是一个自动提取数据和部署模型的 MLOps 平台。有了 Valohai，你的团队在生产机器学习方面向前迈进了一大步。其端到端 MLOps 平台使团队能够快速、自信地创建和部署机器学习系统。

#### Valohai summary

*   您可以使用 Valohai 在任何**云或本地系统**上进行测试，并且您不必担心任何常规的 DevOps 任务。
*   你用 Valohai 做的一切都在平台上**保存和版本化**。
*   从模型到测量，一切都可以在你和你的团队之间轻松共享。
*   您可以**跟踪您的执行情况**主要 KPI，并根据您的独特指标轻松安排它们。
*   从代码中以 JSON 形式发布的任何内容都有可能被捕获为 Valohai 元数据。
*   您可以**将执行指标**作为时间序列或散点图进行比较。

你可以在 Valohai 网站上找到更多关于这些功能的信息。

#### 瓦罗海 vs 顶点 ML 元数据

*   Valohai 提供了一个名为 *valohai-utils* 的 Python 实用程序库来帮助处理日常的样板文件。
*   它确保过程是一致的，并且团队中的每个人都知道正在发生什么。
*   你可以用图表或表格的形式比较实验的结果。
*   兼容任何编程语言和 ML 框架。
*   您可以选择将元数据下载为 CSV 或 JSON 文件。

Amazon SageMaker 让数据科学家准备、构建、培训、调整、部署和管理所有的 ML 实验。它有一个用户友好的界面，使 ML 工程师和数据科学家的任务变得相当容易。如果您目前使用 AWS，Sagemaker Studio 是理想的选择，因为它为所有 AWS 产品提供了出色的集成支持。

![Amazon SageMaker UI](img/fae0c6c379030450b959b6872ad1b497.png)

*Amazon SageMaker Studio UI | [Source ](https://web.archive.org/web/20221201180901/https://mkai.org/customize-amazon-sagemaker-studio-using-lifecycle-configurations/)*

#### pagemaker studio 摘要

*   它可以与其他 AWS 工具无缝协作。
*   易于使用的界面。
*   您可以**跟踪容器的输入和输出。**
*   **跟踪并可视化**数千次实验。
*   Sagemaker 包括一个与 robomaker 集成的 **python 库**，允许两个系统在整个训练过程中进行通信。
*   它带有用于训练和运行你的实验的内置算法。
*   SageMaker 有一个**内置调试器**来帮助你发现和修复问题。

#### 亚马逊 pagemaker vs vertex ml 元数据

*   Sagemaker 可以监控容器的输入和输出。
*   它具有可视化指标的能力。
*   它还允许您从较小的实例开始。
*   Sagemaker 支持模型注册和模型工件重新编译。

|  | 海王星 | ML 元数据 | MLflow | Kubeflow | 瓦罗海 | 著名的专业排版软件 |
| --- | --- | --- | --- | --- | --- | --- |
| **定价** | 

个人免费(+免费额度以上使用量)，a 学院:免费，团队:[付费](https://web.archive.org/web/20221201180901/https://neptune.ai/pricing)

 | **开源** | **开源** | **开源** |  |  |
| **特性** | 

*   灵活，与其他框架配合良好

t

*   直观的 UI

t

*   易于与团队和利益相关者协作

 | 

*   存储是可扩展和可插拔的

t

*   允许您存储广泛的元数据

 | 

*   高度可定制

t

*   完美契合数据科学工作流程

t

*   可与任何机器学习库、语言或任何现有代码

 | 

*   完美适合 Kubernetes 用户

t

*   高度可扩展

t

*   自动记录关于运行的信息，包括工作流工件

 | 

*   易用协作特性

t

*   你用 Valohai 做的一切都保存在平台上并版本化

 | 

*   与 SageMaker 平台

t

*   易于使用的界面

 |
| **主持** |  |  |  |  |  |  |
| **超参数跟踪** |  |  |  |  |  |  |
| **输入/输出工件** |  |  |  |  |  |  |
| **视觉对比** |  |  |  |  |  |  |
| **数据集版本化** |  |  |  |  |  |

让我们快速比较一下这些平台。

## 最后的想法

元数据是任何端到端 ML 开发过程的重要部分，因为它不仅加快了过程，而且提高了最终管道的质量。

Vertex AI 是 ML 专业人士中比较新的机器学习平台。它有很大的潜力，但也有一定的局限性，这就是为什么企业正在寻找更加开放和简单的集成解决方案。我们讨论了几个 ML 元数据存储，你可以根据你的机器学习需求选择一个。我希望你喜欢这篇文章。

快乐实验！

### 参考文献和推荐阅读: