<html>
<head>
<title>The Best Weights &amp; Biases Alternatives </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>最佳权重和偏差备选方案</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/weights-and-biases-alternatives#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/weights-and-biases-alternatives#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p><a href="https://web.archive.org/web/20230304041944/http://wandb.ai/" target="_blank" rel="noreferrer noopener nofollow">权重&amp;偏差</a>，也称为WandB，是一个<a href="/web/20230304041944/https://neptune.ai/blog/best-mlops-tools" target="_blank" rel="noreferrer noopener"> MLOps工具</a>，用于机器学习模型的性能可视化和实验跟踪。它有助于ML模型的自动化、跟踪、培训和改进。</p>



<p>Weights &amp; bias是一项基于云的服务，允许您在一个中央存储库中托管您的实验，如果您有私有基础架构，Weights &amp; bias也可以部署在其上。</p>



<p id="separator-block_e0ba56fb3029447bf6dde312c0a65067" class="block-separator block-separator--5">重量与偏差提供:</p>





<p>一个中央的，用户友好的和交互式的仪表板，您可以查看您的实验和跟踪他们的表现。</p>



<ul>
<li>跟踪模型训练过程的每个部分，可视化模型，并比较实验。</li>



<li>使用<a href="https://web.archive.org/web/20230304041944/https://docs.wandb.ai/guides/sweeps" target="_blank" rel="noreferrer noopener nofollow">扫描</a>进行自动超参数调整，提供了超参数组合的样本，有助于模型性能和理解。</li>



<li><a href="https://web.archive.org/web/20230304041944/https://docs.wandb.ai/guides/reports" target="_blank" rel="noreferrer noopener nofollow">团队协作报告</a>，您可以在其中添加可视化内容，组织、解释和分享您的模型性能、模型版本和进度。</li>



<li>机器学习管道的端到端工件跟踪，从数据准备到模型部署。</li>



<li>与Tensorflow、Pytorch、Keras、Hugging Face等框架轻松集成。</li>



<li>团队中的协作工作，具有共享、实验等多种功能。</li>



<li>这些都是Weights &amp; Biases提供的有用功能，这使得它成为研究团队寻找发现、学习和获得对机器学习实验的见解的良好工具。</li>
</ul>



<p>然而，当谈到交付时，重量和偏差并不总是最好的选择。以下是Weights &amp; Biases目前没有提供的一些功能:</p>







<p><strong>笔记本托管</strong>:从Jupyter笔记本到生产部署机器学习模型是每个数据研究人员的梦想，因为它允许快速迭代并节省时间。</p>



<ul>
<li>ML生命周期管理:管理一个模型的整个生命周期在研究期间是很重要的，即从数据源到模型部署，因为它允许他们在开发的任何阶段正确地监控、调试任何问题。</li>



<li><strong>生产用例</strong>:对于基于生产的团队或项目，权重&amp;偏差不是一个好的选择，因为它缺乏生产引擎。</li>



<li><strong>模型部署</strong>:研究的一个重要部分是测试和执行实时推理。这就是为什么在构建和评估模型之后就需要模型部署的原因。</li>



<li>以下是一些可供选择的工具，您可以尝试一下:</li>
</ul>



<p>Here are some alternative tools you can try out:</p>



<div id="case-study-numbered-list-block_fe6e323d2f2813613cf2497db56dd1d4" class="block-case-study-numbered-list ">

    
    <h2 id="h-"><span class="c-list__counter"> 1 </span>海王星</h2>

    <ul class="c-list">
                    <li class="c-list__item"><span class="c-list__counter"> 2 </span>张量板</li>
                    <li class="c-list__item"><span class="c-list__counter"> 3 </span>彗星</li>
                    <li class="c-list__item"><span class="c-list__counter"> 4 </span> MLflow</li>
                    <li class="c-list__item">库伯流</li>
                    <li class="c-list__item"><span class="c-list__counter"> 6 </span> SageMaker Studio</li>
                    <li class="c-list__item">Neptune是MLOps 的<a href="/web/20230304041944/https://neptune.ai/" target="_blank" rel="noreferrer noopener">元数据存储。它允许您在一个地方记录、存储、组织、显示、比较和查询所有的模型构建元数据。这包括元数据，如模型度量和参数、模型检查点、图像、视频、音频文件、数据版本、交互式可视化、</a><a href="https://web.archive.org/web/20230304041944/https://docs.neptune.ai/you-should-know/what-can-you-log-and-display" target="_blank" rel="noreferrer noopener">等等。</a></li>
            </ul>
</div>







<p>Neptune是为进行大量实验的研究和生产团队构建的，他们希望组织和重现实验，并希望确保将模型转移到生产的过程顺利进行。海王星的主要焦点围绕着<a href="/web/20230304041944/https://neptune.ai/product/experiment-tracking">实验跟踪</a>和<a href="/web/20230304041944/https://neptune.ai/product/model-registry">模型注册</a>，以及团队协作。</p>



<p>主要特点:</p>



<p id="separator-block_e0ba56fb3029447bf6dde312c0a65067" class="block-separator block-separator--5">Neptune允许您以任何想要的结构记录和显示模型元数据。无论是模型的嵌套参数结构，训练和验证度量的不同子文件夹，还是打包模型或生产工件的单独空间。怎么组织就看你自己了。</p>



<figure class="wp-block-video"><video controls="" muted="" src="https://web.archive.org/web/20230304041944im_/https://neptune.ai/wp-content/uploads/Example-dashboard-metadata-structure.mp4"/></figure>



<h3 id="main-features">Neptune的<a href="/web/20230304041944/https://neptune.ai/pricing" target="_blank" rel="noreferrer noopener">定价</a>是基于使用的。对于所有的ML团队来说，它可能更具成本效益，但对于那些偶尔根本不进行实验的团队，或者那些有许多利益相关者没有深入参与实验过程的团队来说尤其如此。</h3>



<ul>
<li>如前所述，Neptune是为运行大量实验的团队构建的，因此它可以处理成千上万次运行，并且不会变慢。它随着你的团队和项目的规模而扩展。</li>



<li>Neptune有SaaS版本，但也可以在内部托管。如果选择第二个选项，安装过程非常容易。</li>



<li>有了Neptune，您可以<a href="https://web.archive.org/web/20230304041944/https://docs.neptune.ai/you-should-know/displaying-metadata#how-to-create-a-custom-dashboard" target="_blank" rel="noreferrer noopener">创建定制的仪表板</a>以一种更好的方式组合不同的元数据类型。</li>



<li>定价</li>



<li>Neptune可以用作托管解决方案，也可以部署在您的场所。有几个可用的计划:</li>
</ul>





<h3 id="pricing">个人:免费(超出免费配额的使用量)</h3>



<p>学术界:免费</p>



<ul>
<li>团队:付费</li>



<li>查看<a href="/web/20230304041944/https://neptune.ai/pricing" target="_blank" rel="noreferrer noopener">海王星的定价</a>了解更多信息。</li>



<li>重量和偏差vs海王星</li>
</ul>



<p>Neptune和Weights &amp; Biases都是托管服务，它们提供实验跟踪、模型管理和数据版本控制。</p>



<h3 id="weights-biases-vs-neptune">Neptune更加关注模型注册特性，而Weights &amp; Biases也提供了自动优化超参数的工具</h3>



<ul>
<li>这两种工具提供的开箱即用集成存在一些差异；Neptune支持R语言、DVC或Optuna，而WandB支持Spacy、Ray Tune或Kubeflow。</li>



<li>总的来说，这两个工具非常相似，都是非常好的解决方案，所以主要的区别可以在定价结构中发现(基于使用和基于用户)。</li>



<li>TensorBoard由TensorFlow团队开发，是一款用于机器学习实验的开源可视化工具。</li>



<li>它用于跟踪ML度量，如损失和准确性、可视化模型图、直方图、将嵌入投影到低维空间等等。</li>
</ul>











<p>有了TensorBoard，你还可以分享你的实验结果。</p>



<p>主要特点:</p>



<p>TensorBoard允许您跟踪您的实验。</p>



<p id="separator-block_e0ba56fb3029447bf6dde312c0a65067" class="block-separator block-separator--5">它还允许您跟踪不是基于TensorFlow的实验。</p>





<h3 id="main-features">TensorBoard允许你通过一个可共享的链接与任何人分享你的实验结果，用于出版、合作等。</h3>



<ul>
<li>它提供对损失和准确性等指标的跟踪和可视化。</li>



<li>TensorBoard拥有What-If工具(WIT)，这是一个易于使用的接口，用于解释和理解黑盒分类和回归ML模型。</li>



<li>TensorBoard有一个强大的用户社区，提供了巨大的支持。</li>



<li>定价</li>



<li>它是免费使用的。</li>



<li>重量和偏差与TensorBoard</li>
</ul>



<h3 id="pricing">如果你需要一个个人使用的工具，不打算花钱买，也不需要额外的功能，TensorBoard可以是一个不错的选择。</h3>



<p>TensorBoard更适合处理张量流的可视化。</p>



<h3 id="weights-biases-vs-tensorboard">Comet是一个基于云的机器学习平台，开发者可以在这个平台上跟踪、比较、分析和优化实验。</h3>



<ul>
<li>Comet安装很快，只需几行代码，您就可以开始跟踪您的ML实验，而无需任何库。</li>



<li>主要特点:</li>
</ul>











<p>Comet允许您为您的实验和数据创建定制的可视化。你也可以在<a href="https://web.archive.org/web/20230304041944/https://www.comet.ml/demo/gallery/view/new#select-panel?gallery-tab=Public" target="_blank" rel="noreferrer noopener nofollow">面板</a>上使用社区提供的。</p>



<p>Comet提供了关于您的实验的实时统计数据和图表。</p>



<p id="separator-block_e0ba56fb3029447bf6dde312c0a65067" class="block-separator block-separator--5">您可以轻松地比较您的实验，包括代码、指标、预测、见解等等。</p>





<h3 id="main-features">使用comet，您可以调试模型错误、特定于环境的错误等。</h3>



<ul>
<li>Comet还允许您监控您的模型，并在出现问题或错误时通知您。</li>



<li>它允许团队和业务涉众之间的协作。</li>



<li>它可以轻松地与Tensorflow、Pytorch等集成。</li>



<li>定价</li>



<li>Comet提供以下定价方案:</li>



<li>个人:免费(超出免费配额的使用量)</li>



<li>学术界:免费</li>
</ul>



<h3 id="pricing">团队:付费</h3>



<p>你可以在这里阅读他们的详细定价<a href="https://web.archive.org/web/20230304041944/https://www.comet.ml/site/pricing/" target="_blank" rel="noreferrer noopener nofollow">。</a></p>



<ul>
<li>权重和偏差与Comet</li>



<li>这两个工具都提供了用户管理特性、托管和本地设置、模型管理、超参数搜索和工件存储。</li>



<li>如果你需要一个自定义可视化的图库，<a href="https://web.archive.org/web/20230304041944/https://www.comet.ml/demo/gallery/view/new#select-panel?gallery-tab=Public" target="_blank" rel="noreferrer noopener nofollow"> Comet </a>就有。</li>
</ul>



<p>Comet为开发提供了Java和R SDK，这是Weights &amp; Biases中所缺少的。</p>



<h3 id="weights-biases-vs-comet">MLflow是一个开源平台，有助于管理整个机器学习生命周期。它有助于实验跟踪，再现性，部署，并给出了一个中央模型注册。</h3>



<ul>
<li> </li>



<li> </li>



<li>MLflow包含四个主要功能:</li>
</ul>











<p><strong> MLflow Tracking </strong>:一个API和UI，用于在运行机器学习代码时记录参数、代码版本、指标和工件，并用于以后可视化和比较结果。</p>



<p id="separator-block_e0ba56fb3029447bf6dde312c0a65067" class="block-separator block-separator--5"><strong> MLflow项目</strong>:将ML代码打包成可重用、可复制的形式，以便与其他数据科学家共享或转移到生产中。</p>



<figure class="wp-block-video aligncenter"><video autoplay="" loop="" muted="" src="https://web.archive.org/web/20230304041944im_/https://neptune.ai/wp-content/uploads/2022/11/Alternatives-to-Weights-Biases_4.mp4"/><figcaption class="wp-element-caption"><a href="https://web.archive.org/web/20230304041944/https://towardsdatascience.com/5-tips-for-mlflow-experiment-tracking-c70ae117b03f" target="_blank" rel="noreferrer noopener nofollow"><strong>Source</strong></a></figcaption></figure>



<p id="separator-block_e0ba56fb3029447bf6dde312c0a65067" class="block-separator block-separator--5"><strong> MLflow Models </strong>:管理来自不同ML库的模型，并将其部署到各种模型服务和推理平台。</p>



<p><strong> MLflow Model Registry </strong>:一个中央模型存储库，用于协作管理MLflow模型的整个生命周期，包括模型版本控制、阶段转换和注释。</p>



<ol>
<li>主要特点:</li>



<li>MLflow Model Registry为组织提供了一套API和直观的UI，用于注册和共享新版本的模型，以及对现有模型执行生命周期管理。</li>



<li>MLflow Model Registry与MLflow tracking组件一起使用，它允许您追溯生成模型和数据工件的原始运行，以及该运行的源代码版本，从而为所有模型和数据转换提供生命周期的完整沿袭。</li>



<li>当存储在增量表或目录中时，自动对存储在数据湖中的数据进行版本控制。</li>
</ol>



<h3 id="main-features">允许您使用版本号或时间戳获取数据的每个版本。</h3>



<ul>
<li>允许您在意外写入或删除错误数据时审核和/或回滚数据。</li>



<li>复制实验和报告。</li>



<li>要了解更多关于MLflow的信息，请查看<a href="https://web.archive.org/web/20230304041944/http://mlflow.org/docs/latest/index.html" target="_blank" rel="noreferrer noopener nofollow"> MLflow文档</a>。</li>



<li>定价</li>



<li>它是免费的。</li>



<li>重量和偏差与MLflow</li>
</ul>



<p>如果你的预算很低，MLflow是一个更好的选择，因为它是免费的(开源的)实验性跟踪。</p>



<h3 id="pricing">MLflow是语言不可知的，即它可以与Python或r中的任何机器学习库一起使用，而Weights &amp; Biases仅适用于Python脚本。</h3>



<p>Weights &amp; Biases提供托管和内部设置，而MLflow仅作为开源解决方案提供，需要您在服务器上进行维护。</p>



<h3 id="weights-biases-vs-mlflow">MLflow提供端到端的ML生命周期管理，而Weights &amp; Biases仅提供实验跟踪、模型管理和数据版本控制等功能。</h3>



<ul>
<li>Kubeflow是一个免费的开源机器学习平台，用于在Kubernetes上构建简单、可移植(通过容器)和可扩展的模型。Kubeflow负责跟踪、数据版本控制、模型版本控制和模型部署。</li>



<li>Kubeflow是Google为数据科学家和ML工程师设计的，他们喜欢开发、测试和部署ML管道、模型和系统到各种环境中。</li>



<li>Kubeflow由以下组件组成:</li>



<li><strong> <a href="https://web.archive.org/web/20230304041944/https://www.kubeflow.org/docs/components/central-dash/overview/" target="_blank" rel="noreferrer noopener nofollow">中央仪表盘</a> : </strong>这个仪表盘提供了一个中央视图，可以快速访问您的所有操作。它容纳了集群中运行的作业和组件，如管道、Katib、笔记本等。</li>
</ul>











<p><strong><a href="https://web.archive.org/web/20230304041944/https://www.kubeflow.org/docs/components/pipelines/" target="_blank" rel="noreferrer noopener nofollow">kube flow Pipelines</a>:</strong>kube flow pipeline是一个平台，允许ml工程师构建和部署打包在Docker映像中的端到端ML工作流。它由用于跟踪实验和作业的UI、用于管道操作的SDK、多步调度引擎和用于构建ML模型的笔记本组成。</p>



<p><strong><a href="https://web.archive.org/web/20230304041944/https://www.kubeflow.org/docs/components/kfserving/" target="_blank" rel="noreferrer noopener nofollow">KFServing</a>:</strong>KFServing组件是Kubeflow的模型部署和服务工具包。它通过在Kubernetes上启用无服务器推理来提供生产模型服务，并为在TensorFlow、XGBoost、scikit-learn、PyTorch和ONNX等框架上的部署提供抽象层。</p>



<p><strong> <a href="https://web.archive.org/web/20230304041944/https://www.kubeflow.org/docs/components/katib/" target="_blank" rel="noreferrer noopener nofollow"> Katib </a> : </strong> Katib是一个模型不可知的Kubernetes-native项目，为AutoML模型提供超参数调整、早期停止和神经架构搜索。它支持各种AutoML算法和框架，如TensorFlow、MXNet、PyTorch等。</p>



<ul>
<li><strong> <a href="https://web.archive.org/web/20230304041944/https://www.kubeflow.org/docs/components/training/" target="_blank" rel="noreferrer noopener nofollow">培训操作员</a> : </strong>该组件提供Kubernetes中Tensorflow、PyTorch、MXNet、XGBoost、MPI模型培训作业的操作员。</li>



<li><strong> <a href="https://web.archive.org/web/20230304041944/https://www.kubeflow.org/docs/components/notebooks/" target="_blank" rel="noreferrer noopener nofollow"> Kubeflow笔记本</a> : </strong>这个Kubeflow的笔记本组件允许你在集群内部运行你的笔记本。您还可以在集群中创建笔记本，并在整个组织中共享它们。</li>



<li>主要特点:</li>



<li>Kubeflow还在其工件存储中存储工件数据；它使用工件来理解各种Kubeflow组件的管道是如何工作的。</li>



<li>Kubeflow Pipeline可以输出工件数据的简单文本视图和丰富的交互式可视化。</li>



<li>Kubeflow有一个用户界面(UI ),用于管理和跟踪实验、作业和运行。</li>
</ul>



<p id="separator-block_e0ba56fb3029447bf6dde312c0a65067" class="block-separator block-separator--5">它为多步ML工作流提供调度。</p>





<h3 id="main-features">它有一个用于定义和操作管道和组件的SDK。</h3>



<ul>
<li>使用SDK与系统交互的笔记本电脑。</li>



<li>定价</li>



<li>它是免费的。</li>



<li>权重和偏差与Kubeflow</li>



<li>使用<a href="https://web.archive.org/web/20230304041944/https://www.kubeflow.org/docs/components/pipelines/" target="_blank" rel="noreferrer noopener nofollow"> Kubeflow管道</a>或<a href="https://web.archive.org/web/20230304041944/https://www.kubeflow.org/docs/components/kfserving/" target="_blank" rel="noreferrer noopener nofollow"> KF服务于Kubeflow中的</a>组件，你可以在docker上部署机器学习模型，这是权重&amp;偏差所缺少的。</li>



<li>Kubeflow提供端到端的机器学习编排和管理，Weights &amp; Biases不提供。</li>
</ul>



<h3 id="pricing">Kubeflow为所有模型工件提供实验性跟踪和元数据跟踪。</h3>



<p>对于不需要交互式可视化的用例，Kubeflow是更好的选择。</p>



<h3 id="weights-biases-vs-kubeflow">Amazon SageMaker Studio是一个基于web的集成开发环境(IDE ),用于构建、培训、可视化、调试、部署和监控您的ML模型。您可以在一个集成的可视化界面中编写代码、跟踪实验、可视化数据以及执行调试和监控。</h3>



<ul>
<li>主要特点:</li>



<li>它提供了一个模型工件存储，该存储存储了包含模型类型和内容信息的模型的s3存储桶位置。</li>



<li>SageMaker studio也为AutoML实验存储工件。</li>



<li>它允许您轻松创建和共享Jupyter笔记本。</li>
</ul>











<p>它提供并管理模型环境的硬件基础设施，以便您可以快速地从一种硬件配置切换到另一种。</p>



<p id="separator-block_e0ba56fb3029447bf6dde312c0a65067" class="block-separator block-separator--5">SageMaker Studio支持Tensorflow、PyTorch、MXNet等框架。</p>





<h3 id="main-features">SageMaker Studio有超过150个预打包的开源模型，用于各种用例。</h3>



<ul>
<li>SageMaker Studio提供端到端的数据准备。它允许您使用自己选择的语言(SQL、Python和Scala)运行Spark作业，并且您还可以轻松连接到运行在Amazon EMR上的Apache Spark数据处理环境。</li>



<li>定价</li>



<li>有了亚马逊SageMaker，你只需为你使用的东西付费。它提供两种付款方式:</li>



<li>按秒计费的按需定价，没有最低费用，也没有前期承诺</li>



<li>SageMaker储蓄计划提供了一种灵活的基于使用量的定价模式，以换取对一致使用量的承诺。</li>



<li>您可以使用<a href="https://web.archive.org/web/20230304041944/https://calculator.aws/#/createCalculator/SageMaker" target="_blank" rel="noreferrer noopener nofollow"> AWS定价计算器</a>来计划您的账单。</li>



<li>重量与偏见vs亚马逊SageMaker工作室</li>
</ul>



<h3 id="pricing">SageMaker Studio的设置很简单，不像Weights &amp; Biases需要一定水平的专业知识，因为它是一种托管和内部服务。</h3>



<p>SageMaker studio在实验跟踪期间提供实验日志和可视化。</p>



<ol>
<li>在SageMaker studio中，您可以设置一个排行榜，自动跟踪您的所有实验，然后对它们的表现进行排名。</li>



<li>与Weights &amp; Biases相比，SageMaker studio以相对较低的价格出租计算资源。</li>
</ol>



<p>SageMaker Studio允许您交互式地查询、探索和可视化数据，除了实验跟踪，SageMaker studio还提供数据注释、大量数据处理、调试以及模型和数据漂移检测。</p>



<h3 id="weights-biases-vs-amazon-sagemaker-studio">结论</h3>



<ul>
<li>对于专注于研究的ML研究团队来说，Weights &amp; Biases是一个很好的工具，因为它擅长进行实验跟踪，但仅此还不够。本文中列出的替代工具有一些独特的价值主张，使它们适合可能不需要权重和偏差的用例。</li>



<li>对于开源的实验性跟踪工具，TensorBoard、MLflow、Kubeflow会是很好的替代品。就元数据和工件的可视化和可伸缩存储而言，付费工具如Neptune和Comet是更好的选择。此外，它们还为企业团队提供高级别的安全性和支持。</li>



<li>因此，根据您的需求，您可以选择上述任何工具。</li>



<li>同时，我还会建议你总是寻找更多适合你的需求和任务的<a href="/web/20230304041944/https://neptune.ai/blog/best-ml-experiment-tracking-tools" target="_blank" rel="noreferrer noopener nofollow">工具</a>，并给你足够的灵活性来最大限度地利用你的工作。</li>



<li>快乐实验！</li>
</ul>







<h2 id="conclusion">Conclusion</h2>



<p>Weights &amp; Biases is a great tool for ML research teams focusing on research because it is good at performing experimental tracking but that alone isn’t enough. The alternative tools listed in this article have some unique value propositions that make them fit into use-cases where Weights &amp; Biases might not be needed. </p>



<p>For open-source experimental tracking tools, TensorBoard, MLflow, Kubeflow would be good alternatives. In terms of visualizations and scalable storage for your metadata and artifacts, paid tools such as Neptune and Comet are better options. Additionally, they also provide high-level security and support for enterprise teams.</p>



<p>So, depending on your requirement, you may choose any of the aforementioned tools.</p>



<p>Simultaneously, I will also advise you to be always on the lookout for more <a href="/web/20230304041944/https://neptune.ai/blog/best-ml-experiment-tracking-tools" target="_blank" rel="noreferrer noopener nofollow">tools</a> that suit your needs, tasks, and give you enough flexibility to get the most out of your work.</p>



<p>Happy experimenting!</p>
        </div>
        
    </div>    
</body>
</html>