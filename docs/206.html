<html>
<head>
<title>Train PyTorch Models Using Genetic Algorithm With PyGAD </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>用遗传算法和PyGAD训练PyTorch模型</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/train-pytorch-models-using-genetic-algorithm-with-pygad#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/train-pytorch-models-using-genetic-algorithm-with-pygad#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p><a href="https://web.archive.org/web/20230131180157/https://pygad.readthedocs.io/" target="_blank" rel="noreferrer noopener nofollow"> PyGAD </a>是一个用于求解优化问题的遗传算法Python 3库。其中一个问题是训练机器学习算法。</p>



<p>PyGAD有一个模块叫做<a href="https://web.archive.org/web/20230131180157/https://github.com/ahmedfgad/KerasGA" target="_blank" rel="noreferrer noopener nofollow"> pygad.kerasga </a>。它使用遗传算法训练Keras模型。2021年1月3日，新发布的<a href="https://web.archive.org/web/20230131180157/https://pygad.readthedocs.io/" target="_blank" rel="noreferrer noopener nofollow"> PyGAD 2.10.0 </a>带来了一个名为<a href="https://web.archive.org/web/20230131180157/https://github.com/ahmedfgad/TorchGA" target="_blank" rel="noreferrer noopener nofollow"> pygad.torchga </a>的新模块来训练PyTorch模型。它非常容易使用，但有几个棘手的步骤。</p>



<p>因此，在本教程中，我们将探索如何使用PyGAD来训练PyTorch模型。</p>







<p>让我们开始吧。</p>



<h2 id="install-pygad">安装PyGAD</h2>



<p>PyGAD是一个Python 3库，可以在<a href="https://web.archive.org/web/20230131180157/https://pypi.org/project/pygad" target="_blank" rel="noreferrer noopener nofollow"> PyPI (Python包索引)</a>获得。因此，您可以简单地使用这个pip命令来安装它:</p>



<pre class="hljs">pip install pygad&gt;=<span class="hljs-number">2.10</span><span class="hljs-number">.0</span></pre>



<p>确保你的版本至少是2.10.0，早期版本不支持pygad.torchga模块。</p>



<p>你也可以从<a href="https://web.archive.org/web/20230131180157/https://files.pythonhosted.org/packages/3b/28/06a37e94ac31a9fe0945f39e7e05ed2390225e45582ff144125433c2f598/pygad-2.10.0-py3-none-any.whl" target="_blank" rel="noreferrer noopener nofollow">这个链接</a>下载PyGAD 2.10.0的轮子分发文件，用下面的命令安装(确保当前目录设置为带有。whl文件)。</p>



<pre class="hljs">pip install pygad<span class="hljs-number">-2.10</span><span class="hljs-number">.0</span>-py3-none-any.whl</pre>



<p>安装完<a href="https://web.archive.org/web/20230131180157/https://pygad.readthedocs.io/" target="_blank" rel="noreferrer noopener nofollow"> PyGAD </a>之后，就该开始使用pygad.torchga模块了。</p>



<p>要了解更多关于PyGAD的信息，请阅读它的文档。你也可以通过<a href="https://web.archive.org/web/20230131180157/https://pygad.readthedocs.io/en/latest/README_pygad_torchga_ReadTheDocs.html" target="_blank" rel="noreferrer noopener nofollow">这个链接</a>直接访问<a href="https://web.archive.org/web/20230131180157/https://pygad.readthedocs.io/en/latest/README_pygad_torchga_ReadTheDocs.html" target="_blank" rel="noreferrer noopener nofollow"> pygad.torchga模块</a>的文档。</p>



<h2 id="pygad.torchga">pygad.torchga模块</h2>



<p>PyGAD 2.10.0允许我们使用遗传算法(GA)训练PyTorch模型。训练PyTorch模型的问题被公式化为g a的优化问题，其中模型中的所有参数(例如，权重和偏差)被表示为单个向量(即，染色体)。</p>



<p>pygad.torchga模块(<strong> torchga </strong>是<strong> Torch遗传算法</strong>的缩写)帮助我们以pygad期望的方式制定PyTorch模型训练问题。该模块有1个类别和2个功能:</p>



<ol>
<li>TorchGA:为PyTorch模型创建解决方案群体(即染色体)的类。每个解/染色体保存一组模型的所有参数。</li>



<li>model_weights_as_vector():一个函数，它接受表示PyTorch模型的名为model的参数，并将其参数作为向量(即染色体)返回。</li>



<li>model_weights_as_dict():一个接受两个参数的函数。第一个被称为模型，它接受PyTorch模型。第二个参数称为weights_vector，它是代表所有模型参数的向量。该函数返回PyTorch模型参数的字典，该字典可以传递给名为load_state_dict()的PyTorch方法来设置模型权重。</li>
</ol>



<p>pygad.torchga模块的源代码可以在<a href="https://web.archive.org/web/20230131180157/https://github.com/ahmedfgad/TorchGA" target="_blank" rel="noreferrer noopener nofollow"> ahmedfgad/TorchGA </a> GitHub项目中获得。</p>



<p>TorchGA类的构造函数接受以下两个参数:</p>



<ol>
<li>型号:PyTorch型号。</li>



<li>num_solutions:群体中解的数量。每个解决方案都有一组不同的PyTorch模型参数。</li>
</ol>



<p>在pygad.torchga.TorchGA类的实例中，每个参数都用作一个属性。这意味着您可以通过使用模型属性来访问模型，如下所示:</p>



<pre class="hljs">torchga = TorchGA(model=---, num_solutions=---)
torchga.model</pre>



<p>第三个属性称为population_weights，它是人口中所有解决方案的2D列表。请记住，每个解决方案都是包含模型参数的1D列表。</p>



<p>下面是一个创建TorchGA类实例的例子。模型参数可以分配给任何PyTorch模型。传递给num_solutions参数的值是10，这意味着群体中有10个解决方案。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> pygad.torchga

torch_ga = pygad.torchga.TorchGA(model=...,
                                 num_solutions=<span class="hljs-number">10</span>)

initial_population = torch_ga.population_weights
</pre>



<p>TorchGA类的构造函数调用一个名为create_population()的方法，该方法创建并向PyTorch模型返回一组解决方案。首先，调用model_weights_as_vector()函数以向量形式返回模型参数。</p>



<p>该向量用于在群体中创建解。为了使解决方案有所不同，随机值被添加到向量中。</p>



<p>假设模型有30个参数，那么population_weights数组的形状是10×30。</p>



<p>现在，让我们回顾一下使用PyGAD训练PyTorch模型所需的步骤。</p>



<h2 id="train-pygad">使用PyGAD训练PyTorch模型</h2>



<p>要使用PyGAD训练PyTorch模型，我们需要完成以下步骤:</p>



<ul>
<li>分类还是回归？</li>



<li>创建PyTorch模型</li>



<li>创建pygad.torchga.TorchGA类的实例</li>



<li>准备培训数据</li>



<li>决定损失函数</li>



<li>建立适应度函数</li>



<li>生成回调函数(可选)</li>



<li>创建pygad的一个实例。GA级</li>



<li>运行遗传算法</li>
</ul>



<p>我们将详细讨论每个步骤。</p>



<h3>分类还是回归？</h3>



<p>决定PyTorch模型所解决的问题类型是分类还是回归是很重要的。这将帮助我们准备:</p>



<ol>
<li>模型的损失函数(用于构建适应度函数)，</li>



<li>模型输出层中的激活函数，</li>



<li>训练数据。</li>
</ol>



<p>对于PyTorch提供的损失函数，检查<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/nn.html#loss-functions" target="_blank" rel="noreferrer noopener nofollow">此链接</a>。回归问题的损失函数的例子包括平均绝对误差(<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss" target="_blank" rel="noreferrer noopener nofollow"> nn。L1Loss </a>和均方误差(<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss" target="_blank" rel="noreferrer noopener nofollow"> nn)。ms loss</a>)。</p>



<p>对于分类问题，一些例子是二元交叉熵(<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss" target="_blank" rel="noreferrer noopener nofollow"> nn。BCELoss </a>)进行二元分类和交叉熵(<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" target="_blank" rel="noreferrer noopener nofollow"> nn。多类问题的CrossEntropyLoss </a>)。</p>



<p>基于问题是分类还是回归，我们可以决定输出层中的激活函数。例如，<strong> softmax </strong>用于分类，<strong>线性</strong>用于回归。</p>



<p>训练数据也取决于问题类型。如果问题是分类，那么输出来自一组有限的离散值。如果问题是回归，那么输出来自一组无限连续的值。</p>



<h3>创建PyTorch模型</h3>



<p>我们将使用torch.nn模块来构建PyTorch模型，以解决一个简单的回归问题。该模型有3层:</p>



<ol>
<li>一个<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/generated/torch.nn.Linear.html" target="_blank" rel="noreferrer noopener nofollow">线性</a>层作为具有3个输入和2个输出的输入层，</li>



<li>一个<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html" target="_blank" rel="noreferrer noopener nofollow"> ReLU </a>激活层，</li>



<li>另一个<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/generated/torch.nn.Linear.html" target="_blank" rel="noreferrer noopener nofollow">线性</a>层作为输出层，有2个输入和1个输出。</li>
</ol>



<p>如果问题是分类，我们必须添加一个合适的输出层，像<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html" target="_blank" rel="noreferrer noopener nofollow"> SoftMax </a>。</p>



<p>最后，该模型被创建为<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html" target="_blank" rel="noreferrer noopener nofollow"> torch.nn.Sequential </a>类的一个实例，它接受所有先前按顺序创建的层。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> torch.nn

input_layer = torch.nn.Linear(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>)
relu_layer = torch.nn.ReLU()
output_layer = torch.nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>)

model = torch.nn.Sequential(input_layer,
                            relu_layer,
                            output_layer)
</pre>



<p>关于如何构建PyTorch模型，我们就不深入探讨了。更多细节，可以查看<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/index.html" target="_blank" rel="noreferrer noopener nofollow"> PyTorch文档</a>。</p>



<p>现在，我们将使用pygad.torchga.TorchGA类创建PyTorch模型参数的初始填充。</p>



<h3>创建pygad.torchga.TorchGA类的实例</h3>



<p>使用TorchGA类，PyGAD提供了一个简单的接口来创建PyTorch模型的初始解决方案群体。只需创建pygad.torchga.TorchGA类的一个实例，就会自动创建一个初始群体。</p>



<p>下面是一个将之前创建的模型传递给TorchGA类的构造函数的示例。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> pygad.torchga

torch_ga = pygad.torchga.TorchGA(model=model,
                                num_solutions=<span class="hljs-number">10</span>)</pre>



<p>现在，让我们创建随机训练数据来训练模型。</p>



<h3><strong>准备培训数据</strong></h3>



<p>基于问题是分类还是回归，我们相应地准备训练数据。</p>



<p>这里有5个随机样本，每个样本有3个输入和1个输出。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> numpy


data_inputs = numpy.array([[<span class="hljs-number">0.02</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.15</span>],
                           [<span class="hljs-number">0.7</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">0.8</span>],
                           [<span class="hljs-number">1.5</span>, <span class="hljs-number">1.2</span>, <span class="hljs-number">1.7</span>],
                           [<span class="hljs-number">3.2</span>, <span class="hljs-number">2.9</span>, <span class="hljs-number">3.1</span>]])


data_outputs = numpy.array([[<span class="hljs-number">0.1</span>],
                            [<span class="hljs-number">0.6</span>],
                            [<span class="hljs-number">1.3</span>],
                            [<span class="hljs-number">2.5</span>]])
</pre>



<p>如果我们正在解决像XOR这样的二进制分类问题，那么它的数据如下所示，其中有4个样本，有2个输入和1个输出。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> numpy


data_inputs = numpy.array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                           [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>],
                           [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>],
                           [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])


data_outputs = numpy.array([[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>],
                            [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>],
                            [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>],
                            [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]])
</pre>



<p>回归和分类问题损失函数的时间。</p>



<h3>决定损失函数</h3>



<h4>回归</h4>



<p>对于回归问题，损失函数包括:</p>







<h4>分类</h4>



<p>对于分类问题，损失函数包括:</p>







<p>查看<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/nn.html#loss-functions" target="_blank" rel="noreferrer noopener nofollow">本页</a>了解PyTorch中损失函数的更多信息。</p>



<p>下面是一个使用torch.nn.BCELoss类计算二进制交叉熵的例子。调用<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/autograd.html#torch.Tensor.detach" target="_blank" rel="noreferrer noopener nofollow"> detach() </a>方法从图中分离张量，以返回其值。查看<a href="https://web.archive.org/web/20230131180157/http://www.bnikolic.co.uk/blog/pytorch-detach.html" target="_blank" rel="noreferrer noopener nofollow">这个链接</a>以获得更多关于<a href="https://web.archive.org/web/20230131180157/https://pytorch.org/docs/stable/autograd.html#torch.Tensor.detach" target="_blank" rel="noreferrer noopener nofollow"> detach() </a>方法的信息。</p>



<pre class="hljs">loss_function = torch.nn.BCELoss()

loss = loss_function(predictions, data_outputs).detach().numpy()</pre>



<p>然后基于所计算的损失来计算适应度函数。</p>



<h3>建立适应度函数</h3>



<p>遗传算法期望适应度函数是最大化的，其输出越高，结果越好。然而，计算机器学习模型的损失是基于最小化损失函数。损失越低，效果越好。</p>



<p>如果适应度设置为等于损失，那么遗传算法将在使适应度增加的方向上搜索。因此，它将在相反的方向上增加损失。这就是为什么适应度是根据下一条线作为损失的倒数来计算的。</p>



<p>当loss=0.0时，添加小值0.00000001是为了避免被零除。</p>



<pre class="hljs">fitness_value = (<span class="hljs-number">1.0</span> / (loss + <span class="hljs-number">0.00000001</span>))
</pre>



<p>当使用PyGAD训练PyTorch模型时，有多个解，并且每个解都是保存模型所有参数的向量。</p>



<p>要构建适应度函数，请遵循以下步骤:</p>



<ol>
<li>从1D向量恢复模型参数。</li>



<li>设置模型参数。</li>



<li>做预测。</li>



<li>计算损失值。</li>



<li>计算适应值。</li>



<li>回归健身值。</li>
</ol>



<p>接下来，我们将为回归和二元分类问题构建适应度函数。</p>



<h4>回归的适应度函数</h4>



<p>PyGAD中的fitness函数是作为常规Python函数构建的，但是它必须接受两个参数，分别表示:</p>



<ol>
<li>计算其适应值的解决方案，</li>



<li>总体中解的指数。</li>
</ol>



<p>传递给适应度函数的解是1D向量。这个向量不能直接用于PyTorch模型的参数，因为模型需要字典形式的参数。因此，在计算损失之前，我们需要将向量转换为字典。我们可以在pygad.torchga模块中使用model_weights_as_dict()函数，如下所示:</p>



<pre class="hljs">model_weights_dict = torchga.model_weights_as_dict(model=model,
                                                   weights_vector=solution)</pre>



<p>一旦创建了参数字典，就调用load_state_dict()方法来使用这个字典中的参数作为模型的当前参数。</p>



<pre class="hljs">model.load_state_dict(model_weights_dict)
</pre>



<p>根据当前参数，模型对训练数据进行预测。</p>



<pre class="hljs">predictions = model(data_inputs)</pre>



<p>模型的预测被传递给损失函数，以计算解决方案的损失。平均绝对误差被用作损失函数。</p>



<pre class="hljs">loss_function = torch.nn.L1Loss()

solution_fitness = <span class="hljs-number">1.0</span> / (loss_function(predictions, data_outputs).detach().numpy() + <span class="hljs-number">0.00000001</span>)
</pre>



<p>最后，返回适应值。</p>



<pre class="hljs">loss_function = torch.nn.L1Loss()

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fitness_func</span><span class="hljs-params">(solution, sol_idx)</span>:</span>
    <span class="hljs-keyword">global</span> data_inputs, data_outputs, torch_ga, model, loss_function

    model_weights_dict = torchga.model_weights_as_dict(model=model,
                                                         weights_vector=solution)

    
    model.load_state_dict(model_weights_dict)

    predictions = model(data_inputs)

    solution_fitness = <span class="hljs-number">1.0</span> / (loss_function(predictions, data_outputs).detach().numpy() + <span class="hljs-number">0.00000001</span>)

    <span class="hljs-keyword">return</span> solution_fitness
</pre>



<h4>二元分类的适合度</h4>



<p>这是二元分类问题的适应度函数。使用的损失函数是二元交叉熵。</p>



<pre class="hljs">loss_function = torch.nn.BCELoss()

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fitness_func</span><span class="hljs-params">(solution, sol_idx)</span>:</span>
    <span class="hljs-keyword">global</span> data_inputs, data_outputs, torch_ga, model, loss_function

    model_weights_dict = torchga.model_weights_as_dict(model=model,
                                                         weights_vector=solution)

    
    model.load_state_dict(model_weights_dict)

    predictions = model(data_inputs)

    solution_fitness = <span class="hljs-number">1.0</span> / (loss_function(predictions, data_outputs).detach().numpy() + <span class="hljs-number">0.00000001</span>)

    <span class="hljs-keyword">return</span> solution_fitness
</pre>



<p>创建的适应度函数应该分配给pygad中的fitness_func参数。GA类的构造函数。</p>



<p>接下来，我们将构建一个在每一代结束时执行的回调函数。</p>



<h3>生成回调函数(可选)</h3>



<p>根据下图所示的PyGAD生命周期，有一个回调函数，每生成一次就调用一次。这个函数可以被实现并用来打印一些调试信息，比如每代中的最佳适应值，以及完成的代数。请注意，这一步是可选的，仅用于调试目的。</p>





<p>您需要做的就是实现回调函数，然后在pygad的构造函数中将它赋给on_generation参数。GA级。下面是一个回调函数，它接受一个表示pygad实例的参数。GA级。</p>



<p>使用这个实例，返回属性generations_completed，它保存已完成的代的数量。best_solution()方法也被调用，它返回关于当前代中最佳解决方案的信息。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">callback_generation</span><span class="hljs-params">(ga_instance)</span>:</span>
    print(<span class="hljs-string">"Generation = {generation}"</span>.format(generation=ga_instance.generations_completed))
    print(<span class="hljs-string">"Fitness    = {fitness}"</span>.format(fitness=ga_instance.best_solution()[<span class="hljs-number">1</span>]))
</pre>



<p>下一步是创建pygad的实例。GA类，负责运行遗传算法来训练PyTorch模型。</p>



<h3>创建pygad的一个实例。GA级</h3>



<p>pygad的建造者。GA类接受许多参数，这些参数可以在<a href="https://web.archive.org/web/20230131180157/https://pygad.readthedocs.io/en/latest/README_pygad_ReadTheDocs.html#init" target="_blank" rel="noreferrer noopener nofollow">文档</a>中找到。下一段代码只使用了其中的一些参数，创建了pygad的一个实例。GA类，并将其保存在ga_instance变量中:</p>



<ul>
<li>num_generations:代的数量。</li>



<li>num _ parents _ mating:要交配的亲本数量。</li>



<li>initial _ population:py torch模型参数的初始总体。</li>



<li>fitness_func:适应函数。</li>



<li>on_generation:生成回调函数。</li>
</ul>



<pre class="hljs">num_generations = <span class="hljs-number">250</span>
num_parents_mating = <span class="hljs-number">5</span>
initial_population = torch_ga.population_weights

ga_instance = pygad.GA(num_generations=num_generations,
                       num_parents_mating=num_parents_mating,
                       initial_population=initial_population,
                       fitness_func=fitness_func,
                       on_generation=callback_generation)
</pre>



<p>请注意，在TorchGA类的构造函数中，群体中的解的数量先前设置为10。因此，要交配的亲本数量必须少于10个。</p>



<p>在下一节中，我们调用run()方法来运行遗传算法并训练PyTorch模型。</p>



<h3>运行遗传算法</h3>



<p>pygad的ga _实例。GA现在可以调用run()方法来启动遗传算法。</p>



<pre class="hljs">ga_instance.run()
</pre>



<p>在这种方法完成后，我们可以使用遗传算法在最后一代中找到的最佳解决方案进行预测。</p>



<p>pygad中有一个很有用的方法叫做plot_result()。GA类中，它显示了一个将适应值与代数相关联的图形。在run()方法完成后，这很有用。</p>



<pre class="hljs">ga_instance.plot_result(title=<span class="hljs-string">"PyGAD &amp; PyTorch - Iteration vs. Fitness"</span>)</pre>



<h2 id="statistics">有关已定型模型的统计信息</h2>



<p>皮加德人。GA类有一个名为best_solution()的方法，它返回3个输出:</p>



<ol>
<li>找到最佳解决方案，</li>



<li>最佳解决方案的适应值，</li>



<li>群体中最佳解决方案的索引。</li>
</ol>



<p>下一段代码调用best_solution()方法，并输出最佳解决方案的信息。</p>



<pre class="hljs">solution, solution_fitness, solution_idx = ga_instance.best_solution()
print(<span class="hljs-string">"Fitness value of the best solution = {solution_fitness}"</span>.format(solution_fitness=solution_fitness))
print(<span class="hljs-string">"Index of the best solution : {solution_idx}"</span>.format(solution_idx=solution_idx))
</pre>



<p>最佳解决方案的参数可以转换成字典，输入PyTorch模型进行预测。</p>



<pre class="hljs">
best_solution_weights = torchga.model_weights_as_dict(model=model,
                                                      weights_vector=solution)
model.load_state_dict(best_solution_weights)
predictions = model(data_inputs)
print(<span class="hljs-string">"Predictions : n"</span>, predictions.detach().numpy())</pre>



<p>接下来的代码计算模型定型后的损失。</p>



<pre class="hljs">abs_error = loss_function(predictions, data_outputs)
print(<span class="hljs-string">"Absolute Error : "</span>, abs_error.detach().numpy())
</pre>



<p>在介绍了使用PyGAD构建和训练PyTorch模型的所有步骤之后，接下来我们将查看两个带有完整代码的示例。</p>



<h2 id="examples">例子</h2>



<h3 id="example-regression">回归</h3>



<p>对于使用平均绝对误差作为损失函数的回归问题，这里是完整的代码。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torchga
<span class="hljs-keyword">import</span> pygad

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fitness_func</span><span class="hljs-params">(solution, sol_idx)</span>:</span>
    <span class="hljs-keyword">global</span> data_inputs, data_outputs, torch_ga, model, loss_function

    model_weights_dict = torchga.model_weights_as_dict(model=model,
                                                       weights_vector=solution)

    
    model.load_state_dict(model_weights_dict)

    predictions = model(data_inputs)
    abs_error = loss_function(predictions, data_outputs).detach().numpy() + <span class="hljs-number">0.00000001</span>

    solution_fitness = <span class="hljs-number">1.0</span> / abs_error

    <span class="hljs-keyword">return</span> solution_fitness

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">callback_generation</span><span class="hljs-params">(ga_instance)</span>:</span>
    print(<span class="hljs-string">"Generation = {generation}"</span>.format(generation=ga_instance.generations_completed))
    print(<span class="hljs-string">"Fitness    = {fitness}"</span>.format(fitness=ga_instance.best_solution()[<span class="hljs-number">1</span>]))


input_layer = torch.nn.Linear(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>)
relu_layer = torch.nn.ReLU()
output_layer = torch.nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>)

model = torch.nn.Sequential(input_layer,
                            relu_layer,
                            output_layer)



torch_ga = torchga.TorchGA(model=model,
                           num_solutions=<span class="hljs-number">10</span>)

loss_function = torch.nn.L1Loss()


data_inputs = torch.tensor([[<span class="hljs-number">0.02</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.15</span>],
                            [<span class="hljs-number">0.7</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">0.8</span>],
                            [<span class="hljs-number">1.5</span>, <span class="hljs-number">1.2</span>, <span class="hljs-number">1.7</span>],
                            [<span class="hljs-number">3.2</span>, <span class="hljs-number">2.9</span>, <span class="hljs-number">3.1</span>]])


data_outputs = torch.tensor([[<span class="hljs-number">0.1</span>],
                             [<span class="hljs-number">0.6</span>],
                             [<span class="hljs-number">1.3</span>],
                             [<span class="hljs-number">2.5</span>]])


num_generations = <span class="hljs-number">250</span> 
num_parents_mating = <span class="hljs-number">5</span> 
initial_population = torch_ga.population_weights 
parent_selection_type = <span class="hljs-string">"sss"</span> 
crossover_type = <span class="hljs-string">"single_point"</span> 
mutation_type = <span class="hljs-string">"random"</span> 
mutation_percent_genes = <span class="hljs-number">10</span> 
keep_parents = <span class="hljs-number">-1</span> 

ga_instance = pygad.GA(num_generations=num_generations,
                       num_parents_mating=num_parents_mating,
                       initial_population=initial_population,
                       fitness_func=fitness_func,
                       parent_selection_type=parent_selection_type,
                       crossover_type=crossover_type,
                       mutation_type=mutation_type,
                       mutation_percent_genes=mutation_percent_genes,
                       keep_parents=keep_parents,
                       on_generation=callback_generation)

ga_instance.run()


ga_instance.plot_result(title=<span class="hljs-string">"PyGAD &amp; PyTorch - Iteration vs. Fitness"</span>, linewidth=<span class="hljs-number">4</span>)


solution, solution_fitness, solution_idx = ga_instance.best_solution()
print(<span class="hljs-string">"Fitness value of the best solution = {solution_fitness}"</span>.format(solution_fitness=solution_fitness))
print(<span class="hljs-string">"Index of the best solution : {solution_idx}"</span>.format(solution_idx=solution_idx))


best_solution_weights = torchga.model_weights_as_dict(model=model,
                                                      weights_vector=solution)
model.load_state_dict(best_solution_weights)
predictions = model(data_inputs)
print(<span class="hljs-string">"Predictions : n"</span>, predictions.detach().numpy())

abs_error = loss_function(predictions, data_outputs)
print(<span class="hljs-string">"Absolute Error : "</span>, abs_error.detach().numpy())
</pre>



<p><strong>下图是调用</strong> <strong> plot_result() </strong> <strong>方法的结果。</strong>显示适应值逐代变化。</p>





<p>下面是代码中打印语句的输出。平均汇率为0.0069。</p>



<pre class="hljs">Fitness value of the best solution = <span class="hljs-number">145.42425295191546</span>
Index of the best solution : <span class="hljs-number">0</span>
Predictions :
Predictions :
[[<span class="hljs-number">0.08401088</span>]
 [<span class="hljs-number">0.60939324</span>]
 [<span class="hljs-number">1.3010881</span> ]
 [<span class="hljs-number">2.5010352</span> ]]
Absolute Error :  <span class="hljs-number">0.006876422</span>
</pre>



<h3 id="example-classification"><strong>使用CNN分类</strong></h3>



<p>接下来的代码使用PyTorch构建了一个卷积神经网络(CNN ),用于对80幅图像的数据集进行分类，其中每幅图像的大小为100x100x3。在这个例子中使用了交叉熵损失，因为有两个以上的类。</p>



<p>可以从以下链接下载培训数据:</p>



<ol>
<li><a href="https://web.archive.org/web/20230131180157/https://github.com/ahmedfgad/NumPyCNN/blob/master/dataset_inputs.npy" target="_blank" rel="noreferrer noopener nofollow"> dataset_inputs.npy </a></li>



<li><a href="https://web.archive.org/web/20230131180157/https://github.com/ahmedfgad/NumPyCNN/blob/master/dataset_outputs.npy" rel="noreferrer noopener nofollow" target="_blank"> dataset_outputs.npy </a></li>
</ol>



<pre class="hljs"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torchga
<span class="hljs-keyword">import</span> pygad
<span class="hljs-keyword">import</span> numpy

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fitness_func</span><span class="hljs-params">(solution, sol_idx)</span>:</span>
    <span class="hljs-keyword">global</span> data_inputs, data_outputs, torch_ga, model, loss_function

    model_weights_dict = torchga.model_weights_as_dict(model=model,
                                                       weights_vector=solution)

    model.load_state_dict(model_weights_dict)

    predictions = model(data_inputs)

    solution_fitness = <span class="hljs-number">1.0</span> / (loss_function(predictions, data_outputs).detach().numpy() + <span class="hljs-number">0.00000001</span>)

    <span class="hljs-keyword">return</span> solution_fitness

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">callback_generation</span><span class="hljs-params">(ga_instance)</span>:</span>
    print(<span class="hljs-string">"Generation = {generation}"</span>.format(generation=ga_instance.generations_completed))
    print(<span class="hljs-string">"Fitness    = {fitness}"</span>.format(fitness=ga_instance.best_solution()[<span class="hljs-number">1</span>]))


input_layer = torch.nn.Conv2d(in_channels=<span class="hljs-number">3</span>, out_channels=<span class="hljs-number">5</span>, kernel_size=<span class="hljs-number">7</span>)
relu_layer1 = torch.nn.ReLU()
max_pool1 = torch.nn.MaxPool2d(kernel_size=<span class="hljs-number">5</span>, stride=<span class="hljs-number">5</span>)

conv_layer2 = torch.nn.Conv2d(in_channels=<span class="hljs-number">5</span>, out_channels=<span class="hljs-number">3</span>, kernel_size=<span class="hljs-number">3</span>)
relu_layer2 = torch.nn.ReLU()

flatten_layer1 = torch.nn.Flatten()

dense_layer1 = torch.nn.Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">15</span>)
relu_layer3 = torch.nn.ReLU()

dense_layer2 = torch.nn.Linear(in_features=<span class="hljs-number">15</span>, out_features=<span class="hljs-number">4</span>)
output_layer = torch.nn.Softmax(<span class="hljs-number">1</span>)

model = torch.nn.Sequential(input_layer,
                            relu_layer1,
                            max_pool1,
                            conv_layer2,
                            relu_layer2,
                            flatten_layer1,
                            dense_layer1,
                            relu_layer3,
                            dense_layer2,
                            output_layer)


torch_ga = torchga.TorchGA(model=model,
                           num_solutions=<span class="hljs-number">10</span>)

loss_function = torch.nn.CrossEntropyLoss()


data_inputs = torch.from_numpy(numpy.load(<span class="hljs-string">"dataset_inputs.npy"</span>)).float()
data_inputs = data_inputs.reshape((data_inputs.shape[<span class="hljs-number">0</span>], data_inputs.shape[<span class="hljs-number">3</span>], data_inputs.shape[<span class="hljs-number">1</span>], data_inputs.shape[<span class="hljs-number">2</span>]))


data_outputs = torch.from_numpy(numpy.load(<span class="hljs-string">"dataset_outputs.npy"</span>)).long()


num_generations = <span class="hljs-number">200</span> 
num_parents_mating = <span class="hljs-number">5</span> 
initial_population = torch_ga.population_weights 
parent_selection_type = <span class="hljs-string">"sss"</span> 
crossover_type = <span class="hljs-string">"single_point"</span> 
mutation_type = <span class="hljs-string">"random"</span> 
mutation_percent_genes = <span class="hljs-number">10</span> 
keep_parents = <span class="hljs-number">-1</span> 


ga_instance = pygad.GA(num_generations=num_generations,
                       num_parents_mating=num_parents_mating,
                       initial_population=initial_population,
                       fitness_func=fitness_func,
                       parent_selection_type=parent_selection_type,
                       crossover_type=crossover_type,
                       mutation_type=mutation_type,
                       mutation_percent_genes=mutation_percent_genes,
                       keep_parents=keep_parents,
                       on_generation=callback_generation)


ga_instance.run()


ga_instance.plot_result(title=<span class="hljs-string">"PyGAD &amp; PyTorch - Iteration vs. Fitness"</span>, linewidth=<span class="hljs-number">4</span>)


solution, solution_fitness, solution_idx = ga_instance.best_solution()
print(<span class="hljs-string">"Fitness value of the best solution = {solution_fitness}"</span>.format(solution_fitness=solution_fitness))
print(<span class="hljs-string">"Index of the best solution : {solution_idx}"</span>.format(solution_idx=solution_idx))


best_solution_weights = torchga.model_weights_as_dict(model=model,
                                                      weights_vector=solution)
model.load_state_dict(best_solution_weights)
predictions = model(data_inputs)



print(<span class="hljs-string">"Crossentropy : "</span>, loss_function(predictions, data_outputs).detach().numpy())


accuracy = torch.sum(torch.max(predictions, axis=<span class="hljs-number">1</span>).indices == data_outputs) / len(data_outputs)
print(<span class="hljs-string">"Accuracy : "</span>, accuracy.detach().numpy())
</pre>



<p><strong>下图是调用</strong> <strong> plot_result() </strong> <strong>方法的结果。</strong>显示适应值逐代变化。</p>





<p>以下是一些关于已训练模型的信息。</p>



<pre class="hljs">Fitness value of the best solution = <span class="hljs-number">1.3009520689219258</span>
Index of the best solution : <span class="hljs-number">0</span>
Crossentropy :  <span class="hljs-number">0.7686678</span>
Accuracy :  <span class="hljs-number">0.975</span>
</pre>



<h2 id="h-conclusion">结论</h2>



<p>我们探索了如何使用名为<a href="https://web.archive.org/web/20230131180157/https://pygad.readthedocs.io/" target="_blank" rel="noreferrer noopener nofollow"> PyGAD </a>的Python 3库通过遗传算法训练PyTorch模型。</p>



<p>PyGAD有一个模块<a href="https://web.archive.org/web/20230131180157/https://github.com/ahmedfgad/TorchGA" target="_blank" rel="noreferrer noopener nofollow"> torchga </a>，它帮助将训练PyTorch模型的问题公式化为遗传算法的优化问题。<a href="https://web.archive.org/web/20230131180157/https://github.com/ahmedfgad/TorchGA" target="_blank" rel="noreferrer noopener nofollow"> torchga </a>模块创建PyTorch模型参数的初始群体，其中每个解决方案为模型保存一组不同的参数。使用PyGAD，进化群体中的解。</p>



<p>这是一个研究遗传算法的好方法。尝试一下，试验一下，看看会出现什么！</p>



<p id="separator-block_5074b08b6b1532eaecf36fb86949c3db" class="block-separator block-separator--10"> </p>



<p id="separator-block_5074b08b6b1532eaecf36fb86949c3db" class="block-separator block-separator--10"> </p>
        </div>
        
    </div>    
</body>
</html>