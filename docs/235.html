<html>
<head>
<title>How to Use Google Colab for Deep Learning - Complete Tutorial </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>如何使用Google Colab进行深度学习-完整教程</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/how-to-use-google-colab-for-deep-learning-complete-tutorial#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/how-to-use-google-colab-for-deep-learning-complete-tutorial#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>如果你是一名程序员，你想探索深度学习，需要一个平台来帮助你做到这一点——这篇教程正是为你准备的。</p>



<p>Google Colab是深度学习爱好者的一个很好的平台，它也可以用来测试基本的机器学习模型，获得经验，并开发一种关于深度学习方面的直觉，如超参数调整，预处理数据，模型复杂性，过拟合等等。</p>



<p>让我们一起探索吧！</p>



<h2 id="h-introduction">介绍</h2>



<p>Google的Colaboratory(简称Google Colab)是一个基于Jupyter笔记本的运行时环境，它允许你完全在云上运行代码。</p>



<p>这是必要的，因为这意味着你可以训练大规模的ML和DL模型，即使你没有强大的机器或高速互联网接入。</p>



<p>Google Colab支持GPU和TPU实例，这使得它成为深度学习和数据分析爱好者的完美工具，因为本地机器上的计算限制。</p>



<p>因为Colab笔记本可以通过浏览器从任何机器远程访问，所以它也非常适合商业用途。</p>



<p>在本教程中，您将学习:</p>



<ul>
<li>在Google Colab中四处逛逛</li>



<li>在Colab中安装python库</li>



<li>在Colab中下载大型数据集</li>



<li>在Colab中训练深度学习模型</li>



<li>在Colab中使用TensorBoard</li>
</ul>







<h2 id="h-creating-your-first-ipynb-notebook-in-colab">创造你的第一个。colab中的ipynb笔记本</h2>



<p>打开你选择的浏览器，进入<a href="https://web.archive.org/web/20230308085238/http://colab.research.google.com/" target="_blank" rel="noreferrer noopener nofollow">colab.research.google.com</a>，使用你的谷歌账户登录。单击一个新的笔记本来创建一个新的运行时实例。</p>





<p>在左上角，你可以通过点击将笔记本的名称从“Untitled.ipynb”更改为你选择的名称。</p>



<p>单元执行块是您键入代码的地方。若要执行单元格，请按shift + enter。</p>



<p>在一个单元格中声明的变量可以作为全局变量在其他单元格中使用。如果明确声明，环境会自动在代码块的最后一行打印变量值。</p>



<h2 id="h-training-a-sample-tensorflow-model">训练样本张量流模型</h2>



<p>在Colab中训练一个机器学习模型是非常容易的。它最大的好处是不必建立一个定制的运行时环境，这一切都是为您处理的。</p>







<p>例如，让我们看看训练一个基本的深度学习模型来识别在MNIST数据集上训练的手写数字。</p>



<p>数据从标准的Keras数据集档案中加载。该模型非常基本，它将图像分类为数字并识别它们。</p>



<h3><strong>设置:</strong></h3>



<pre class="hljs">
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf


mnist = tf.keras.datasets.mnist

(x_train,y_train), (x_test,y_test) = mnist.load_data()
x_train, x_test = x_train / <span class="hljs-number">255.0</span>, x_test / <span class="hljs-number">255.0</span>
</pre>



<p>该代码片段的输出如下所示:</p>



<pre class="hljs">Downloading data <span class="hljs-keyword">from</span> https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
<span class="hljs-number">11493376</span>/<span class="hljs-number">11490434</span> [==============================] - <span class="hljs-number">0</span>s <span class="hljs-number">0</span>us/step
</pre>



<p><strong>接下来，我们使用Python定义Google Colab模型:</strong></p>



<pre class="hljs">
model = tf.keras.models.Sequential([
                               tf.keras.layers.Flatten(input_shape=(<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)),
                                   tf.keras.layers.Dense(<span class="hljs-number">128</span>,activation=<span class="hljs-string">'relu'</span>),
                                   tf.keras.layers.Dropout(<span class="hljs-number">0.2</span>),
                                   tf.keras.layers.Dense(<span class="hljs-number">10</span>)
])


loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-keyword">True</span>)


model.compile(optimizer=<span class="hljs-string">'adam'</span>,
             loss=loss_fn,
             metrics=[<span class="hljs-string">'accuracy'</span>])


model.fit(x_train,y_train,epochs=<span class="hljs-number">5</span>)
</pre>



<p>执行上述代码片段的预期输出是:</p>



<pre class="hljs">Epoch <span class="hljs-number">1</span>/<span class="hljs-number">5</span>
<span class="hljs-number">1875</span>/<span class="hljs-number">1875</span> [==============================] - <span class="hljs-number">3</span>s <span class="hljs-number">2</span>ms/step - loss: <span class="hljs-number">0.3006</span> - accuracy: <span class="hljs-number">0.9125</span>
Epoch <span class="hljs-number">2</span>/<span class="hljs-number">5</span>
<span class="hljs-number">1875</span>/<span class="hljs-number">1875</span> [==============================] - <span class="hljs-number">3</span>s <span class="hljs-number">2</span>ms/step - loss: <span class="hljs-number">0.1461</span> - accuracy: <span class="hljs-number">0.9570</span>
Epoch <span class="hljs-number">3</span>/<span class="hljs-number">5</span>
<span class="hljs-number">1875</span>/<span class="hljs-number">1875</span> [==============================] - <span class="hljs-number">3</span>s <span class="hljs-number">2</span>ms/step - loss: <span class="hljs-number">0.1098</span> - accuracy: <span class="hljs-number">0.9673</span>
Epoch <span class="hljs-number">4</span>/<span class="hljs-number">5</span>
<span class="hljs-number">1875</span>/<span class="hljs-number">1875</span> [==============================] - <span class="hljs-number">3</span>s <span class="hljs-number">2</span>ms/step - loss: <span class="hljs-number">0.0887</span> - accuracy: <span class="hljs-number">0.9729</span>
Epoch <span class="hljs-number">5</span>/<span class="hljs-number">5</span>
<span class="hljs-number">1875</span>/<span class="hljs-number">1875</span> [==============================] - <span class="hljs-number">3</span>s <span class="hljs-number">2</span>ms/step - loss: <span class="hljs-number">0.0763</span> - accuracy: <span class="hljs-number">0.9754</span>
&lt;tensorflow.python.keras.callbacks.History at <span class="hljs-number">0x7f2abd968fd0</span>&gt;
</pre>



<pre class="hljs">
model.evaluate(x_test,y_test,verbose=<span class="hljs-number">2</span>)
</pre>



<p>预期产出:</p>



<pre class="hljs"><span class="hljs-number">313</span>/<span class="hljs-number">313</span> - <span class="hljs-number">0</span>s - loss: <span class="hljs-number">0.0786</span> - accuracy: <span class="hljs-number">0.9761</span>
[<span class="hljs-number">0.07860152423381805</span>, <span class="hljs-number">0.9761000275611877</span>]
</pre>



<pre class="hljs">
probability_model = tf.keras.Sequential([
                                        model,
                                        tf.keras.layers.Softmax()])
</pre>



<h2 id="h-installing-packages-in-google-colab">在Google Colab中安装软件包</h2>



<p>您不仅可以使用Colab中的code单元运行Python代码，还可以运行shell命令。随便加个<strong>！</strong>前一个命令。感叹号告诉笔记本单元将下面的命令作为shell命令运行。</p>



<p>深度学习所需的大多数通用包都是预装的。在某些情况下，您可能需要不太流行的库，或者您可能需要在不同版本的库上运行代码。为此，您需要手动安装软件包。</p>



<p>用于安装包的包管理器是pip。</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/dfbe364c31f002c4a0e0a594e3b1ee75.png" alt="import tensorflow" class="wp-image-33559" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230308085238im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/import-tensorflow.png?ssl=1"/></figure>



<p>要安装TensorFlow的特定版本，请使用以下命令:</p>



<pre class="hljs">!pip3 install tensorflow==<span class="hljs-number">1.5</span><span class="hljs-number">.0</span>
</pre>



<p>运行以上命令后，预期会有以下输出:</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/0dd0feaca91cfdbf0992d860a4910c1c.png" alt="tensorflow install output" class="wp-image-33561" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230308085238im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/tensorflow-install-output.png?ssl=1"/></figure>



<p>点击<strong>重启运行时间</strong>，使用新安装的版本。</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/0c525694b21f4da5ab2c8e4db17221a4.png" alt="tf version" class="wp-image-33563" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230308085238im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/tf-version.png?ssl=1"/></figure>



<p>正如你在上面看到的，我们将Tensorflow版本从“2.3.0”更改为“1.5.0”。</p>



<p>对于我们上面训练的模型，测试精度大约为97%。一点也不差，但这是一个简单的问题。</p>



<p>训练模型通常不是那么容易，我们经常不得不从像Kaggle这样的第三方来源下载数据集。</p>



<p>因此，让我们看看当我们没有直接链接时，如何下载数据集。</p>



<p id="separator-block_d79e2fc83c4acf876099256773018cf9" class="block-separator block-separator--5">下载数据集</p>



<h2 id="h-downloading-a-dataset">当您在本地机器上训练机器学习模型时，您可能会遇到下载和存储训练模型所需的数据集所带来的存储和带宽成本问题。</h2>



<p>深度学习数据集的规模可能非常大，从20到50 Gb不等。如果你生活在发展中国家，下载它们是最具挑战性的，因为那里不可能有高速互联网。</p>



<p>使用数据集最有效的方式是使用云接口下载它们，而不是从本地机器手动上传数据集。</p>



<p>令人欣慰的是，Colab为我们提供了多种从通用数据托管平台下载数据集的方法。</p>



<p> </p>



<p id="separator-block_d79e2fc83c4acf876099256773018cf9" class="block-separator block-separator--5"><strong>从Kaggle下载数据集</strong></p>



<h3>要从Kaggle下载现有数据集，我们可以遵循以下步骤:</h3>



<p>进入你的Kaggle账户，点击“创建新的API令牌”。这将下载一个kaggle.json文件到你的机器上。</p>



<ol>
<li>转到您的Google Colab项目文件，并运行以下命令:</li>



<li> </li>
</ol>



<pre class="hljs">! pip install -q kaggle
<span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> files


files.upload()
! mkdir ~/.kaggle


cp kaggle.json ~/.kaggle/


! chmod <span class="hljs-number">600</span> ~/.kaggle/kaggle.json


! kaggle competitions download -c <span class="hljs-string">'name-of-competition'</span>
</pre>



<p id="separator-block_d79e2fc83c4acf876099256773018cf9" class="block-separator block-separator--5"><strong>从任何通用网站下载数据集</strong></p>



<h3>根据您使用的浏览器，有一些扩展可以将数据集下载链接转换为“curl”或“wget”格式。您可以使用它来有效地下载数据集。</h3>



<p>对于Firefox，有一个cliget浏览器扩展:<a href="https://web.archive.org/web/20230308085238/https://addons.mozilla.org/en-US/firefox/addon/cliget/" target="_blank" rel="noreferrer noopener nofollow">CLI Get–为Firefox (en-US)获取这个扩展</a></p>



<ol>
<li>对于Chrome，有一个curlget扩展:<a href="https://web.archive.org/web/20230308085238/https://chrome.google.com/webstore/detail/curlwget/dgcfkhmmpcmkikfmonjcalnjcmjcjjdn?hl=en" target="_blank" rel="noreferrer noopener nofollow"> Ad增加了curlget 52</a></li>



<li>只要你点击浏览器中的任何下载按钮，这些扩展就会生成一个curl/wget命令。</li>
</ol>



<p>然后，您可以复制该命令，并在您的Colab笔记本中执行它，以下载数据集。</p>



<p><strong> <em>注</em> </strong> <em>:默认情况下，Colab笔记本使用Python shell。要在Colab中运行终端命令，您必须使用"</em> <strong> <em>！</em> </strong> <em>”命令的开始。</em></p>



<p>例如，要从some.url下载文件并将其保存为some.file，可以在Colab中使用以下命令:</p>



<p><strong> <em>注</em></strong><em>:curl命令会在Colab工作区下载数据集，每次运行时断开连接都会丢失。因此，一个安全的做法是，一旦数据集下载完成，就将数据集移动到您的云驱动器中。</em></p>



<pre class="hljs">!curl http://some.url --output some.file
</pre>



<p><strong>从GCP或Google Drive下载数据集</strong></p>



<h3>谷歌云平台是一个云计算和存储平台。您可以使用它来存储大型数据集，并且可以将该数据集直接从云中导入到Colab中。</h3>



<p>要在GCP上传和下载文件，首先你需要验证你的谷歌账户。</p>



<p>它会要求你使用你的谷歌账户访问一个链接，并给你一个认证密钥。将密钥粘贴到提供的空白处，以验证您的帐户。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> auth
auth.authenticate_user()
</pre>



<p>之后安装gsutil上传下载文件，然后初始化gcloud。</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/b64f11a8e2c6745614c2e17d27083ce0.png" alt="google colab auth" class="wp-image-33567" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230308085238im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/google-colab-auth.png?ssl=1"/></figure>



<p>这样做将要求您从基本设置的某些选项中进行选择:</p>



<pre class="hljs">!curl https://sdk.cloud.google.com | bash
!gcloud init
</pre>



<p>一旦您配置了这些选项，您就可以使用以下命令从Google云存储中下载/上传文件。</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/3262ebf8e17435023d06656d03d69ead.png" alt="gcloud init" class="wp-image-33570" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230308085238im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/gcloud-init.png?ssl=1"/></figure>



<p>要将文件从云存储下载到Google Colab，请使用:</p>



<p>要将文件从Google Colab上传到云，请使用:</p>



<pre class="hljs">!gsutil cp gs://maskaravivek-data/data_file.csv
</pre>



<p>在启用GPU/TPU的情况下启动运行时</p>



<pre class="hljs">gsutil cp test.csv gs://maskaravivek-data/
</pre>



<h2 id="h-initiating-a-runtime-with-gpu-tpu-enabled">深度学习是一个计算量很大的过程，需要同时执行大量计算来训练一个模型。为了缓解这个问题，Google Colab不仅为我们提供了经典的CPU运行时，还提供了GPU和TPU运行时的选项。</h2>



<p>CPU运行时最适合训练大型模型，因为它提供了高内存。</p>



<p>GPU运行时对于不规则计算，如小批量和非大型计算，表现出更好的灵活性和可编程性。</p>



<p>TPU运行时针对大批量和CNN进行了高度优化，具有最高的训练吞吐量。</p>



<p>如果你有一个较小的模型要训练，我建议在GPU/TPU运行时上训练模型，以充分发挥Colab的潜力。</p>



<p>要创建支持GPU/TPU的运行时，您可以在文件名下方的工具栏菜单中单击运行时。从那里，点击“<strong>更改运行时类型</strong>”，然后在硬件加速器下拉菜单下选择GPU或TPU。</p>



<p>请注意，Google Colab的免费版本并不保证GPU/TPU支持的运行时的持续可用性。如果使用时间过长，您的会话可能会被终止！</p>







<p>你可以购买Colab Pro(如果你在美国或加拿大，目前只能在这些国家购买)。每月10美元，不仅提供更快的GPU，还提供更长的会话。前往<a href="https://web.archive.org/web/20230308085238/https://colab.research.google.com/signup" target="_blank" rel="noreferrer noopener nofollow">此链接</a> <a href="https://web.archive.org/web/20230308085238/https://colab.research.google.com/signup">。</a></p>



<p>训练更复杂和更大的模型</p>



<h2 id="h-training-more-complex-and-larger-models">为了训练复杂的模型，通常需要加载大型数据集。建议使用mount drive方法直接从Google Drive加载数据。</h2>



<p>这将把所有数据从您的驱动器导入运行时实例。首先，您需要安装存储数据集的Google Drive。</p>



<p>您还可以使用Colab中的默认存储，并将数据集从GCS或Kaggle直接下载到Colab。</p>



<p><strong>安装驱动器</strong></p>



<h3>Google Colab允许您从Google Drive帐户导入数据，以便您可以从Google Drive访问训练数据，并使用大型数据集进行训练。</h3>



<p>有两种方法可以在Colab中挂载驱动器:</p>



<p>使用GUI</p>



<ul>
<li>使用代码片段</li>



<li><strong> 1。使用GUI </strong></li>
</ul>



<p>点击屏幕左侧的文件图标，然后点击“安装驱动器”图标来安装您的谷歌驱动器。</p>



<p><strong> 2。使用代码片段</strong></p>





<p>执行以下代码块在Colab上安装您的Google Drive:</p>



<p>单击链接，复制代码，并将其粘贴到提供的框中。按enter键安装驱动器。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive
drive.mount(<span class="hljs-string">'/content/drive'</span>)
</pre>



<p>接下来，我们将训练一个卷积神经网络(CNN)来识别手写数字。这是在一个基本数据集和一个原始模型上训练的，但现在我们将使用一个更复杂的模型。</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/54d0dfce834d6362fa2679edc1a318fa.png" alt="Google colab code" class="wp-image-33583" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230308085238im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Google-colab-code.png?ssl=1"/></figure>



<p><strong>用Keras训练模型</strong></p>



<h3>Keras是用Python写的API，它运行在Tensorflow之上。它用于快速原型实验模型和评估性能。</h3>



<p>与Tensorflow相比，在Keras中部署模型非常容易。这里有一个例子:</p>



<p>一旦这个单元被执行，您将会看到类似如下的输出:</p>



<pre class="hljs">
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

<span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive
drive.mount(<span class="hljs-string">'/content/drive'</span>)


cd drive/My Drive/


data = pd.read_csv(<span class="hljs-string">'train.csv'</span>)


train = data.iloc[<span class="hljs-number">0</span>:<span class="hljs-number">40000</span>,:] 
train_X = train.drop(<span class="hljs-string">'label'</span>,axis=<span class="hljs-number">1</span>)
train_Y = train.iloc[:,<span class="hljs-number">0</span>]

val = data.iloc[<span class="hljs-number">40000</span>:,:]    
val_X = val.drop(<span class="hljs-string">'label'</span>,axis=<span class="hljs-number">1</span>)
val_Y = val.iloc[:,<span class="hljs-number">0</span>]

train_X = train_X.to_numpy() 
train_Y = train_Y.to_numpy()
val_X = val_X.to_numpy()

val_Y = val_Y.to_numpy()
train_X = train_X/<span class="hljs-number">255.</span>    
val_X = val_X/<span class="hljs-number">255.</span>

train_X = np.reshape(train_X,(<span class="hljs-number">40000</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>,<span class="hljs-number">1</span>)) 
val_X = np.reshape(val_X,(<span class="hljs-number">2000</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>,<span class="hljs-number">1</span>))


model = keras.Sequential([
   keras.layers.Conv2D(<span class="hljs-number">32</span>,(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),activation=<span class="hljs-string">'relu'</span>,input_shape=(<span class="hljs-number">28</span>,<span class="hljs-number">28</span>,<span class="hljs-number">1</span>)),
   keras.layers.MaxPooling2D((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)),
   keras.layers.Conv2D(<span class="hljs-number">64</span>,(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),activation=<span class="hljs-string">'relu'</span>),
   keras.layers.MaxPooling2D((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)),
   keras.layers.Conv2D(<span class="hljs-number">64</span>,(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),activation=<span class="hljs-string">'relu'</span>),
   keras.layers.Flatten(),
   
   keras.layers.Dense(<span class="hljs-number">64</span>,activation=<span class="hljs-string">'relu'</span>),
   
   keras.layers.Dense(<span class="hljs-number">10</span>)
])


model.compile(optimizer=<span class="hljs-string">'adam'</span>,
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-keyword">True</span>),
            metrics=[<span class="hljs-string">'accuracy'</span>])


model.fit(train_X,train_Y,epochs=<span class="hljs-number">10</span>,validation_data=(val_X, val_Y))
</pre>



<p>预期产出:</p>



<pre class="hljs">Epoch <span class="hljs-number">1</span>/<span class="hljs-number">10</span>
<span class="hljs-number">1250</span>/<span class="hljs-number">1250</span> [==============================] - <span class="hljs-number">37</span>s <span class="hljs-number">30</span>ms/step - loss: <span class="hljs-number">0.1817</span> - accuracy: <span class="hljs-number">0.9433</span> - val_loss: <span class="hljs-number">0.0627</span> - val_accuracy: <span class="hljs-number">0.9770</span>
Epoch <span class="hljs-number">2</span>/<span class="hljs-number">10</span>
<span class="hljs-number">1250</span>/<span class="hljs-number">1250</span> [==============================] - <span class="hljs-number">36</span>s <span class="hljs-number">29</span>ms/step - loss: <span class="hljs-number">0.0537</span> - accuracy: <span class="hljs-number">0.9838</span> - val_loss: <span class="hljs-number">0.0471</span> - val_accuracy: <span class="hljs-number">0.9850</span>
Epoch <span class="hljs-number">3</span>/<span class="hljs-number">10</span>
<span class="hljs-number">1250</span>/<span class="hljs-number">1250</span> [==============================] - <span class="hljs-number">36</span>s <span class="hljs-number">29</span>ms/step - loss: <span class="hljs-number">0.0384</span> - accuracy: <span class="hljs-number">0.9883</span> - val_loss: <span class="hljs-number">0.0390</span> - val_accuracy: <span class="hljs-number">0.9875</span>
...
<span class="hljs-number">1250</span>/<span class="hljs-number">1250</span> [==============================] - <span class="hljs-number">36</span>s <span class="hljs-number">29</span>ms/step - loss: <span class="hljs-number">0.0114</span> - accuracy: <span class="hljs-number">0.9963</span> - val_loss: <span class="hljs-number">0.0475</span> - val_accuracy: <span class="hljs-number">0.9880</span>
Epoch <span class="hljs-number">10</span>/<span class="hljs-number">10</span>
<span class="hljs-number">1250</span>/<span class="hljs-number">1250</span> [==============================] - <span class="hljs-number">36</span>s <span class="hljs-number">29</span>ms/step - loss: <span class="hljs-number">0.0101</span> - accuracy: <span class="hljs-number">0.9967</span> - val_loss: <span class="hljs-number">0.0982</span> - val_accuracy: <span class="hljs-number">0.9735</span>
</pre>



<pre class="hljs">
test_loss, test_acc = model.evaluate(val_X,val_Y,verbose=<span class="hljs-number">2</span>)
Expected output:
<span class="hljs-number">63</span>/<span class="hljs-number">63</span> - <span class="hljs-number">1</span>s - loss: <span class="hljs-number">0.0982</span> - accuracy: <span class="hljs-number">0.9735</span>



predict_model = tf.keras.Sequential([
   model,tf.keras.layers.Softmax()
])


test_image = val_X[<span class="hljs-number">140</span>]
test_image = np.reshape(test_image,(<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>,<span class="hljs-number">1</span>))
result = predict_model.predict(test_image)
print(np.argmax(result))
plt.imshow(val_X[<span class="hljs-number">140</span>].reshape(<span class="hljs-number">28</span>,<span class="hljs-number">28</span>))
plt.show()
</pre>



<p><strong>使用FastAI </strong></p>





<h3>FastAI是一个工作在PyTorch之上的高级库。它让你用很少几行代码来定义。它用于通过遵循自上而下的方法来学习深度学习的基础知识，即首先我们编码并查看结果，然后研究其背后的理论。</h3>



<p>这里可以看到FastAI在Colab上的一个示例实现<a href="https://web.archive.org/web/20230308085238/https://course.fast.ai/start_colab" target="_blank" rel="noreferrer noopener nofollow">。</a></p>



<p>如何使用<a href="https://web.archive.org/web/20230308085238/https://docs.neptune.ai/integrations-and-supported-tools/model-training/tensorflow-keras" target="_blank" rel="noreferrer noopener"> Neptune-Keras integration </a>或<a href="https://web.archive.org/web/20230308085238/https://docs.neptune.ai/integrations-and-supported-tools/model-training/fastai" target="_blank" rel="noreferrer noopener">Neptune-fastai integration</a>跟踪模型训练元数据。</p>



<section id="blog-intext-cta-block_45f7a2d0dfcbdb7e50cfb9d7a2c0b94c" class="block-blog-intext-cta  c-box c-box--default c-box--dark c-box--no-hover c-box--standard ">

            
    
            <p>Google Colab中的TensorBoard</p>
    
    </section>



<h2 id="h-tensorboard-in-google-colab">TensorBoard是Tensorflow提供的用于可视化机器学习相关数据的工具包。</h2>



<p>它通常用于绘制度量标准，例如迭代次数的损失和准确性。它还可以用于可视化和总结模型，并显示图像、文本和音频数据。</p>



<p><strong>使用张量板的监测数据</strong></p>



<h3>要使用TensorBoard，需要导入一些必要的库。运行以下代码片段来导入这些库:</h3>



<p>在我们开始可视化数据之前，我们需要在model.fit()中做一些更改:</p>



<pre class="hljs">
%load_ext tensorboard
<span class="hljs-keyword">import</span> datetime, os
</pre>



<p>训练结束后，您可以启动TensorBoard工具包来查看模型的表现:</p>



<pre class="hljs">logdir = os.path.join(<span class="hljs-string">"logs"</span>, datetime.datetime.now().strftime(<span class="hljs-string">"%Y%m%d-%H%M%S"</span>))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=<span class="hljs-number">1</span>)

model.fit(x=x_train,y=y_train,epochs=<span class="hljs-number">5</span>,validation_data=(x_test, y_test),callbacks=[tensorboard_callback])
</pre>



<p>它给出了精度和损失如何随运行的时期数而变化的信息。</p>



<pre class="hljs">%tensorboard --logdir logs</pre>





<p>保存和加载模型</p>







<h2 id="h-saving-and-loading-models">训练模型需要花费大量时间，因此能够保存训练好的模型以便反复使用将是明智的。每次都训练它会非常令人沮丧和耗时。Google Colab允许您保存模型并加载它们。</h2>



<p><strong>保存和加载模型重量</strong></p>



<h3>训练DL模型的基本目的是以正确预测输出的方式调整权重。仅保存模型的权重，并在需要时加载它们是有意义的。</h3>



<p>要手动保存重量，请使用:</p>



<p>要在模型中加载权重，请使用:</p>



<pre class="hljs"> model.save_weights(<span class="hljs-string">'./checkpoints/my_checkpoint'</span>)
</pre>



<p><strong>保存并加载整个模型</strong></p>



<pre class="hljs">model.load_weights(<span class="hljs-string">'./checkpoints/my_checkpoint'</span></pre>



<h3>有时候，最好保存整个模型，这样可以省去定义模型、处理输入维度和其他复杂性的麻烦。您可以保存整个模型并将其导出到其他机器。</h3>



<p>要保存整个模型，请使用:</p>



<p>要加载已保存的模型，请使用:</p>



<pre class="hljs">
model.save(<span class="hljs-string">'saved_model/my_model'</span></pre>



<p>结论</p>



<pre class="hljs">new_model = tf.keras.models.load_model(<span class="hljs-string">'saved_model/my_model'</span>)
</pre>



<h2 id="h-conclusion">现在你看到Google Colab是一个很好的工具，可以原型化和测试深度学习模型。</h2>



<p>凭借其免费的GPU和从Google Drive导入数据的能力，Colab脱颖而出，成为在计算和存储有限的低端机器上训练模型的非常有效的平台。</p>



<p>它还管理Google Drive中的笔记本，为希望一起从事同一项目的程序员提供一个稳定而有组织的数据管理系统。</p>



<p>感谢阅读！</p>



<p>Thanks for reading!</p>
        </div>
        
    </div>    
</body>
</html>