# 利用机器学习项目改善工作流程的最佳 7 种数据版本控制工具

> 原文：<https://web.archive.org/web/https://neptune.ai/blog/best-data-version-control-tools>

跟踪所有用于模型和实验的数据并不容易。这需要很多时间，而且不仅仅是管理和跟踪文件。你需要确保每个人都在同一个页面上，并同时跟踪最新版本的变化。

使用正确的软件，你可以毫不费力地做到这一点！一个好的数据版本控制工具可以让你拥有一个统一的数据集和一个强大的实验库。

它还将实现所有团队成员之间的顺畅协作，因此每个人都可以实时跟踪变化，并始终知道发生了什么。

这是系统化数据版本控制、改进工作流程和最小化出错风险的好方法。

因此，请查看这些用于数据版本控制的顶级工具，它们可以帮助您实现工作自动化并优化流程。

如果您关心可再现性、可追溯性和 ML 模型血统，那么数据版本化工具对您的工作流程至关重要。

它们帮助您获得一个工件的版本，一个数据集或模型的散列，您可以在以后使用它来识别和比较。通常，您会将此数据版本记录到您的元数据管理解决方案中，以确保您的模型训练是版本化的和可重复的。

要为您的工作流选择合适的数据版本化工具，您应该检查:

*   **支持您的数据形态**:它是如何支持视频/音频的？它是否为表格数据提供了一些预览？
*   易用性:在你的工作流程中使用起来有多容易？它给你的执行增加了多少开销？
*   **Diff and compare** :可以比较数据集吗？你能看到你的图像目录的不同吗？
*   **它与您的堆栈配合得如何**:您能否轻松连接到您的基础设施、平台或模型培训工作流？
*   **你能让你的团队参与进来吗**:如果你的团队不采用它，工具再好也没用。所以，记住你的队友的技能和偏好。

这里有一些值得探索的工具。

Neptune 是一个 ML 元数据存储库，为运行许多实验的研究和生产团队而构建。

您可以[记录和显示几乎任何 ML 元数据](https://web.archive.org/web/20230130145948/https://docs.neptune.ai/you-should-know/what-can-you-log-and-display)，从超参数和度量到视频、交互式可视化和**数据版本**。

使用 Neptune 工件，您只需一行代码就可以从本地文件系统或任何 S3 兼容的存储中对数据集、模型和其他文件进行版本控制。具体来说，它可以节省:

*   文件或文件夹的**版本**(哈希)
*   文件或文件夹的**位置**
*   文件夹**结构**(递归)
*   **文件或文件夹的大小**

一旦登录，您可以使用 Neptune UI 对数据集版本进行[分组运行，或者查看](https://web.archive.org/web/20230130145948/https://docs.neptune.ai/how-to-guides/data-versioning/version-datasets)[工件 c](https://web.archive.org/web/20230130145948/https://docs.neptune.ai/how-to-guides/data-versioning/compare-datasets) [如何在运行](https://web.archive.org/web/20230130145948/https://docs.neptune.ai/how-to-guides/data-versioning/compare-datasets)之间挂起。

**说到数据版本控制，Neptune 是一个非常轻量级的解决方案，**您可以很快上手。也就是说，它可能无法满足您在数据版本方面的所有需求。

另一方面，您可以将[实验跟踪](/web/20230130145948/https://neptune.ai/product/experiment-tracking)和[模型注册](/web/20230130145948/https://neptune.ai/product/model-registry)都放在一个地方，并使用[灵活的元数据结构](https://web.archive.org/web/20230130145948/https://docs.neptune.ai/you-should-know/logging-metadata#run-structure-namespaces)以您想要的方式组织培训和生产元数据。它类似于您在代码中创建并显示在 UI 中的字典或文件夹结构。

如果您想知道它是否适合您的工作流程:

Pachyderm 是一个完整的版本控制的数据科学平台，有助于控制端到端的机器学习生命周期。它有三个不同的版本，社区版(开源，可以在任何地方部署)、企业版(完整的版本控制平台)和 Hub 版(托管版，仍处于测试阶段)。

这是一个在任何类型的机器学习项目上进行**灵活协作**的绝佳平台。

**下面是你可以用 Pachyderm 作为数据版本工具做的事情:**

*   Pachyderm 允许您不断更新 repo 主分支中的数据，同时在单独的分支中试验特定的数据提交
*   它支持任何类型、大小和数量的文件，包括二进制和纯文本文件
*   厚皮动物提交是集中式和事务性的
*   出处使团队能够在彼此工作的基础上构建、共享、转换和更新数据集，同时自动维护完整的审计跟踪，以便所有结果都是可重复的

DVC 是一个机器学习项目的开源版本控制系统。这是一个工具，让你定义你的管道，不管你用什么语言。

当您在 ML 模型的先前版本中发现问题时，DVC 通过利用代码数据和管道版本化为您提供再现性来节省您的时间。您还可以训练您的模型，并通过 DVC 管道与您的队友分享。

DVC 可以处理大量数据的版本和组织，并以一种组织良好、易于访问的方式存储它们。它侧重于数据和管道版本化和管理，但也有一些(有限的)实验跟踪功能。

**DVC–摘要:**

*   可以使用不同类型的存储—不受存储限制
*   完整的代码和数据来源有助于跟踪每个 ML 模型的完整发展
*   通过始终如一地维护输入数据、配置和最初用于运行实验的代码的组合来实现可重复性
*   跟踪指标
*   一种将 ML 步骤连接到 DAG 并端到端运行整个管道的内置方式
*   跟踪失败的尝试
*   运行在任何 Git 存储库之上，并与任何标准 Git 服务器或提供商兼容

Git 大文件存储(LFS)是一个开源项目。它**用 Git 中的文本指针替换大文件**，如音频样本、视频、数据集和图形，同时将文件内容存储在远程服务器上，如 GitHub.com 或 GitHub Enterprise。

它允许你用 Git **在你的 Git 存储库中托管更多的****版本的大文件**——甚至是那些大到几个 GB 大小的文件——用 Git，**从处理大文件的存储库中更快地克隆和获取**。

同时，在使用 GitHub 这样的远程主机时，您可以像 Git 存储库的其他部分一样，保留您的工作流以及对大文件的访问控制和权限。

Dolt 是一个 SQL 数据库，您可以像 git 存储库一样*派生、克隆、分支、合并、推送和拉取*。Dolt 允许数据和模式一起进化，以**使版本控制数据库成为更好的体验**。这是与您的团队合作的一个很好的工具。

您可以自由地连接到 Dolt，就像连接到任何 MySQL 数据库一样，使用 SQL 命令运行查询或更新数据。

使用命令行界面导入 CSV 文件，提交您的更改，将它们推送到远程，或合并您队友的更改。

你所知道的所有 Git 命令对 Dolt 都是一样的。Git 版本文件，Dolt 版本表。

还有[**DoltHub**](https://web.archive.org/web/20230130145948/https://www.dolthub.com/)——一个分享 Dolt 数据库的地方。

lakeFS 是一个开源平台，它提供了一个类似 Git 的分支和提交模型，通过利用 S3 或 GCS 进行存储，该模型可以扩展到数 Pb 的数据。

这种分支模型使您的数据湖符合 ACID，因为它允许在独立的分支中发生变化，这些分支可以被自动地、即时地创建、合并和回滚。

lakeFS 有三个主要区域，让您关注 ML 模型的不同方面:

1.  **数据开发环境:**提供了一些工具，您可以使用这些工具来隔离湖泊的快照，您可以对这些快照进行实验，而其他快照则不会暴露出来；比较变化和改进实验的再现性
2.  **持续数据集成:**按照自己的规则录入和管理数据
3.  **连续数据部署:**快速恢复数据变化的能力；提供数据集中的一致性；测试生产数据以避免连锁质量问题

lakeFS 是一个很好的工具，可以专注于数据集的特定区域，使 ML 实验更加一致。

Delta Lake 是一个开源存储层，它为数据湖带来了**可靠性。Delta Lake 提供了 ACID 事务、可扩展的元数据处理，并统一了流式和批量数据处理。它运行在您现有的数据湖之上，并且与 Apache Spark APIs 完全兼容。**

**三角洲湖-概要:**

*   **可扩展的元数据处理**:利用 Spark 的分布式处理能力轻松处理数十亿个文件的 Pb 级表的所有元数据。
*   **流和批统一**:Delta Lake 中的一个表是一个批表，也是一个流的源和汇。流式数据接收、批量历史回填、交互式查询都是开箱即用的。
*   **模式实施**:自动处理模式变化，以防止在摄取期间插入不良记录。
*   **可串行化隔离**级别确保读者永远不会看到不一致的数据。
*   **数据版本支持回滚、完整的历史审计跟踪和可重复的机器学习实验**
*   **支持合并、更新、**和删除操作，以支持复杂的用例，如变化数据捕获、渐变维度(SCD)操作、流上插等等。

## 把它包起来

现在您已经有了数据版本控制的最佳工具列表，您“仅仅”需要弄清楚如何让它为您和您的团队工作。

这可能很棘手。

选择数据版本时需要考虑的一些事项包括:

*   **设置**有多简单:你现在可能没有时间、需求或预算来测试一些沉重的东西。
*   **你能让你的团队参与进来吗**:有时候，解决方案很棒，但是你需要更多面向软件工程的心态来使用它。一些 ML 研究人员或数据科学家可能不会最终使用它。
*   **您目前使用的是什么工具组合**:您使用的是与特定数据版本化解决方案良好集成的特定工具、基础设施或平台吗？在这种情况下，可能最好的选择就是这样。
*   **数据形态**:是图像、表格、文本，还是全部？有时该工具并不十分支持您的模态，因为它构建时考虑了不同的用例。

如果您想讨论如何选择它或设置您的 MLOps 堆栈，我很乐意提供帮助。

[联系我](https://web.archive.org/web/20230130145948/mailto:jakub.czakon@neptune.ai)，让我们看看我能做些什么！