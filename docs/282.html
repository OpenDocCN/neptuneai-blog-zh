<html>
<head>
<title>Image Processing Techniques That You Can Use in Machine Learning Projects </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>可以在机器学习项目中使用的图像处理技术</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>图像处理是一种对图像执行操作以从中提取信息或增强图像的方法。数字图像处理有着广泛的应用，如图像恢复、医学成像、遥感、图像分割等。每个过程都需要不同的技术。</p>



<p>在这篇文章中，我们将讨论机器学习的六大图像处理技术。</p>



<ol><li>图像恢复</li><li>线性过滤</li><li>独立成分分析</li><li>像素化</li><li>模板匹配</li><li>图像生成技术</li></ol>







<p id="separator-block_5f86b1c8f3dc2" class="block-separator block-separator--5">1.图像恢复</p>



<h2 id="h-1-image-restoration">图像质量下降的原因有很多，例如，用旧技术相机拍摄的你祖父母的旧图像可能会变得模糊或失去其原始形式。</h2>







<p>如果图像受到一些物理压力，或者如果它是数字形式，它可能会因运动模糊或附加噪声而恶化，这种情况就会发生。</p>



<p>那你打算怎么恢复呢？也许这在50年前是不可能的，但现在——是可能的。</p>



<p><a href="https://web.archive.org/web/20230112125124/http://www.owlnet.rice.edu/~elec539/Projects99/BACH/proj2/intro.html" target="_blank" rel="noreferrer noopener nofollow"> <strong>研究人员想出了一个退化模型</strong> </a> <strong>，可以撤销输入图像上的退化效果。退化模型作为具有线性移位不变量的卷积来工作。</strong></p>



<p>因此，我们用退化滤波器拍摄退化前的图像(称为“真实图像”)和退化后的图像(称为“观察图像”)，退化滤波器<em>估计</em>为“真实图像”。</p>



<p> </p>







<p id="separator-block_5f86b3f1f3dc9" class="block-separator block-separator--5"><strong>使用OpenCV图像修复的图像恢复示例</strong></p>



<h3><a href="https://web.archive.org/web/20230112125124/https://en.wikipedia.org/wiki/Inpainting" target="_blank" rel="noreferrer noopener nofollow">图像赋予</a>又称<strong>“油漆损失赔偿”。</strong>这种技术通常用于从图像中移除不想要的对象，以恢复退化图像的受损部分。</h3>



<p>在上面的代码中，我们有两种类型的图像</p>



<pre class="hljs"><span class="hljs-keyword">import</span> cv2

img = cv2.imread(<span class="hljs-string">'damaged_image.png'</span>)
mask = cv2.imread(<span class="hljs-string">'mask.png'</span>, <span class="hljs-number">0</span>)
dst = cv2.inpaint(img, mask, <span class="hljs-number">3</span>, cv2.INPAINT_NS)

cv2.imwrite(<span class="hljs-string">'restored.png'</span>, dst)</pre>



<p>被损坏的</p>



<ol><li>戴面具的</li><li>被掩蔽的图像具有与噪声图像中存在的噪声相同的空间维度。</li></ol>



<p>所以如果我们用上面的代码输入下面的图像:</p>



<p>带着面具:</p>







<p>然后我们会得到下面的图像:</p>







<p>OpenCV的图像修复最大的问题是，我们需要为我们想要修复的特定图像手动输入一个遮罩。那么，我们怎样才能使这个过程自动化呢？</p>







<p>答案是<strong> GAN(一般对抗性网络)</strong>。这篇<a href="https://web.archive.org/web/20230112125124/https://ieeexplore.ieee.org/document/8686914" target="_blank" rel="noreferrer noopener nofollow">论文</a>提出，通过使用GAN网络，可以使用<strong>邻域损失函数和梯度损失</strong>来进行图像修复，恢复的图像质量更好。</p>



<p>2.线性过滤</p>



<p id="separator-block_5f86b1d1f3dc3" class="block-separator block-separator--5">线性滤波是一个过程，其中输出像素的值是相邻输入像素的线性组合。这个过程是通过一种叫做<strong>卷积的技术来完成的。</strong></p>



<h2 id="h-2-linear-filtering"><strong>卷积是将图像的每个元素添加到其局部邻居的过程，由内核加权。</strong></h2>







<p>我们有一个输入图像和一个带有锚点的内核。在上图中，是H(1，1)。</p>



<p>这个过滤器像一个滑动窗口一样对图像进行卷积。</p>







<p>我们将每个像素乘以相应的核，然后求和。该总和成为输出图像中的新像素。</p>



<p><strong>让我们在OpenCV </strong>的帮助下看看这是怎么回事</p>



<p> </p>



<h3>3.独立成分分析</h3>



<pre class="hljs"><span class="hljs-keyword">import</span> cv2 <span class="hljs-keyword">as</span> cv
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

image = cv.imread(<span class="hljs-string">"pics/goku.jpeg"</span>)

fig, ax = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>))
fig.tight_layout()


ax[<span class="hljs-number">0</span>].imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))
ax[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">'Original Image'</span>)

kernel_sharpening = np.array([[<span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>],
                             [<span class="hljs-number">-1</span>, <span class="hljs-number">9</span>, <span class="hljs-number">-1</span>],
                             [<span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>]])

kernel_sharpening_2 = np.array([[<span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>],
                             [<span class="hljs-number">-1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">-1</span>],
                             [<span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>]])

sharpened = cv.filter2D(image, <span class="hljs-number">-1</span>, kernel_sharpening)
ax[<span class="hljs-number">1</span>].imshow(cv.cvtColor(sharpened, cv.COLOR_BGR2RGB))
ax[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">'Sharpened Kernel Image'</span>)

sharpened_2 = cv.filter2D(image, <span class="hljs-number">-1</span>, kernel_sharpening_2)
ax[<span class="hljs-number">2</span>].imshow(cv.cvtColor(sharpened_2, cv.COLOR_BGR2RGB))
ax[<span class="hljs-number">2</span>].set_title(<span class="hljs-string">'Sharpened Kernel Image 2'</span>)

plt.show()</pre>



<p id="separator-block_5f86b1eaf3dc4" class="block-separator block-separator--5">独立成分分析或简称ICA是一种将多元信号分离成其基本成分的<strong>技术。</strong> ICA有助于从多种成分或信号的混合物中提取所需成分。</p>



<h2 id="h-3-independent-component-analysis">让我解释一下。</h2>







<p>在ICA中，我们<em>“白化”</em>我们的信号。这意味着给定的将被转换，其组件之间的潜在相关性被移除，并且每个组件的方差等于1。</p>



<p><strong>使用sklearn的ICA</strong></p>



<p>输出:</p>



<h3><strong>ICA using sklearn</strong></h3>



<pre class="hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> signal
<span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> FastICA, PCA

n_samples = <span class="hljs-number">2000</span>
time = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">8</span>, n_samples)

s1 = np.sin(<span class="hljs-number">2</span> * time)  
s2 = np.sign(np.sin(<span class="hljs-number">3</span> * time))  
s3 = signal.sawtooth(<span class="hljs-number">2</span> * np.pi * time)  

S = np.c_[s1, s2, s3]
S += <span class="hljs-number">0.2</span> * np.random.normal(size=S.shape)  

S /= S.std(axis=<span class="hljs-number">0</span>)  

A = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0.5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1.0</span>], [<span class="hljs-number">1.5</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>]])  
X = np.dot(S, A.T)  


ica = FastICA(n_components=<span class="hljs-number">3</span>)
S_ = ica.fit_transform(X)  
A_ = ica.mixing_  

plt.figure()

models = [X, S, S_]
names = [<span class="hljs-string">'Observations (mixed signal)'</span>,
         <span class="hljs-string">'True Sources'</span>,
         <span class="hljs-string">'ICA recovered signals'</span>]
colors = [<span class="hljs-string">'red'</span>, <span class="hljs-string">'steelblue'</span>, <span class="hljs-string">'orange'</span>]

<span class="hljs-keyword">for</span> ii, (model, name) <span class="hljs-keyword">in</span> enumerate(zip(models, names), <span class="hljs-number">1</span>):
    plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, ii)
    plt.title(name)
    <span class="hljs-keyword">for</span> sig, color <span class="hljs-keyword">in</span> zip(model.T, colors):
        plt.plot(sig, color=color)

plt.tight_layout()
plt.show()</pre>



<p>4.像素化</p>







<p id="separator-block_5f86b1eff3dc5" class="block-separator block-separator--5">当图像的尺寸被放大到可以观察到单个像素的程度，或者像素被拉伸到超出其原始尺寸的程度时，就会出现像素化。</p>



<h2 id="h-4-pixelation"><strong>使用OpenCV进行像素化</strong></h2>







<p>输入:</p>



<h3>输出:</h3>



<pre class="hljs"><span class="hljs-keyword">import</span> cv2


input = cv2.imread(<span class="hljs-string">'cat.png'</span>)


height, width = input.shape[:<span class="hljs-number">2</span>]


w, h = (<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)


temp = cv2.resize(input, (w, h), interpolation=cv2.INTER_LINEAR)


output = cv2.resize(temp, (width, height), interpolation=cv2.INTER_NEAREST)

cv2.imshow(<span class="hljs-string">'Input'</span>, input)
cv2.imshow(<span class="hljs-string">'Output'</span>, output)

cv2.waitKey(<span class="hljs-number">0</span>)
</pre>



<div class="is-layout-flex wp-container-3 wp-block-columns">
<div class="is-layout-flow wp-block-column">
<p>5.模板匹配</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/253a3bbd896f9954d5e8fd16d449d8d3.png" alt="" class="wp-image-27721" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230112125124im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/image-impainting-3.png?ssl=1"/></figure>
</div>



<div class="is-layout-flow wp-block-column">
<p>模板匹配是一种在<em>较大的</em>图像中搜索并找到<em>模板</em>位置的方法。你可以把它看作是一种非常简单的物体检测方法。</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/140ee1463eea087a52ca42dc10a32546.png" alt="" class="wp-image-27768" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230112125124im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/cat-pixelated.png?ssl=1"/></figure>
</div>
</div>



<p id="separator-block_5f86b1f3f3dc6" class="block-separator block-separator--5">在模板匹配中，我们将<em>模板</em>图像滑动到<em>较大的</em>图像上，就像我们在卷积过程中所做的那样，并找到匹配部分</p>



<h2 id="h-5-template-matching"><strong>使用OpenCV进行模板匹配</strong></h2>







<p>模板:</p>



<p>大图:</p>



<h3>输出:</h3>



<pre class="hljs"><span class="hljs-keyword">import</span> cv2 <span class="hljs-keyword">as</span> cv
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt

img_rgb = cv.imread(<span class="hljs-string">'waldo.jpg'</span>)
img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)
template = cv.imread(<span class="hljs-string">'waldo_temp.jpg'</span>,<span class="hljs-number">0</span>)
w, h = template.shape[::<span class="hljs-number">-1</span>]
res = cv.matchTemplate(img_gray,template,cv.TM_CCOEFF_NORMED)
threshold = <span class="hljs-number">0.8</span>
loc = np.where( res &gt;= threshold)

<span class="hljs-keyword">for</span> pt <span class="hljs-keyword">in</span> zip(*loc[::<span class="hljs-number">-1</span>]):
    cv.rectangle(img_rgb, pt, (pt[<span class="hljs-number">0</span>] + w, pt[<span class="hljs-number">1</span>] + h), (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">255</span>), <span class="hljs-number">2</span>)

cv.imshow(<span class="hljs-string">'img_rgb'</span>, img_rgb)
cv.waitKey(<span class="hljs-number">0</span>)</pre>



<p>6.图像生成技术</p>







<p>在生成对抗网络(GANs)的帮助下，我们可以在图像数据上训练深度学习模型，以生成相同类型的图像数据。</p>







<p>gan是由Ian Goodfellow在2014年发明的，他在论文<a href="https://web.archive.org/web/20230112125124/https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" target="_blank" rel="noreferrer noopener nofollow">生成对抗网络</a>中对此进行了描述。</p>







<p id="separator-block_5f86b1f9f3dc7" class="block-separator block-separator--5"><strong>gan由两种不同的型号组成</strong></p>



<h2 id="h-6-image-generation-technique-gan"><strong>发电机</strong></h2>







<p><strong>鉴别器</strong></p>



<p><strong>发生器</strong>的工作是产生<em>假</em>图像和<strong>鉴别器</strong>试图在<strong>假图像和真实图像</strong>之间进行分类。在训练期间，<strong>生成器</strong>试图通过生成更好的假图像来胜过鉴别器，鉴别器试图改进自身以区分真实图像和假图像。您可以在本文中阅读更多关于<a href="/web/20230112125124/https://neptune.ai/blog/6-gan-architectures" target="_blank" rel="noreferrer noopener"> GAN架构和培训的信息。</a></p>



<p>最后的想法</p>



<ol><li>所以在本文中，我简要解释了任何机器学习项目中最常用的图像处理技术:</li><li>线性过滤</li></ol>



<p>图像恢复</p>



<p id="separator-block_5f86b1fef3dc8" class="block-separator block-separator--5">模板匹配</p>



<h2 id="h-final-thoughts">图像生成技术</h2>



<p>像素化</p>



<ul><li>独立成分分析</li><li>但是选择正确的技术需要经验，经验来自实践。</li><li>所以继续学习。</li><li>Image Generation Technique (GAN)</li><li>Pixelation</li><li>Independent Component Analysis</li></ul>



<p>But choosing the right technique requires experience and experience comes from practice. </p>



<p>So keep learning.</p>


        </div>
        
    </div>    
</body>
</html>