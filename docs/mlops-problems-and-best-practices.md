# MLOps 问题和最佳实践

> 原文：<https://web.archive.org/web/https://neptune.ai/blog/mlops-problems-and-best-practices>

你、我、我们所有人在网上度过的每一分钟都会产生大量的数据。对于商业和科学来说，这是一个不容忽视的机会。随着越来越多的组织采用这些技术，对人工智能和机器学习的宣传不断升温。

用户生成的数据量呈指数级增长。传统的内部部署服务器转变为灵活、可扩展的云。任何产生大量数据的组织都希望利用这些数据，从数据中提取有价值的见解来指导业务决策。

随着数据的增长，我们可以看到许多与数据相关的工作机会。数据科学家、数据分析师、数据工程师、机器学习工程师、人工智能工程师、深度学习工程师，不胜枚举。

最近，业界对一个新角色有很多讨论，这个新角色就是[**m lops 工程师**](/web/20221201165917/https://neptune.ai/blog/mlops-engineer) 。这项工作位于机器学习、DevOps 和数据工程的交叉点。

在我们为普通 MLOps 工程师的问题定义解决方案之前，让我们看看这种专业化如何适应承担不同责任的各种数据科学角色。

## MLOps 工程师的角色和职责

如果你是一个有抱负的专业人士，准备接受一个 [MLOps 工程师](/web/20221201165917/https://neptune.ai/blog/roles-in-ml-team-and-how-they-collaborate)的角色，下面是你做这份工作需要的东西，以及它看起来会是什么样子(粗略地说)。

### MLOps 工程师技能和资格

注意:这些要求相当宽泛，可能不代表任何工作描述。与 MLOps 相关的工作可能来自广泛的行业，并且可能包含这些要求的子集。

1.  具有高度分析学科的学位(学士、硕士或博士)，如统计学、经济学、计算机科学、数学、运筹学等，具有深厚的定量/编程背景。
2.  在端到端管理机器学习项目方面总共有 3-6 年的经验，过去 18 个月专注于 MLOps。
3.  使用自动化监控和警报工具监控构建和生产系统。
4.  具有使用 MLOps 工具的经验，如 ModelDB、Kubeflow、Pachyderm 和数据版本控制(DVC)。
5.  在支持基于 IDE 的模型和 autoML 工具的模型构建和模型部署、[实验跟踪](/web/20221201165917/https://neptune.ai/experiment-tracking)、模型管理、版本跟踪&模型培训(Dataiku、Datarobot、Kubeflow、Kubeflow tfx、MLflow)、模型超参数优化、模型评估和可解释性(SHAP、Tensorboard)方面具有丰富的经验。
6.  机器学习框架知识:TensorFlow，PyTorch，Keras，Scikit-Learn。

### 这些技能让你成为不可抗拒的 MLOps 候选人

1.  集装箱技术经验(Docker，Kubernetes，EKS，ECS)。
2.  拥有与多家云提供商合作的经验(AWS、GCP、Azure 等)。
3.  分布式计算经验。

### MLOps 工程师工作职责

1.  部署和实施 MLOps，特别是实施:
    1.  模型超参数优化
    2.  模型评估和可解释性
    3.  模型训练和自动化再训练
    4.  从入职、运营到退役的工作流建模
    5.  模型版本跟踪和治理
    6.  数据存档和版本管理
    7.  模型和漂移监控
2.  创建和使用基准、指标和监控来衡量和改进服务。
3.  提供最佳实践，执行 POC 以大规模实现自动化和高效的模型操作。
4.  设计和开发可扩展的 MLOps 框架，以支持基于客户需求的模型。
5.  作为销售团队的 MLOps 专家，提供技术设计解决方案以支持 RFP。

MLOps 工程师从项目一开始就与数据科学团队中的数据科学家和数据工程师密切合作。

**让我们继续机器学习项目生命周期**。它有几个阶段，我们将看到 MLOps 工程师是否以及如何参与其中。

## 机器学习项目生命周期

没有一个所有公司都遵循的标准项目生命周期。ML 发展迅速，最佳实践也日新月异。

但还是有一个共同的模式。让我们来看一个简化的 [ML 项目生命周期](/web/20221201165917/https://neptune.ai/blog/life-cycle-of-a-machine-learning-project)来更好地理解 MLOps。

你可以在上图中看到一个机器学习项目的基本部分和职责。我们来分析一下其中的每一部分。

## 1.机器学习

我们简化项目生命周期的第一部分是机器学习。这个阶段有三个部分:

1.  数据采集
2.  商业理解
3.  初始建模

### 数据采集

数据是整个生命周期最重要的东西。在我们可以在项目中做任何事情之前，我们需要收集必要的数据并存储它。

#### 责任

数据工程师是项目这一阶段的主要参与者。他们创建管道来收集来自不同来源的数据，检查数据的一致性和正确性，将其存储在存储库中，等等。

#### 数据采集问题

1.  **数据通常不完整**–*确保收集所有必要的数据。*
2.  **格式问题**–*如果数据以一种格式出现，您可能会在数据格式转换过程中丢失数据*
3.  **数据清理技术**–*当数据工程师用最少的知识清理或执行 ETL 转换时，丢失有价值数据的风险很高。*
4.  **数据接收频率**–*根据数据迭代创建一个管道，否则你可能会丢失数据。*

#### 最佳实践

1.  了解数据的 5 V(容量、速度、多样性、准确性、价值)。
2.  维护失败管道和数据收集的通知。
3.  维护元数据。
4.  在不同的地理位置维护备份。
5.  了解谁负责数据清理和 ETL 操作。

### 商业理解

一旦我们收集了数据并将其转换到我们的存储库中，我们需要了解企业想要用这些数据做什么。几乎所有的数据科学团队成员都将参与这一阶段，因为每个人都应该知道我们在做什么。经理和其他项目涉众将告诉我们他们需要从数据中得到什么。

#### 责任

在这个阶段，每个人都需要理解业务目标并定义一个行动计划。每个团队领导将被分配一部分工作和交付时间表。

#### 商业理解问题

1.  **缺乏明确性**–*团队领导经常不清楚可交付成果的时间表，这会导致不必要的压力和匆忙*
2.  **更少的讨论时间**–*讨论通常很匆忙，许多人容易误解他们正在做的工作*

#### 最佳实践

1.  了解你的工作，毫不犹豫地表达你的想法。
2.  不要对你的时间表犹豫不决。
3.  确保每个人都理解路线图。
4.  确保在路线图中包含模型的迭代测试。

### 初始建模

这是“初始”建模，因为在我们生命周期的开发阶段还有另一个建模步骤。这个阶段是最耗时的。数据科学项目的大部分时间都将花费在这里。

初始建模有三个部分:

1.  数据准备
2.  特征工程
3.  模型训练和模型选择

这是整个生命周期中最关键的一步，人们在这里会犯很多错误。让我们看看那些错误是什么。

检查[实验跟踪](/web/20221201165917/https://neptune.ai/blog/ml-experiment-tracking)如何帮助你组织这部分过程，避免错误。

#### 数据准备

新手在数据获取和数据准备之间有很多困惑。大三学生倾向于混淆这两个阶段。在数据获取中，我们引入了业务需要的所有数据(模型、仪表板以及两者之间的任何东西都可能需要这些数据)。在数据准备中，我们专注于可以解决业务问题的数据，并准备好被我们的 ML 模型吸收。

##### 责任

在数据准备中，我们获取所有数据并对其进行清理。比方说，我们的业务问题是**流失**。在这种情况下，我们希望获得所有可以帮助我们分析客户流失原因的数据。一旦我们得到数据，我们就检查异常值、空值、缺失值、类不平衡、删除不需要的列，并根据数据进行其他数据检查。

##### 数据准备问题

1.  没有收集所有必要的数据—*这是由于数据工程师的集成问题，我们最终得到的数据不完整。*
2.  不理解数据，或根据标准数据准备实践删除列—*这很常见，许多人往往会忘记 EDA(探索性数据分析),并根据标准实践删除列，从而在此过程中删除有价值的信息。*
3.  时间表–*由于严格的截止日期，专业人员可能不会验证他们的数据准备，这可能会导致后续步骤出现问题。*
4.  误解商业问题——*当你的目标错了，你最终会遇到问题。*

##### 最佳实践

1.  确保您拥有解决业务问题所需的所有数据。
2.  不要只是按照标准代码来清理你的数据。
3.  在删除任何不需要的列之前，进行 EDA(探索性数据分析)。
4.  检查空值或缺失值是否有任何模式。
5.  花时间为建模准备数据，这样就不会再回到这一步。

#### 特征工程

特征工程是机器学习管道中最重要的部分之一，因为它优化了事物的数据方面，所以我们得到了数据的水果部分，这必将在我们的策划模型上表现良好。为此，我们分析数据中的每个特征/属性，并选择能够解释目标变量中大部分差异的子集/超集。

##### 责任

这里的职责取决于我们正在处理的数据类型和业务问题本身。任务的几个例子可以是 one-hot 编码分类数据、标准化、应用对数和其他数学函数、分组一些列以使它们更容易学习和缩放。

##### 特征工程问题

1.  **太多的功能**–*一些专业人士不理解他们的数据，并按照标准做法创建更多的功能，这些功能将来会被删除，因为他们很少在培训中做出贡献。*
2.  **没有足够的特征**–*这是一个棘手的问题，记住这里应该遵循偏差-方差权衡。功能数量不能多也不能少，但需要权衡。*
3.  **无法识别业务问题/用例** —在进入特性工程之前，识别业务用例以及与之相关的术语/特性是很重要的。
    例如，在贷款预测问题的情况下，您可以创建一个称为“固定债务收入比”或 **FOIR** 的东西，可以使用 EMI/生活成本进行计算。这是贷方确定申请人贷款资格时最常用的参数，反过来也可以证明是数据集的一个精心设计的指标。

##### 最佳实践

1.  尝试基于您的数据和您正在解决的业务问题选择的多种特征工程方法。
2.  确保不要创建不必要的特征。
3.  特征工程是一件不可能一蹴而就的事情，它需要不断地用数据和模型差异进行反复试验。

#### 模型训练和模型选择

模型训练和模型选择是一个过程，在这个过程中，基于业务问题，我们选择几个具有不同参数的模型，并用我们干净的和特征工程的数据训练它们。根据验证指标和其他结果，我们将为后续阶段选择一个模型。

##### 责任

在这个阶段，我们需要尝试很多模型。多少？这取决于我们面临的问题的类型。我们倾向于测试监督学习的更多模型，无论是分类回归，还是非监督学习(聚类)的更少模型。我们试图用我们的训练数据来拟合所有入围的模型，并根据评估指标来决定最佳模型。

##### 模型训练和选择问题

1.  考虑较少的模型–*无论是截止日期还是有限的资源，有时我们考虑的模型不够多。*
2.  **虚假模型选择**–*我们倾向于根据一些评估指标来选择模型，准确率高达 99%的模型可能不是最符合我们数据的。*
3.  **过于频繁地引入深度学习模型**–*由于围绕深度学习的大肆宣传，我们倾向于添加它们，这可能会影响模型的可解释性。我们需要了解何时添加深度学习模型。*

##### 最佳实践

1.  确保你已经尝试了所有可能的模式。
2.  在选择最终模型的过程中，尝试添加更多的验证技术。
3.  不要只使用一个评估指标，检查所有可用的指标，然后再做决定。

## 2.发展

我们项目生命周期的下一部分是开发。我们已经在机器学习中开发了一个 POC 模型，现在，我们进一步开发该模型，并将其推向生产。三的规则在这篇文章中很强，所以我们又有三个部分:

1.  超参数调谐
2.  CI/CD(持续集成和持续发展)
3.  真实世界测试

### 超参数调谐

既然我们已经训练和验证了我们的模型，为什么我们还需要这个阶段？模型训练有助于我们理解描述数据的最佳特征，但是我们在超参数调整期间使用超参数来获得所选模型的最佳拟合。

#### 责任

在机器学习部分的建模阶段之后，我们经常最终无法选择一个 ML 模型。因此，我们从该阶段中选择他们表现最好的模型，并决定在该阶段进一步选择哪一个。我们使用不同的超参数调整技术，这可能会导致各种问题。

#### 超参数调谐问题

1.  **默认参数**–*当专业人士表现良好时，他们倾向于坚持默认的模型参数，他们可能会错过最佳拟合，这使他们最终回到这个阶段。*
2.  **过度调整**–*不要过度调整你的模型。使用交叉验证、回溯测试和正则化来避免它。*
3.  **手动超参数调整**–*专业人士倾向于选择手动调整，而不是遵循标准做法，这可能会增加时间，并减少他们使用自动化方法可以实现的不同结果集。*

#### 最佳实践

1.  千万不要使用默认的模型超参数集。
2.  确保不要为了寻找最佳拟合而过度拟合模型。
3.  保持超参数之间的权衡，不要太低，也不要太高。
4.  使用标准调优技术(网格搜索、随机搜索)，不要手动操作。

### 持续集成和持续部署(CI/CD)

您可能经常从 DevOps 工程师那里听到这种说法。CI/CD 是一组自动化集成和部署的实践。假设我们已经完成了我们的 ML 模型开发，并且在版本控制库中拥有了我们的全部代码。当我们在一个团队中工作时，许多人在代码的不同部分工作，所以我们需要以某种方式集成所有的更改，并在我们的所有环境(开发、测试、生产)中部署最新的代码。这就是 CI/CD 的用武之地。

#### 责任

这是 MLOps 工程师工作最多的阶段。有许多版本控制存储库和部署实例。我们不要挑毛病，把责任一概而论。在这个阶段，我们需要为持续集成创建一个管道来部署一个 ML 模型。这个管道从数据准备开始，一直到模型部署。数据工程师和数据科学家都会用到它。

例如，数据工程团队获得了添加数据清理技术的新需求，但是我们目前处于模型培训阶段。数据工程团队可以在管道中更新他们的代码，如果我们有一个 **CI 管道**，新的变化将会自动反映出来。

管道的下一阶段是持续部署。每当我们的版本控制代码库中有变化时，这有助于创建构建并将它们部署到我们所有的环境中。

#### CI/CD 问题

1.  **缺乏沟通**–*每当团队成员开发他们的代码并与存储库集成时，如果他们遇到困难，他们需要与 MLOps 工程师沟通。*
2.  **不必要的代码块**–*每个团队成员都应该知道 CI/CD 的流程，并确保添加所需的代码部分。这减少了自动化时间。*
3.  不必要的运行*——虽然有很多方法可以回滚到之前的代码，但这是这个阶段最常见的错误。*

#### 最佳实践

1.  确保在管道中包含通知。
2.  确保在管道中包含正确的代码。
3.  确保您添加了授权和身份验证。
4.  尝试对每个管道进行注释，以便每个团队成员可以检查哪个管道做什么。

### 真实世界测试

一旦 CI/CD 管道按预期设置并运行，我们需要在部署的 ML 模型中测试真实世界的数据。

#### 责任

在这个阶段，我们用定期(每小时、每天、每周、每月)的新数据测试我们的 ML 模型，并随着时间的推移检查模型的正确性。

#### 真实世界的测试问题

1.  **避免这一阶段将导致麻烦**–这一阶段告诉我们模型在真实数据和训练数据上是否像预期的那样运行。如果不是这样，我们需要回到导致这种情况的阶段。避免这一阶段可能会导致意外的停机和错误，从而影响用户体验。

#### 最佳实践

1.  不要回避用真实世界的数据进行测试。
2.  重复测试不仅有助于增强软件基础设施，还有助于提升整体用户体验和产品的整体性能。

## 3.操作

这是我们项目生命周期的最后一部分。一旦模型被训练、测试和部署，这个循环就不会结束。我们需要确保部署的模型能够长期工作，并监控是否会遇到任何问题。运营有三个部分:

1.  连续交货
2.  数据反馈回路
3.  监视

### 连续交货

许多项目在项目的 DevOps 部分包括这个阶段以及 CI/CD 阶段。即使我们的数据或业务需求有微小的变化，持续交付也能保持我们的产出按时交付。这有助于我们在几个阶段提供我们的整体产品，这些阶段被称为软件发布。

#### 责任

基于公司的业务问题和工作文化，对软件发布进行规划。利益相关者指定他们对每个版本的需求和要求，基于此，整个数据科学团队需要详细的计划来交付它们。

#### 连续交货问题

1.  **混淆**–*团队成员经常混淆来自不同版本的需求*
2.  **时间表**–*不要以牺牲效率为代价屈服于最后期限。*

#### 最佳实践

1.  确保您了解每个版本的全部需求，并据此制定计划。
2.  确保所有团队成员意见一致。

### 数据反馈回路

数据反馈循环通过发回错误预测的数据来帮助模型从错误中学习。如果没有数据反馈环，ML 模型往往会随着时间的推移而失去其指标，因为它不能适应数据的变化。

#### 责任

这一阶段的职责取决于我们处理的数据类型和我们试图解决的业务问题。让我们假设我们已经开发并部署了一个基于历史数据预测*股票价格的 ML 模型。该模型运行良好，开始预测时误差较小。最终，它试图只根据部署前训练的历史数据进行预测，而不是根据部署后的数据。*

为了使我们的模型适应一段时间内更新的股票表现，我们需要创建一个数据反馈循环，将我们的模型预测错误的数据(我们可以为其指定一个阈值)发送回模型进行训练。这条管道可以根据我们正在处理的数据及时运行。

#### 数据反馈回路问题

1.  **忽略数据反馈循环**–*许多团队倾向于忽略这个阶段，这使得他们的模型随着时间变得越来越差。*
2.  **反馈时间**–*如果我们更频繁地发送不正确的数据，模型会试图对数据进行过度拟合。*

#### 最佳实践

1.  了解模型无法预测的原因，并找出原因。
2.  确保你的反馈循环管道有时间触发器。

### 监视

监控在软件开发中与在数据科学中一样重要。一旦我们的模型部署好了，反馈回路到位了，我们就不能休息了。我们需要不断地监控模型，让用户满意。例如，模型可能被部署并准确预测，但是我们不能向我们的最终消费者展示这一点，因为我们有一个坏的网关。这是监控重要性的典型例子。

#### 最佳实践

1.  确保输入的数据是正确的。
2.  持续的健康检查。
3.  确保数据库和存储库都完好无损并且功能正常。
4.  为我们的模型获取实时功能，如单独的仪表板。
5.  永远不要完全依赖单一指标。
6.  使用 Neptune 之类的自动化模型监控。Neptune 是 MLOps 的一个元数据存储库，为运行大量实验的研究和生产团队而构建。

## 结论

如果你做到了这一步，感谢你的阅读！如你所见，MLOps 工程师是一个非常有趣的角色。

我所分享的工作流程和经验来自我自己的经历，对于其他团队和公司来说会有些许不同。如果你觉得我错过了一些重要的东西，或者你有非常不同的经历，请在评论区告诉我！

### 参考

1.  https://caiomsouza . medium . com/mlops-machine-learning-and-operations-and-ai-at-scale-ff CAC 7 e 50 f 62
2.  [https://towards data science . com/ml-ops-machine-learning-as-an-engineering-discipline-b 86ca 4874 a 3f](https://web.archive.org/web/20221201165917/https://towardsdatascience.com/ml-ops-machine-learning-as-an-engineering-discipline-b86ca4874a3f)
3.  [https://towards data science . com/machine-learning-monitoring-what-it-is-and-what-we-missing-e 644268023 ba](https://web.archive.org/web/20221201165917/https://towardsdatascience.com/machine-learning-monitoring-what-it-is-and-what-we-are-missing-e644268023ba)
4.  [https://elitedatascience.com/feature-engineering](https://web.archive.org/web/20221201165917/https://elitedatascience.com/feature-engineering)
5.  [https://towards data science . com/complete-data-science-project-part-1-business-understanding-b 8456 bb 14 BD 4](https://web.archive.org/web/20221201165917/https://towardsdatascience.com/complete-data-science-project-part-1-business-understanding-b8456bb14bd4)
6.  [https://towards data science . com/understanding-hyperparameters-and-its-optimization-techniques-f 0 debba 07568](https://web.archive.org/web/20221201165917/https://towardsdatascience.com/understanding-hyperparameters-and-its-optimisation-techniques-f0debba07568)
7.  [https://toward sai . net/p/data-science/two-productivity-secrets-from-elon-musk-the-can-help-in-data-science](https://web.archive.org/web/20221201165917/https://towardsai.net/p/data-science/two-productivity-secrets-from-elon-musk-that-can-help-in-data-science)