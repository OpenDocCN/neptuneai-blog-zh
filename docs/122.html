<html>
<head>
<title>How to Work with Autoencoders [Case Study Guide] </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>如何使用自动编码器[案例研究指南]</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/autoencoders-case-study-guide#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/autoencoders-case-study-guide#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p><a href="https://web.archive.org/web/20230220131423/https://www.youtube.com/watch?v=q222maQaPYo" target="_blank" rel="noreferrer noopener nofollow">自动编码器是一类神经网络</a>，用于无监督学习任务。他们有两个神经网络组件:<strong>编码器</strong>和<strong>解码器</strong>。两个组件具有基本相同的配置，这意味着输入的形状将类似于输出的形状，并且输入将与输出相同。</p>







<p>把输入复制到输出的架构有什么用？一点用都没有。让我解释一下:</p>



<p>为了理解这些网络，它们之间有一个叫做“T0”的信息瓶颈“T1”。与编码器和解码器相比，这个瓶颈区域中的神经元数量要少得多。这迫使网络减少信息，从而减少噪声，并且它们只能<strong>近似原始数据</strong>，而不是端到端地复制它。</p>



<p>训练这些算法的目的是:</p>



<ol>
<li>从瓶颈中的给定数据集学习表示或模式。</li>



<li>根据输入生成一组新数据。</li>
</ol>



<p>传统上，自动编码器用于降维，高维数据可以在低维空间中表示，类似于PCA。但是主成分分析受到线性度的限制，不能用高维非线性流形表示低维空间的数据。</p>



<p>多亏了神经网络，自动编码器可以做到这一点。这就是为什么autoencoder及其变体被用于许多应用中，包括高能和量子物理、分子生物学、医学图像分割、数据压缩等等。</p>



<h2 id="math">自动编码器背后的数学直觉</h2>



<p>使用数学概念定义自动编码器的一般方法是f(x) = h，其中x是输入数据，h是信息瓶颈中的潜在变量。这个公式表示网络的编码器部分。</p>



<p>解码器从信息瓶颈中提取潜在变量，然后将它们映射到可以表示为g(h)= x’的输出中。解码器通常与编码器正好相反。</p>



<p>让我们更深入地探讨“信息瓶颈”和“潜在变量”这两个术语，因为它们非常重要。</p>



<p><strong>信息瓶颈</strong> (IB)于1999年推出，当时的假设是，it可以通过压缩可以在网络中传输的信息量来提取重要信息或表示。这些信息被称为<strong>潜在变量</strong>或<strong>潜在表征</strong>。</p>



<p>简而言之，潜变量是不能直接观察到，而是从分布中提取出来的随机变量。这些变量是非常基本的，它们给了我们拓扑和数据分布的抽象知识。潜在变量，这里表示为h，可以根据您使用的自动编码器的不同而不同。</p>



<p>整个自动编码器可以描述为:</p>





<p>其中<em> f </em>和<em> g </em>都是非线性函数。</p>





<h2 id="types">自动编码器的类型</h2>



<p>自1987年问世以来，自动编码器已经有了很大的发展，它们的应用程序使它们更加针对特定的任务。在这里，我们将讨论不同的自动编码器及其工作原理。</p>



<h3>欠完整自动编码器</h3>



<p>欠完整自动编码器旨在通过<strong>尽可能限制模型</strong>的容量，将输入x映射到输出x `，从而最小化流经网络的信息量。</p>





<p>欠完整自动编码器通过最小化相同的损失函数来学习特征:</p>





<p>其中<em> L </em>是惩罚<em> g(f(x)) </em>偏离原始输入<em> x </em>的损失函数。<em> L </em>可以是均方误差，甚至是平均绝对误差。</p>



<p>自动编码器功能强大，因为它们的容量减少了——隐藏层中的节点数量随着信息瓶颈中的节点数量一起减少。之所以这样，是因为即使瓶颈只包含一个维度，当模型的容量很高时，自动编码器仍然可以将输入复制到输出，而不提取任何信息。</p>



<p>我们的目标总是提取表示，然后从这些表示中重建输入。为了使自动编码器能够学习和提取表示并重建输入，我们需要:</p>



<ol>
<li>增加模型容量，</li>



<li>增加信息瓶颈容量，</li>



<li><strong>正则化模型，使其支持以上两点。</strong></li>
</ol>



<p><strong>优点:</strong></p>



<p>因为欠完整自动编码器最大化了概率分布，所以它们不需要正则化函数。</p>



<p><strong>缺点:</strong></p>



<p>欠完整自动编码器不是通用的，它们往往会过拟合。它过度拟合的原因之一是因为它是一个容量有限的简单模型，不允许它具有灵活性。</p>



<h3>正则化自动编码器</h3>



<p>正则化自动编码器是基于数据复杂性设计的，它们解决了欠完整自动编码器的问题。编码器和解码器，随着信息瓶颈，可以有更高的容量。这使得它们更加灵活和强大。</p>



<p>正则化自动编码器对以下属性使用损失函数:</p>



<ol>
<li>通过逼近从输入重构输出的能力。</li>



<li>表示的稀疏性。</li>



<li>表示的导数的微小性。</li>



<li>对噪声、异常值或缺失输入的鲁棒性。</li>
</ol>



<h4>稀疏自动编码器</h4>



<p>稀疏自动编码器是正则化的自动编码器，在隐藏层上伴随着重构损失有损失:</p>





<p>其中<em> h </em>代表隐藏层。</p>



<p>这种惩罚隐藏层的方法意味着自动编码器可以具有更大的容量，同时仍然限制网络学习表示。该网络被限制为只激活隐藏层中一定数量的神经元。</p>



<p>值得注意的是，神经元的激活取决于输入数据，因此它们是<strong>数据依赖的</strong>，这意味着输入数据的分布导致隐藏层中神经元的激活。</p>





<p>从上面的图像中，你可以看到稀疏自动编码器如何激活隐藏层中的不同神经元来学习表示。</p>



<p>有两种方法可以在给定的网络上实现稀疏性:</p>



<ol>
<li>L1正则化</li>



<li>KL-散度</li>
</ol>



<p>在<strong> L1正则化</strong>中，我们给我们的损失函数<em>增加了一个λ项，该λ项惩罚层<em> h </em>中激活<em> a </em>的绝对值。</em></p>





<p>这个λ项帮助我们正则化整个模型，因为正则化项只依赖于λ。</p>



<p><strong>另一方面，Kullback-Leibler散度或KL-Divergence </strong>计算两个概率分布之间的差异。KL-divergence在测量执行近似时丢失了多少数据方面非常出色。</p>



<p>KL-divergence来自信息论，在信息论中，我们使用<strong>熵</strong>来计算一条信息的随机性。随机性或熵越高，解释数据就越困难。</p>



<p>定义熵的另一种方法是编码所需的最小信息量。本质上，如果随机性高，则需要更多的信息，如果随机性低，则需要更少的信息。</p>



<p>信息熵表示为:</p>





<p>其中x是所需的信息</p>



<p>信息熵的问题在于，我们无法获得实现编码所需的最佳信息。</p>



<p>另一方面，KL-divergence通过考虑近似分布来修改信息熵。</p>



<p>我们可以将KL散度描述为:</p>





<p>从上面的公式中，可以看到增加了一个近似项。通过计算KL散度来测量分布中的差异，我们现在可以将这个正则化项与损失函数相加。KL-散度也称为相对熵。</p>





<p><strong>优点:</strong></p>



<p>在稀疏自动编码器中，通过应用稀疏惩罚来防止<strong>过拟合</strong>。稀疏惩罚应用于隐藏层和重构误差。通过增加容量和学习复杂的拓扑结构，这使得模型更加通用。</p>



<p><strong>缺点:</strong></p>



<p>重要的是，节点是数据相关的，因为输入向量负责在训练期间产生结果的不同节点的激活。因此，测试数据中任何微小的统计变化都会产生不同的结果。</p>



<h3>收缩自动编码器</h3>



<p>收缩型自动编码器学习对输入数据的微小变化具有鲁棒性的表示。收缩式自动编码器背后的思想是将有限的输入分布映射到更小的输出分布。这种想法本质上训练自动编码器学习表示，即使相邻点稍微改变。</p>



<p>与我们之前讨论的类型一样，这也在损失标准中增加了一个惩罚项。</p>





<p>让我们探索等式的第二部分。就是<strong>雅可比矩阵</strong> <em> J </em>的平方<strong> Frobenius </strong> ||A||范数。Frobenius可以认为是矩阵的L2范数，雅可比矩阵表示向量值函数的一阶偏导数，即潜在表示的向量。</p>





<p>上面的术语描述了潜在表示<em> h </em>相对于输入<em> x </em>的梯度场。这一项惩罚了雅可比矩阵的<strong>大导数</strong>或者潜在表示<em> h </em>的梯度场。输入中的任何小变化导致表征空间中的大变化或变动都是不利的。</p>



<p><strong>优点:</strong></p>



<p>相比稀疏自动编码器，收缩自动编码器是学习良好表示的好选择，因为它们对微小的变化是鲁棒的，并且节点不依赖于数据。</p>



<p><strong>缺点:</strong></p>



<p>在输入向量的编码和解码过程中，收缩自动编码器的主要缺点是其重构误差。这导致忽略了重建时值得考虑的更细微的细节。</p>



<h4>降噪自动编码器</h4>



<p>到目前为止，我们已经看到了如何通过惩罚与原始输入<em> x </em>不同的自动编码器来改进它。我们现在看到的方法是相反的。我们设计我们的损失函数，使得模型训练与原始输出不太相似。</p>



<p>在去噪自动编码器中，我们传递添加了噪声的输入。这里的目标是训练一个自动编码器来消除这些噪声，并产生一个无噪声的输出。假设<strong>更高层次的</strong> <strong>表示相对稳定</strong>并且容易提取。</p>



<figure class="wp-block-image size-large is-resized"><img decoding="async" loading="lazy" src="../Images/c76f99caafe4d80045bd1ed3157fa31f.png" alt="" class="wp-image-49407" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230220131423im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Denoising-Autoencoders.png?resize=900%2C411&amp;ssl=1"/><figcaption class="wp-element-caption"><a href="https://web.archive.org/web/20230220131423/https://www.jeremyjordan.me/autoencoders/" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></figcaption></figure>



<p>为了实现这一点，我们需要自动编码器来最大限度地降低以下标准:</p>





<p>不是最小化传统标准:</p>





<p>去噪自动编码器被训练来学习表示，而不是简单地记忆和复制输入到输出，因为输入和输出不再相同。</p>



<p><strong>优点:</strong></p>



<p>对自动编码器去噪有利于<strong>学习</strong> <strong>损坏数据中的潜在表示</strong>，同时创建相同的鲁棒表示，允许模型恢复真实特征。</p>



<p><strong>缺点</strong>:</p>



<p>为了训练去噪自动编码器，重要的是执行初步随机映射以破坏数据，然后将其用作输入。这不允许模型创建映射，因为输入和输出是不同的。</p>



<h4>可变自动编码器</h4>



<p>变型自动编码器，俗称VAE，是自动编码器的一种更高级的变体。虽然在基本架构上相似，但它们拥有完全不同的数学公式。</p>



<p>人们可以观察到的最大变化之一是潜在变量的计算方式。VAE使用概率方法来寻找潜在的变量或代表。这个属性使它非常强大，可以与我们之前看到的自动编码器相比较。</p>



<p>VAE的信息瓶颈由两部分组成。一个分量代表输入分布的平均值，而另一个分量代表分布的标准偏差。</p>



<p>直观上，平均值控制输入的编码应该集中在哪里，而标准差控制“面积”；编码可以与平均值相差多少。我们还将高斯分布注入潜在空间，这允许VAE随机采样噪声，然后使用均值和标准差对其建模。</p>



<p>这使得VAE有一种概率方法来表示给定输入的每个潜在属性。</p>





<p>VAE的编码器(也称为近似推理网络)试图推断潜在变量z的属性。这可以描述为:</p>





<p>解码器(称为发生器)从潜像中提取样本并生成输出。解码器可以描述为:</p>





<p>VAE可以被描述为:</p>





<p>等式的第一部分描述了试图最大化重建似然的重建似然，第二部分是正则化项。</p>



<p>VAE中的潜在变量是连续的这一事实使它们成为一个强大的生成模型。此外，参数编码器与生成器的同步训练鼓励模型学习可预测的坐标系，使它们成为流形学习的绝佳选择。</p>



<p><strong>优点:</strong></p>



<p>VAE让我们能够控制我们希望如何对潜在变量的分布进行建模，而不是其他模型，这些模型可以在以后用于生成新数据。</p>



<p><strong>缺点:</strong></p>



<p>由于潜在空间中注入的高斯分布，生成的图像是模糊的。</p>



<h2 id="applications">自动编码器的应用</h2>



<p>自动编码器已被广泛用于降维和表示学习。与PCA相比，自动编码器产生的重建误差更小。它还表明，从自动编码器中提取的低维流形提高了许多任务的性能，例如:</p>



<ul>
<li>分类</li>



<li>异常检测</li>



<li>数据去噪</li>



<li>图像修复</li>



<li>信息检索</li>
</ul>



<h2 id="pytorch-and-mnist">使用MNIST了解Pytorch中的自动编码器[教程]</h2>



<p>现在，让我们了解如何用PyTorch编写自动编码器，并做一些可视化工作来探索潜在空间和解释模型。</p>



<p>对于一个普通的自动编码器，下面的库就足够了。我们还将为设备定义一个变量。它会自动检测colab笔记本是有cpu还是有gpu。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms
<span class="hljs-keyword">import</span> os

device = torch.device(<span class="hljs-string">"cuda"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)</pre>



<p>从Pytorch库下载的图像是PIL格式的，应该转换成张量格式。转变。ToTensor()将PIL转换为Pytorch要求的张量格式。</p>



<pre class="hljs">transform = transforms.Compose([transforms.ToTensor(),
                               transforms.Normalize((<span class="hljs-number">0.5</span>, ), (<span class="hljs-number">0.5</span>, ))
                              ])</pre>



<p>下载并加载培训数据。</p>



<pre class="hljs">trainset = datasets.MNIST(<span class="hljs-string">'MNIST_data/'</span>, download = <span class="hljs-keyword">True</span>, train = <span class="hljs-keyword">True</span>, transform = transform)
testset = datasets.MNIST(<span class="hljs-string">'MNIST_data/'</span>, download = <span class="hljs-keyword">True</span>, train = <span class="hljs-keyword">False</span>, transform = transform)

batch_size  = <span class="hljs-number">128</span>
trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = <span class="hljs-keyword">True</span>)
testloader  = torch.utils.data.DataLoader(testset,  batch_size = batch_size, shuffle = <span class="hljs-keyword">True</span>)</pre>



<p>让我们检查一个样本。</p>



<pre class="hljs">dataiter = iter(trainloader)
images, labels = dataiter.next()
plt.figure()
plt.imshow(images[<span class="hljs-number">0</span>].numpy().squeeze(), cmap = <span class="hljs-string">'gray'</span>)

plt.colorbar(fraction=<span class="hljs-number">0.046</span>, pad=<span class="hljs-number">0.04</span>)</pre>





<p>我们将定义一个学习函数，它将:</p>



<ol>
<li>训练模型，</li>



<li>计算每个小批量的损耗并更新参数，</li>



<li>在每个纪元后显示视觉进度。</li>
</ol>



<p>还有，注意损失函数。我们将定义均方误差损失来计算损失，并在优化过程中使用adam optimizer。亚当是最受欢迎的优化器之一，用于大多数深度学习任务。</p>



<pre class="hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Learner</span><span class="hljs-params">()</span>:</span>
 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, train_dl, valid_dl, model, loss_func = nn.MSELoss<span class="hljs-params">()</span>)</span>:</span>
   self.train_dl, self.valid_dl = train_dl, valid_dl
   self.model        = model
   self.loss_func    = loss_func
   self.train_losses = []
   self.valid_losses = []

 
 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">update</span><span class="hljs-params">(self,x, optm, vae)</span>:</span>
   


   
   
   y_hat, z = self.model(x)
   loss = self.loss_func(y_hat,x)


   
   loss.backward()
   optm.step() 
   optm.zero_grad() 

   <span class="hljs-keyword">return</span> loss.item()
 
 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">show_visual_progress</span><span class="hljs-params">(self, rows, title, epoch, flatten, vae)</span>:</span>

   image_title = f<span class="hljs-string">'{title}{epoch}'</span>
   plt.title(image_title)

   iter(self.valid_dl)
   image_rows = []

   <span class="hljs-keyword">for</span> idx, (image, label) <span class="hljs-keyword">in</span> enumerate(self.valid_dl):

     
     <span class="hljs-keyword">if</span> rows == idx:
         <span class="hljs-keyword">break</span>

     image = image.to(device)
     <span class="hljs-keyword">if</span> flatten:
       image = image.view(image.size(<span class="hljs-number">0</span>), <span class="hljs-number">28</span>*<span class="hljs-number">28</span>)

     
     images, z = self.model(image)
     images = images.detach().cpu().numpy().reshape(image.size(<span class="hljs-number">0</span>),<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)
     self.z = z.detach().cpu().numpy()


image_idxs = [list(label.numpy()).index(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>)]
     combined_images = np.concatenate([images[x].reshape(<span class="hljs-number">28</span>,<span class="hljs-number">28</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> image_idxs],<span class="hljs-number">1</span>)
     image_rows.append(combined_images)

   plt.imshow(np.concatenate(image_rows))
   plt.show()

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span><span class="hljs-params">(self, epochs = <span class="hljs-number">1</span>, lr = <span class="hljs-number">1e-4</span>, flatten = False, vae = False)</span>:</span>
   opt   = torch.optim.Adam(self.model.parameters(), lr = lr) 
   <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(epochs):
     <span class="hljs-keyword">for</span> image, label <span class="hljs-keyword">in</span> self.train_dl:
       image = image.to(device)
       <span class="hljs-keyword">if</span> flatten:
         image = image.view(image.size(<span class="hljs-number">0</span>), <span class="hljs-number">28</span>*<span class="hljs-number">28</span>)
       self.train_losses.append(self.update(image, opt, vae=vae))

     <span class="hljs-keyword">for</span> image, label <span class="hljs-keyword">in</span> self.valid_dl:
       image = image.to(device)
       <span class="hljs-keyword">if</span> flatten:
         image = image.view(image.size(<span class="hljs-number">0</span>), <span class="hljs-number">28</span>*<span class="hljs-number">28</span>)
       self.valid_losses.append(self.update(image, opt, vae= vae))
     print(<span class="hljs-string">"Epoch number {} finished."</span>.format(epoch))
     self.show_visual_progress(rows=<span class="hljs-number">5</span>, title=<span class="hljs-string">'AutoEncoder Learning State at Epoch: '</span>, epoch = epoch, flatten = flatten, vae= vae)</pre>



<p>我们定义了一个非常简约的模型，其中潜在的大小可以改变。这将有助于我们看到和理解模型如何执行变化的潜在大小。</p>



<pre class="hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AutoEncoder</span><span class="hljs-params">(nn.Module)</span>:</span>

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, latent_size = <span class="hljs-number">3</span>)</span>:</span>
   super(AutoEncoder, self).__init__()
   self.encoder = nn.Sequential(
       nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">512</span>),
       nn.ReLU(),
       nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">128</span>),
       nn.ReLU(),
       nn.Linear(<span class="hljs-number">128</span>, latent_size)
   )

   self.decoder = nn.Sequential(
       nn.Linear(latent_size, <span class="hljs-number">128</span>),
       nn.ReLU(),
       nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">512</span>),
       nn.ReLU(),
       nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">784</span>)
   )

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
   z = self.encoder(x)
   o = self.decoder(z)
   <span class="hljs-keyword">return</span> o, z</pre>



<p>开始训练。</p>



<pre class="hljs">model = AutoEncoder().to(device)
learn = Learner(trainloader, testloader, model)
learn.fit(epochs = <span class="hljs-number">10</span>, lr = <span class="hljs-number">1e-4</span>, flatten = <span class="hljs-keyword">True</span>)


plt.subplot(<span class="hljs-number">121</span>)
plt.plot(learn.train_losses)
plt.subplot(<span class="hljs-number">122</span>)
plt.plot(learn.valid_losses)</pre>



<p>下图来自第九个时期，当时潜在变量固定为5。你会观察到它重建图像的效果有多好。</p>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/75d968043a0e25570648885a8ff45d80.png" alt="Autoencoders output" class="wp-image-49411" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230220131423im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Autoencoders-output.png?ssl=1"/><figcaption class="wp-element-caption"><em>The image above shows the output yielded by the autoencoder after 9 epochs.</em></figcaption></figure></div>


<h2 id="case-study-1">案例研究1:使用去噪自动编码器进行图像去噪</h2>



<p>在第一个案例研究中，我们将应用自动编码器来消除图像中的噪声。这在计算机断层扫描(CT)中非常有用，在这种扫描中，图像可能很模糊，并且很难解释或训练分割模型。</p>



<h3>MNIST py torch中的自动编码器</h3>



<p>我们将再次使用MNIST，这次使用Keras来下载数据集，因为Pytorch MNIST数据是PIL格式的。虽然为了本文的简单起见，您可以使用它，但是我们将从Keras下载数据，因为它将确保我们以NumPy格式下载数据，以便我们可以添加噪声。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms
<span class="hljs-keyword">import</span> os

<span class="hljs-keyword">from</span> keras.datasets <span class="hljs-keyword">import</span> mnist
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader,Dataset</pre>



<p>向数据集添加噪声，我们将添加两种类型的噪声:</p>



<ol>
<li>高斯的</li>



<li>点缀</li>
</ol>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">add_noise</span><span class="hljs-params">(img,noise_type=<span class="hljs-string">"gaussian"</span>)</span>:</span>
  row,col=<span class="hljs-number">28</span>,<span class="hljs-number">28</span>
 img=img.astype(np.float32)
  <span class="hljs-keyword">if</span> noise_type==<span class="hljs-string">"gaussian"</span>:
   mean=<span class="hljs-number">0</span>
   var=<span class="hljs-number">10</span>
   sigma=var**<span class="hljs-number">.5</span>
   noise=np.random.normal(<span class="hljs-number">-5.9</span>,<span class="hljs-number">5.9</span>,img.shape)
   noise=noise.reshape(row,col)
   img=img+noise
   <span class="hljs-keyword">return</span> img

 <span class="hljs-keyword">if</span> noise_type==<span class="hljs-string">"speckle"</span>:
   noise=np.random.randn(row,col)
   noise=noise.reshape(row,col)
   img=img+img*noise
   <span class="hljs-keyword">return</span> img

noises=[<span class="hljs-string">"gaussian"</span>,<span class="hljs-string">"speckle"</span>]
noise_ct=<span class="hljs-number">0</span>
noise_id=<span class="hljs-number">0</span>
traindata=np.zeros((<span class="hljs-number">60000</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>))

<span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> (range(len(xtrain))):
  <span class="hljs-keyword">if</span> noise_ct&lt;(len(xtrain)/<span class="hljs-number">2</span>):
   noise_ct+=<span class="hljs-number">1</span>
   traindata[idx]=add_noise(xtrain[idx],noise_type=noises[noise_id])

 <span class="hljs-keyword">else</span>:
   print(<span class="hljs-string">"n{} noise addition completed to images"</span>.format(noises[noise_id]))
   noise_id+=<span class="hljs-number">1</span>
   noise_ct=<span class="hljs-number">0</span>

print(<span class="hljs-string">"n{} noise addition completed to images"</span>.format(noises[noise_id]))

noise_ct=<span class="hljs-number">0</span>
noise_id=<span class="hljs-number">0</span>
testdata=np.zeros((<span class="hljs-number">10000</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>))

<span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> (range(len(xtest))):
  <span class="hljs-keyword">if</span> noise_ct&lt;(len(xtest)/<span class="hljs-number">2</span>):
   noise_ct+=<span class="hljs-number">1</span>
   x=add_noise(xtest[idx],noise_type=noises[noise_id])
   testdata[idx]=x

 <span class="hljs-keyword">else</span>:
   print(<span class="hljs-string">"n{} noise addition completed to images"</span>.format(noises[noise_id]))
   noise_id+=<span class="hljs-number">1</span>
   noise_ct=<span class="hljs-number">0</span>
print(<span class="hljs-string">"n{} noise addition completed to images"</span>.format(noises[noise_id]))</pre>



<p>可视化数据。</p>



<pre class="hljs">f, axes=plt.subplots(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)


axes[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].imshow(xtrain[<span class="hljs-number">0</span>])
axes[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_title(<span class="hljs-string">"Original Image"</span>)
axes[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].imshow(traindata[<span class="hljs-number">0</span>])
axes[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_title(<span class="hljs-string">"Noised Image"</span>)


axes[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].imshow(xtrain[<span class="hljs-number">25000</span>])
axes[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_title(<span class="hljs-string">"Original Image"</span>)
axes[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].imshow(traindata[<span class="hljs-number">25000</span>])
axes[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].set_title(<span class="hljs-string">"Noised Image"</span>)</pre>





<p>数据经过预处理后，我们可以:</p>



<ol>
<li>将数据转换成张量，</li>



<li>创建包含原始数据和噪声数据的数据集，</li>
</ol>



<p>使用Pytorch的DataLoader函数创建可用于训练和建模的生成器变量。</p>



<pre class="hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">noisedDataset</span><span class="hljs-params">(Dataset)</span>:</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,datasetnoised,datasetclean,labels,transform)</span>:</span>
   self.noise=datasetnoised
   self.clean=datasetclean
   self.labels=labels
   self.transform=transform
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
   <span class="hljs-keyword">return</span> len(self.noise)
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self,idx)</span>:</span>
   xNoise=self.noise[idx]
   xClean=self.clean[idx]
   y=self.labels[idx]

   <span class="hljs-keyword">if</span> self.transform != <span class="hljs-keyword">None</span>:
     xNoise=self.transform(xNoise)
     xClean=self.transform(xClean)


   <span class="hljs-keyword">return</span> (xNoise,xClean,y)

transform =transforms.Compose([
   transforms.ToTensor()
])

trainset=noisedDataset(traindata,xtrain,ytrain,transform)
testset=noisedDataset(testdata,xtest,ytest,transform)

batch_size=<span class="hljs-number">32</span>
trainloader=DataLoader(trainset,batch_size=<span class="hljs-number">32</span>,shuffle=<span class="hljs-keyword">True</span>)
testloader=DataLoader(testset,batch_size=<span class="hljs-number">1</span>,shuffle=<span class="hljs-keyword">True</span>)</pre>



<p>定义一个去噪模型类似于定义一个普通的自动编码器，唯一改变的是用于从编码器获得最终输出的sigmoid函数。</p>



<p>sigmoid函数将确保最终输出在0到1的范围内，因为干净数据在0到1的范围内。我们将最终信号转换到相同的范围是有意义的。</p>



<pre class="hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">denoising_model</span><span class="hljs-params">(nn.Module)</span>:</span>
 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
   super(denoising_model,self).__init__()
   self.encoder=nn.Sequential(
                 nn.Linear(<span class="hljs-number">28</span>*<span class="hljs-number">28</span>,<span class="hljs-number">256</span>),
                 nn.ReLU(<span class="hljs-keyword">True</span>),
                 nn.Linear(<span class="hljs-number">256</span>,<span class="hljs-number">128</span>),
                 nn.ReLU(<span class="hljs-keyword">True</span>),
                 nn.Linear(<span class="hljs-number">128</span>,<span class="hljs-number">64</span>),
                 nn.ReLU(<span class="hljs-keyword">True</span>)

                 )

   self.decoder=nn.Sequential(
                 nn.Linear(<span class="hljs-number">64</span>,<span class="hljs-number">128</span>),
                 nn.ReLU(<span class="hljs-keyword">True</span>),
                 nn.Linear(<span class="hljs-number">128</span>,<span class="hljs-number">256</span>),
                 nn.ReLU(<span class="hljs-keyword">True</span>),
                 nn.Linear(<span class="hljs-number">256</span>,<span class="hljs-number">28</span>*<span class="hljs-number">28</span>),
                 nn.Sigmoid(),
                 )

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self,x)</span>:</span>
   z=self.encoder(x)
  sigmoid =self.decoder(z)

   <span class="hljs-keyword">return</span> sigmoid</pre>



<p>我们也将为此任务初始化相同的损失和优化器函数。</p>



<pre class="hljs">model=denoising_model().to(device)
criterion=nn.MSELoss()
optimizer=torch.optim.Adam(model.parameters(),lr=<span class="hljs-number">0.01</span>)</pre>



<p>初始化120个时期的训练。</p>



<pre class="hljs">epochs=<span class="hljs-number">120</span>
l=len(trainloader)
losslist=list()
epochloss=<span class="hljs-number">0</span>
running_loss=<span class="hljs-number">0</span>
<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(epochs):
  print(<span class="hljs-string">"Entering Epoch: "</span>,epoch)
 <span class="hljs-keyword">for</span> (idx), (dirty,clean,label) <span class="hljs-keyword">in</span> enumerate(trainloader):
   <span class="hljs-keyword">if</span> idx == <span class="hljs-number">50</span>:
     print(<span class="hljs-string">'+'</span>, end=<span class="hljs-string">''</span>)


   dirty=dirty.view(dirty.size(<span class="hljs-number">0</span>),<span class="hljs-number">-1</span>).type(torch.FloatTensor)
   clean=clean.view(clean.size(<span class="hljs-number">0</span>),<span class="hljs-number">-1</span>).type(torch.FloatTensor)
   dirty,clean=dirty.to(device),clean.to(device)



   
   output=model(dirty)
   loss=criterion(output,clean)
   
   optimizer.zero_grad()
   loss.backward()
   optimizer.step()

   running_loss+=loss.item()
   epochloss+=loss.item()
 
 losslist.append(running_loss/l)
 running_loss=<span class="hljs-number">0</span>
 print(<span class="hljs-string">"======&gt; epoch: {}/{}, Loss:{}"</span>.format(epoch,epochs,loss.item()))</pre>



<p>可视化结果。</p>



<pre class="hljs">f,axes= plt.subplots(<span class="hljs-number">6</span>,<span class="hljs-number">3</span>,figsize=(<span class="hljs-number">20</span>,<span class="hljs-number">20</span>))
axes[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_title(<span class="hljs-string">"Original Image"</span>)
axes[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_title(<span class="hljs-string">"Dirty Image"</span>)
axes[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>].set_title(<span class="hljs-string">"Cleaned Image"</span>)

test_imgs=np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">10000</span>,size=<span class="hljs-number">6</span>)
<span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> range((<span class="hljs-number">6</span>)):
 dirty=testset[test_imgs[idx]][<span class="hljs-number">0</span>]
 clean=testset[test_imgs[idx]][<span class="hljs-number">1</span>]
 label=testset[test_imgs[idx]][<span class="hljs-number">2</span>]
 dirty=dirty.view(dirty.size(<span class="hljs-number">0</span>),<span class="hljs-number">-1</span>).type(torch.FloatTensor)
 dirty=dirty.to(device)
 output=model(dirty)
  output=output.view(<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)
 output=output.permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>).squeeze(<span class="hljs-number">2</span>)
 output=output.detach().cpu().numpy()
  dirty=dirty.view(<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>)
 dirty=dirty.permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>).squeeze(<span class="hljs-number">2</span>)
 dirty=dirty.detach().cpu().numpy()
  clean=clean.permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>).squeeze(<span class="hljs-number">2</span>)
 clean=clean.detach().cpu().numpy()
  axes[idx,<span class="hljs-number">0</span>].imshow(clean,cmap=<span class="hljs-string">"gray"</span>)
 axes[idx,<span class="hljs-number">1</span>].imshow(dirty,cmap=<span class="hljs-string">"gray"</span>)
 axes[idx,<span class="hljs-number">2</span>].imshow(output,cmap=<span class="hljs-string">"gray"</span>)</pre>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/edf25751f0e713fb0719106a0e541c36.png" alt="Denoising autoencoders output" class="wp-image-49414" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230220131423im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Denoising-outoencoders-output.png?ssl=1"/><figcaption class="wp-element-caption">The image above shows the output yielded by the denoising autoencoder which was able successfully remove noise from the input image and produced images similar to the original image. </figcaption></figure>



<h2 id="case-study-2">案例研究2:利用LSTM自动编码器检测心电图异常</h2>



<p>心电图(ECG或EKG)是一种通过测量心脏的电活动来检查心脏功能的测试。这些信号可以用智能手表来测量。</p>



<p>ECG信号可以告诉我们很多关于一个人的健康和幸福的信息。在本案例研究中，我们将预测ECG信号并检测信号中的异常。</p>



<p>我们将使用属性关系文件格式(ARFF)，所以我们将安装两个包来支持它们。首先是arff2pandas，将arff文件转换成pandas框架。第二:pandas profiling，从pandas DataFrame生成profile报告。</p>



<p>要在colab笔记本中安装这些包，我们使用以下命令:</p>



<pre class="hljs">!pip install -qq arff2pandas
!pip install -U pandas-profiling</pre>



<p>一旦安装了所需的包，我们就可以开始导入它们以及本案例研究所需的其他包。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> torch

<span class="hljs-keyword">import</span> copy
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">from</span> pylab <span class="hljs-keyword">import</span> rcParams
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> rc
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split

<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, optim

<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">from</span> arff2pandas <span class="hljs-keyword">import</span> a2p</pre>



<p>为了视觉上吸引人的情节，我们设置以下变量:</p>



<pre class="hljs">%matplotlib inline
%config InlineBackend.figure_format=<span class="hljs-string">'retina'</span>

sns.set(style=<span class="hljs-string">'whitegrid'</span>, palette=<span class="hljs-string">'muted'</span>, font_scale=<span class="hljs-number">1.2</span>)

HAPPY_COLORS_PALETTE = [<span class="hljs-string">"#01BEFE"</span>, <span class="hljs-string">"#FFDD00"</span>, <span class="hljs-string">"#FF7D00"</span>, <span class="hljs-string">"#FF006D"</span>, <span class="hljs-string">"#ADFF02"</span>, <span class="hljs-string">"#8F00FF"</span>]

sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))

rcParams[<span class="hljs-string">'figure.figsize'</span>] = <span class="hljs-number">12</span>, <span class="hljs-number">8</span>

RANDOM_SEED = <span class="hljs-number">42</span>
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)</pre>



<p>以下命令可用于将数据直接下载到您的colab笔记本:</p>



<pre class="hljs">!gdown --id <span class="hljs-number">16</span>MIleqoIr1vYxlGk4GKnGmrsCPuWkkpT
Once the data <span class="hljs-keyword">is</span> downloaded we unzip it <span class="hljs-keyword">in</span> the desired folder. </pre>



<p>mkdir -p命令创建一个子目录和父目录。在我们的例子中，“data”是父目录，“timeseries”是子目录。</p>



<pre class="hljs">!mkdir -p data/timeseries</pre>



<p>同样，我们可以使用！unzip ECG 5000 . zip-d data/time series用于解压缩文件。参数-d允许文件在期望的路径中解压缩。在我们的例子中，我们创建的目录。</p>



<pre class="hljs">!unzip ECG5000.zip -d data/timeseries</pre>



<p>我们将定义CPU或GPU使用的设备。</p>



<pre class="hljs">device = torch.device(<span class="hljs-string">"cuda"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)</pre>



<p>一旦文件被解压缩，我们就可以使用a2p函数打开它，该函数使用pandas数据帧打开arff文件。</p>



<pre class="hljs"><span class="hljs-keyword">with</span> open(<span class="hljs-string">'data/timeseries/ECG5000_TRAIN.arff'</span>) <span class="hljs-keyword">as</span> f:
 train = a2p.load(f)

<span class="hljs-keyword">with</span> open(<span class="hljs-string">'data/timeseries/ECG5000_TEST.arff'</span>) <span class="hljs-keyword">as</span> f:
 test = a2p.load(f)</pre>



<p>可视化数据。</p>



<pre class="hljs">df = train.append(test)
df = df.sample(frac=<span class="hljs-number">1.0</span>)
df.shape
CLASS_NORMAL = <span class="hljs-number">1</span>

class_names = [<span class="hljs-string">'Normal'</span>,<span class="hljs-string">'R on T'</span>,<span class="hljs-string">'PVC'</span>,<span class="hljs-string">'SP'</span>,<span class="hljs-string">'UB'</span>]

ax = sns.countplot(df.target)
ax.set_xticklabels(class_names);</pre>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/cd26b6dcfe8870aeee97f1e34d3ad41a.png" alt="Autoencoders classes" class="wp-image-49415" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230220131423im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Autoencoders-classes.png?resize=651%2C414&amp;ssl=1"/><figcaption class="wp-element-caption"><em>As you can see from the bar chart above, the normal class has by far the most examples. Now let’s plot a time series graph to see how these features look like against the target feature.</em></figcaption></figure></div>


<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_time_series_class</span><span class="hljs-params">(data, class_name, ax, n_steps=<span class="hljs-number">10</span>)</span>:</span>
 time_series_df = pd.DataFrame(data)

 smooth_path = time_series_df.rolling(n_steps).mean()
 path_deviation = <span class="hljs-number">2</span> * time_series_df.rolling(n_steps).std()

 under_line = (smooth_path - path_deviation)[<span class="hljs-number">0</span>]
 over_line = (smooth_path + path_deviation)[<span class="hljs-number">0</span>]

 ax.plot(smooth_path, linewidth=<span class="hljs-number">2</span>)
 ax.fill_between(
   path_deviation.index,
   under_line,
   over_line,
   alpha=<span class="hljs-number">.125</span>
 )
 ax.set_title(class_name)

classes = df.target.unique()

fig, axs = plt.subplots(
 nrows=len(classes) // <span class="hljs-number">3</span> + <span class="hljs-number">1</span>,
 ncols=<span class="hljs-number">3</span>,
 sharey=<span class="hljs-keyword">True</span>,
 figsize=(<span class="hljs-number">14</span>, <span class="hljs-number">8</span>)
)

<span class="hljs-keyword">for</span> i, cls <span class="hljs-keyword">in</span> enumerate(classes):
 ax = axs.flat[i]
 data = df[df.target == cls]
   .drop(labels=<span class="hljs-string">'target'</span>, axis=<span class="hljs-number">1</span>)
   .mean(axis=<span class="hljs-number">0</span>)
   .to_numpy()
 plot_time_series_class(data, class_names[i], ax)

fig.delaxes(axs.flat[<span class="hljs-number">-1</span>])
fig.tight_layout()</pre>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img decoding="async" src="../Images/3ffd3d7ed593446718191dfb29e9123e.png" alt="Autoencoders classes" class="wp-image-49416" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230220131423im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Autoencoders-classes-2.png?ssl=1"/><figcaption class="wp-element-caption"><em>If you observe carefully, the normal class stands out compared to other classes. This data attribute can help the autoencoder find anomalies more easily. </em></figcaption></figure></div>


<p>使用条件语句创建带有两个变量(正常和异常)的数据集的时间。一旦创建了这两个变量，我们就可以使用sklearn中的train_test_split来分离训练、测试和验证数据。</p>



<pre class="hljs">normal_df = df[df.target == str(CLASS_NORMAL)].drop(labels=<span class="hljs-string">'target'</span>, axis=<span class="hljs-number">1</span>)

anomaly_df = df[df.target != str(CLASS_NORMAL)].drop(labels=<span class="hljs-string">'target'</span>, axis=<span class="hljs-number">1</span>)
train_df, val_df = train_test_split(
 normal_df,
 test_size=<span class="hljs-number">0.15</span>,
 random_state=RANDOM_SEED
)

val_df, test_df = train_test_split(
 val_df,
 test_size=<span class="hljs-number">0.33</span>,
 random_state=RANDOM_SEED
)</pre>



<p>一旦数据被分离，我们就将NumPy转换成二维张量，autoencoder可以用它来训练和模拟数据。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_dataset</span><span class="hljs-params">(df)</span>:</span>

 sequences = df.astype(np.float32).to_numpy().tolist()

 dataset = [torch.tensor(s).unsqueeze(<span class="hljs-number">1</span>).float() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> sequences]

 n_seq, seq_len, n_features = torch.stack(dataset).shape

 <span class="hljs-keyword">return</span> dataset, seq_len, n_features

train_dataset, seq_len, n_features = create_dataset(train_df)
val_dataset, _, _ = create_dataset(val_df)
test_normal_dataset, _, _ = create_dataset(test_df)
test_anomaly_dataset, _, _ = create_dataset(anomaly_df)</pre>



<p>现在，让我们编码自动编码器。与我们之前用来建模图像的方法不同，我们使用不同的方法来建模时间序列或序列数据。在这个案例研究中，我们将使用长短期记忆或LSTM。</p>



<p>LSTMs擅长对顺序数据建模。他们可以记住长期序列，这使得根据序列长度预测变量变得更加容易。</p>



<pre class="hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Encoder</span><span class="hljs-params">(nn.Module)</span>:</span>

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, seq_len, n_features, embedding_dim=<span class="hljs-number">64</span>)</span>:</span>
   super(Encoder, self).__init__()

   self.seq_len, self.n_features = seq_len, n_features
   self.embedding_dim, self.hidden_dim = embedding_dim, <span class="hljs-number">2</span> * embedding_dim

   self.\r\nn1 = nn.LSTM(
     input_size=n_features,
     hidden_size=self.hidden_dim,
     num_layers=<span class="hljs-number">1</span>,
     batch_first=<span class="hljs-keyword">True</span>
   )

   self.\r\nn2 = nn.LSTM(
     input_size=self.hidden_dim,
     hidden_size=embedding_dim,
     num_layers=<span class="hljs-number">1</span>,
     batch_first=<span class="hljs-keyword">True</span>
   )

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
   x = x.reshape((<span class="hljs-number">1</span>, self.seq_len, self.n_features))

   x, (_, _) = self.\r\nn1(x)
   x, (hidden_n, _) = self.\r\nn2(x)

   <span class="hljs-keyword">return</span> hidden_n.reshape((self.n_features, self.embedding_dim))</pre>



<p>一旦编码器准备好了，我们还要定义一个解码器。解码器也将具有相同的LSTM架构。</p>



<pre class="hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Decoder</span><span class="hljs-params">(nn.Module)</span>:</span>

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, seq_len, input_dim=<span class="hljs-number">64</span>, n_features=<span class="hljs-number">1</span>)</span>:</span>
   super(Decoder, self).__init__()

   self.seq_len, self.input_dim = seq_len, input_dim
   self.hidden_dim, self.n_features = <span class="hljs-number">2</span> * input_dim, n_features

   self.\r\nn1 = nn.LSTM(
     input_size=input_dim,
     hidden_size=input_dim,
     num_layers=<span class="hljs-number">1</span>,
     batch_first=<span class="hljs-keyword">True</span>
   )

   self.\r\nn2 = nn.LSTM(
     input_size=input_dim,
     hidden_size=self.hidden_dim,
     num_layers=<span class="hljs-number">1</span>,
     batch_first=<span class="hljs-keyword">True</span>
   )

   self.output_layer = nn.Linear(self.hidden_dim, n_features)

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
   x = x.repeat(self.seq_len, self.n_features)
   x = x.reshape((self.n_features, self.seq_len, self.input_dim))

   x, (hidden_n, cell_n) = self.\r\nn1(x)
   x, (hidden_n, cell_n) = self.\r\nn2(x)
   x = x.reshape((self.seq_len, self.hidden_dim))

   <span class="hljs-keyword">return</span> self.output_layer(x)</pre>



<p>让我们将编码器和解码器封装在一个模块中。</p>



<pre class="hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RecurrentAutoencoder</span><span class="hljs-params">(nn.Module)</span>:</span>

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, seq_len, n_features, embedding_dim=<span class="hljs-number">64</span>)</span>:</span>
   super(RecurrentAutoencoder, self).__init__()

   self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)
   self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)

 <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
   z = self.encoder(x)
   o = self.decoder(z)
   <span class="hljs-keyword">return</span> o</pre>



<p>现在我们定义模型。</p>



<pre class="hljs">model = RecurrentAutoencoder(seq_len, n_features, <span class="hljs-number">128</span>)
model = model.to(device)</pre>



<p>让我们写一个我们将要训练的函数。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_model</span><span class="hljs-params">(model, train_dataset, val_dataset, n_epochs)</span>:</span>
 optimizer = torch.optim.Adam(model.parameters(), lr=<span class="hljs-number">1e-3</span>)
 criterion = nn.L1Loss(reduction=<span class="hljs-string">'sum'</span>).to(device)
 history = dict(train=[], val=[])

 best_model_wts = copy.deepcopy(model.state_dict())
 best_loss = <span class="hljs-number">10000.0</span>
  <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, n_epochs + <span class="hljs-number">1</span>):
   model = model.train()

   train_losses = []
   <span class="hljs-keyword">for</span> seq_true <span class="hljs-keyword">in</span> train_dataset:
     optimizer.zero_grad()

     seq_true = seq_true.to(device)
     seq_pred = model(seq_true)

     loss = criterion(seq_pred, seq_true)

     loss.backward()
     optimizer.step()

     train_losses.append(loss.item())

   val_losses = []
   model = model.eval()
   <span class="hljs-keyword">with</span> torch.no_grad():
     <span class="hljs-keyword">for</span> seq_true <span class="hljs-keyword">in</span> val_dataset:

       seq_true = seq_true.to(device)
       seq_pred = model(seq_true)

       loss = criterion(seq_pred, seq_true)
       val_losses.append(loss.item())

   train_loss = np.mean(train_losses)
   val_loss = np.mean(val_losses)

   history[<span class="hljs-string">'train'</span>].append(train_loss)
   history[<span class="hljs-string">'val'</span>].append(val_loss)

   <span class="hljs-keyword">if</span> val_loss &lt; best_loss:
     best_loss = val_loss
     best_model_wts = copy.deepcopy(model.state_dict())

   print(f<span class="hljs-string">'Epoch {epoch}: train loss {train_loss} val loss {val_loss}'</span>)

 model.load_state_dict(best_model_wts)
 <span class="hljs-keyword">return</span> model.eval(), history</pre>



<p>注意:我们使用L1Loss或平均绝对误差。这在处理数据中的异常值或异常时非常有用。此外，对于序列分析，它工作得非常好，因为它使用与被测量的数据相同的尺度。</p>



<p>让我们开始训练吧。</p>



<pre class="hljs">model, history = train_model(
 model,
 train_dataset,
 val_dataset,
 n_epochs=<span class="hljs-number">150</span>
)</pre>



<p>一旦模型经过训练，我们就可以开始预测值，并将它们与原始数据进行比较，以了解我们的模型的表现如何。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span><span class="hljs-params">(model, dataset)</span>:</span>
 predictions, losses = [], []
 criterion = nn.L1Loss(reduction=<span class="hljs-string">'sum'</span>).to(device)
 <span class="hljs-keyword">with</span> torch.no_grad():
   model = model.eval()
   <span class="hljs-keyword">for</span> seq_true <span class="hljs-keyword">in</span> dataset:
     seq_true = seq_true.to(device)
     seq_pred = model(seq_true)

     loss = criterion(seq_pred, seq_true)

     predictions.append(seq_pred.cpu().numpy().flatten())
     losses.append(loss.item())
 <span class="hljs-keyword">return</span> predictions, losses

_, losses = predict(model, train_dataset)
sns.distplot(losses, bins=<span class="hljs-number">50</span>, kde=<span class="hljs-keyword">True</span>)</pre>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/ee6a0aca3c0fbacc4150a43a6eae76b2.png" alt="Autoencoders case study loss" class="wp-image-49417" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230220131423im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Autoencoders-case-study-loss.png?resize=635%2C402&amp;ssl=1"/><figcaption class="wp-element-caption"><em>As you can see from the graph, the model managed to minimize loss on the training data set. Now let’s do the same with the test dataset and see how our model performs.</em></figcaption></figure></div>


<pre class="hljs">predictions, pred_losses = predict(model, test_normal_dataset)
sns.distplot(pred_losses, bins=<span class="hljs-number">50</span>, kde=<span class="hljs-keyword">True</span>)</pre>


<div class="wp-block-image">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/e4562c56ac9f8f3bd4acaa4326c5bec9.png" alt="Autoencoders case study performance" class="wp-image-49418" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230220131423im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Autoencoders-case-study-performance.png?resize=612%2C375&amp;ssl=1"/><figcaption class="wp-element-caption"><em>You can see similar performance on the validation set as well. The losses are reduced. </em></figcaption></figure></div>


<p>最后，让我们在时序图中看看模型性能。</p>



<pre class="hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_prediction</span><span class="hljs-params">(data, model, title, ax)</span>:</span>
 predictions, pred_losses = predict(model, [data])

 ax.plot(data, label=<span class="hljs-string">'true'</span>)
 ax.plot(predictions[<span class="hljs-number">0</span>], label=<span class="hljs-string">'reconstructed'</span>)
 ax.set_title(f<span class="hljs-string">'{title} (loss: {np.around(pred_losses[0], 2)})'</span>)
 ax.legend()
fig, axs = plt.subplots(
 nrows=<span class="hljs-number">2</span>,
 ncols=<span class="hljs-number">6</span>,
 sharey=<span class="hljs-keyword">True</span>,
 sharex=<span class="hljs-keyword">True</span>,
 figsize=(<span class="hljs-number">22</span>, <span class="hljs-number">8</span>)
)

<span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> enumerate(test_normal_dataset[:<span class="hljs-number">6</span>]):
 plot_prediction(data, model, title=<span class="hljs-string">'Normal'</span>, ax=axs[<span class="hljs-number">0</span>, i])

<span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> enumerate(test_anomaly_dataset[:<span class="hljs-number">6</span>]):
 plot_prediction(data, model, title=<span class="hljs-string">'Anomaly'</span>, ax=axs[<span class="hljs-number">1</span>, i])

fig.tight_layout()</pre>





<p>从上图可以明显看出，该模型在预测正常心电图模式方面表现良好。它没有足够的准确性来对异常模式做出好的预测。如果我们的模型针对更多的时期和更多的数据进行训练，那么它可以在给定的任务中表现良好。</p>



<p>注意:该模型在预测正常模式方面表现出色，因为数据集的正常特征多于异常特征。</p>



<h2 id="h-conclusion">结论</h2>



<p>我们已经讨论了什么是自动编码器，以及它们如何发现数据中的结构。压缩数据的信息瓶颈很重要，因为它允许自动编码器学习潜在的表示，这些表示可用于各种深度学习任务。自动编码器是PCA的高级版本，其可以是非线性流形，并且仍然对异常值具有鲁棒性。</p>



<p>我们看到了自动编码器的不同变体，以及它们如何针对特定任务相互改进。我们还对autoencoder进行了编码，以更好地理解它的工作原理，并了解了不同维度的潜在空间对结果的不同影响。</p>



<p>最后，我们探讨了如何使用自动编码器完成两项任务:图像去噪和异常检测。</p>



<p>我希望这个教程是有趣的和有益的。感谢您的阅读！</p>



<h3>承认</h3>



<p>第二个案例研究中使用的代码受到了<a href="https://web.archive.org/web/20230220131423/https://github.com/curiousily" target="_blank" rel="noreferrer noopener nofollow"> Venelin </a>的启发。我只是修改了一下让它更易读。</p>



<h3>进一步阅读</h3>



<ol>
<li><a href="https://web.archive.org/web/20230220131423/https://en.wikipedia.org/wiki/Autoencoder" target="_blank" rel="noreferrer noopener nofollow">自动编码器</a></li>



<li><a href="https://web.archive.org/web/20230220131423/http://www.deeplearningbook.org/contents/autoencoders.html" target="_blank" rel="noreferrer noopener nofollow">深度学习书籍(第14章):自动编码器</a></li>



<li><a href="https://web.archive.org/web/20230220131423/https://hackernoon.com/autoencoders-deep-learning-bits-1-11731e200694" target="_blank" rel="noreferrer noopener nofollow">自动编码器——深度学习位</a></li>



<li><a href="https://web.archive.org/web/20230220131423/https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798" target="_blank" rel="noreferrer noopener nofollow">应用深度学习–第3部分:自动编码器</a></li>



<li><a href="https://web.archive.org/web/20230220131423/https://www.jeremyjordan.me/autoencoders/" target="_blank" rel="noreferrer noopener nofollow">自动编码器简介</a></li>
</ol>
        </div>
        
    </div>    
</body>
</html>