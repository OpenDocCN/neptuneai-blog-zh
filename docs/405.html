<html>
<head>
<title>Distributed Training: Frameworks and Tools </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>分布式培训:框架和工具</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/distributed-training-frameworks-and-tools#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/distributed-training-frameworks-and-tools#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>深度学习的最新发展已经带来了一些令人着迷的最新成果，特别是在自然语言处理和计算机视觉等领域。成功的几个原因通常来自于大量数据的可用性和<a href="https://web.archive.org/web/20230307085657/https://towardsdatascience.com/review-of-recent-advances-in-dealing-with-data-size-challenges-in-deep-learning-ac5c1844af73" target="_blank" rel="noreferrer noopener nofollow">不断增长的深度学习(DL)模型</a>。这些算法能够提取有意义的模式，并推导出输入和输出之间的相关性。但开发和训练这些复杂的算法可能需要几天，有时甚至几周，这也是事实。</p>



<p>为了解决这个问题，需要一种快速有效的方法来设计和开发新的模型。人们不能在单个GPU上训练这些模型，因为这将导致信息瓶颈。为了解决单核GPU上的信息瓶颈问题，我们需要使用多核GPU。这就是<strong>分布式培训</strong>的想法出现的地方。</p>



<p>在本文中，我们将研究一些用于分布式培训的最佳框架和工具。但在此之前，让我们快速了解一下分布式培训本身。</p>



<h2 id="distributed-training">分布式培训</h2>



<p>DL训练通常依赖于可伸缩性，可伸缩性简单地意味着DL算法学习或处理任意数量数据的能力。本质上，任何DL算法的可扩展性取决于三个因素:</p>



<div id="case-study-numbered-list-block_e206ac8011b1dea9114e2d724887b5f9" class="block-case-study-numbered-list ">

    
    <h2 id="h-"/>

    <ul class="c-list">
                    <li class="c-list__item"><span class="c-list__counter"> 1 </span>深度学习模型的规模和复杂性</li>
                    <li class="c-list__item"><span class="c-list__counter"> 2 </span>训练数据量</li>
                    <li class="c-list__item"><span class="c-list__counter"> 3 </span>包括GPU和存储单元等硬件在内的基础设施的可用性，以及这些设备之间的平稳集成</li>
            </ul>
</div>



<p><a href="/web/20230307085657/https://neptune.ai/blog/distributed-training" target="_blank" rel="noreferrer noopener">分布式训练</a>满足所有三个要素。它负责模型的大小和复杂性，批量处理训练数据，并在称为节点的多个处理器中拆分和分布训练过程。更重要的是，它大大减少了训练时间，使得迭代时间更短，从而使得实验和部署更快。</p>



<p>分布式培训有两种类型:</p>



<div id="case-study-numbered-list-block_c5e9d946dcfdc95993c47579ad1a27f2" class="block-case-study-numbered-list ">

    
    <h2 id="h-"/>

    <ul class="c-list">
                    <li class="c-list__item"><span class="c-list__counter"> 1 </span>数据并行训练<br/></li>
                    <li class="c-list__item"><span class="c-list__counter"> 2 </span>模型-平行训练</li>
            </ul>
</div>


<div class="wp-block-image">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/00fabf769c270c835db5397a2a8a852d.png" alt="Distributed training model parallelism vs data parallelism " class="wp-image-61294" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-training-model-data-parallelism.png?ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training model parallelism vs data parallelism | <a href="https://web.archive.org/web/20230307085657/https://towardsdatascience.com/deep-learning-on-supercomputers-96319056c61f" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>在数据并行训练中，数据根据可用于训练的节点数量划分为子集。并且在所有可用节点中共享相同的模型架构。在训练过程中，所有节点必须相互通信，以确保每个节点的训练相互同步。这是训练模型最有效的方法，也是最常见的做法。</p>



<p>在模型并行训练中，DL模型根据可用节点的数量被分割成多个部分。每个节点都被馈送相同的数据。在模型并行训练中，DL模型本身被分成不同的段，然后每个段被馈送到不同的节点。如果DL模型具有可以单独训练的独立组件，则这种类型的训练是可能的。请记住，每个节点必须在模型不同部分的共享权重和偏差方面保持同步。</p>



<p>在这两种类型的培训中，数据并行性是非常常用的，当我们发现分布式培训的框架时，您会发现无论模型并行性如何，它们都提供数据并行性。</p>



<h2 id="criteria-for-choosing-the-right-framework-for-distributed-training">为分布式培训选择正确框架的标准</h2>



<p>在我们深入研究框架之前，在选择正确的框架和工具时，有几点需要考虑:</p>



<ol>
<li><strong>计算图类型:</strong>整个深度学习社区主要分为两派，一派使用PyTorch或动态计算图，另一派使用TensorFlow或静态计算图。因此，大多数分布式框架都建立在这两个库之上已经不是什么新闻了。所以，如果你喜欢其中一个，那么你已经做了一半的决定。</li>



<li><strong>培训成本</strong>:当您处理分布式计算时，负担能力是一个关键问题，例如，一个涉及BigGAN培训的项目可能需要大量的GPU，成本可能会随着数量的增加而成比例增加。因此，价格适中的工具总是正确的选择。</li>



<li><strong>培训类型</strong>:根据您的培训需求，即数据并行或模型并行，您可以选择其中一种工具。</li>



<li><strong>效率</strong>:这个基本上是指你需要写多少行才能启用分布式训练，越少越好。</li>



<li>灵活性:你选择的框架可以跨平台使用吗？尤其是当你需要在内部或者云平台上进行培训的时候。</li>
</ol>







<h2 id="frameworks-for-distributed-training">分布式培训框架</h2>



<p>现在，让我们讨论一些提供分布式培训的图书馆。</p>



<section id="blog-intext-cta-block_519e65445749da8fa6f9129dc357552e" class="block-blog-intext-cta  c-box c-box--default c-box--dark c-box--no-hover c-box--standard ">

            
    
            <p>在Neptune中，你可以<a href="https://web.archive.org/web/20230307085657/https://docs.neptune.ai/how-to-guides/neptune-api/distributed-computing" target="_blank" rel="noopener">跟踪来自许多进程</a>的数据，特别是在不同机器上运行的数据。</p>
    
    </section>



<h3 id="1-pytorch">1. PyTorch</h3>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/d0a3e6c2c9df5b69447c30c019e6fbce.png" alt="Distributed training: PyTorch" class="wp-image-61137" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_12.png?resize=469%2C94&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: PyTorch | <a href="https://web.archive.org/web/20230307085657/https://github.com/pytorch/pytorch" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>PyTorch是脸书开发的最流行的深度学习框架之一。它是最灵活、最容易学习的框架之一。PyTorch允许您非常有效地创建和实现神经网络模块，通过其分布式训练模块，您可以用几行代码轻松实现并行训练。</p>



<p>PyTorch提供了多种执行分布式培训的方法:</p>



<ol>
<li><a href="https://web.archive.org/web/20230307085657/https://pytorch.org/docs/stable/nn.html#dataparallel" target="_blank" rel="noreferrer noopener nofollow"> <strong> nn。DataParallel </strong> </a> <strong> : </strong>这个包可以让你在一台有多个GPU的机器上进行并行训练。一个优点是它需要最少的代码。</li>



<li><a href="https://web.archive.org/web/20230307085657/https://pytorch.org/docs/stable/nn.html#distributeddataparallel" target="_blank" rel="noreferrer noopener nofollow"> <strong> nn。DistributedDataParallel </strong> </a>:这个包允许你在多台机器内跨多个GPU进行并行训练。配置培训流程还需要一些额外的步骤。</li>



<li><a href="https://web.archive.org/web/20230307085657/https://pytorch.org/docs/stable/rpc.html" target="_blank" rel="noreferrer noopener nofollow"><strong>torch . distributed . RPC</strong></a><strong>:</strong>这个包允许你执行模型并行策略。如果您的模型很大，并且不适合单个GPU，这将非常有效。</li>
</ol>



<h4 id="advantages">优势</h4>



<ol>
<li>很容易实现。</li>



<li>PyTorch非常用户友好。</li>



<li>提供现成的数据并行和模型并行方法。</li>



<li>大多数云计算平台都支持PyTorch。</li>
</ol>



<h4 id="when-to-use-pytorch">什么时候用PyTorch？</h4>



<p>在以下情况下，您应该选择PyTorch:</p>



<ul>
<li>你有大量的数据，因为数据并行很容易实现。</li>
</ul>


















<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/78a2c31a8f4e88b0180b61ffd684858f.png" alt="Distributed training: DeepSpeed" class="wp-image-61156" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_16.png?resize=405%2C150&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: DeepSpeed | <a href="https://web.archive.org/web/20230307085657/https://github.com/microsoft/DeepSpeed" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>PyTorch分布式培训专门研究数据并行。DeepSpeed构建于PyTorch之上，目标是其他方面，即模型并行性。DeepSpeed由微软开发，旨在为大规模模型提供分布式训练。</p>



<p>当训练具有数万亿个参数的模型时，DeepSpeed可以有效地应对内存挑战。它减少了内存占用，同时保持了计算和通信效率。有趣的是，DeepSpeed提供了3D并行性，通过它你可以分发数据、模型和管道，这基本上意味着现在你可以训练一个大型的、消耗大量数据的模型，就像GPT-3或图灵NLG一样。</p>



<h4 id="advantages">优势</h4>



<ol>
<li>模型扩展到数万亿个参数。</li>



<li>训练速度提高10倍。</li>



<li>民主化人工智能，这意味着用户可以在单个GPU上运行更大的模型，而不会耗尽内存。</li>



<li>压缩训练允许用户通过减少计算注意力操作所需的内存来训练注意力模型。</li>



<li>易学易用。</li>
</ol>



<h4 id="when-to-use-deepspeed">何时使用DeepSpeed？</h4>



<p>在以下情况下，您应该选择DeepSpeed:</p>



<ul>
<li>你想做数据和模型并行。</li>



<li>如果你的代码库是基于PyTorch的。</li>
</ul>














<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/3dd56b1b7b5215ccb30023d87e54a36f.png" alt="Distributed training: TensorFlow" class="wp-image-61145" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_4.png?resize=450%2C151&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: TensorFlow | <a href="https://web.archive.org/web/20230307085657/https://github.com/tensorflow/tensorflow" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>TensorFlow由Google开发，它支持分布式训练。它使用数据并行技术进行训练。您可以通过使用<strong> tf.distribute </strong> API来利用TensorFlow上的分布式培训。该API允许您根据自己的需求配置培训。默认情况下，TensorFlow只使用一个GPU，但tf.distribute允许您使用多个GPU。</p>



<p>TensorFlow提供了三种主要类型的分布式培训策略:</p>



<ol>
<li><strong>TF . distribute . mirroredstrategy()</strong>:这个简单的策略允许你在一台机器上的多个GPU之间分配训练。这种方法也称为同步数据并行。值得注意的是，每个工人节点将有自己的一套梯度。这些梯度然后被平均并用于更新模型参数。</li>
</ol>



<ol start="2">
<li><strong>TF . distribute . multiworkermirroredstrategy()</strong>:这个策略允许你将训练分布到多台机器和单台机器上的多个GPU上。所有操作都类似于tf.distribute.MirroredStrategy()。这也是一种同步数据并行方法。</li>
</ol>



<ol start="3">
<li><strong>TF . distribute . experimental . parameter server strategy()</strong>:这是一种异步数据并行方法，在多台机器上按比例放大模型训练是常见的做法。在这种策略中，参数存储在参数服务器中，工人相互独立。这种策略可以很好地扩展，因为工作节点不需要等待彼此的参数更新。</li>
</ol>



<h4 id="advantages">优势</h4>



<ol>
<li>巨大的社区支持。</li>



<li>这是一个静态的编程范例。</li>



<li>与谷歌云和其他基于云的服务非常好地集成。</li>
</ol>



<h4 id="when-to-use-distributed-tensorflow">什么时候使用分布式张量流？</h4>



<p>您应该使用分布式张量流:</p>



<ul>
<li>如果要做数据并行。</li>



<li>如果你喜欢与动态相比的静态编程范式。</li>



<li>如果你在谷歌云生态系统中，因为TensorFlow针对TPU进行了很好的优化。</li>



<li>最后，如果您有大量数据并且需要高处理能力。</li>
</ul>














<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/d0bfe20456f8f26a59836a0309809792.png" alt="Distributed training: TensorFlow" class="wp-image-61145" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_4.png?resize=453%2C152&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: TensorFlow | <a href="https://web.archive.org/web/20230307085657/https://github.com/tensorflow/tensorflow" target="_blank" rel="noreferrer noopener nofollow"/><a href="https://web.archive.org/web/20230307085657/https://github.com/tensorflow/tensorflow">Source</a></em></figcaption></figure></div>


<p>Mesh Tensorflow也是Tensorflow分布式训练的扩展，但专门设计用于在张量处理单元(TPUs)上训练大型DL模型，AI加速类似于GPU，但速度更快。虽然Mesh TensorFlow可以执行数据并行，但它旨在解决参数无法在一台设备上安装的大型模型的分布式训练。</p>



<p>Mesh TensorFlow受同步数据并行方法的启发，即每个工人都参与每个操作。除此之外，所有的工人将有相同的程序，它使用像Allreduce集体沟通。</p>



<h4 id="advantages">优势</h4>



<ol>
<li>它可以训练具有数百万和数十亿参数的大型模型，如:GPT-3，GPT-2，伯特，等等。</li>



<li>工作人员潜在的低延迟。</li>



<li>良好的TensorFlow社区支持。</li>



<li>谷歌TPU豆荚的可用性。</li>
</ol>



<h4 id="when-to-use-mesh-tensorflow">什么时候使用网格张量流？</h4>



<p>应该使用网格张量流:</p>



<ul>
<li>如果你想做模型并行。</li>



<li>如果你想开发巨大的模型和实践快速成型。</li>



<li>如果您特别是在处理大量数据的自然语言处理领域工作。</li>
</ul>














<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/d0bfe20456f8f26a59836a0309809792.png" alt="Distributed training: TensorFlow" class="wp-image-61145" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_4.png?resize=453%2C152&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: TensorFlow | <a href="https://web.archive.org/web/20230307085657/https://github.com/tensorflow/tensorflow" target="_blank" rel="noreferrer noopener nofollow"/><a href="https://web.archive.org/web/20230307085657/https://github.com/tensorflow/tensorflow">Source</a></em></figcaption></figure></div>


<p><strong> Apache Spark </strong>是最知名的开源大数据处理平台之一。它允许用户进行各种与数据相关的工作，如数据工程、数据科学和机器学习。我们已经知道张量流是什么了。但是如果你想在Apache Spark上使用TensorFlow，那么你必须使用TensorFlowOnSpark。</p>



<p>TensorFlowOnSpark是一个机器学习框架，允许您在Apache Spark集群和Apache Hadoop上执行分布式训练。它是由雅虎开发的。该框架允许分布式训练和推理，对共享网格上的现有TensorFlow代码进行最小的代码改变。</p>



<h4 id="advantages">优势</h4>



<ol>
<li>允许使用现有TensorFlow程序轻松迁移到Spark集群。</li>



<li>代码中的更改更少。</li>



<li>所有TensorFlow功能都可用。</li>



<li>Spark和TensorFlow可以分别高效地推送和拉取数据集。</li>



<li>云开发在CPU或GPU上简单高效。</li>



<li>可以轻松创建培训管道。</li>
</ol>



<h4 id="when-to-use-tensorflowonspark">何时使用TensorFlowOnSpark？</h4>



<p>您应该使用TensorflowOnSpark:</p>



<ul>
<li>如果您的工作流基于Apache Spark，或者您更喜欢Apache Spark。</li>



<li>如果你的首选框架是TensorFlow。</li>
</ul>


















<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/531f1b0d9edb7b849958cf20ce03bb8b.png" alt="Distributed training: BigDL" class="wp-image-61135" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_14.png?resize=264%2C131&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: BigDL | <a href="https://web.archive.org/web/20230307085657/https://github.com/intel-analytics/BigDL" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>BigDL也是Apache Spark分布式培训的开源框架。它是由英特尔开发的，允许DL算法运行Hadoop和Spark集群。BigDL的一大优势是，它可以帮助您轻松地构建和处理端到端管道中的生产数据，用于数据分析和深度学习应用程序。</p>



<p>BigDL提供了两个选项:</p>



<ol>
<li>您可以像使用Apache Spark为数据工程、数据分析等提供的任何其他库一样直接使用BigDL。</li>



<li>您可以在Spark生态系统中横向扩展python库，如PyTorch、TensorFlow和Keras。</li>
</ol>



<h4 id="advantages">优势</h4>



<ol>
<li><strong>端到端管道</strong>:如果您的大数据杂乱而复杂，这通常是在实时数据流的情况下，那么采用BigDL是合适的，因为它在端到端管道中集成了数据分析和深度学习。</li>



<li><strong>效率</strong>:Spark BigDL采用跨不同组件的集成方法，使得所有组件的开发、部署和运营直接、无缝且高效。</li>



<li><strong>通信和计算</strong>:由于所有的硬件和软件都是缝合在一起的，所以它们运行流畅，没有任何中断，使得不同工作流之间的通信清晰，计算速度更快。</li>
</ol>



<h4 id="when-to-use-bigdl">什么时候使用BigDL？</h4>



<p>您应该使用BigDL:</p>



<ul>
<li>如果您想开发一个Apache Spark工作流，</li>



<li>如果您的首选框架是PyTorch。</li>



<li>如果你想持续集成所有组件，如数据挖掘、数据分析、机器学习等等。</li>
</ul>














<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/f5d3f77c42888c6962290ea53a125147.png" alt="Distributed training: Horovod" class="wp-image-61139" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_10.png?resize=257%2C257&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: Horovod | <a href="https://web.archive.org/web/20230307085657/https://github.com/horovod/horovod" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>Horovod是优步在2017年推出的。这是一个开源项目，专门用于分布式培训。它是米开朗基罗的内部组件，米开朗基罗是优步用来实现其DL算法的深度学习工具包。Horovod利用数据并行分布式培训，这使得扩展变得非常容易和高效。它还可以在大约5行python代码中扩展到数百个GPU。这个想法是为单个GPU编写一个训练脚本，Horovod可以将其扩展到多个并行的GPU上进行训练。</p>



<p>Horovod是为Tensorflow、Keras、Pytorch和Apache MXNet等框架构建的。这是易于使用和快速。</p>



<h4 id="advantages">优势</h4>



<ol>
<li>如果熟悉Tensorflow、Keras、Pytorch和Apache MXNet，很容易学习和实现。</li>



<li>如果您使用Apache Spark，那么您可以在一个管道上统一所有的进程。</li>



<li>良好的社区支持。</li>



<li>它很快。</li>
</ol>



<h4 id="when-to-use-horovod">何时使用Horovod？</h4>



<p>您应该使用Horovod:</p>



<ul>
<li>如果您希望在多个GPU之间快速扩展单个GPU脚本。</li>



<li>如果你使用微软Azure作为你的云计算平台。</li>
</ul>














<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/cde47843a938193e3e4f343ae066ece5.png" alt="Distributed training: Ray" class="wp-image-61144" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_5.png?resize=453%2C141&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: Ray | <a href="https://web.archive.org/web/20230307085657/https://github.com/ray-project/ray" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>Ray是构建在Pytorch之上的另一个用于分布式培训的开源框架。它提供了在任何云提供商上启动GPU集群的工具。与我们迄今为止讨论的任何其他库不同，Ray非常灵活，可以在任何地方工作，如Azure、GCD、AWS Apache Spark和Kubernetes。</p>



<p>Ray在其捆绑包中提供了以下库，用于超参数调整、强化学习、深度学习、缩放等等:</p>



<ol>
<li><a href="https://web.archive.org/web/20230307085657/https://docs.ray.io/en/master/tune.html" target="_blank" rel="noreferrer noopener nofollow">调优</a>:可伸缩超参数调优。</li>



<li><a href="https://web.archive.org/web/20230307085657/https://docs.ray.io/en/master/rllib/index.html" target="_blank" rel="noreferrer noopener nofollow"> RLlib </a>:分布式强化学习。</li>



<li><a href="https://web.archive.org/web/20230307085657/https://docs.ray.io/en/master/train/train.html" target="_blank" rel="noreferrer noopener nofollow"> Train </a>:分布式深度学习，目前测试版。</li>



<li><a href="https://web.archive.org/web/20230307085657/https://docs.ray.io/en/master/data/dataset.html" target="_blank" rel="noreferrer noopener nofollow">数据集</a>:分布式数据加载和计算，目前处于测试版。</li>



<li><a href="https://web.archive.org/web/20230307085657/https://docs.ray.io/en/master/serve/index.html" target="_blank" rel="noreferrer noopener nofollow">发球</a>:可伸缩可编程发球。</li>



<li><a href="https://web.archive.org/web/20230307085657/https://docs.ray.io/en/master/workflows/concepts.html" target="_blank" rel="noreferrer noopener nofollow">工作流程</a>:快速、持久的应用流程。</li>
</ol>



<p>除了这些库之外，Ray还集成了第三方库和框架，允许您以最少的代码更改来开发、培训和扩展您的工作负载。下面给出了集成库的列表:</p>



<ol>
<li>气流</li>



<li>课堂视觉</li>



<li>达斯克</li>



<li>弗兰贝</li>



<li>霍罗沃德</li>



<li>拥抱面部变形金刚</li>



<li>英特尔分析动物园</li>



<li>约翰·斯诺实验室</li>



<li>莱特格姆</li>



<li>路德维希艾</li>



<li>三月</li>



<li>莫丁(莫丁)</li>



<li>插入记号</li>



<li>PyTorch闪电</li>



<li>RayDP</li>



<li>scikit很少学习不在场证明</li>



<li>XGBoost</li>



<li>优势</li>



<li>它支持Jupyter笔记本</li>
</ol>



<h4 id="advantages">它使您的代码在单台和多台机器上并行运行</h4>



<ol>
<li>它集成了多个框架和库。</li>



<li>它适用于所有主要的云计算平台</li>



<li>什么时候用雷？</li>



<li>你应该用雷:</li>
</ol>



<h4 id="when-to-use-ray">如果你想进行分布式强化学习</h4>



<p>如果您想要执行分布式超参数调整</p>



<ol>
<li>如果您想在不同的机器上使用分布式数据加载和计算。</li>



<li>如果你想为你的应用服务。</li>



<li>分布式培训的云平台</li>



<li>到目前为止，我们已经讨论了可用于支持分布式培训的框架和库。现在，让我们来讨论和探索云平台，在这里您可以使用硬件来高效地训练您的DL模型。但在此之前，让我们列出一些标准，让您能够根据自己的需求选择最佳的云平台。</li>
</ol>











<h2 id="cloud-platforms-for-distributed-training"><strong>硬件和软件支持:</strong>学习和理解这些平台提供的硬件(如GPU、TPU、存储单元等)非常重要。除此之外，你还应该看到他们提供的API，这样(取决于你的项目)你就可以访问托管设施、容器、数据分析工具等等。</h2>



<p>可用性区域:可用性区域是云计算中的一个重要因素，它为用户提供了在世界任何地方建立和部署项目的灵活性。用户也可以随时转移他们的项目。</p>



<ol>
<li><strong>定价:</strong>平台是根据你的使用情况收费，还是提供基于订阅的模式。</li>



<li>现在，让我们讨论云计算选项。我们将讨论两个极其可行的即用型实验笔记本平台和三个最流行的云计算服务。</li>



<li>Google Colab是中小型项目中最可靠和最容易使用平台之一。Google Colab的一个好处是，你可以轻松地连接到Google Cloud，并且可以使用上面提到的任何python库。它提供三种型号:</li>
</ol>



<p>Google Colab 是免费的，它可以让你访问GPU和TPU。但是你可以使用有限的存储和内存。一旦其中任何一个超过，程序就会停止。</p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/d0fd6173b31e5a06cc67914295f80c83.png" alt="Magic quadrant for cloud infrastructure as a service" class="wp-image-61138" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_11.png?resize=574%2C599&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Magic quadrant for cloud infrastructure as a service | <a href="https://web.archive.org/web/20230307085657/https://www.c-sharpcorner.com/article/top-10-cloud-service-providers/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>





<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/dfcfbbab56f0b1df56fd2c824fdf3a96.png" alt="Distributed training: Google Colab" class="wp-image-61197" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_17.png?resize=311%2C138&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: Google Colab | <a href="https://web.archive.org/web/20230307085657/https://colab.research.google.com/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p><strong> Google Colab Pro </strong>是Google Colab的订阅版本，在这里你有额外的内存和存储空间。你可以运行一个很重的模型，但是它也是有限的。</p>



<ol>
<li>Google Colab Pro + 是一种基于订阅模式的新服务，也很贵。它提供了更快的GPU和TPU以及额外的内存，因此您可以在相当大的数据集上运行相当大的模型。</li>



<li>下面给出的是三者的官方对比。</li>



<li>AWS SageMaker是最受欢迎和最古老的分布式培训云计算平台之一。它与Apache MXNet、Pytorch和TensorFlow非常好地集成在一起，允许您轻松部署深度学习算法，并减少代码修改。SageMaker API有<a href="https://web.archive.org/web/20230307085657/https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html" target="_blank" rel="noreferrer noopener nofollow"> 18+机器学习算法</a>，其中一些算法是从零开始重写的，使整个过程变得可扩展和简单。这些内置算法经过优化，可以充分利用硬件。</li>
</ol>



<p>SageMaker还有一个集成的Jupyter笔记本，允许数据科学家和机器学习工程师在旅途中构建和开发管道算法，并允许您直接在托管环境中部署它们。您可以从SageMaker Studio或SageMaker控制台根据您的需求和偏好配置硬件和环境。所有的托管和开发都按照每分钟的<strong>使用量计费。</strong></p>












<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/06a002f4b3167ba7c82b36dca7790a62.png" alt="Distributed training: AWS SageMaker" class="wp-image-61143" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_6.png?resize=376%2C160&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: AWS SageMaker | <a href="https://web.archive.org/web/20230307085657/https://nub8.net/machine-learning-with-amazon-sagemaker/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>AWS SageMaker提供数据并行和模型并行分布式培训。事实上，SageMaker还提供了一种混合训练策略，在这种策略中，您可以同时使用模型和数据并行性。</p>



<p>谷歌云计算是谷歌在2010年开发的，旨在加强他们自己的平台，如谷歌搜索引擎和Youtube。渐渐地，他们开始向公众开放源代码。谷歌云计算提供了所有谷歌平台使用的相同基础设施。</p>



<p>Google云计算为TensorFlow、Pytorch、Scikit-Learn等库提供内置支持。此外，除了在工作流程中配置GPU之外，您还可以添加TPU来加快培训过程。就像我之前提到的，你可以将你的谷歌实验室连接到谷歌云平台，并访问它提供的所有功能。</p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/bcc6223860423af70ee2663afe2a5a74.png" alt="Distributed training: AWS SageMaker" class="wp-image-61148" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_1.png?resize=780%2C496&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: AWS SageMaker | <a href="https://web.archive.org/web/20230307085657/https://aws.amazon.com/blogs/machine-learning/the-aws-deep-learning-ami-now-with-ubuntu/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>





<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/5e891dde35f0099f14209ff5b1cb346c.png" alt="Distributed training: Google Cloud Computing" class="wp-image-61134" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_15.png?resize=165%2C165&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: Google Cloud Computing | <a href="https://web.archive.org/web/20230307085657/https://cloud.google.com/" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>它提供的一些功能有:</p>



<p>计算(虚拟硬件，如GPU和TPU)</p>



<p>储物桶，</p>



<ol>
<li>数据库</li>



<li>建立工作关系网</li>



<li>管理工具</li>



<li>安全性</li>



<li>物联网</li>



<li>API平台</li>



<li>托管服务</li>



<li>值得注意的是，与AWS相比，GCP的可用性区域较少，但成本也较低。</li>



<li>微软Azure是另一个非常受欢迎的云计算平台。OpenAI的一个流行语言模型GPT-3就是在Azure中训练出来的。它还提供了<a href="https://web.archive.org/web/20230307085657/https://docs.microsoft.com/en-us/azure/machine-learning/concept-distributed-training#data-parallelism" target="_blank" rel="noreferrer noopener nofollow">数据并行</a>和<a href="https://web.archive.org/web/20230307085657/https://docs.microsoft.com/en-us/azure/machine-learning/concept-distributed-training#model-parallelism" target="_blank" rel="noreferrer noopener nofollow">模型并行</a>方法，并支持TensorFlow和Pytorch。事实上，如果你想优化计算速度，你也可以利用优步的Horovod。</li>
</ol>



<p>Azure机器学习服务面向编码人员和非编码人员。它只是提供了一个拖放方法，可以优化您的工作流程。它还通过自动机器学习减少了手动工作，可以帮助您开发更智能的工作原型。</p>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/8ae55a95010059dcdbb8e0543c79ccd6.png" alt="Distributed training: Google Cloud Computing" class="wp-image-61136" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_13.png?resize=800%2C500&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: Google Cloud Computing | Source: Author</em></figcaption></figure></div>





<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="../Images/62f6df5ae7a4d384c86c449fc4a91dd6.png" alt="Distributed training: Microsoft Azure" class="wp-image-61140" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_9.png?resize=347%2C195&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: Microsoft Azure | <a href="https://web.archive.org/web/20230307085657/https://medium.com/analytics-vidhya/azure-machine-learning-service-part-1-80e43e4af71b" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>Azure Python SDK还允许您在任何Python环境中进行交互，如Jupyter笔记本、Visual Studio代码等等。在提供服务方面，它与AWS和GCP非常相似。这些是Azure提供的服务:</p>



<p>人工智能、机器学习和深度学习</p>



<p>计算能力(GPU)</p>



<ol>
<li>分析学</li>



<li>区块链</li>



<li>容器</li>



<li>数据库</li>



<li>开发者工具</li>



<li>DevOps</li>



<li>物联网</li>



<li>混合现实</li>



<li>移动的</li>



<li>网络等等</li>



<li>让我们一起来比较一下这三个主要工具，让你在选择时有一个更好的视角。</li>



<li>云平台对照表</li>
</ol>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/beb16a7fcd00d0ad73e6564db67325d3.png" alt="Distributed training: Microsoft Azure" class="wp-image-61146" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_3.png?resize=781%2C527&amp;ssl=1"/><figcaption class="wp-element-caption"><em>Distributed training: Microsoft Azure |  <a href="https://web.archive.org/web/20230307085657/https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-dashboards" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<p>最后的想法</p>



<h3 id="comparison-table-for-cloud-platform">在本文中，我们看到了不同的库和工具，它们可以帮助您为自己的深度学习应用程序实现分布式培训。请记住，所有的库都是好的，并且在它们所做的事情上非常有效，最终，这一切都归结于您的偏好和需求。</h3>


<div class="wp-block-image is-style-default">
<figure class="aligncenter size-full"><img decoding="async" src="../Images/7f4189da541b7fe12fe77922030e1c6f.png" alt="Comparison table for cloud platform" class="wp-image-61147" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230307085657im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Distributed-Training-Libraries-and-Tools_2.png?ssl=1"/><figcaption class="wp-element-caption"><em>Comparison table for cloud platform | <a href="https://web.archive.org/web/20230307085657/https://medium.com/georgian-impact-blog/comparing-google-cloud-platform-aws-and-azure-d4a52a3adbd2" target="_blank" rel="noreferrer noopener nofollow">Source</a></em></figcaption></figure></div>


<h2 id="final-thoughts">您一定已经注意到，所有讨论的框架都主要以某种方式集成了Pytorch和TensorFlow。这个特质很容易帮你隔离选择的框架。一旦你的框架确定下来，你就可以看看它的优势，决定哪种分布式培训工具最适合你。</h2>



<p>我希望你喜欢这篇文章。如果你想尝试我们讨论过的所有框架，那么请点击教程链接。</p>



<p>感谢阅读！</p>



<p>参考</p>



<p>Thanks for reading!</p>



<h3 id="references">References</h3>




        </div>
        
    </div>    
</body>
</html>