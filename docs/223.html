<html>
<head>
<title>MLflow vs Kubeflow vs neptune.ai: What Are the Differences? </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>MLflow vs Kubeflow vs neptune.ai:有什么区别？</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/mlflow-vs-kubeflow-vs-neptune-differences#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/mlflow-vs-kubeflow-vs-neptune-differences#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>作为一名数据科学家、ML/DL研究人员或工程师，您可能会遇到或听说过MLflow、Kubeflow和neptune.ai。由于ML和DL的大量采用，围绕部署、可伸缩性和可再现性出现了许多问题。因此，MLOps作为数据工程、DevOps和机器学习的混合体而诞生。</p>



<p>我们必须为ML想出这种新的方法，因为ML开发是复杂的。</p>



<p>很自然的问题是为什么？</p>



<p>很自然的，你可能会认为是因为数学，算法，需要的资源(GPU，TPUs，CPUs)，数据，API，库，框架。嗯，有一部分是真的，但不完全是，因为现在大部分都被我们抽象化了。如果我们以拥抱脸或fast.ai为例，你只需调用一个特定类的实例，框架/库就会帮你完成所有繁重的工作。再者，随着<strong> <a href="/web/20230304141727/https://neptune.ai/blog/transfer-learning-guide-examples-for-images-and-text-in-keras" target="_blank" rel="noreferrer noopener">迁移学习</a> </strong>的发展，我们不再需要海量的数据来训练一个模型。</p>



<p>那么复杂性从何而来？</p>



<p>复杂性来自几个方面:</p>



<ol>
<li>ML本质上是实验性的</li>



<li>它有更多的部分需要考虑，例如:数据(收集、标记、版本化)、模型(培训、评估、版本化和部署)和配置(超参数等等)。</li>



<li>我们如何进行传统软件开发(DevOps)的<a href="/web/20230304141727/https://neptune.ai/blog/data-science-project-management-in-2021-the-new-guide-for-ml-teams" target="_blank" rel="noreferrer noopener nofollow">范式</a>不同于我们如何进行ML (MLOps)。</li>
</ol>



<p>随着<a href="/web/20230304141727/https://neptune.ai/blog/mlops-what-it-is-why-it-matters-and-how-to-implement-it-from-a-data-scientist-perspective" target="_blank" rel="noreferrer noopener"> MLOps </a>的成熟，许多工具已经出现并正在出现，以解决工作流的不同部分，这三个工具在MLOps工作流中发挥着关键作用，以降低复杂性并解决我们将在后面的章节中讨论的问题。</p>





<p>现在，他们到底是做什么的，他们是如何相互比较的？</p>



<p>在这篇文章中，我们将回答这些问题，甚至更多。以下是我们正在解决的问题:</p>



<ul>
<li>工具<ul>
<li>MLflow</li>



<li>库贝弗洛</li>



<li>neptune.ai</li>
</ul>
</li>



<li>你应该在什么时候使用哪一个？</li>



<li>高级功能对照表</li>
</ul>



<p>让我们开始吧！</p>



<h2 id="h-mlflow">MLflow</h2>



<div class="is-layout-flex wp-container-3 wp-block-columns are-vertically-aligned-center">
<div class="is-layout-flow wp-block-column is-vertically-aligned-center">
<p>这是一个<strong>开源</strong> MLOps平台，它诞生于学习大技术的标准，专注于创建可转移的知识、易用性、模块化以及与流行的ML库和框架的兼容性。它是为1人或1000多人的组织设计的。</p>
</div>




</div>



<p>MLFlow允许您在本地或远程开发、跟踪(和比较实验)、打包和部署。它处理从数据版本化、模型管理、<a href="/web/20230304141727/https://neptune.ai/experiment-tracking" target="_blank" rel="noreferrer noopener">实验跟踪</a>到部署的所有事情，除了数据源、标签和流水线。</p>



<p>它几乎是MLOps工作流程的万金油和/或瑞士刀。</p>





<p>该平台由4个组件组成:</p>



<ul>
<li>物流跟踪</li>



<li>MLflow项目</li>



<li>ml流程模型</li>



<li>只是模型注册表</li>
</ul>



<p>让我们更深入地了解这些组件中每一个的重要性以及它们是如何工作的。</p>



<h3>物流跟踪</h3>



<p>MLflow跟踪组件是一个API和UI，用于在运行机器学习代码时记录参数、代码版本、指标和输出文件，并在以后可视化和比较结果。MLflow Tracking允许您使用Python、REST、R API和Java API APIs来记录和查询实验。</p>



<p>如前所述，MLFlow允许本地或远程开发，因此实体和工件存储都是可定制的，这意味着您可以在本地或云上保存(AWS s3，GCP等)</p>



<p><strong>跟踪中的关键概念</strong></p>



<ul>
<li>参数:代码的键值输入</li>



<li>指标:数值(可以随时更新)</li>



<li>标签和注释:关于跑步的信息</li>



<li>工件:文件、数据和模型</li>



<li>来源:运行了什么代码？</li>



<li>版本:代码运行的版本是什么？</li>



<li>Run:由MLFlow运行的代码实例，其中将记录度量和参数</li>
</ul>



<p><strong>跟踪API</strong></p>



<ul>
<li>流畅的MLFlow APIs(高级)</li>



<li>MLFlow客户端(低级)</li>
</ul>



<h3>MLflow项目</h3>



<p>MLflow项目是一个独立的执行单元，包含以下内容:</p>



<ul>
<li>密码</li>



<li>配置</li>



<li>属国</li>



<li>数据</li>
</ul>



<p>将其部署在本地或远程服务器上。</p>



<p>这种格式有助于再现性，并允许创建具有单独项目(或同一项目中的入口点)作为单个步骤的多步骤工作流。</p>





<p>换句话说，MLflow项目只是一个组织和描述代码的约定，以便让其他数据科学家(或自动化工具)运行它。每个项目只是一个文件目录，或者一个Git存储库，包含您的代码。MLflow可以根据在此目录中放置文件的惯例运行一些项目(例如，conda.yaml文件被视为conda环境)，但您可以通过添加MLproject文件来更详细地描述您的项目，该文件基本上是yaml格式的文本文件。</p>



<h3>ml流程模型</h3>



<p>MLflow模型是打包机器学习模型的标准格式，可用于各种下游工具，例如，通过REST API或Apache Spark上的批处理推理进行实时服务。该格式定义了一个约定，允许您以不同的“风格”保存模型，这些风格可以被不同的下游工具所理解。</p>





<p>口味是使MLFlow模型强大的关键概念:它们是部署工具可以用来理解模型的约定。基本上，我们通过创建一种中间格式来抽象模型，该格式将您想要部署到各种环境中的模型打包，就像模型的docker文件或lambda函数一样，您可以将它部署到所需的环境中，并调用其名为predict的评分函数。</p>



<h3>模型注册表</h3>





<p>MLflow模型注册组件是一个集中式模型存储、一组API和UI，用于协作管理MLflow模型的整个生命周期。它提供了模型沿袭(MLflow实验和运行产生了模型)、模型版本化、阶段转换(例如从阶段转换到生产)和注释。</p>







<h2 id="h-kubeflow">Kubeflow</h2>



<div class="is-layout-flex wp-container-6 wp-block-columns are-vertically-aligned-center">
<div class="is-layout-flow wp-block-column is-vertically-aligned-center">
<p>Kubeflow是一个<strong>开源</strong>项目，它利用Kubernetes构建可扩展的MLOps管道并编排复杂的工作流。您可以将其视为Kubernetes的机器学习(ML)工具包。</p>



<p><strong> <em>注</em> </strong> <em> : Kubernetes(或简称K8s)是一个容器编排工具。</em></p>
</div>




</div>



<p>现在，出现了两个问题:</p>



<ol>
<li>为什么要容器化你的ML应用？</li>



<li>为什么K8s上的ML？</li>
</ol>



<h3>为什么要将ML应用容器化</h3>



<p>通常团队中不同的人所处的环境是不同的，这些差异可以延伸到:</p>



<ul>
<li>依赖性(库、框架和版本)</li>



<li>代码(辅助功能、培训和评估)</li>



<li>配置(数据转换、网络架构、批量大小等)</li>



<li>软件和硬件</li>
</ul>



<p>如果两个或两个以上的成员要合作或继承某人的工作并做出改进，这会导致各种各样的问题。</p>



<p>但是通过容器，你可以简单地发送一个docker镜像，只要对方在本地或者他的云环境中安装了docker。他可以轻而易举地重现同样的环境、实验和结果。</p>



<h4>集装箱的好处</h4>



<ul>
<li>包装:<ul>
<li>密码</li>



<li>属国</li>



<li>配置</li>
</ul>
</li>
</ul>



<ul>
<li>帮助创建ML envs:<ul>
<li>轻量级选手</li>



<li>轻便的</li>



<li>可攀登的</li>
</ul>
</li>
</ul>



<h3>为什么K8s上的ML？</h3>





<p>正如我之前提到的，K8s是一个容器编排工具。它实现了容器化应用程序的自动化部署、扩展和管理。但问题在于k8s本身的管理，它可能是heptic。但是现在有不同的k8s即服务提供商，例如:AWS EKS、Google GKE和Azure AKS。</p>



<p>使用托管k8s作为服务，允许ML从业者充分利用k8s带来的好处，例如:</p>



<ul>
<li>可组合性</li>



<li>轻便</li>



<li>可量测性</li>



<li>或者它已经是公司或团队工作流程的一部分</li>
</ul>



<p>既然我们已经解决了这个问题，让我们更详细地看看Kubeflow。</p>



<h3>Kubeflow组件</h3>



<p><strong> Kubeflow </strong>由各种项目/工具组成，但这里我们将重点关注4个主要项目:</p>



<ul>
<li>笔记本电脑</li>



<li>管道</li>



<li>培养</li>



<li>服务</li>
</ul>



<p><strong>笔记本</strong></p>



<p>Kubeflow包括创建和管理交互式Jupyter笔记本的服务。您可以自定义笔记本电脑部署和计算资源，以满足您的数据科学需求。在本地试验您的工作流，然后在准备就绪时将它们部署到云中。</p>



<p><strong>管道</strong></p>





<p>这可能是最著名的项目，也是很多团队选择kubeflow的原因。简而言之，kubeflow pipelines是一个基于Docker容器构建和部署可移植、可扩展的机器学习(ML)工作流的平台——它可作为kubeflow组件或独立安装使用。</p>



<p>该项目的核心是两个部分:</p>



<ul>
<li><strong>Pipeline</strong>–是对ML工作流的描述，包括工作流中的所有组件以及它们如何以图表的形式组合在一起。管道包括运行管道所需的输入(参数)以及每个管道组件的输入和输出的定义。</li>



<li><strong>管道组件</strong>–是一组独立的用户代码，打包成Docker映像，执行管道中的一个步骤。例如，一个组件可以负责数据预处理、数据转换、模型训练等等。</li>
</ul>



<p><strong>管道特征</strong></p>



<ul>
<li>用于管理和跟踪实验、作业和运行的用户界面(UI)。</li>



<li>用于安排多步骤ML工作流的引擎。</li>



<li>用于定义和操作管道和组件的SDK。</li>



<li>使用SDK与系统交互的笔记本电脑。</li>



<li>可重用性:使您能够重用组件和管道，而不必每次都重新构建。</li>
</ul>



<p><strong>训练</strong></p>



<p>该项目为您提供了不同的培训ML模型框架，例如:</p>



<ul>
<li>链式训练</li>



<li>MPI培训</li>



<li>MXNet培训</li>



<li>PyTorch培训</li>



<li>作业调度</li>



<li>张量流训练(TFJob)</li>
</ul>



<p>在这里，您可以执行培训工作，监控培训和更多。其中一个很酷的特性实际上是能够容易地定义和利用kubernetes副本，它允许您旋转容器映像的多个相同版本。因此，如果一个或多个副本在培训作业期间失败，您的进度不会完全丢失，因为您有另一个版本在并行运行。</p>



<p><strong>上菜</strong></p>



<p>说到服务模型，kubeflow提供了很大的支持。</p>



<p>Kubeflow有一个名为KFServing的组件，它支持Kubernetes上的无服务器推理，并为TensorFlow、XGBoost、scikit-learn、PyTorch和ONNX等常见机器学习(ML)框架提供高性能、高抽象的接口，以解决生产模型服务用例。</p>



<p>KFServing可用于以下目的:</p>



<ul>
<li>为在任意框架上服务ML模型提供Kubernetes定制资源定义。</li>



<li>封装自动扩展、网络、健康检查和服务器配置的复杂性，为您的ML部署带来尖端的服务功能，如GPU自动扩展、零扩展和canary部署。</li>



<li>通过提供现成的预测、预处理、后处理和可解释性，为您的生产ML推理服务器提供一个简单、可插入和完整的故事。</li>
</ul>



<p>此外，除了KFserving，Kubeflow还支持TensorFlow服务容器将训练好的TensorFlow模型导出到Kubernetes。它还与Seldon Core(一个用于在Kubernetes上部署机器学习模型的开源平台)和NVIDIA Triton Inference Server集成，以便在大规模部署ML/DL模型时最大化GPU利用率。最后，它还支持<a href="https://web.archive.org/web/20230304141727/https://www.bentoml.com/" target="_blank" rel="noreferrer noopener nofollow"> BentoML </a>，这是一个用于高性能ML模型服务的开源平台。它使得为您的ML模型构建生产API端点变得容易，并支持所有主要的机器学习培训框架，包括Tensorflow、Keras、PyTorch、XGBoost、scikit-learn等</p>



<p>但这并没有结束，除此之外，你还可以在Kubernetes Engine和AWS、GCP或Azure上运行Kubeflow。以AWS为例，Kubeflow与AWS Sagemaker进行了集成，允许您充分利用这种托管服务带来的规模优势。</p>



<p>在我看来，我不认为端到端的ML平台是一条出路。更多细节你可以稍后阅读这篇 <a href="https://web.archive.org/web/20230304141727/https://neptune.ai/blog/mlops-what-it-is-why-it-matters-and-how-to-implement-it-from-a-data-scientist-perspective"> <em>文章</em> </a> <em>我会详细解释，一旦你完成这篇文章。</em></p>



<p>我相信微服务可以让您更加灵活地将任何新服务插入到您的管道中，或者替换损坏的服务/组件或工具，但kubeflow和这些不同的云提供商等集成可以让您构建更强大的解决方案。</p>







<h2 id="h-neptune-ai">neptune.ai</h2>



<figure class="wp-block-image size-full"><a href="https://web.archive.org/web/20230304141727/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?ssl=1" target="_blank" rel="noopener"><img decoding="async" loading="lazy" src="../Images/aa671c30d75c451bfca8e52a415735f7.png" alt="ML Metadata Store" class="wp-image-15676" srcset="https://web.archive.org/web/20230304141727im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?w=1200&amp;ssl=1 1200w, https://web.archive.org/web/20230304141727im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?resize=768%2C402&amp;ssl=1 768w, https://web.archive.org/web/20230304141727im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?resize=200%2C105&amp;ssl=1 200w, https://web.archive.org/web/20230304141727im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?resize=220%2C115&amp;ssl=1 220w, https://web.archive.org/web/20230304141727im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?resize=120%2C63&amp;ssl=1 120w, https://web.archive.org/web/20230304141727im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?resize=160%2C84&amp;ssl=1 160w, https://web.archive.org/web/20230304141727im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?resize=300%2C157&amp;ssl=1 300w, https://web.archive.org/web/20230304141727im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?resize=480%2C251&amp;ssl=1 480w, https://web.archive.org/web/20230304141727im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?resize=1020%2C534&amp;ssl=1 1020w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230304141727im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2023/01/Metadata-store.png?resize=1200%2C628&amp;ssl=1"/></a></figure>



<p>neptune.ai是MLOps的元数据存储，为运行大量实验的研究和生产团队而构建。</p>



<p>它为您提供了一个中心位置来记录、存储、显示、组织、比较和查询机器学习生命周期中生成的所有元数据。</p>



<p>成千上万的ML工程师和研究人员使用Neptune进行实验跟踪和模型注册，无论是作为个人还是在大型组织的团队内部。</p>



<p>现在，可能会出现一个问题:为什么是元数据存储？</p>



<h3>为什么是元数据存储？</h3>



<p>与notes、组织协议或开源工具不同，正如我之前提到的，元数据存储是一个集中的地方，但它也是轻量级的、自动的，并由组织(在这种情况下是Neptune)或社区维护，因此人们可以专注于实际做ML而不是元数据簿记。</p>



<p>此外，元数据存储是作为MLOps工作流的不同部分/阶段/工具之间的连接器的工具。</p>



<h4>元数据存储的好处</h4>



<ul>
<li>记录和显示所有元数据类型，包括参数、图像、HTML、音频、视频</li>



<li>在仪表板中组织和比较实验</li>



<li>观看模型训练直播</li>



<li>让别人(不是你)来维护和备份它(元数据存储)</li>



<li>无需额外努力即可调试和比较实验和模型</li>



<li>数据库和仪表板都可以通过数千次实验进行扩展</li>



<li>帮助简化从研究到生产的过渡</li>



<li>在其基础上轻松构建定制库/工具</li>
</ul>



<p>既然我们已经解决了这个问题，让我们更详细地看看海王星。</p>



<h3>海王星组件</h3>



<p><strong>海王星</strong>由3个主要部件组成:</p>



<ul>
<li>数据版本化</li>



<li>实验跟踪</li>



<li>模型注册表</li>
</ul>



<h4>数据版本化</h4>





<p>版本控制系统帮助开发人员管理源代码的变更。而数据版本控制是一组工具和过程，其试图使版本控制过程适应数据世界，以管理与数据集相关的模型的改变，反之亦然。换句话说，该功能有助于跟踪我们用来训练模型的特定版本的数据集或数据集的子集，从而实现并促进实验的可重复性。</p>



<p>借助Neptun  e中的<a href="https://web.archive.org/web/20230304141727/https://docs.neptune.ai/how-to-guides/data-versioning" target="_blank" rel="noreferrer noopener">数据版本功能，您可以:</a></p>



<ul>
<li>在使用工件的模型训练运行中跟踪数据集版本</li>



<li>查询以前运行的数据集版本，以确保您在相同的数据集版本上进行训练</li>



<li>根据训练的数据集版本对Neptune跑步进行分组</li>
</ul>



<h4>实验跟踪</h4>





<p>海王星的这个特性帮助你在一个地方组织你的ML实验:</p>



<ul>
<li>记录和显示度量、参数、图像和其他ML元数据</li>



<li>无需额外努力即可搜索、分组和比较实验</li>



<li>在实验运行时实时可视化和调试实验</li>



<li>通过发送持久链接来共享结果</li>



<li>以编程方式查询实验元数据</li>
</ul>



<h4>模型注册表</h4>





<p>这个特性允许您通过在<a href="https://web.archive.org/web/20230304141727/https://docs.neptune.ai/how-to-guides/model-registry" target="_blank" rel="noreferrer noopener">中央模型注册中心</a>中组织您的模型来控制您的模型开发，使它们可重复和可追踪。</p>



<p>这意味着您可以在模型开发到部署的过程中对模型进行版本化、存储、组织和查询。保存的元数据包括:</p>



<ul>
<li>数据集、代码、环境配置版本</li>



<li>参数和评估指标</li>



<li>模型二进制文件、描述和其他细节</li>



<li>测试集预测预览和模型解释</li>
</ul>



<p>此外，它还使地理位置接近或远离的团队能够在实验中进行协作，因为您的团队记录到Neptune的所有内容都可以被每个团队成员自动访问。所以再现性不再是问题。</p>



<p>您可以通过API访问模型训练运行信息，如代码、参数、模型二进制文件或其他对象。</p>



<p>使用Neptune，您可以用一个真实的来源来代替文件夹结构、电子表格和命名约定，在这个来源中，您的所有模型构建元数据都是有组织的，易于查找、共享和查询。</p>



<p>该工具通过记录模型开发过程中发生的所有事情，让您能够控制模型和实验。</p>





<p>这相当于减少了寻找配置和文件、上下文切换、非生产性会议所花费的时间，并将更多时间用于高质量的ML工作。有了Neptune，您不必实现记录器、维护数据库或仪表板，或者教人们如何使用它们。</p>



<p>通过跟踪你已经尝试过的所有想法以及你使用了多少资源，你可以充分利用你的计算资源。实时监控您的ML运行，并在运行失败或模型停止收敛时快速做出反应。</p>



<p>最后，Neptune允许您通过对所有的模型训练运行进行版本化来构建可再现的、兼容的和可追踪的模型，并且还允许您知道谁构建了生产模型，使用了哪些数据集和参数，以及它在任何时候是如何执行的。</p>



<h2 id="h-now-just-tell-me-which-one-and-when-to-use-it">现在，只要告诉我哪一个和什么时候使用它</h2>



<h3>MLflow</h3>



<p>如果您想要一个由<strong>开源</strong>社区支持的MLOps平台，它允许您:</p>



<ul>
<li>跟踪、可视化和比较实验元数据</li>



<li>允许您可视化和比较实验结果的用户界面</li>



<li>开发(打包和部署)模型</li>



<li>允许您创建多步骤工作流的平台(很像Kubeflow管道，但不使用容器)</li>
</ul>



<p>以及一种抽象模型的方法，从而可以轻松地将其部署到各种环境中，那么MLflow就是一种方法。</p>



<h3>Kubeflow</h3>



<p>如果您想要一个端到端<strong>开源</strong>平台，让您能够:</p>



<ul>
<li>管理和设置不同团队的资源配额，以及在本地或云中编码、运行和跟踪实验元数据</li>



<li>能够使用跨越整个ML生命周期(从数据收集一直到模型构建和部署)的组件构建可重复的管道，那么kubeflow就是一条路</li>



<li>允许您可视化管道和实验元数据以及比较实验结果的UI。</li>



<li>内置笔记本服务器服务</li>
</ul>



<p>最后，您的K8s环境可能资源有限，但K8s和kubeflow都与AWS Sagemaker集成，支持从Kubernetes或Kubeflow本机跨ML工作流使用完全托管的Sagemaker ML工具，这意味着您可以利用它的功能来扩展资源(即GPU实例)和服务(即Sagemaker地面真相、模型监视器等)。</p>



<p>这消除了您手动管理和优化基于Kubernetes的ML基础设施的需要，同时仍然保持对编排和灵活性的控制。</p>



<h3>neptune.ai</h3>



<p>如果你想要集中的地方:</p>



<ul>
<li>存储所有元数据(数据版本、实验跟踪和模型注册)</li>



<li>它具有直观且可定制的用户界面，允许您可视化和比较实验结果，并按照您的意愿排列显示的数据</li>



<li>拥有一个项目wiki，有助于分享关于项目进度、运行和数据探索笔记本的报告、见解和评论</li>



<li>笔记本检查点(用于Jupyter)</li>



<li>它可以与业界大多数最佳工具以及MLOps平台轻松无缝地集成<ul>
<li>例如，Neptune集成了MLflow和许多其他库、工具和ML/DL框架。</li>



<li>如果集成不可用，您可以将其添加到笔记本中。py项目或容器化的ML项目(如果您使用的是Kubernetes或Kubeflow ),由您喜欢的库、工具和框架提供支持，例如使用python客户端的Pytorch。</li>
</ul>
</li>
</ul>



<p>最后，如果您想要一个完全托管的服务，或者如果您想要更多的控制，有服务器版本，那么Neptune是一个不错的选择。</p>



<h2 id="h-high-level-feature-comparison-table">高级功能对照表</h2>



<p id="separator-block_82af4eaf2617b17afa4edfdb227d6da9" class="block-separator block-separator--10"> </p>



<div id="medium-table-block_b2a969fe6153922ed73dcbbbecfb28aa" class="block-medium-table c-table__outer-wrapper ">

    <table class="c-table">
                    <thead class="c-table__head">
            <tr>
                                    <td class="c-item">
                        <p class="c-item__inner">                                                      </p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">MLflow</p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">Kubeflow</p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">neptune.ai</p>
                    </td>
                            </tr>
            </thead>
        
        <tbody class="c-table__body">

                    
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil"><div class="c-ceil__inner"> <p>对个人免费，非营利和教育研究<br/> <a href="/web/20230304141727/https://neptune.ai/pricing">对团队付费</a> </p> </div></td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil"><div class="c-ceil__inner"> <p>有一条学习曲线</p> </div></td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                </tr>

                    
        </tbody>
    </table>

</div>



<p id="separator-block_b8d6c42743140b9c156cea189f8b390e" class="block-separator block-separator--20"><strong>结论</strong></p>



<h2 id="h-conclusion">最终，选择权在你手中，这取决于你的要求和需求，但我想让你知道，这不是一个非此即彼的情况。这些工具并不互相排斥，您可以根据自己的需求和愿望混合搭配它们。</h2>



<p>它可以是Kubeflow与MLflow或Kubeflow与neptune.ai以及MLflow与neptune.ai。</p>



<p>让我详细说明一下，例如Kubeflow和MLflow或Kubeflow和Neptune，在这两种情况下，Kubeflow可能没有直接集成，但您可以将MLflow或Neptune添加到管道组件(也称为容器化应用程序)。</p>



<p>现在当涉及到MLflow和海王星的时候就容易多了，因为海王星和MLflow是一体的。</p>



<p>因此，您不会只使用一种工具。</p>



<p>我们已经兜了一圈，下面是一大堆参考资料供你查阅和消化。玩得开心！</p>



<p>谢谢大家！</p>



<p><strong>参考文献</strong></p>



<h2 id="h-references">MLflow(流动)</h2>







<h3>忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈忽必烈</h3>







<h3>海王星啊</h3>







<h3>neptune.ai</h3>







<p/>
        </div>
        
    </div>    
</body>
</html>