<html>
<head>
<title>Latent Dirichlet Allocation (LDA) Tutorial: Topic Modeling of Video Call Transcripts (With Zoom) </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>潜在狄利克雷分配(LDA)教程:视频通话记录的主题建模(带缩放)</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/latent-dirichlet-allocation-lda-tutorial-topic-modeling#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/latent-dirichlet-allocation-lda-tutorial-topic-modeling#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>在本教程中，我们将使用NLP机器学习模型来识别在录制的视频会议中讨论的主题。我们将使用<a href="https://web.archive.org/web/20230216014251/https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" target="_blank" rel="noreferrer noopener nofollow">潜在的狄利克雷分配</a> (LDA)，一种流行的主题建模技术。我们将应用LDA将会议的内容(抄本)转换成一组主题，并导出潜在的模式。</p>



<p>这将是一个没有任何不必要的绒毛快速教程。我们开始吧！</p>



<h2 id="h-prerequisites">先决条件</h2>



<p>为了遵循并完全理解本教程，您需要具备:</p>



<ul>
<li>Python 3.6或更新版本。</li>



<li>理解自然语言处理。</li>



<li>视频会议记录。</li>
</ul>



<h2 id="h-file-structure">文件结构</h2>



<p>这个项目的文件目录应该是这样的。已经安排实施干净编码最佳实践:</p>



<pre class="hljs">├── README.md
├── converter.py
├── env
├── key.json
├── main.py
├── modeling.py
├── sentence-split.py
├── transcribe.py
</pre>



<p>在本教程中，我们将在上面的目录树中创建所有文件。</p>



<h2 id="h-setting-up-a-python-virtual-environment">设置Python虚拟环境</h2>



<p>我们需要为这个项目特有的各种python依赖项创建一个隔离的环境。</p>



<p>首先，要在终端中创建一个新的开发文件夹，运行:</p>



<pre class="hljs">$ mkdir zoom-topic-modeling
</pre>



<p>接下来，创建一个新的Python虚拟环境。如果您使用的是Anaconda，可以运行以下命令:</p>



<pre class="hljs">$ conda create -n env python=<span class="hljs-number">3.6</span>
</pre>



<p>然后，您可以使用以下方式激活环境:</p>



<pre class="hljs">$ conda activate env
</pre>



<p>如果您使用的是标准Python发行版，请通过运行以下命令创建一个新的虚拟环境:</p>



<pre class="hljs">$ python -m venv env
</pre>



<p>要在Mac或Linux上激活新环境，请运行:</p>



<pre class="hljs">$ source env/bin/activate
</pre>



<p>如果您使用的是Windows，请按如下方式激活环境:</p>



<pre class="hljs">$ venvScriptsactivate
</pre>



<p>无论您使用何种方法创建和激活虚拟环境，您的提示都应该修改为:</p>



<pre class="hljs">(zoom-topic-modeling) $</pre>



<h2 id="h-requirement-file">需求文件</h2>



<p>接下来，随着环境的建立，我们将安装项目依赖项的特定版本(这些版本是我撰写本文时的最新版本)。为了重现我的结果，您应该使用相同版本的软件包:</p>



<pre class="hljs">gensim==<span class="hljs-number">3.8</span><span class="hljs-number">.3</span>
google-api-core==<span class="hljs-number">1.24</span><span class="hljs-number">.1</span>
google-api-python-client==<span class="hljs-number">1.12</span><span class="hljs-number">.8</span>
google-auth==<span class="hljs-number">1.24</span><span class="hljs-number">.0</span>
google-auth-httplib2==<span class="hljs-number">0.0</span><span class="hljs-number">.4</span>
google-cloud-speech==<span class="hljs-number">2.0</span><span class="hljs-number">.1</span>
googleapis-common-protos==<span class="hljs-number">1.52</span><span class="hljs-number">.0</span>
nltk==<span class="hljs-number">3.5</span>
pandas==<span class="hljs-number">1.2</span><span class="hljs-number">.0</span>
pydub==<span class="hljs-number">0.24</span><span class="hljs-number">.1</span>
pyLDAvis==<span class="hljs-number">2.1</span><span class="hljs-number">.2</span>
</pre>



<p>你可以简单地<code>$ pip install -r requirements.txt</code>或<code>conda install --file requirements.txt</code>(如果你在Anaconda上)然后瞧！该程序的所有依赖项都将被下载、安装，并准备就绪。</p>



<p>或者，您可以按如下方式安装所有软件包:</p>







<pre class="hljs">pip install en_core_web_sm gensim google-api-core google-api-pyton-client google-auth google-auth-httplib2 google-cloud-speech googleapis-common-protos nltk pandas pyLDAvis
</pre>







<pre class="hljs">conda install -c conda-forge en_core_web_sm gensim google-api-core google-api-pyton-client google-auth google-auth-httplib2 google-cloud-speech googleapis-common-protos nltk pandas pyLDAvis</pre>



<h2 id="h-separation-of-settings-parameters-and-source-code">设置参数和源代码的分离</h2>



<p>我们将积极地生成API凭证，这些凭证是存在于我们源代码之外的变量，对每个用户都是唯一的。首先，您需要创建一个环境文件(。env)，这可以在您的IDE中通过创建一个新文件并命名它来轻松完成。env也可以通过终端完成，如下所示:</p>



<pre class="hljs">(zoom-topic-modeling) $ touch .env   
(zoom-topic-modeling) $ nano .env    
</pre>



<p>环境变量由名称/值对组成，在给定的时间点，可以创建任意数量的变量供参考。</p>



<p>例如，的内容。env文件看起来应该有点像这样:</p>



<pre class="hljs">user=Brain
key=xxxxxxxxxxxxxxxxxxxxxxxxxx</pre>



<p>与项目相关的参数直接指向源代码。与项目实例相关的参数转到环境文件。</p>



<p>或者，您可以将API凭证文件添加到<a href="https://web.archive.org/web/20230216014251/https://git-scm.com/docs/gitignore" target="_blank" rel="noreferrer noopener nofollow"> gitignore </a>文件中。这可以防止敏感信息(如API键和其他配置值)在源代码中公开。</p>



<h2 id="h-project-scope-statement">项目范围说明书</h2>



<p>如果有一句话我们在2020年后不会忘记，那就是“呆在家里，保持安全。”疫情迫使世界各地的人们呆在家里，以帮助遏制病毒的传播。每个能做到这一点的人都开始在远程环境中工作。</p>



<p>这导致视频会议服务如Zoom、Cisco WebEx、Microsoft Teams或Google Hangouts Meet的受欢迎程度激增。这种新的社交距离文化迫使人们通过在线会议保持社交的创造性，学校，音乐会，仪式，健身项目从现实世界转移到屏幕上。</p>



<p>因为我们在组织中的虚拟会议比以往任何时候都多，所以对于高管和员工来说，参加所有的虚拟会议可能是低效和耗时的。因此，在这个项目中，我们将尝试使用主题建模来提供人们无法参加的会议的主题摘要。</p>



<h2 id="h-project-workflow">项目工作流程</h2>



<p>任何项目工作流的三个组成部分是:</p>



<ul>
<li>输入，</li>



<li>转变，</li>



<li>所需的输出。</li>
</ul>



<p>在这个项目的背景下，输入是视频或音频形式的视频会议记录(来自Zoom)。</p>



<p>接下来，我们必须处理这个输入，并将其转换为一致的文件格式，在我们的例子中是–<a href="https://web.archive.org/web/20230216014251/https://en.wikipedia.org/wiki/FLAC" target="_blank" rel="noreferrer noopener nofollow">FLAC</a>(免费的<strong>无损</strong>音频编解码器)。这是一种压缩的音频编码<strong>无损</strong>文件格式。此外，为了处理FLAC文件的上下文，我们需要将其转换为文本，以执行各种自然语言处理(NLP)操作。考虑到这一点，我们将利用<a href="https://web.archive.org/web/20230216014251/https://cloud.google.com/speech-to-text" target="_blank" rel="noreferrer noopener nofollow">谷歌的语音转文本API </a>来准确地将音频内容转录成文本。</p>



<p>有了文字稿，我们将执行NLP预处理，开始LDA建模，并可视化主题。</p>







<h2 id="h-script-and-explanation">脚本和解释</h2>



<p>每个脚本都是根据面向对象的编程范式编写的。以下是对每个脚本的高级解释。</p>



<h3>1.Converter.py</h3>



<p>为了使这个项目无缝，我们将把所有的音频/视频文件转换成FLAC格式，这是一种由谷歌语音到文本API 支持的<a href="https://web.archive.org/web/20230216014251/https://cloud.google.com/speech-to-text/docs/reference/rest/v1/RecognitionConfig#AudioEncoding" target="_blank" rel="noreferrer noopener nofollow">编码方案。Pyhub库是一个强大的python库，可以快速完成这些转换。</a></p>



<pre class="hljs"><span class="hljs-keyword">import</span> pydub

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Converter</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, file_path)</span>:</span>
        self.audio = pydub.AudioSegment.from_file(file_path)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">convert</span><span class="hljs-params">(self, desired_format)</span>:</span>
        output = <span class="hljs-string">'./audio.'</span>+ desired_format
        self.audio.export(output, format=desired_format)
        print(<span class="hljs-string">'Successfully completed conversion'</span>)
</pre>



<h3>2.转录. py</h3>



<p>通过将音频/视频文件转换为FLAC，我们可以将音频内容转录为txt格式的文本。为了使用谷歌的API，你需要设立一个<a href="https://web.archive.org/web/20230216014251/https://cloud.google.com/free" target="_blank" rel="noreferrer noopener nofollow">谷歌云免费层账户</a>，在这里你可以获得300美元的免费积分来探索谷歌云平台。</p>



<p>在撰写本文时，大约有三种类型的转录类:长音频文件、短音频文件和流文件，正如你在这里看到的<a href="https://web.archive.org/web/20230216014251/https://cloud.google.com/speech-to-text/docs/how-to" target="_blank" rel="noreferrer noopener nofollow"/>。在这篇文章中，我们<strong>转录长音频文件</strong>。</p>



<p>任何超过1分钟的音频文件都被视为长音频文件。为了转录一个长音频文件，该文件必须存储在谷歌云存储中，如<a href="https://web.archive.org/web/20230216014251/https://cloud.google.com/speech-to-text/docs/async-recognize" target="_blank" rel="noreferrer noopener nofollow">文档</a>中所述。这意味着如果文件很短，我们只能直接从本地机器上传文件进行转录。这就是为什么我们需要一个谷歌云存储桶。如果你还没有一个桶的话，跟随这个<a href="https://web.archive.org/web/20230216014251/https://cloud.google.com/storage/docs/creating-buckets" target="_blank" rel="noreferrer noopener nofollow">链接</a>来创建一个桶。</p>



<p>最后，为了连接我们的应用程序和google语音转文本API，我们需要创建并激活一个Google云服务帐户，它将为您提供一个JSON文件。点击此链接快速入门。</p>



<p><em> <strong>注意:</strong>下载的JSON文件应该保存在与transcribe.py脚本相同的目录下。</em></p>



<pre class="hljs"><span class="hljs-keyword">import</span> time

<span class="hljs-keyword">from</span> google.cloud <span class="hljs-keyword">import</span> speech

<span class="hljs-keyword">from</span> google.oauth2 <span class="hljs-keyword">import</span> service_account
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Transcriber</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,URI)</span>:</span>
        self.credentials = service_account.Credentials.from_service_account_file(
            <span class="hljs-string">'key.json'</span>)
        self.client = speech.SpeechClient(credentials=self.credentials)
        
        self.gcs_uri = URI
        self.audio = speech.RecognitionAudio(uri=self.gcs_uri)
        self.config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.FLAC,
            language_code=<span class="hljs-string">"en-US"</span>,
            audio_channel_count=<span class="hljs-number">2</span>,
            enable_separate_recognition_per_channel=<span class="hljs-keyword">True</span>,
        )

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">transcribe</span><span class="hljs-params">(self)</span>:</span>
        transcript = <span class="hljs-string">''</span>

        
        operation = self.client.long_running_recognize(
            config=self.config, audio=self.audio)
        start_time = time.time()
        print(<span class="hljs-string">"Waiting for operation to complete..."</span>)
        response = operation.result()

        <span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> response.results:
            transcript += result.alternatives[<span class="hljs-number">0</span>].transcript
        print(<span class="hljs-string">'Transcribing completed'</span>)
        print(<span class="hljs-string">'Transcription took {time.time()-start_time}seconds'</span>)

        
        print(<span class="hljs-string">'saving transcript'</span>)
        <span class="hljs-keyword">with</span> open(<span class="hljs-string">'transcript.txt'</span>, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> file:
            file.write(transcript)
</pre>



<h3>3.分句. py</h3>



<p>transcribe.py脚本为相应的音频文件返回一个script.txt文件。为了构建理解底层模式的LDA模型，我们需要为模型提供CSV格式的文本文件。在这里，我们将把抄本分成一个数据帧，用实例作为句子。为了做到这一点，我们将通过“.”来分割文本文件内容，语法上的意思是一句话的结尾。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> csv

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Spliter</span><span class="hljs-params">()</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">split</span><span class="hljs-params">(self)</span>:</span>
        
        <span class="hljs-keyword">with</span> open(<span class="hljs-string">'transcript.txt'</span>) <span class="hljs-keyword">as</span> file_, open(<span class="hljs-string">'transcript.csv'</span>, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> csvfile:
            lines = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> file_.read().strip().split(<span class="hljs-string">'.'</span>) <span class="hljs-keyword">if</span> x]
            writer = csv.writer(csvfile, delimiter=<span class="hljs-string">','</span>)
            writer.writerow((<span class="hljs-string">'ID'</span>, <span class="hljs-string">'text'</span>))
            <span class="hljs-keyword">for</span> idx, line <span class="hljs-keyword">in</span> enumerate(lines, <span class="hljs-number">1</span>):
                writer.writerow((idx, line.strip(<span class="hljs-string">'.'</span>)))
</pre>



<h3>4.建模. py</h3>



<p>这个脚本由一个LdaModeling类组成，该类加载了script.csv(这是将脚本拆分成句子后生成的数据)。该类有四个方法:预处理，建模，绘图，性能。</p>



<p>为了通过LDA进行主题建模，我们需要一个数据字典和一袋单词语料库。预处理方法从标记化开始，这是创建数据字典和词袋语料库的关键方面。它包括将一段文本分成更小的单元，称为标记。</p>



<p>我们需要从数据集中删除标点符号和停用词，以便将注意力集中在重要的词上。为了统一起见，我们将所有的记号都转换成小写，并对它们进行词汇化，以提取单词的词根形式并去除屈折词尾。此外，我们删除了5个字符以下的所有标记。预处理方法返回一个数据字典和单词语料库包作为gensim_corpus，gensim_dictionary。</p>



<p>现在，我们已经拥有了在Gensim中创建LDA模型所需的一切。我们将使用gensim.models.ldamodel模块中的LdaModel类来创建LDA模型。我们需要将我们之前创建的单词库作为第一个参数传递给LdaModel构造函数，后面是主题数、我们之前创建的字典和传递次数(模型的迭代次数)。建模方法返回LDA模型实例。</p>



<p>为了可视化我们的数据，我们可以使用本文开头下载的pyLDAvis库。该库包含一个用于Gensim LDA模型的模块。首先，我们需要通过将字典、单词库和LDA模型传递给准备方法来准备可视化。接下来，我们需要调用pyLDAvis库的gensim模块上的显示，如绘图方法所示。</p>



<p>作为一个好的LDA模型的经验法则，困惑分数应该低，而一致性应该高。Gensim库有一个CoherenceModel类，可用于查找LDA模型的一致性。对于困惑，LdaModel对象包含一个log-perferency方法，该方法将一包单词语料库作为参数，并返回相应的困惑。CoherenceModel类将LDA模型、标记化的文本、词典和字典作为参数。为了获得一致性分数，使用get_coherence方法。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> nltk
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> re
<span class="hljs-keyword">import</span> gensim
<span class="hljs-keyword">import</span> gensim.corpora <span class="hljs-keyword">as</span> corpora
<span class="hljs-keyword">from</span> gensim.utils <span class="hljs-keyword">import</span> simple_preprocess
<span class="hljs-keyword">from</span> gensim.models <span class="hljs-keyword">import</span> CoherenceModel
<span class="hljs-keyword">import</span> pyLDAvis
<span class="hljs-keyword">import</span> pyLDAvis.gensim
nltk.download(<span class="hljs-string">'stopwords'</span>)
en_stop = set(nltk.corpus.stopwords.words(<span class="hljs-string">'english'</span>))
<span class="hljs-keyword">from</span> nltk.stem <span class="hljs-keyword">import</span> WordNetLemmatizer
stemmer = WordNetLemmatizer()
<span class="hljs-keyword">import</span> warnings
warnings.filterwarnings(<span class="hljs-string">"ignore"</span>)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LdaModeling</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, data)</span>:</span>
        self.df = pd.read_csv(data)
        self.df = self.df.drop(columns=[<span class="hljs-string">'ID'</span>])
        self.corpus_superlist = self.df[[<span class="hljs-string">'text'</span>]].values.tolist()
        
        self.corpus = []
        <span class="hljs-keyword">for</span> sublist <span class="hljs-keyword">in</span> self.corpus_superlist:
            <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> sublist:
                self.corpus.append(item)
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocessing</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocess_text</span><span class="hljs-params">(document)</span>:</span>
        
            document = re.sub(<span class="hljs-string">r'W'</span>, <span class="hljs-string">' '</span>, str(document))

            
            document = re.sub(<span class="hljs-string">r's+[a-zA-Z]s+'</span>, <span class="hljs-string">' '</span>, document)

            
            document = re.sub(<span class="hljs-string">r'^[a-zA-Z]s+'</span>, <span class="hljs-string">' '</span>, document)

            
            document = re.sub(<span class="hljs-string">r's+'</span>, <span class="hljs-string">' '</span>, document, flags=re.I)

            
            document = re.sub(<span class="hljs-string">r'^bs+'</span>, <span class="hljs-string">''</span>, document)

            
            document = document.lower()

            
            tokens = document.split()
            tokens = [stemmer.lemmatize(word) <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> tokens]
            tokens = [word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> en_stop]
            tokens = [word <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> len(word)  &gt; <span class="hljs-number">5</span>]

            <span class="hljs-keyword">return</span> tokens

        processed_data = [];
        <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> self.corpus:
            tokens = preprocess_text(doc)
            processed_data.append(tokens)

        gensim_dictionary = corpora.Dictionary(processed_data)
        gensim_corpus = [gensim_dictionary.doc2bow(token, allow_update=<span class="hljs-keyword">True</span>) <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> processed_data]

        <span class="hljs-keyword">return</span> gensim_corpus, gensim_dictionary
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">modeling</span><span class="hljs-params">(self)</span>:</span>
        lda_model = gensim.models.ldamodel.LdaModel(gensim_corpus, num_topics=<span class="hljs-number">3</span>, id2word=gensim_dictionary, passes=<span class="hljs-number">50</span>)
        lda_model.save(<span class="hljs-string">'gensim_model.gensim'</span>)
        <span class="hljs-keyword">return</span> lda_model

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plotting</span><span class="hljs-params">(self, lda_model, gensim_corpus, gensim_dictionary)</span>:</span>
        print(<span class="hljs-string">'display'</span>)
        vis_data = pyLDAvis.gensim.prepare(lda_model, gensim_corpus, gensim_dictionary)
        pyLDAvis.show(vis_data)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">performance</span><span class="hljs-params">(self, lda_model, gensim_corpus, gensim_dictionary)</span>:</span>
        print(<span class="hljs-string">'nPerplexity:'</span>, lda_model.log_perplexity(gensim_corpus))
        coherence_score_lda = CoherenceModel(model=lda_model, texts=gensim_corpus, dictionary=gensim_dictionary, coherence=<span class="hljs-string">'c_v'</span>)
        coherence_score = coherence_score_lda.get_coherence()
        print(<span class="hljs-string">'nCoherence Score:'</span>, coherence_score)
</pre>



<h3>5.Main.py</h3>



<p>这是程序的执行点。在这里，我们导入所有的脚本类，并输入所需的参数。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> converter <span class="hljs-keyword">import</span> Converter
<span class="hljs-keyword">from</span> transcribe <span class="hljs-keyword">import</span> Transcriber
<span class="hljs-keyword">from</span> sentence-split <span class="hljs-keyword">import</span> Spliter
<span class="hljs-keyword">from</span> modeling <span class="hljs-keyword">import</span> LdaModeling

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>

    <span class="hljs-title">if</span> <span class="hljs-title">__name__</span> == '<span class="hljs-title">__main__</span>':</span>
        audio_converter = Converter(<span class="hljs-string">'./audio.mp3'</span>)
        audio_converter.convert(<span class="hljs-string">'flac'</span>)
        zoom_project = Transcriber(<span class="hljs-string">"gs://zoom_project_data/audio.flac"</span>)
        transcript = zoom_project.transcribe()
        sentence_spliter = Spliter.split()
        lda_instance = LdaModeling(<span class="hljs-string">'transcript.csv'</span>)
        gensim_corpus, gensim_dictionary = lda_instance.preprocessing()
        lda_model = lda_instance.modeling()
        
        lda_plot = lda_instance.plotting(lda_model, gensim_corpus, gensim_dictionary)
        print(lda_plot)

main()
</pre>



<h2 id="h-results">结果</h2>



<p>下图中的每个圆圈对应于使用3个主题的LDA模型输出中的一个主题。圆圈之间的距离显示了主题彼此之间的不同，重叠的圆圈显示了主题通过常用词的交集。当您将鼠标悬停在任何圆圈上时，该主题的最常用术语列表将出现在右侧，同时还会显示该主题的出现频率。</p>





<p>模型性能非常令人满意，因为它产生了低困惑分数和高一致性，如下所示:</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/9a81930160dd71fd510bab9e95ea313e.png" alt="Topic modeling LDA model perf" class="wp-image-41344" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20230216014251im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Topic-modeling-LDA-model-perf.png?ssl=1"/></figure>



<h2 id="h-conclusion">结论</h2>



<p>至此，本教程到此结束。您可以尝试其他短信示例来查看结果。我相信你已经想到了这种建模的所有令人惊奇的可能性和用例。感谢阅读！</p>



<h3>资源</h3>



<ol>
<li>杰罗达尔，h，王，y，袁，c，冯，x，蒋，x，李，y，赵，l(2018)。潜在狄利克雷分配(LDA)和主题建模:模型，应用，综述。arXiv:1711.04305v2 [cs。IR】。</li>



<li>Putra, I. M., &amp; Kusumawardani, R. P. (2017). Analisis Topik Informasi Publik Media Sosial di Surabaya Menggunakan Pemodelan Latent Dirichlet Allocation (LDA). Jurnal Teknik ITS Vol. 6, №2, 311–316.</li>



<li>h . m . wallach、I . Murray、r . Salakhutdinov和d . Mimno(2009年)。主题模型的评估方法。<em>2009年ICML第26届机器学习国际会议论文集</em>，<em> 4 </em>，1105–1112。</li>



<li><a href="https://web.archive.org/web/20230216014251/http://qpleple.com/perplexity-to-evaluate-topic-models/" target="_blank" rel="noreferrer noopener nofollow">http://qpleple.com/perplexity-to-evaluate-topic-models/</a></li>



<li><a href="https://web.archive.org/web/20230216014251/http://qpleple.com/topic-coherence-to-evaluate-topic-models/" target="_blank" rel="noreferrer noopener nofollow">http://qp ple . com/topic-coherence-to-evaluate-topic-models/</a></li>
</ol>
        </div>
        
    </div>    
</body>
</html>