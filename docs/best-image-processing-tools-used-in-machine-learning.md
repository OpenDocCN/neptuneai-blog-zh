# 机器学习中使用的最佳图像处理工具

> 原文：<https://web.archive.org/web/https://neptune.ai/blog/best-image-processing-tools-used-in-machine-learning>

图像处理是一项非常有用的技术，该行业的需求似乎每年都在增长。历史上，使用机器学习的图像处理出现在 20 世纪 60 年代，作为模拟人类视觉系统和自动化图像分析过程的尝试。随着技术的发展和改进，针对特定任务的解决方案开始出现。

2010 年计算机视觉的快速加速，得益于深度学习以及开源项目和大型图像数据库的出现，只是增加了对图像处理工具的需求。

目前，已经创建了许多有用的库和项目，可以帮助您使用机器学习解决图像处理问题，或者简单地改进您使用 ML 的计算机视觉项目中的处理管道。

在本文中，我们将为您提供一个工具列表，这些工具将改进您的计算机视觉项目，分为:

*   框架和库
*   资料组
*   特定任务的现成解决方案

让我们开始吧！

## 框架和库

理论上，你可以从头开始构建你的图像处理应用程序，只需要你和你的电脑。但实际上，站在巨人的肩膀上，使用其他人构建的东西，并在需要的地方扩展或调整它，会更好。

这就是库和框架的用武之地，在图像处理中，创建高效的实现通常是一项困难的任务，这一点更是如此。

所以，让我给你一个你可以在你的图像处理项目中使用的库和框架的列表:

计算机视觉和图像处理算法的开源库。

专为实时计算机视觉应用而设计和优化。

旨在开发开放式基础设施。

功能性:

*   基本数据结构
*   图像处理算法
*   计算机视觉的基本算法
*   图像和视频的输入和输出
*   人脸检测
*   搜索立体声匹配(全高清)
*   光流
*   持续集成系统
*   CUDA 优化架构
*   安卓版本
*   Java API
*   内置性能测试系统
*   跨平台

用于机器学习的开源软件库。

旨在解决构建和训练神经网络的问题，目的是自动查找和分类图像，达到人类感知的质量。

功能性:

*   在多个并行处理器上工作
*   通过多维数据阵列计算——张量
*   张量处理器的优化
*   即时模型迭代
*   简单调试
*   自有记录系统
*   交互式日志可视化工具

开源机器学习平台。

旨在加速从研究原型到工业开发的开发周期。

功能性:

*   轻松过渡到生产
*   分布式学习和性能优化
*   丰富的工具和库生态系统
*   对主要云平台的良好支持
*   优化和自动微分模块

### 了解更多信息

了解如何使用 [TensorFlow + Neptune](https://web.archive.org/web/20220928190539/https://docs.neptune.ai/essentials/integrations/deep-learning-frameworks/tensorflow-keras) 集成或 [PyTorch + Neptune](https://web.archive.org/web/20220928190539/https://docs.neptune.ai/essentials/integrations/deep-learning-frameworks/pytorch) 集成来跟踪模型训练元数据。

专注于解决图像分类和分割问题的深度学习框架。

功能性:

*   使用 blobs 的计算–并行计算中使用的多维数据阵列
*   模型定义和配置优化，无需硬编码
*   轻松切换 CPU 和 GPU
*   工作的高速度

跨平台。用于图像处理的 OpenCV . net 插件。

功能性:

*   一起工作。NET 兼容语言——c#、VB、VC ++、IronPython 等。
*   兼容 Visual Studio、Xamarin Studio 和 Unity
*   可以在 Windows、Linux、Mac OS、iOS 和 Android 上运行

开源 C ++库的集合。

功能性:

*   加载、保存和修改许多常见文件格式的图像，包括非常大的图像
*   1、2 或 3 维中的点、曲线和其他基本对象的几何
*   相机几何
*   从运动中恢复结构
*   设计图形用户界面
*   拓扑学
*   3D 图像

用于读写栅格和矢量地理空间数据格式的库。

功能性:

*   获取有关栅格数据的信息
*   转换成各种格式
*   数据重投影
*   从栅格创建镶嵌图
*   使用栅格切片索引创建 shapefiles

2D/三维医学图像分割框架。

功能性:

*   创建分段管道
*   初步加工
*   输入输出
*   数据增长
*   补丁分析
*   自动评估
*   交互效度分析

计算机视觉 JavaScript 库。

功能性:

*   颜色跟踪
*   人脸识别
*   使用现代 HTML5 规范
*   轻量级内核(大约 7 KB)

眼球追踪库。

使用网络摄像头实时确定访问者在页面上的注视位置(用户正在看的地方)。

功能性:

*   模型的自校准，观察互联网访问者与网页的交互，并训练眼睛功能和屏幕上位置之间的显示
*   大多数现代浏览器中的实时外观预测
*   只需几行 JavaScript 就能轻松集成
*   预测多个视图的能力
*   在客户端的浏览器中工作，无需将数据传输到服务器

一个处理视频和图像的框架。

功能性:

*   捕捉视频帧
*   用于视频滤波的帧处理
*   多线程图像处理
*   通过 GUI 支持插件集成
*   从图像分量中提取特征
*   分形的产生
*   目标跟踪
*   运动检测

PyTorch 中的计算机视觉库。

功能性:

*   图像转换
*   极线几何
*   深度估计
*   低级图像处理(例如直接在张量上过滤和边缘检测)
*   颜色校正
*   特征识别
*   滤像
*   边界识别

## 数据集

没有数据，你无法建立机器学习模型。这在图像处理应用中尤其重要，在图像处理应用中，向训练数据集添加更多标记数据通常会比最先进的网络架构或训练方法获得更大的改进。

记住这一点，让我给你一个可以在你的项目中使用的图像数据集列表:

旨在减少算法偏差的数据集。

一百万张不同国籍、年龄和性别的人的面部标签图像，以及其他指标——头部大小、面部对比度、鼻子长度、前额高度、面部比例等。以及他们之间的关系。

用于识别伪造照片和视频的数据集。

使用 Face2Face、FaceSwap 和 DeepFakes 方法创建的一组图像(超过 50 万张)。

1000 个视频，使用每种伪造方法制作人脸。

Youtube 视频的数据集，带有 dynamics 中的标记内容。

大约 23.7 万个布局和 1000 个类别。

用于训练神经网络进行归纳的数据集

这些数据由真实世界的标记图像和未标记草图组成。

用于对无人机图像中的对象进行计数的数据集。

15532 次 RGB 无人机拍摄，每张图像都有一次红外拍摄。

对象标记可用于 RGB 和红外图像。

数据集包含方向对象边界和对象类。

在 31，064 幅图像的数据集中，总共标记了 441，642 个对象。

用于训练自动驾驶车辆的数据集。

包括带标记物体驾驶的视频。

3000 个总计 16.7 小时的驾驶视频，60 万帧，约 2500 万个 3D 物体边界和 2200 万个 2D 物体边界。

为了消除视频的一致性问题，在各种条件下进行记录。视频选项包括天气、行人、灯光、骑自行车的人和建筑工地。

数据的多样性提高了模型的泛化能力。

神经网络无法正确分类的图像数据集。

根据测试结果，模型从数据集中预测对象，精确度为 3%。

包含七千五百幅图像，其独特之处在于它们包含自然的视错觉。

旨在研究神经网络对模糊对象图像的稳定性，这将有助于提高模型的泛化能力。

## 现成的解决方案

现成的解决方案是为解决特定的、通常是专门化的任务而构建的开源存储库和软件工具。

通过使用这些解决方案，您可以将您的模型构建或图像处理流程“外包”给一个工具，只需点击一下鼠标或执行一个命令即可完成。

记住这一点，让我给你我的清单。

一组针对移动设备优化的计算机视觉算法。

功能性:

*   面部分析
*   根据环境确定位置
*   直接在智能手机上识别
*   低延迟和低功耗

面向 iOS 和 Android 开发者的机器学习平台。

功能性:

*   直接在移动设备上运行，无需数据传输
*   将模型移植到其他框架并更新应用程序中的模型，而无需发布新版本

用于标记照片和视频的交互式工具。

功能性:

*   用于标记的形状–矩形、多边形、折线、点
*   无需安装
*   合作能力
*   标记过程的自动化
*   支持各种注释脚本

三维图像中物体的分割。

解决实例分割问题在计算上比其他现有方法好 10 倍。

端到端神经网络，接受 3D 图像作为输入，并在输出端给出已识别对象的边界。

从数以千计的类别中识别物体。

检测图像中难以看见的物体。

允许您在任何现有检测器之上工作的体系结构。

噪声数据上物体边界的检测。

提高标记对象边界的精度。

任何语义编辑器和损失函数的附加层。

生成逼真的多功能图像。

修复了使用 GAN 生成图像的缺点。

编码器和解码器两级通信系统。

从视频中恢复帧。

当帧接近时恢复清晰度，并恢复视频录制中模糊帧的内容。

该模型在模型的输入端接收模糊帧，在输出端接收无模糊的恢复帧。

视频的自动标记。

从一个图像到整个视频的标记分发。

基于一个自我监督的模型。

用其他对象替换对象。

用最少的训练数据将物体图像从一类转换到另一类。

基于 GAN 架构。

图像问题的生成。

基于图片和期望的答案类型，显示生成的问题。

基于最大化相互信息。

对一个物体的部分进行视觉识别。

从部分图像中识别真实世界的物体。

基于将图像分成多个部分并学习这些部分如何组合在一起。

来自照片的布局。

从 360°照片恢复房间布局。

端到端模型。

从声音的音频记录中生成人脸的图像。

恢复声音所有者的主要外部特征。

以一个声谱图为输入，生成一个人的全脸无情绪的人脸。

物体与摄像机的接近度。

确定对象离相机有多近。

基于完全邻近图的比较。

从图像中建模物体的三维形状。

输入图像中对象的 3D 形状预测。

端到端模型。

从几张照片恢复三维视图。

从几张输出照片中恢复，从其他角度查看，以便可以在 3D 中查看图像。

基于一系列卷积神经网络。

将图像分辨率提高 8 倍。

更准确的面部图像质量更好，没有失真。

基于 GAN。

预测图像中的人数。

保留图像不同部分信息的确定。

端到端模型。

三维人体建模。

从一张照片恢复一个穿着衣服的人的 3D 模型。

端到端模型。

## 结论

项目的成功、执行效率和质量可能取决于许多因素，但选择正确的工具是最重要的因素之一——它可以让您显著节省时间和资源，并获得最佳结果。

有了图像处理的机器学习工具的知识，你可以更容易、更快、更有效地解决这类问题。

也就是说，阅读最佳工具是不够的:您仍然需要自己动手。因此，选择最适合您的工具并开始工作吧！

* * *

**阅读下一篇**

## ML 实验跟踪:它是什么，为什么重要，以及如何实施

10 分钟阅读|作者 Jakub Czakon |年 7 月 14 日更新

我来分享一个听了太多次的故事。

> *“…我们和我的团队正在开发一个 ML 模型，我们进行了大量的实验，并获得了有希望的结果…*
> 
> *…不幸的是，我们无法确切地说出哪种性能最好，因为我们忘记了保存一些模型参数和数据集版本…*
> 
> *…几周后，我们甚至不确定我们实际尝试了什么，我们需要重新运行几乎所有的东西"*
> 
> 不幸的 ML 研究员。

事实是，当你开发 ML 模型时，你会进行大量的实验。

这些实验可能:

*   使用不同的模型和模型超参数
*   使用不同的培训或评估数据，
*   运行不同的代码(包括您想要快速测试的这个小变化)
*   在不同的环境中运行相同的代码(不知道安装的是 PyTorch 还是 Tensorflow 版本)

因此，它们可以产生完全不同的评估指标。

跟踪所有这些信息会很快变得非常困难。特别是如果你想组织和比较这些实验，并且确信你知道哪个设置产生了最好的结果。

这就是 ML 实验跟踪的用武之地。

[Continue reading ->](/web/20220928190539/https://neptune.ai/blog/ml-experiment-tracking)

* * *