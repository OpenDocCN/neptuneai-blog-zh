<html>
<head>
<title>Installing MuJoCo to Work With OpenAI Gym Environments </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>安装MuJoCo以在OpenAI健身房环境中工作</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/installing-mujoco-to-work-with-openai-gym-environments#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/installing-mujoco-to-work-with-openai-gym-environments#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p><strong>在本文中，我将向您展示如何在Mac/Linux机器上安装MuJoCo，以便从OpenAI的Gym </strong>运行连续控制环境。这些环境包括像HalfCheetah、Hopper、Walker、Ant和Humanoid这样的经典环境，以及像用机械臂或机械手灵巧操作物体这样的较难的环境。我还将讨论环境提供的其他代理诊断，这些诊断您以前可能没有考虑过。</p>







<h2 id="h-how-do-you-get-mujoco">你怎么得到MuJoCo？</h2>



<p>你可能会想，安装MuJoCo有什么特别的地方需要指南？嗯，获得许可证并正确安装它可能相对容易，但当你匹配MuJoCo和OpenAI Gym版本，并安装mujoco-py包时，大问题就开始了。我第一次尝试花了好几个小时才把它做好！</p>



<p>为了省去你的麻烦，我会一步一步地引导你完成安装过程。然后，我将讨论一些需要关注的有用的诊断，我们将看看来自人形训练的诊断示例。最后，我将链接代码，让您在MuJoCo任务上训练代理，并使用Neptune观察诊断。首先，我会给你一些关于MuJoCo和OpenAI健身房环境的背景。</p>











<p>MuJoCo是一个<strong>快速而精确的物理模拟引擎</strong>，旨在研究和开发机器人、生物力学、图形和动画。这是一个引擎，这意味着，它不提供现成的模型或环境来工作，而是<strong>运行环境</strong>(就像OpenAI的健身房提供的那些)。</p>



<h2 id="h-what-is-openai-gym">什么是OpenAI健身房？</h2>



<p>OpenAI Gym(或简称Gym)是一个环境的集合。其中一些被称为连续控制，运行在MuJoCo引擎上。所有环境都有两个重要特征:</p>



<ol><li>代理观察描述受控机器人运动特性的向量。这意味着状态空间是连续的。</li><li>代理动作也是向量，它们指定了应用在机器人关节上的扭矩。这意味着动作空间也是连续的</li></ol>



<p>健身房MuJoCo环境包括经典的连续控制、用机械臂操纵物体和机器人手(影子手)的灵活性。在这些环境中，有多种任务可供培训。下图显示了其中一些。你可以在健身房<a href="https://web.archive.org/web/20221207191934/https://gym.openai.com/envs/#mujoco" target="_blank" rel="noreferrer noopener nofollow">环境列表</a>中找到所有这些的详细信息。<a href="https://web.archive.org/web/20221207191934/https://openai.com/blog/ingredients-for-robotics-research/" target="_blank" rel="noreferrer noopener nofollow">这个帖子</a>对机器人手臂和机器人手环境特别有用。如果你还不知道Gym API，我鼓励你阅读<a href="https://web.archive.org/web/20221207191934/https://gym.openai.com/docs/#environments" target="_blank" rel="noreferrer noopener nofollow">文档</a>—“环境”和“观察”这两个简短的部分应该足够开始了。</p>







<p class="has-text-align-center has-small-font-size"><em>经典连续控制——任务从左到右:Walker2d，And，and Humanoid。<br/>来源:</em><a href="https://web.archive.org/web/20221207191934/https://openai.com/blog/roboschool/" target="_blank" rel="noreferrer noopener nofollow"><em>OpenAI Roboschool</em></a></p>











<p class="has-text-align-center has-small-font-size"><em>影子手的灵巧性——手操纵积木的任务。<br/>来源:</em> <a href="https://web.archive.org/web/20221207191934/https://gym.openai.com/envs/#robotics" target="_blank" rel="noreferrer noopener nofollow"> <em> OpenAI健身房机器人</em> </a></p>



<h2 id="h-installing-mujoco-and-openai-gym">安装MuJoCo和OpenAI健身房</h2>



<p>在这一节中，我将向您展示从哪里获得MuJoCo许可证，如何安装所有需要的东西，以及如何解决一个常见的macOS问题。</p>



<h3>许可证</h3>



<p>你可以在 <a href="https://web.archive.org/web/20221207191934/https://www.roboti.us/license.html" target="_blank" rel="noreferrer noopener nofollow"> <strong> MuJoCo网站</strong> </a>上获得30天的免费试用，或者——如果你是学生——获得一年的免费教育许可。许可证密钥将通过电子邮件发送给您，其中包含您的用户名和密码。如果你不是学生，你可以试着鼓励你工作的机构购买许可证。</p>



<h3>安装mujoco-py</h3>



<p>以下是逐步说明，下面我添加了一些解释和故障排除提示:</p>



<ol><li>下载适用于<a href="https://web.archive.org/web/20221207191934/https://www.roboti.us/download/mjpro150_linux.zip" target="_blank" rel="noreferrer noopener nofollow"> Linux </a>或<a href="https://web.archive.org/web/20221207191934/https://www.roboti.us/download/mjpro150_osx.zip" target="_blank" rel="noreferrer noopener nofollow"> macOS </a>的MuJoCo版本1.50二进制文件。</li><li>将下载的<code>mjpro150</code>目录解压到<code>~/.mujoco/mjpro150</code>，并将您的许可证密钥(您电子邮件中的<code>mjkey.txt</code>文件)放在<code>~/.mujoco/mjkey.txt.</code></li><li>运行<code>pip3 install -U 'mujoco-py&lt;1.50.2,&gt;=1.50.1'</code></li><li>运行<code>python3 -c 'import mujoco_py'</code></li></ol>



<p>如果您看到类似于<strong>“objc[…]:Class GLFW…在两者中都实现了…”的警告，请忽略它们</strong>。如果你在macOS上看到“clang:error:unsupported option '-fopenmp '”或任何其他与编译相关的错误，那么转到<em>故障排除</em>小节。如果你想知道为什么MuJoCo 1.5，那么去<em>版本</em>小节。如果你没有更多的顾虑，那么你可以跳进健身房安装！</p>



<h4>解决纷争</h4>



<p>如果在macOS上，<strong>“clang:error:unsupported option '-fopenmp '”错误或任何其他与编译器</strong>(例如gcc，如果您安装了一个)相关的错误在安装或运行<code>python3 -c ‘import mujoco_py’</code>期间发生，请遵循以下步骤:</p>



<p>1.如果还没有安装<a href="https://web.archive.org/web/20221207191934/https://brew.sh/"> brew </a>。</p>



<p>2.卸载<strong>所有</strong>其他编译器，如果你有一些，例如运行<code>brew uninstall gcc</code>。如果您有多个版本，可能需要运行几次。</p>



<p>3.运行<code>brew install llvm boost hdf5</code></p>



<p>4.将此添加到您的<code>.bashrc / .zshrc</code></p>



<pre class="hljs">export PATH=<span class="hljs-string">"/usr/local/opt/llvm/bin:$PATH"</span>
export CC=<span class="hljs-string">"/usr/local/opt/llvm/bin/clang"</span>
export CXX=<span class="hljs-string">"/usr/local/opt/llvm/bin/clang++"</span>
export CXX11=<span class="hljs-string">"/usr/local/opt/llvm/bin/clang++"</span>
export CXX14=<span class="hljs-string">"/usr/local/opt/llvm/bin/clang++"</span>
export CXX17=<span class="hljs-string">"/usr/local/opt/llvm/bin/clang++"</span>
export CXX1X=<span class="hljs-string">"/usr/local/opt/llvm/bin/clang++"</span>
export LDFLAGS=<span class="hljs-string">"-L/usr/local/opt/llvm/lib"</span>
export CPPFLAGS=<span class="hljs-string">"-I/usr/local/opt/llvm/include"</span></pre>



<p>5.在编辑完之后，不要忘记对您的<code>.bashrc / .zshrc</code>(例如，重新启动您的cmd)进行源代码处理，并确保您的python环境已被激活。</p>



<p>6.尝试卸载并再次安装mujoco-py。</p>



<p>更多信息见本<a href="https://web.archive.org/web/20221207191934/https://github.com/openai/mujoco-py/issues/465#issuecomment-651124360" target="_blank" rel="noreferrer noopener nofollow"> GitHub问题</a>。你也应该看到<a href="https://web.archive.org/web/20221207191934/https://github.com/openai/mujoco-py/tree/master#troubleshooting" target="_blank" rel="noreferrer noopener nofollow"> mujoco-py自述</a>的<em>故障排除</em>部分。</p>



<h3>版本</h3>



<p>在这里，我们遇到了第一个陷阱！<strong>最新的OpenAI健身房与MuJoCo 2.0 </strong>不兼容，如果你想了解详情，请参见<a href="https://web.archive.org/web/20221207191934/https://github.com/openai/gym/issues/1541">本期GitHub</a>。这就是你需要下载MuJoCo版二进制文件的原因。或者，如果你真的需要使用MuJoCo 2.0，可以下载<a href="https://web.archive.org/web/20221207191934/https://www.roboti.us/download/mujoco200_linux.zip"> Linux </a>或者<a href="https://web.archive.org/web/20221207191934/https://www.roboti.us/download/mujoco200_macos.zip"> OSX </a>的MuJoCo 2.0二进制文件，安装最新的mujoco-py，然后安装最后一个支持MuJoCo 2.0的健身房:<code>pip install -U gym[all]==0.15.3</code></p>



<h2 id="h-installing-openai-gym-environments-tutorial">安装OpenAI健身房环境(教程)</h2>



<p>在这里，重要的是安装带有“mujoco”和“robotics”附加组件的OpenAI Gym包，或者简单地安装所有附加组件:</p>



<ol><li>运行<code>pip3 install gym[mujoco,robotics]</code>或<code>pip3 install gym[all]</code></li><li>通过运行以下命令检查安装:</li></ol>



<pre class="hljs">python3 -c <span class="hljs-string">"import gym; env = gym.make('Humanoid-v2'); print('nIt is OKAY!' if env.reset() is not None else 'nSome problem here...')"</span>
</pre>



<p>如果你看到“没关系！”印在cmd的最后，那就没事了！同样，<strong>您可以忽略类似“objc[…]: Class GLFW…在两个…</strong>中实现”的警告。</p>



<h2 id="h-mujoco-diagnostics">穆乔科诊断公司</h2>



<p>现在，我将讨论由OpenAI Gym MuJoCo环境提供的有用指标。它们依赖于环境版本，所以我将它们分为v2和v3诊断。您可以在环境步骤方法提供的“info”字典中访问这些指标:observation、reward、done、<strong> info </strong> = env.step(action)。详见<a href="https://web.archive.org/web/20221207191934/https://gym.openai.com/docs/#observations">健身房文档</a>。<strong>下表提供了允许您访问字典中的指标和指标简短描述的关键字</strong>。</p>



<p id="separator-block_61b33c772727f" class="block-separator block-separator--10"> </p>



<div id="medium-table-block_61b33c7e27280" class="block-medium-table c-table__outer-wrapper ">

    <table class="c-table">
                    <thead class="c-table__head">
            <tr>
                                    <td class="c-item">
                        <p class="c-item__inner">名字</p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">版本</p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">钥匙</p>
                    </td>
                                    <td class="c-item">
                        <p class="c-item__inner">描述</p>
                    </td>
                            </tr>
            </thead>
        
        <tbody class="c-table__body">

                    
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil"><div class="c-ceil__inner"> <p> <span>正向奖励机器人前进速度。</span> </p> <p> <span>对机器人动作向量幅度的负奖励。</span> </p> </div></td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil"><div class="c-ceil__inner"> <p> <span>在X轴的位置。</span></p><p><span>X轴上的速度(前进速度)。</span> </p> </div></td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil"><div class="c-ceil__inner"> <p> <span>在X轴的位置。</span></p><p><span>X轴上的速度(前进速度)。</span> </p> </div></td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil"><div class="c-ceil__inner"> <p> <span>在X轴的位置。</span></p><p><span>X轴上的速度(前进速度)。</span> </p> </div></td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil"><div class="c-ceil__inner"> <p> <span>奖励_转发</span> </p> <p> <span>奖励_控制</span> </p> <p> <span>奖励_联系</span> </p> <p> </p> <p> <span>奖励_生存</span> </p> </div></td>

                    
                        <td class="c-ceil"><span>对机器人前进速度的正向奖励。</span></td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil"><div class="c-ceil__inner"><p><span>x _位置</span></p><p><span>x _速度</span></p><p><span>y _位置</span></p><p><span>y _速度</span> </p> <p> <span>距离_起点</span> </p> </div></td>

                    
                        <td class="c-ceil"><span>x _位置</span></td>

                    
                        <td class="c-ceil"><span>X轴上的位置。</span></td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil">                                                      </td>

                    
                        <td class="c-ceil"><div class="c-ceil__inner"> <p> <span>奖励_linvel </span> </p> <p> <span>奖励_ quad ctrl</span></p><p><span>奖励_影响</span> </p> <p> </p> <p> <span>奖励_活着</span> </p> </div></td>

                    
                        <td class="c-ceil"><span>奖励_林维尔</span></td>

                    
                        <td class="c-ceil"><span>机器人动作向量幅度的负奖励。</span></td>

                    
                </tr>

            
                <tr class="c-row">

                    
                        <td class="c-ceil"><div class="c-ceil__inner"><p><span>x _位置</span></p><p><span>x _速度</span></p><p><span>y _位置</span></p><p><span>y _速度</span> </p> <p> <span>距离_起点</span> </p> </div></td>

                    
                        <td class="c-ceil"><span>x _位置</span></td>

                    
                        <td class="c-ceil"><span>x _速度</span></td>

                    
                        <td class="c-ceil"><span>X轴的速度。</span></td>

                    
                </tr>

                    
        </tbody>
    </table>

</div>



<p id="separator-block_61b34573272b1" class="block-separator block-separator--5"> </p>



<p class="has-text-align-center"><strong>奖励成分可能特别有用，</strong>例如，前进速度奖励——这是这些任务的目标。然而，请注意，信息字典中缺少一些度量并不意味着，比如说，生存奖励没有加到霍普或沃克的奖励中——它加了！对于像这样的更多细节，我鼓励你在GitHub上查看特定任务的代码，例如<a href="https://web.archive.org/web/20221207191934/https://github.com/openai/gym/blob/master/gym/envs/mujoco/walker2d_v3.py" target="_blank" rel="noreferrer noopener nofollow"> Walker2d-v3 </a>。</p>



<p id="separator-block_61b3457b272b2" class="block-separator block-separator--20">现在，让我们来看看人形任务的示例度量值。</p>



<p>人形诊断学</p>



<p>上图比较了三种不同DRL算法的速度:<a href="https://web.archive.org/web/20221207191934/https://arxiv.org/abs/1812.05905?ref=hackernoon.com" target="_blank" rel="noreferrer noopener nofollow"> SAC </a>、<a href="https://web.archive.org/web/20221207191934/https://arxiv.org/abs/1910.02208" target="_blank" rel="noreferrer noopener nofollow"> SOP </a>和<a href="https://web.archive.org/web/20221207191934/https://arxiv.org/abs/2007.04938" target="_blank" rel="noreferrer noopener nofollow"> SUNRISE </a>。绘制了完全训练过的特工在事件的不同点的速度。您可以看到SOP代理运行最快，这是该任务的目标。在下图中，我们调查了SAC代理在不同训练阶段每集结束时的位置。</p>



<h3>你可以看到这个特殊的SAC代理在负X和正Y方向上运行，随着训练它会越来越远。因为它在一集结束前的时间保持不变，这意味着它通过训练学会了跑得更快。请注意，代理没有被训练为向任何特定方向运行。它被训练成朝任何方向尽可能快地向前跑。这意味着不同的代理可以学习向不同的方向运行。此外，代理可以在训练的某个时间点改变跑步方向，如下图所示。</h3>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/422ccb26a5aa81f166f7547709b3e8b0.png" alt="Humanoid velocity" class="wp-image-49360" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221207191934im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/humanoid_velocity.png?ssl=1"/><figcaption><em> Comparison of velocities of three different DRL algorithms: SAC, SOP, and SUNR  </em></figcaption></figure></div>



<p>结论</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/bf92dd3c085e4616f07ffe503ff0b0f2.png" alt="MuJoCo logs_AverageXPosition-2" class="wp-image-49361" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221207191934im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/MuJoCo-logs_AverageXPosition-2.png?ssl=1"/><figcaption><em>SAC final positions in the X-axis across training on the Humanoid task. </em><a href="https://web.archive.org/web/20221207191934/https://app.neptune.ai/piojanu/bayesian-exploration/e/BAY-1797/charts" target="_blank" rel="noreferrer noopener"><em>Neptune experiment</em></a><em>.</em></figcaption></figure></div>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/f8df820cbde6fb1a1bd717b9877db097.png" alt="MuJoCo logs_AverageYPosition-2" class="wp-image-49362" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221207191934im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/MuJoCo-logs_AverageYPosition-2.png?ssl=1"/><figcaption><em>SAC final positions in the Y-axis across training on the Humanoid task. </em><a href="https://web.archive.org/web/20221207191934/https://app.neptune.ai/piojanu/bayesian-exploration/e/BAY-1797/charts" target="_blank" rel="noreferrer noopener"><em>Neptune experiment</em></a><em>.</em></figcaption></figure></div>



<p>恭喜你，你让MuJoCo开始运行了！现在，您会对在这些环境中培训代理感兴趣——查看<a href="https://web.archive.org/web/20221207191934/https://github.com/awarelab/spinningup_tf2" target="_blank" rel="noreferrer noopener nofollow">这个库</a>。它包括一个简单易懂的代码DRL算法在现代TF2实施。这段代码基于新人友好的<a href="https://web.archive.org/web/20221207191934/https://spinningup.openai.com/" target="_blank" rel="noreferrer noopener nofollow"> SpinningUp </a>代码库。而且，<strong>包含了登录Neptune.ai平台</strong>的功能，非常方便存储和分析训练结果！我在我的研究中使用它，你也必须试一试，特别是他们发布了他们的<a href="https://web.archive.org/web/20221207191934/https://neptune.ai/blog/neptune-new" target="_blank" rel="noreferrer noopener">新的、惊人的API </a>。</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/d6c6d6352b6984de43e4685be0d934d1.png" alt="MuCoJo logs_AverageXPosition-3" class="wp-image-49364" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221207191934im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/MuCoJo-logs_AverageXPosition-3.png?ssl=1"/><figcaption><em>SAC final positions in the X-axis across training on the Humanoid task. It changes the run direction in one-third of training. </em><a href="https://web.archive.org/web/20221207191934/https://app.neptune.ai/piojanu/bayesian-exploration/e/BAY-1783/charts" target="_blank" rel="noreferrer noopener"><em>Neptune experiment</em></a><em>.</em></figcaption></figure></div>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/3896866130cf62213ef4616e9ef76b3c.png" alt="MuJoCo logs_AverageYPosition-3" class="wp-image-49365" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221207191934im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/MuJoCo-logs_AverageYPosition-3.png?ssl=1"/><figcaption><em>SAC final positions in the Y-axis across training on the Humanoid task. It changes the run direction late in the training. </em><a href="https://web.archive.org/web/20221207191934/https://app.neptune.ai/piojanu/bayesian-exploration/e/BAY-1783/charts" target="_blank" rel="noreferrer noopener"><em>Neptune experiment</em></a><em>.</em></figcaption></figure></div>



<h2 id="h-conclusions">Conclusions</h2>



<p>Congratulations, you’ve got MuJoCo up and running! Now you’ll be interested in training agents in these environments—check out <a href="https://web.archive.org/web/20221207191934/https://github.com/awarelab/spinningup_tf2" target="_blank" rel="noreferrer noopener nofollow">this repository</a>. It includes an easy-to-understand code of DRL algorithms implemented in modern TF2. This code is based on the newcomer-friendly <a href="https://web.archive.org/web/20221207191934/https://spinningup.openai.com/" target="_blank" rel="noreferrer noopener nofollow">SpinningUp</a> codebase. Moreover, <strong>it includes the ability to log into the Neptune.ai platform</strong>, which is very convenient to store and analyze the training results! I use it in my research and you have to give it a try too, especially that they shipped their <a href="https://web.archive.org/web/20221207191934/https://neptune.ai/blog/neptune-new" target="_blank" rel="noreferrer noopener">new, amazing API</a>. </p>
        </div>
        
    </div>    
</body>
</html>