# 为商业开发人工智能/人工智能项目-最佳实践

> 原文：<https://web.archive.org/web/https://neptune.ai/blog/building-ai-ml-projects-for-business-best-practices>

根据最近对 3000 名高管的调查，只有 10%的人工智能/人工智能项目产生了积极的财务影响。

鉴于这些可能性，似乎建立一个产生利润的 ML 项目需要整个组织从计划到生产的大量工作。

在这篇文章中，我将分享企业的最佳实践，以确保他们在机器学习和人工智能方面的投资实际上是有利可图的，并为整个组织创造重大价值。

## 识别人工智能用例的最佳实践

大多数人工智能项目在第一个障碍就失败了——对可以用人工智能解决的业务问题缺乏理解。这是 AI 成功部署的主要瓶颈。

这个问题由于人工智能的组织直觉的早期阶段，以及如何利用它来解决关键的业务问题而变得复杂。

这是什么意思？不是每个问题都可以用人工智能来解决。要了解您的特定问题是否可行，您需要经过尝试和测试的实践和方法。

如果你正在寻找建立能够交付成功结果的人工智能团队的最佳实践，请参见我以前的文章[3] [如何建立能够交付](/web/20221207114904/https://neptune.ai/blog/how-to-build-machine-learning-teams-that-deliver)的机器学习团队。

### 人工智能用例

人工智能改变了工业。它自动化了常规和手动流程，并为几乎所有业务功能提供了重要的预测性见解。表 1 显示了一些使用 AI 成功解决的业务用例的列表。

| 投入 | 输出 | 应用 | 工业 |
| --- | --- | --- | --- |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |
|  |  |  |  |

*表 1。人工智能解决的业务用例*

理想情况下，应该与业务领导、产品经理和任何可用的主题专家一起对适当的业务问题进行头脑风暴。然后，应该审查源自整个组织的业务问题列表，并使用人工智能分析潜在的解决方案。

不是每一个商业问题都应该用 AI 来解决。通常，基于规则或工程的解决方案就足够了。此外，可以从客户评论或反馈中挖掘出许多业务问题，这些问题通常指向需要修复的中断的业务流程。

在表 2 中，您可以看到一个问题清单，包括技术和商业两个方面，以确定商业问题是否与 AI 相关。

|  | 数据 |
| --- | --- |
|  | 

结构化(表格)还是非结构化(图像、视频、文本、音频、多模态)？

 |
|  | 

每个数据样本的大小和整个可用于训练的语料库

 |
|  | 

金融、电子商务、客户服务、物流等。

 |
|  | 

多久为用例生成一次数据，生成多少数据？

 |
|  | 

标签对数据的可用性？贴标签的成本？是否有内部或外部领域专家来标记数据集？

 |
|  | 

从最终用户到内部生态系统的数据流是怎样的，直到模型预测服务于用户？

 |
|  | 

使用数据构建和部署 AI 模型是否有任何数据隐私、监管或合规约束？

 |

|  | 人工智能相关性 |
| --- | --- |
|  | 

这是类似公司或更广泛的相关市场中的既定用例吗？

 |
|  | 有没有关于这个主题的重要学术研究来了解什么样的人工智能模型和方法可能是相关的？ |
|  | 

什么样的模型与用例相关？经典 ML，系综还是深度学习模型？

 |
|  | 

模型是部署在云端还是移动/边缘设备上？

 |
|  | 

用例需要实时还是批量/离线预测？

 |
|  | 

衡量模型性能的指标有哪些？

 |
|  | 

模型在生产中的精度、延迟和吞吐量有哪些约束？

 |

|  | 商业 |
| --- | --- |
|  | 

什么是用户角色？如何最好地展现人工智能模型预测？UX 设计和实物模型，以确保易用性

 |
|  | 

这是一个有数据可用的现有产品还是一个数据有限的新产品/功能来训练 AI 模型

 |
|  | 是否有定义明确的业务指标或需要重新集思广益？ |
|  | 

这个用例是短期投资还是长期投资？

 |
|  | 

用例的端到端交付是否有清晰的路线图？

 |
|  | 

可以分配多少预算来构建端到端的用例？

 |
|  | 

用例需要哪些职能团队协作？

 |
|  | 

涉众团队有多少带宽？

 |

*表 2。一份数据、模型和业务问题的清单，以验证潜在人工智能解决方案的业务问题。*

kri 和指标

### 作为规划过程的一部分，应该讨论每个潜在用例的适当模型和业务度量。从预期的结果开始向后工作，就更容易明确要优化哪个特定的指标。

为了说明这一点，在表 3 中，我准备了一个 AI 用例以及相应的模型和业务度量的列表。对于一个人工智能项目的成功来说，确保实现业务指标和目标是非常重要的。

投入

| 输出 | 技术指标 | 商业指标 |  |
| --- | --- | --- | --- |
|  |  |  |  |
|  |  | 

依赖于域，例如罪犯或[跟踪者](https://web.archive.org/web/20221207114904/https://www.washingtonexaminer.com/news/taylor-swift-used-airport-style-facial-recognition-on-concertgoers)等的 ID。

 | 依赖于域，例如罪犯或[跟踪者](https://web.archive.org/web/20221207114904/https://www.washingtonexaminer.com/news/taylor-swift-used-airport-style-facial-recognition-on-concertgoers)等的 ID。 |
|  |  | 

收入损失、欺诈销售比率等。

 | 收入损失、欺诈销售比率等。 |
|  | 

K 点平均精度

 | K 时的平均精度 | 提高每个用户的平均收入，或增加购物车中的商品数量等。 |
|  |  | 

提高每个用户的平均收入，或增加购物车中的商品数量等。

 | 提高每个用户的平均收入，或增加购物车中的商品数量等。 |
|  |  |  |  |
|  |  |  |  |

*表 3。示例人工智能用例及其技术和业务指标。*

优化

我们有一系列的商业问题。在仔细考虑了表 2 中列出的标准，并分析了表 3 中列出的适当业务指标后，对它们进行了审查和记录。用例的候选列表需要根据对总体业务策略和目标的影响和相关性进行优先排序。

### 从描述业务用例的全面方面和潜在的基于人工智能的解决方案的详细书面文档来看，有一个客观的标准来在相同的规模上量化所有提议的用例是有用的。在这里，[产品经理和业务负责人](/web/20221207114904/https://neptune.ai/blog/data-science-project-management-in-2021-the-new-guide-for-ml-teams)对人工智能在实践中如何工作有自己的直觉，或者依靠专注于产品的技术或领域专家的判断是至关重要的。虽然根据某些成功标准对项目进行排序很容易，但对人工智能项目的相关风险进行评级就不那么简单了。

一个平衡的度量应该考虑和权衡人工智能项目成功结果的可能性和影响，以及它失败或没有产生足够影响的风险。项目的风险可能与组织方面、人工智能问题的特定领域方面有关，或者与业务范围之外的外部因素有关。一旦定义了一个合适的平衡指标，它会将所有利益相关者和领导层联系起来，然后他们能够根据客观分数形成自己的主观观点。

在对一个特定的人工智能项目作出“是”或“否”的决定之前，需要考虑许多因素，以及在规定的时期内选择的人工智能相关项目的数量。获得领导层的认同很难。某些最终的执行决策可能看起来很主观，或者不是数据驱动的，但通过前面提到的规划过程以尽可能最好的方式呈现每个人工智能项目，并最大限度地提高人工智能项目被选中执行的可能性，仍然是绝对关键的。

规划人工智能用例的最佳实践

作为跨职能团队规划过程的一部分，组织必须有一个精简的机制来定义人工智能产品愿景或路线图、带宽、每个团队中个人贡献者和经理的具体角色和责任，以及技术方面(数据管道、建模堆栈、生产和维护的基础设施)。

## 在这一部分，我将描述构建一个成功的人工智能产品所必需的具体计划步骤的细节。

人工智能产品要求

对于每一个确定的用例，有必要画出路线图，说明产品如何随着时间的推移从基线版本发展到更成熟的产品。在表 4 中，我概述了为每个用例创建一个全面的 AI 路线图需要满足的一组基本问题和标准。

敬路线图

|  | 是否有从客户角度撰写的 FAQ 文档，解释人工智能产品如何解决特定的客户问题？ |
| --- | --- |
| 是否有一个 FAQ 文档，从客户的角度来写，解释 AI 产品如何解决特定的客户问题？ |  |
| 是否有一个全面的产品需求文档，详细描述了构建和交付 AI 产品的所有必要的组织成分？ |  |
| 人工智能用例是由客户问题激发的吗？如果是由产品团队提出的，是否经过了客户调查的验证？ |  |
| PRD 是否记录了产品开发期间在特定时间内可实现的里程碑，以评估和评价进度？ |  |
| 是否所有可能使产品脱轨或延迟人工智能产品发布或开发的潜在风险因素都得到解决？ |  |
| 根据表 3，业务指标和 KPI 是否定义良好？ |  |
| 根据表 3，人工智能模型度量标准是否定义良好？ |  |
| 对于人工智能产品的每一次阶段性发布，是否明确建立了验收标准？ |  |

PR-FAQ(新闻稿-常见问题)和 PRD(产品需求文档)是通常在产品构思和概念的初始阶段准备的两个关键文档。由 Amazon 首创，这两个文档充当所有相关团队的北极星，使他们与产品保持一致，并相应地构建和扩展产品。所有涉众团队对这些文档做出有意义的贡献，并分享他们特定领域的专业知识，以精心编制一份供管理层审阅的文档，这是绝对必要的。

所有涉众团队经理都有必要对文档进行评审和贡献，这样任何特定于团队或领域的产品开发的固有偏见都会暴露出来，并得到相应的解决。通常，团队应该依靠数据驱动的直觉进行产品开发。在缺乏内部数据的情况下，人工智能产品的直觉可以借鉴其他公司所做的工作或同一领域的研究[2，4]。

数据要求

由于路线图是在利益相关者会议后定义和最终确定的，因此准备好一个 MVP 或 AI 产品的基本原型来验证初始假设并提交给领导层总是有益的。这项工作也有助于简化必要的数据和工程管道，以获取、清理和处理数据，并训练模型以获得 MVP。

### MVP 不应该是一个高度复杂的模型。它应该足够基本，能够成功地将输入数据转换为模型预测，并在最小的训练数据集上进行训练。如果 MVP 作为 API 托管，每个跨职能的涉众团队可以探索产品，并为如何为最终客户更好地开发 AI 产品建立直觉。

从数据的角度来看，机器学习团队可以更深入地研究最少的训练数据，并对表 5 中列出的数据进行仔细的分析。

数据检查

|  | 

特征是分类的、数值的、文本的？

 |
| --- | --- |
| 特征是分类的、数字的还是文本的？ |  |
| 每个特征的分布是怎样的？分类问题有多少个目标类？每个类的数据是否平衡？ | 

离群值、缺失值和空值

 |
| 

数据的稳健程度如何？有多少缺失值和空值？您将如何解释这些问题并消除任何异常值？

 | 

特征选择/工程

 |
| 所有的特征在直觉上对任务都很重要吗？您能否进行特征选择以减少冗余或高度相关的特征，或者将特征转换到低维空间，或者设计新的或复合的特征？ |  |
| 每个训练样本都有标签吗？手动检查各类标签的随机样本的质量。 |  |
| 现有的数据足以训练一个 MVP 吗？是否需要增加新的数据样本或创建合成数据？ |  |
| 用于训练、验证和测试集的数据集是否被很好地管理和平衡以评估可推广性？ |  |
| 是否有机制对原始、清理、转换、训练、验证和测试数据集的每个版本进行版本控制？ |  |
| 训练模型并在生产中为其服务的最佳数据格式是什么？有没有更好的替代方案？ |  |
| 在当前和未来的实验中，如何存储和访问整个数据处理和建模生命周期中的数据？ |  |
| 是否建立了结构化且记录完善的数据转换管道，并牢记上述所有数据质量检查？ |  |

模型要求

在系统评估了表 5 中列出的数据质量、特征、统计、标签和其他检查之后，机器学习团队可以开始构建原型/ MVP 模型。在产品开发的早期阶段，最好的方法是快速行动，而不是精确行动。初始(基线)模型应该足够简单，以证明该模型是可行的，数据和建模管道是无缺陷的，并且模型度量表明该模型的性能明显好于偶然。

多年来，机器学习用例和产品变得越来越复杂。虽然线性回归和二元或多类分类模型曾经太常见，但现在有了新的模型类别，它们训练起来更快，并且在真实世界的测试数据上概括得更好。对于 ML 科学家或工程师来说，不可能使用相同的工具和库的技术栈来构建两个用例。根据与 AI 用例相关的数据的特征(参见表 2)，数据科学团队必须定义特定于每个用例的建模堆栈(参见下面的表 6)。

人工智能模型检查

| 

用例是否需要基于回归、分类、优化或推荐等的 ML 解决方案。？

 | 用例需要基于回归、分类、优化或推荐等的 ML 解决方案吗？？ |
| --- | --- |
|  | 

传统 ML 模型能否有效解决用例？如果是，什么是合适的 ML 基线模型？

 |
|  | 

是否有足够的(非结构化)数据来利用更复杂的神经网络和深度学习模型？

 |
|  | 

ML/DL 模型的组合是否解决了用例的特定方面或数据的特定部分？

 |
| 

超参数优化

 | 超参数优化 |
| 对于每一类 ML/DL 模型，需要优化的关键超参数是什么？最好的搜索方法是什么——网格搜索、随机搜索还是贝叶斯优化？ | 模型版本和格式 |
| 每个不同的模型将如何版本化和存储？部署模型的最佳模型格式是什么？ | 

对于每个模型训练和超参数优化实验，实验元数据和结果将如何在团队中存储、访问和共享？

 |
|  | 是否有适当的框架来分析和分类模型错误、错误类型(假阳性或假阴性)以及如何用更新或更好的模型解释这些错误？ |
|  | 

从训练数据到模型预测、结果和可视化，是否存在端到端的 ML/DL 建模管道？

 |
|  | 

在发布的每个阶段，模型在准确性、延迟和吞吐量方面的验收标准是什么？

 |
|  | 

是否有清晰的管道将模型带入生产？该模型将通过 Docker 或云或笔记本服务器部署？什么样的实例最适合部署？

 |
|  | 

是否设置了包括仪表盘、日志、指标在内的模型监控工具？

 |
|  | *表 6。人工智能模型列表和人工智能 MVP 的可行性检查。* |

执行人工智能用例的最佳实践

在确定和规划了有前途的人工智能用例之后，下一步就是实际执行项目。看起来执行是一个简单的过程，机器学习团队开始施展他们的魔法。但是，仅仅“构建模型”对于成功的部署是不够的。模型构建必须以协作和迭代的方式完成:

涉及产品用户以及跨职能团队的反馈，

## 整合来自产品团队的任何新的或修改的特性请求，

基于业务或操作环境的任何变化更新用例的初始假设，

*   然后才向用户推出产品。
*   将模型交付生产是一个值得庆祝、记录并在组织内分享的重要里程碑，但工作并未就此停止。监控模型在来自客户的真实世界数据上的表现，并定期应用修复或更新模型，使其不会随着以下方面的变化而过时，这一点至关重要:
*   数据的分布，
*   用例的性质，

客户行为，

*   等等..
*   在下一节中，我将讨论成功执行和部署 AI 模型以及实现所提议的商业价值的操作方面的最佳实践。
*   审查和反馈
*   一旦人工智能项目启动，机器学习团队就必须与利益相关者(包括产品团队和业务领导层)举行定期和临时的审查会议。在规划阶段准备的文档(PR-FAQ 和 PRD)作为任何更新或变更的背景。

定期会议的目标是评估产品路线图的进展状态，并解决以下方面的任何变化:

### 产品或商业策略，

组织结构，

分配给项目的资源。

*   虽然计划很重要，但大多数公司项目并不像最初计划的那样进行。重要的是要灵活敏捷，对任何新信息(关于技术、产品或业务方面)做出反应，并朝着共同的前进方向重新调整。例如，2020 年的停摆严重影响了经济。鉴于这种高影响的意外事件，适应和改变人工智能用例的策略也是至关重要的。
*   除了定期的内部反馈，在整个 AI 生命周期中与产品的最终用户保持联系也是很好的。在初始阶段(用户研究，目标用户角色及其人口统计的定义)，尤其是在产品设计和与模型预测的交互中。应该维持一个来自目标细分市场的核心用户群，以便在产品开发的所有阶段获得定期反馈。
*   一旦 MVP 准备好了，用户可以很有帮助地提供早期反馈，这通常可以揭示一些见解，并发现任何偏见或缺点。当人工智能模型准备好出货，不同的模型版本将被评估时，用户的反馈可以再次非常有见地。用户对设计、易用性、感知速度和整体用户流的洞察可以帮助产品团队根据需要完善产品策略。

迭代构建

从技术角度来看，模型构建过程通常是一个迭代过程。在建立了一个健壮的基线之后，团队可以洞察模型的性能离已建立的验收标准有多远。在模型构建的早期阶段，重点应该主要放在准确性而不是延迟上。

在模型开发的每个阶段，对验证集上的模型错误的全面分析可以揭示对模型缺点的重要见解，以及如何解决它们。还应与主题专家一起审查错误，以评估数据注释中的任何错误以及错误中的任何特定模式。

### 如果模型容易出现某种错误，它可能需要额外的特性。或者，可能需要将它更改为基于不同目标函数或基本原则的模型，以克服这些错误。这种重复的过程有助于机器学习团队巩固他们对用例的直觉，跳出框框思考，并提出新的创意或算法来实现预期的指标。

在建模过程中，机器学习实践者应该系统地记录每个实验和相应的结果。结构化方法不仅有助于特定的用例，也有助于建立有助于新员工的组织知识，或者作为成功的人工智能部署的光辉榜样。

部署和维护

一旦候选机器学习模型准备就绪，并在验证和测试集上进行彻底的基准测试，分析错误，并满足验收标准，该模型就可以投入生产。模型培训和部署环境之间存在巨大差异。模型的定型格式可能与将模型投入生产不兼容，需要进行适当的序列化并转换为正确的格式。

在模拟生产设置的环境中，应在保留数据集上再次验证模型准确性和延迟。部署应该通过将模型呈现给一小部分真实世界的流量或模型的输入来逐步完成，最好首先由内部或核心用户组进行测试。

### 一旦 MLOps 团队对部署管道进行了严格的测试和审查，就可以将更多的流量导向模型。在有一个或多个候选模型可用的情况下，应该系统地进行这些模型的 A/B 测试，并评估统计上的显著差异，以确定获胜的模型。

部署后，确保在数据生态系统中收集并适当归档所有输入输出对非常重要。应定期评估启动的模型，并将真实世界数据的分布与训练数据的分布进行比较，以评估数据和模型漂移。在这种情况下，将一些真实世界的测试样本反馈到原始训练数据集中的主动学习管道有助于减轻部署模型的缺点。

最后，一旦模型生产环境和所有管道稳定，机器学习和产品团队应该评估业务指标和 KPI，以评估指标是否满足预定义的成功标准。如果是这样，那么只有用例被认为是成功的，并且整个用例和结果的总结应该被记录并在内部与每个涉众和业务领导共享。

包扎

如果创业公司和企业中的机器学习、产品和业务团队采用系统化的方法，并遵循本文中列出的最佳实践，那么人工智能成功的可能性只会增加。

充分的前期准备至关重要。没有它，团队将无法纠正任何错误或应对变化，也无法实现人工智能可以提供的巨大商业潜力。

## 参考

If machine learning, product and business teams in startups and enterprises adopt a systematic approach and follow the best practices as laid out in this article, then the likelihood of successful AI outcomes can only increase. 

Adequate upfront preparation is crucial. Without it, teams won’t be able to rectify any errors or respond to changes, nor realize the massive commercial potential that AI can deliver.

### References