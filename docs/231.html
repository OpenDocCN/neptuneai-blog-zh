<html>
<head>
<title>Best 8 Machine Learning Model Deployment Tools That You Need to Know </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>你需要知道的最好的8个机器学习模型部署工具</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/best-8-machine-learning-model-deployment-tools#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/best-8-machine-learning-model-deployment-tools#0001-01-01</a></blockquote><div><div class="article__content col-lg-10">
<p>机器学习在科技界并不新鲜。它为许多行业带来了革命性的变化，能够实现渠道自动化，并增加业务工作流程的灵活性。</p>



<p>我们如何在生产环境中创建和部署训练有素的模型API由机器学习生命周期的许多方面控制。<a href="/web/20220926090659/https://neptune.ai/blog/mlops-what-it-is-why-it-matters-and-how-to-implement-it-from-a-data-scientist-perspective" target="_blank" rel="noreferrer noopener"> MLOps </a>的概念对于处理复杂的ML部署环境非常有益。</p>



<p>实施可靠的MLOps可以为投资机器学习的公司带来巨大的好处。理解使用和执行什么是这个难题的一个重要部分。学习和适应简化整体工作流程的新工具是另外一回事。</p>



<p>本文列出了用于模型部署的最佳MLOps工具。帮助您扩展和管理机器学习生命周期的所有要素，包括服务、监控和管理API端点。</p>











<p>如果您想将训练好的模型部署为端点，您可以使用TensorFlow服务来实现。</p>



<p>它允许您创建一个REST API端点来服务于训练好的模型。TensorFlow Serving是一个健壮的高性能系统，用于服务机器学习模型。</p>



<p>您可以轻松部署最先进的机器学习算法，同时维护与其各自端点相同的服务器架构。它足够强大，可以为不同类型的模型和数据以及TensorFlow模型提供服务。</p>



<p>它是由谷歌创建的，许多顶级公司都使用它。将模型作为集中的模型库是一个很好的方法。服务架构对于大量用户同时访问模型是足够有效的。</p>



<p>如果由于大量请求而出现任何阻塞，可以使用负载平衡器轻松维护。总体而言，该系统具有较高的可扩展性和可维护性。</p>



<p><strong> TensorFlow发球优势:</strong></p>


<div class="custom-point-list">
<ul><li>一旦部署模型准备就绪，这个工具就可以轻松地提供服务。</li><li>它可以向同一个模型发起批量请求，因此可以有效地利用硬件。</li><li>它还提供了模型版本管理。</li><li>该工具易于使用，并负责建模和服务管理。</li></ul>
</div>


<p><strong> TensorFlow发球缺点:</strong></p>


<div class="custom-point-list">
<ul><li>加载新型号或更新旧型号时，无法确保零停机时间。</li><li>仅适用于张量流模型。</li></ul>
</div>











<p>如果您正在寻找一个开源工具来组织您的整个ML生命周期，这可能是您的平台。</p>



<p>MLflow提供管理ML流程和部署的解决方案。它可以进行实验、复制、部署，或者作为一个中央模型注册中心。</p>



<p>该平台可以被个人开发者和团队用于ML部署。它可以整合到任何编程生态系统中。该库旨在满足各种技术需求，并可用于不同的机器学习库。</p>



<p>组织整个ML生命周期围绕着四个主要功能:跟踪、项目、模型和模型注册。</p>






<p>它有助于简化自动化ML模型跟踪的过程。但是一个缺点是它不能自动处理模型定义。这意味着向模型定义添加额外的工作需要手动完成。</p>



<p><strong> MLflow优点:</strong></p>


<div class="custom-point-list">
<ul><li>模型跟踪机制很容易建立。</li><li>它为服务提供了非常直观的API。</li><li>日志记录实用且简单，因此很容易进行实验。</li><li>代码优先的方法。</li></ul>
</div>


<p><strong> MLflow缺点:</strong></p>


<div class="custom-point-list">
<ul><li>向模型添加额外的工作并不是自动的。</li><li>对于将模型部署到不同的平台来说，这并不容易，也不理想。</li></ul>
</div>











<p>Kubeflow的主要目标是维护机器学习系统。这是为Kubernetes设计的强大套件。</p>



<p>主要操作包括打包，组织docker容器，帮助维护整个机器学习系统。</p>



<p>它简化了机器学习工作流的开发和部署，从而使模型具有可追溯性。它提供了一套强大的ML工具和架构框架来有效地执行各种ML任务。</p>



<p>多功能UI仪表板使管理和跟踪实验、任务和部署运行变得容易。笔记本功能使我们能够使用指定的平台开发套件与ML系统进行交互。</p>



<p>组件和管道是模块化的，可以重复使用以提供快速解决方案。这个平台是Google通过Kubernetes为TensorFlow任务服务而启动的。后来，它扩展到执行整个ML管道的多云、多架构框架。</p>



<p><strong> Kubeflow优点:</strong></p>


<div class="custom-point-list">
<ul><li>一致的基础架构，提供监控、运行状况检查、每次复制，以及对新功能的扩展。</li><li>简化新团队成员的入职流程。</li><li>标准化流程有助于建立安全性并更好地控制基础架构。</li></ul>
</div>


<p>Kubeflow cons :</p>


<div class="custom-point-list">
<ul><li>难以手动设置和配置。</li><li>高可用性不是自动的，需要手动配置。</li><li>这个工具的学习曲线很陡。</li></ul>
</div>











<p>Cortex是一个开源的多框架工具，非常灵活，可以用作模型服务工具，也可以用于模型监控等目的。</p>



<p>凭借其处理不同机器学习工作流的能力，它允许您完全控制模型管理操作。它还可以作为使用SageMaker工具提供模型的替代方案，以及基于AWS服务(如Elastic Kubernetes Service (EKS)、Lambda或Fargate)的模型部署平台。</p>



<p>Cortex扩展到Docker、Kubernetes、TensorFlow Serving和TorchServe等开源项目。它可以与cohesion中的任何ML库或工具一起工作。它提供端点的可扩展性来管理负载。</p>



<p>它允许您在单个API端点中部署多个模型。它还可以作为一种解决方案，在不停止服务器的情况下更新已经存在的生产端点。它覆盖了模型监控工具的足迹，监督端点的性能以及预测数据。</p>



<p><strong>皮质优点</strong>:</p>


<div class="custom-point-list">
<ul><li>当网络流量波动时，允许API安全的自动扩展功能。</li><li>支持多个平台，如Keras、TensorFlow、Scikit-learn、PyTorch等..</li><li>更新型号时不会停机。</li></ul>
</div>


<p><strong>皮层cons </strong>:</p>


<div class="custom-point-list">
<ul><li>设置过程可能有些令人望而生畏。</li></ul>
</div>








<p>Seldon.io提供了Seldon core，这是一个开源的框架。该框架简化并加速了ML模型和实验部署。</p>



<p>它处理和服务在任何其他开源ML框架中构建的模型。ML模型部署在Kubernetes。当它与Kubernetes一起伸缩时，它使我们能够使用最先进的Kubernetes特性，比如定制资源定义来处理模型图。</p>



<p>Seldon还提供了将您的项目与持续集成和部署(CI/CD)工具相连接的能力，以扩展和更新模型部署。</p>



<p>它有一个警报系统，当监控生产中的模型出现问题时，它会通知您。您可以定义模型来解释某些预测。该工具在云中可用，在内部也可用。</p>



<p><strong>谢顿优点</strong>:</p>


<div class="custom-point-list">
<ul><li>定制离线模型。</li><li>向外部客户公开API的实时预测。</li><li>简化部署过程。</li></ul>
</div>


<p><strong>谢顿缺点:</strong></p>


<div class="custom-point-list">
<ul><li>设置可能有点复杂。</li><li>对新来的人来说，学习可能很难。</li></ul>
</div>








<p>BentoML简化了构建机器学习服务的过程。它为部署和维护生产级API提供了一个基于Python的标准架构。这种架构允许用户使用任何ML框架轻松打包训练好的模型，用于在线和离线模型服务。</p>



<p>BentoML的高性能模型服务器支持自适应微批处理，以及独立于业务逻辑扩展模型推理工人的能力。UI仪表板提供了一个集中的系统来组织模型和监控部署过程。</p>



<p>其模块化设计使配置可在现有GitOps工作流中重复使用，自动docker映像生成使生产部署成为一个简单的版本化流程。</p>



<p>多用途框架解决了ML模型的服务、组织和部署。主要重点是连接数据科学和DevOps部门，以实现更高效的工作环境，并产生高性能的可扩展API端点。</p>



<p>欢迎使用:</p>


<div class="custom-point-list">
<ul><li>易于大规模部署预测服务的实用格式</li><li>以单一统一的格式支持高性能模型服务和部署</li><li>支持部署到多个平台，而不仅仅是Kubernetes</li></ul>
</div>


<p>膨润土辅料:</p>


<div class="custom-point-list">
<ul><li>不注重实验管理。</li><li>不支持开箱即用的水平扩展。</li></ul>
</div>








<p>AWS Sagemaker是亚马逊提供的强大服务。它让ML开发者能够快速构建、训练和部署机器学习模型。</p>



<p>它通过删除一些复杂的步骤来简化整个机器学习过程，从而提供高度可扩展的ML模型。</p>



<p>机器学习开发生命周期是一个复杂的迭代过程。它迫使你整合复杂的工具和工作流程。这项任务可能要求很高，令人恼火，而且可能会消耗你大量的时间。更不用说配置时出错的麻烦了。</p>



<p>Sagemaker使这一过程变得更加容易，在一个集中的工具集中提供了用于机器学习的所有组件。没有必要配置每一个，因为它已经安装并准备使用。</p>



<p>这以最小的努力和成本加速了模型的生产和部署。该工具可用于使用任何ML框架创建的端点。它还提供预测跟踪和捕获，以及日程监控。</p>



<p><strong> AWS Sagemaker优点</strong>:</p>


<div class="custom-point-list">
<ul><li>设置过程很简单，可以用Jupyter笔记本运行。因此，脚本的管理和部署得到了简化。</li><li>基于您使用的功能，成本是模块化的。</li><li>模型训练在多台服务器上完成。</li></ul>
</div>


<p>AWS Sagemaker缺点:</p>


<div class="custom-point-list">
<ul><li>初级开发人员的陡峭学习曲线。</li><li>严格的工作流程很难定制。</li><li>仅适用于AWS ecostystem</li></ul>
</div>













<p>Torchserve是一个Pytorch模型服务框架。它简化了训练有素的PyTorch模型的大规模部署。它消除了为模型部署编写定制代码的需要。</p>



<p>Torchserve由AWS设计，是PyTorch项目的一部分。对于那些使用PyTorch环境构建模型的人来说，这使得设置变得很容易。</p>



<p>它支持低延迟的轻量级服务。部署的模型具有高性能和广泛的可伸缩性。</p>



<p>Torchserve为一些ML任务提供了内置库，比如对象检测或文本分类。它可以节省你花在编写代码上的时间。它提供了强大的特性，比如多模型服务、用于A/B测试的模型版本控制、用于监控的指标以及用于应用程序集成的RESTful端点。</p>



<p>火炬服务的优点:</p>


<div class="custom-point-list">
<ul><li>扩展部署的模型得到了简化。</li><li>服务端点是轻量级的，具有高性能规模。</li></ul>
</div>


<p>火炬服务的缺点:</p>


<div class="custom-point-list">
<ul><li>因为这个工具是实验性的，所以经常会发生变化和更新。</li><li>仅适用于PyTorch型号</li></ul>
</div>


<h2>结论</h2>



<p>创建和部署高性能和可扩展的机器学习模型是具有挑战性的任务。</p>



<p>幸运的是，本文中列出的部署工具和框架可以帮助您创建健壮的ML模型，并快速、轻松地部署它们。</p>



<p>处理和组织全面的机器学习生命周期绝非易事。这些工具将帮助你节省时间和精力。</p>



<p>祝你好运！</p>



<h3>资源:</h3>



<p><a href="https://web.archive.org/web/20220926090659/https://towardsdatascience.com/ml-infrastructure-tools-for-production-part-2-model-deployment-and-serving-fcfc75c4a362" target="_blank" rel="noreferrer noopener nofollow"> ML生产基础设施工具Aparna Dhinakaran </a></p>




<div id="author-box-new-format-block_6040ee2430c86" class="article__footer article__author">
  

  <div class="article__authorContent">
          <h3 class="article__authorContent-name">克里斯萨纳瓦特·卡韦桑穆昂</h3>
    
          <p class="article__authorContent-text">InstaMobile的开发者关系 <br/>只是一个典型的内向开发者，美国——没有上瘾，对人工智能和区块链充满热情。</p>
    
          
    
  </div>
</div>


<div class="wp-container-1 wp-block-group"><div class="wp-block-group__inner-container">
<hr class="wp-block-separator"/>



<p class="has-text-color"><strong>阅读下一篇</strong></p>



<h2>你需要知道的最好的机器学习模型管理工具</h2>



<p class="has-small-font-size">9分钟阅读|作者弗拉基米尔·利亚申科| 2021年7月14日更新</p>


<p id="block_5ffc75def9f8e" class="separator separator-10"/>



<p>开发您的模型是ML项目工作的重要部分。这通常是一个艰难的挑战。</p>



<p>每个数据科学家都必须面对它，还有困难，比如失去实验的线索。这些困难很可能既烦人又不明显，会让你时不时感到困惑。</p>



<p>这就是为什么简化管理ML模型的过程是有好处的，幸运的是有几个工具可以做到这一点。这些工具有助于:</p>


<div class="custom-point-list">
<ul><li>实验跟踪</li><li>模型版本控制</li><li>测量推理时间</li><li>团队协作</li><li>资源监控</li></ul>
</div>


<p>因此，寻找和使用适合您的项目的工具是常识和良好的实践。</p>



<p>在本文中，我们将探索模型管理工具的<strong>前景。我将尝试向您展示各种工具，并强调它们的优点。</strong></p>



<p>我们将涵盖:</p>


<div class="custom-point-list">
<ul><li>选择<strong>模型管理工具</strong>的标准</li><li><strong>模型管理工具</strong> : <strong> Neptune、亚马逊SageMaker、Azure机器学习、Domino数据科学平台、Google Cloud AI平台、Metaflow、MLflow </strong></li></ul>
</div>

<a class="button continous-post blue-filled" href="/web/20220926090659/https://neptune.ai/blog/best-machine-learning-model-management-tools" target="_blank">
    Continue reading -&gt;</a>



<hr class="wp-block-separator"/>
</div></div>
</div>
      </div>    
</body>
</html>