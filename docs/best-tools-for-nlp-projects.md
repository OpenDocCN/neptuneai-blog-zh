# 每个数据科学家和 ML 工程师都应该尝试的 NLP 项目的最佳工具

> 原文：<https://web.archive.org/web/https://neptune.ai/blog/best-tools-for-nlp-projects>

[自然语言处理](https://web.archive.org/web/20221206133311/https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32) (NLP)是人工智能极其重要的子集。在智能设备使用(也称为人机通信)的增加、自然语言处理在医疗保健领域的进步以及基于云的解决方案的采用等因素的推动下，自然语言处理在企业中得到广泛采用。但是 NLP 到底是什么，为什么它很重要？

NLP 处于语言学、计算机科学和人工智能的交汇点。NLP 的应用程序处理和分析大量自然语言数据——人类所说的所有语言都是自然语言，无论该语言是英语、法语还是普通话——以便以类似人类的方式模仿人类之间的交互。一个好的 NLP 系统能够理解文档的内容，包括其中的细微差别。

## 为什么 NLP 如此重要？

我们比以往任何时候都更依赖于机器，这在很大程度上要归功于它们比我们更准确的能力，以及让我们更高效的能力。他们不会累。他们没有抱怨。他们从不感到无聊。然而，对于 NLP 任务，有一个主要的障碍…

对于人类来说，掌握一门语言相对简单，但对于机器来说，掌握自然语言是一个很大的挑战。自然语言的创造性和语言的模糊性使得自然语言处理成为一个高要求的领域。解决问题意味着，对于我们的问题，我们提出了一个解决语言创造性和模糊性问题的解决方案，因此，我们向被视为非结构化的数据添加了结构(即，文本没有模式，不像商店中的交易历史记录)。

## 不同类型的 NLP 任务

NLP 可以执行许多不同的任务，但是有一组基本任务在各种 NLP 项目中经常重复出现。由于它们的重复性，这些任务比其他 NLP 任务得到了更深入的研究。这些基本的 NLP 任务是:

### 语言建模

语言建模(LM)是给任何单词序列分配一个概率。本质上，在语言建模任务中，我们试图预测序列中出现的下一个单词，给定之前出现的单词的历史。LM 在 NLP 的各种应用中至关重要，是机器能够理解定性信息的原因。语言建模的一些应用包括:语音识别、光学字符识别、手写识别、机器翻译和拼写纠正。

### 文本分类

文本分类根据文本的内容将预定义的类别分配给文本。到目前为止，文本分类是 NLP 最受欢迎的应用，用于构建各种工具，如垃圾邮件检测器和情感分析机器人。

### 信息提取

信息抽取(IE)是从非结构化和/或半结构化的文本文档中自动抽取相关信息。这些类型的文档包括电子邮件中的日历事件，或社交媒体上帖子中提到的人名。

### 信息检索

每个在线的人都与某种信息检索(IR)系统互动，例如谷歌搜索。信息检索的任务是从大量的文档集合中找到与用户查询相关的文档。

### 对话代理

对话式智能体属于对话式人工智能。对话式人工智能包括建立对话系统，模仿人类在对话方面的互动。对话式人工智能的流行例子包括 Alexa、Siri、Google Home 和面向 Windows 爱好者的 Cortana。像聊天机器人这样的技术也是由对话代理驱动的，并且在企业公司中越来越受欢迎。

### 文本摘要

自动摘要是通过计算缩短一组数据的过程，以创建代表原始内容中最重要或最相关信息的子集[来源:[维基百科](https://web.archive.org/web/20221206133311/https://en.wikipedia.org/wiki/Automatic_summarization) ]。

### 问题回答

问题回答的任务是构建能够自动回答人类用自然语言提出的问题的系统。

### 机器翻译

机器翻译(MT)是计算语言学的一个分支，涉及将一段文本从一种语言转换成另一种语言。这种类型的一个流行应用是谷歌翻译。

### 主题建模

主题建模是一种无监督的机器学习技术，它揭示了大量文档集合的主题结构。NLP 的这种应用是一种非常常见的工具，用于各种领域，如文学和生物信息学。

虽然这些任务各不相同，但是牢牢掌握这些任务足以让任何有抱负的 NLP 实践者具备构建各种 NLP 应用程序的良好基础。掌握这些应用程序的一部分包括学习在解决问题时可以用来提高生产力的技术。

有各种开源工具可以在非结构化文本(或其他形式的自然语言)中找到有价值的见解，并解决各种问题。下面提供的框架列表绝不是详尽的，但是它们是一个很好的开始，使得自然语言处理对于企业或者任何希望在他们的项目中使用 NLP 的人来说都是可行的。事不宜迟，这里列出了自然语言处理(NLP)项目中最常用的框架。

### 我是 NLTK

自然语言工具包(NLTK)是构建 Python 程序来处理和分析人类语言数据的领先平台之一。 [NLTK 文档](https://web.archive.org/web/20221206133311/https://www.nltk.org/)声明“*”提供了 50 多个语料库和词汇资源(如 WordNet)的易用接口，以及一套用于分类、标记化、词干化、标记、解析和语义推理的文本处理库、工业级 NLP 库的包装器和一个活跃的讨论论坛。*'

像编程世界中的大多数事情一样，掌握 NLTK 需要一些时间。幸运的是，有很多资源可以帮助你掌握这个框架，比如 NLTK 的创造者自己写的《用 Python 进行自然语言处理[](https://web.archive.org/web/20221206133311/http://www.nltk.org/book/)*》一书——这是一种非常实用的自然语言处理任务编程方法。*

 *可以用 NLTK 执行的一些任务的例子包括标记化、标记、词干化、词汇化、解析、分类等等。看看下面来自 [NLTK 文档](https://web.archive.org/web/20221206133311/https://www.nltk.org/)的代码片段。

```py
import nltk

sentence = """At eight o'clock on Thursday morning Arthur didn't feel very good."""
tokens = nltk.word_tokenize(sentence)
print(tokens)

>>>> ['At', 'eight', "o'clock", 'on', 'Thursday', 'morning', 'Arthur', 'did', "n't", 'feel', 'very', 'good', '.']

tagged = nltk.pos_tag(tokens)
print(tagged[0:6])

>>>> [('At', 'IN'), ('eight', 'CD'), ("o'clock", 'JJ'), ('on', 'IN'),
('Thursday', 'NNP'), ('morning', 'NN')]

entities = nltk.chunk.ne_chunk(tagged)
print(entities)

>>>> Tree('S', [('At', 'IN'), ('eight', 'CD'), ("o'clock", 'JJ'),
           ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'),
       Tree('PERSON', [('Arthur', 'NNP')]),
           ('did', 'VBD'), ("n't", 'RB'), ('feel', 'VB'),
           ('very', 'RB'), ('good', 'JJ'), ('.', '.')])

from nltk.corpus import treebank

t = treebank.parsed_sents('wsj_0001.mrg')[0]
t.draw()
```

### 空间

SpaCy 的首次发布是在 2015 年 2 月，使其成为 Python 自然语言处理应用程序的最新开源框架之一。与 2001 年创建的 NLTK 相比，SpaCy 的创建者有足够的时间来学习 NLTK 并了解它的不足之处。与 NTLK 相比，最显著的改进之一是性能增强，因为 SpaCy 使用了一些最新最好的算法。

此外，SpaCy 有很好的文档记录，并被设计为支持大量数据。它还包括一系列预训练的自然语言处理模型，这使得学习、教学和使用 SpaCy 进行自然语言处理变得更加容易。

**注意** : *如果你希望将深度学习算法应用于你的非结构化数据，SpaCy 可能是你要使用的库——提取任务也是如此。*

下面是 SpaCy 文档中 SpaCy 功能的一个例子。

```py
import spacy

nlp = spacy.load("en_core_web_sm")

text = ("When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.
I can tell you very senior CEOs of major American car companies would
shake my hand and turn away because 'I wasn't worth talking to',
said Thrun, in an interview with Recode earlier this week.")
doc = nlp(text)

print("Noun phrases:", [chunk.text for chunk in doc.noun_chunks])
print("Verbs:", [token.lemma_ for token in doc if token.pos_ == "VERB"])

for entity in doc.ents:
    print(entity.text, entity.label_)

>>>> Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']
Verbs: ['start', 'work', 'drive', 'take', 'can', 'tell', 'would', 'shake', 'turn', 'talk', 'say']
Sebastian NORP
Google ORG
2007 DATE
American NORP
Recode ORG
earlier this week DATE
```

### 斯坦福·科伦普

CoreNLP 是一个非常受欢迎的用于自然语言处理任务的库，由斯坦福 NLP 社区构建——他们也积极维护该框架。与分别用 Python 或 Cython 编写的 NLTK 和 SpaCy 相反，CoreNLP 是用 Java 编写的——这意味着你的计算机需要有 JDK(但它有用于大多数编程语言的 API)。

在 CoreNLP 主页上，开发者将 CoreNLP 描述为“*Java 自然语言处理的一站式商店！CoreNLP 使用户能够导出文本的语言注释，包括标记和句子边界、词性、命名实体、数值和时间值、依存和选区解析器、共指、情感、引用属性和关系。CoreNLP 目前支持 6 种语言:阿拉伯语，中文，英语，法语，德语和西班牙语。*

CoreNLP 的主要优势之一是它的可伸缩性，这使它成为复杂任务的首选。另一个因素是，它在建造时就考虑到了速度——它已经过优化，速度极快。

### Gensim

Gensim 是一个专门的开源 Python 框架，用于以最有效、最轻松的方式将文档表示为语义向量。作者设计了 Gensim 来使用各种机器学习算法处理原始的、非结构化的纯文本——因此使用 Gensim 来处理主题建模等任务是一个好主意。此外，Gensim 在识别文本相似性、索引文本和导航不同文档方面做得很好。

在[文档](https://web.archive.org/web/20221206133311/https://radimrehurek.com/gensim/intro.html)中，作者明确指出 Gensim 是从零开始构建的，原因有三:

*   **实用性**–作为行业专家，我们专注于解决实际行业问题的久经考验的算法。更多关注工程，更少关注学术。
*   **内存独立性**–不需要在任何时候将整个训练语料库完全驻留在 RAM 中。它可以使用数据流处理大型网络规模的语料库。
*   **性能**–使用 C、BLAS 和内存映射对流行的向量空间算法进行了高度优化。

下面是 Gensim [Word2Vec 教程](https://web.archive.org/web/20221206133311/https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py)文档页面上的一些代码示例。

```py
import gensim.downloader as api
wv = api.load('word2vec-google-news-300')

for index, word in enumerate(wv.index2entity):
    if index == 10:
        break
    print(f"word #{index}/{len(wv.index2entity)} is {word}")

>>>> word 
     word 
     word 
     word 
     word 
     word 
     word 
     word 
     word 
     word 

```

```py
pairs = [
    ('car', 'minivan'),   
    ('car', 'bicycle'),   
    ('car', 'airplane'),  
    ('car', 'cereal'),    
    ('car', 'communism'),
]
for w1, w2 in pairs:
    print('%rt%rt%.2f' % (w1, w2, wv.similarity(w1, w2)))

>>>> ‘car’    ‘minivan’    0.69
     ‘car’    ‘bicycle’    0.54
     ‘car’    ‘airplane’   0.42
     ‘car’    ‘cereal’     0.14
     ‘car’    ‘communism’  0.06

```

### TensorFlow & PyTorch

尽管是两个非常不同的框架，我认为最好列出这两个框架，因为它们都被认为是深度学习的流行框架。Tensorflow 是较早的一个，它是由谷歌的大脑团队开发的——他们也积极地将该框架用于研究和生产级别的项目。另一方面，Pytorch 是一个基于 torch 库的开源库，主要由脸书的 AI 研究(FAIR)实验室开发。

关于 Tensorflow 或 PyTorch 的争论由来已久，这绝对超出了本文的范围。我给那些不确定学习哪一个的人的建议是学习你的组织使用的，或者你想为之工作的组织。如果他们还没有完全采用深度学习，那么我会说 PyTorch 有一个更容易的学习曲线。

下面你可以看到如何使用这两个框架建立一个 LSTM 模型。首先是 tensor flow——完整的源代码，请访问 [Christian Versloot 机器曲线博客。](https://web.archive.org/web/20221206133311/https://www.machinecurve.com/index.php/2021/01/07/build-an-lstm-model-with-tensorflow-and-keras/)

```py
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.layers import Embedding, Dense, LSTM
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.sequence import pad_sequences

additional_metrics = ['accuracy']
batch_size = 128
embedding_output_dims = 15
loss_function = BinaryCrossentropy()
max_sequence_length = 300
num_distinct_words = 5000
number_of_epochs = 5
optimizer = Adam()
validation_split = 0.20
verbosity_mode = 1

tf.compat.v1.disable_eager_execution()

(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_distinct_words)
print(x_train.shape)
print(x_test.shape)

padded_inputs = pad_sequences(x_train, maxlen=max_sequence_length, value = 0.0) 
padded_inputs_test = pad_sequences(x_test, maxlen=max_sequence_length, value = 0.0) 

model = Sequential()
model.add(Embedding(num_distinct_words, embedding_output_dims, input_length=max_sequence_length))
model.add(LSTM(10))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)

model.summary()

history = model.fit(padded_inputs, y_train, batch_size=batch_size, epochs=number_of_epochs, verbose=verbosity_mode, validation_split=validation_split)

test_results = model.evaluate(padded_inputs_test, y_test, verbose=False)
print(f'Test results - Loss: {test_results[0]} - Accuracy: {100*test_results[1]}%')

>>>> Test results - Loss: 0.3655 - Accuracy: 85.6880
```

这是 PyTorch 中的一个 LSTM——要获得完整的运行和源代码，请访问 PyTorch 文档中的[序列模型教程](https://web.archive.org/web/20221206133311/https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html)。

```py
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

torch.manual_seed(1)

def prepare_sequence(seq, to_ix):
    idxs = [to_ix[w] for w in seq]
    return torch.tensor(idxs, dtype=torch.long)
training_data = [

    ("The dog ate the apple".split(), ["DET", "NN", "V", "DET", "NN"]),
    ("Everybody read that book".split(), ["NN", "V", "DET", "NN"])
]
word_to_ix = {}

for sent, tags in training_data:
    for word in sent:
        if word not in word_to_ix:  
            word_to_ix[word] = len(word_to_ix)  
tag_to_ix = {"DET": 0, "NN": 1, "V": 2}  

EMBEDDING_DIM = 6
HIDDEN_DIM = 6

class LSTMTagger(nn.Module):

    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):
        super(LSTMTagger, self).__init__()
        self.hidden_dim = hidden_dim

        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)

        self.lstm = nn.LSTM(embedding_dim, hidden_dim)

        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)

    def forward(self, sentence):
        embeds = self.word_embeddings(sentence)
        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))
        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))
        tag_scores = F.log_softmax(tag_space, dim=1)
        return tag_scores

model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))
loss_function = nn.NLLLoss()
optimizer = optim.SGD(model.parameters(), lr=0.1)

with torch.no_grad():
    inputs = prepare_sequence(training_data[0][0], word_to_ix)
    tag_scores = model(inputs)
    print(tag_scores)

for epoch in range(300):  
    for sentence, tags in training_data:

        model.zero_grad()

        sentence_in = prepare_sequence(sentence, word_to_ix)
        targets = prepare_sequence(tags, tag_to_ix)

        tag_scores = model(sentence_in)

        loss = loss_function(tag_scores, targets)
        loss.backward()
        optimizer.step()

with torch.no_grad():
    inputs = prepare_sequence(training_data[0][0], word_to_ix)
    tag_scores = model(inputs)

    print(tag_scores)
>>>> tensor([[-1.1389, -1.2024, -0.9693],
        [-1.1065, -1.2200, -0.9834],
        [-1.1286, -1.2093, -0.9726],
        [-1.1190, -1.1960, -0.9916],
        [-1.0137, -1.2642, -1.0366]])
tensor([[-0.0462, -4.0106, -3.6096],
        [-4.8205, -0.0286, -3.9045],
        [-3.7876, -4.1355, -0.0394],
        [-0.0185, -4.7874, -4.6013],
        [-5.7881, -0.0186, -4.1778]])
```

了解如何使用 [TensorFlow + Neptune](https://web.archive.org/web/20221206133311/https://docs.neptune.ai/essentials/integrations/deep-learning-frameworks/tensorflow-keras) 集成或 [PyTorch + Neptune](https://web.archive.org/web/20221206133311/https://docs.neptune.ai/essentials/integrations/deep-learning-frameworks/pytorch) 集成来跟踪模型训练元数据。

### 拥抱脸

近年来，变压器模型极大地推进了 NLP。它本质上是一种新颖的架构，在解决序列间任务时考虑了长期依赖性。在大多数情况下，NLP 模型非常大，需要大量的计算才能得到一个像样的工作模型。拥抱脸 Python 框架为各种 NLP 任务提供了对大量预训练模型的访问。甚至像亚马逊，谷歌人工智能和脸书人工智能利用这个包。

下面是一个用于情感分析的拥抱脸管道的例子——你可以在[文档](https://web.archive.org/web/20221206133311/https://huggingface.co/transformers/quicktour.html)中读到更多相关信息。

```py
from transformers import pipeline

clf = pipeline("sentiment-analysis")

data = ["I am happy to be reading this article",
        "I am not happy to read this article",
        "This is a really informative article",
        "Thank you for reading"]

results = clf(data)

for result in results:
  print(f"label: {result['label']}, score: {round(result['score'], 4)}")

>>>> label: POSITIVE, score: 0.9999
     label: NEGATIVE, score: 0.9989
     label: POSITIVE, score: 0.9998
     label: POSITIVE, score: 0.9998

```

与传统的机器学习项目类似，NLP 项目是高度迭代的。在项目生命周期的旅程中，迭代特定的部分直到 NLP 系统满足一些期望的内在性能水平是很常见的。内在评估更关注中间目标，例如 NLP 组件如何在定义的子任务上执行。

一旦项目被部署到生产环境中，它还远远没有完成。现实世界中的交互、反馈和变化会改变当前 NLP 组件的需求，这意味着循环回到项目生命周期中的早期步骤来更新(或改进)它。

为了让你的 NLP 项目上线，有各种各样的工具不仅可以帮助开发人员，也可以帮助那些不太懂技术的 AI 团队成员。这些工具包括消息应用、实验管理工具、[跟踪工具](/web/20221206133311/https://neptune.ai/experiment-tracking)等等。这里有一个有价值的项目管理工具的列表，你可能想用在你的 NLP 项目中:

### 海王星 AI

海王星。AI 是一个轻量级的实验跟踪和模型注册。它极大地促进了合作，并且可以跟踪你所有的实验。它非常灵活，可以很好地与许多框架集成(包括上面提到的那些)。使用该工具，您可以记录、存储、显示、组织和查询您的所有机器学习操作(MLOps)元数据。

**海王 AI 提供了什么？**

*   记录和显示机器学习模型的元数据
*   组织实验和模型训练运行的中心
*   轻松比较实验和机器学习模型
*   观看您的机器学习实验实时运行
*   可重复的实验和模型训练运行
*   与队友分享可视化效果的特殊链接
*   以编程方式查询实验和模型训练元数据
*   从任何地方运行您的代码(笔记本电脑、云基础设施或集群)

### MLFlow

MLFlow 的一个很酷的地方是，您可以将它用于任何机器学习库和任何编程语言，因为所有可用的函数都是通过 REST API 和 CLI 访问的。除了从技术角度来看的可访问性之外，MLflow 文档编写得非常好，易于理解。[文档](https://web.archive.org/web/20221206133311/https://mlflow.org/docs/latest/index.html)声明:

“MLflow 是一个管理端到端机器学习生命周期的开源平台。它处理四个主要功能:

*   跟踪实验以记录和比较参数和结果( [MLflow Tracking](https://web.archive.org/web/20221206133311/https://www.mlflow.org/docs/latest/tracking.html#tracking) )。
*   以可重用、可复制的形式包装 ML 代码，以便与其他数据科学家共享或转移到生产中( [MLflow 项目](https://web.archive.org/web/20221206133311/https://www.mlflow.org/docs/latest/projects.html#projects))。
*   从各种 ML 库中管理和部署模型到各种模型服务和推理平台( [MLflow Models](https://web.archive.org/web/20221206133311/https://www.mlflow.org/docs/latest/models.html#models) )。
*   提供一个中央模型库来协作管理 MLflow 模型的整个生命周期，包括模型版本化、阶段转换和注释( [MLflow 模型注册中心](https://web.archive.org/web/20221206133311/https://www.mlflow.org/docs/latest/model-registry.html#registry))。"

这基本上概括了 MLflow 提供的一切—我告诉过你他们的文档写得很好。

另请阅读:[最佳物流替代方案(2021 年更新)](/web/20221206133311/https://neptune.ai/blog/the-best-mlflow-alternatives)

### 开源代码库

Github 是面向开发者的社交网站。它为全球超过 5600 万开发者提供互联网托管以及使用 Git 的版本控制。Github 使协作变得简单而不费力，其特性允许代码托管和审查、全面的项目管理和方便的软件构建。通常，项目经理和开发人员利用 Github 在单一环境中协调、跟踪和更新他们的工作。

平台有很多特性，每个特性都是多方面的。总的来说，Github 提供的功能分为七类:

*   协作编码
*   自动化和持续集成/持续开发(CI/CD)
*   安全性
*   客户端应用程序
*   项目管理
*   团队管理
*   社区

### 彗星 ML

彗星的主页。ML 的网站上写着“*彗星。ML 允许数据科学家和开发人员轻松地监控、比较和优化他们的机器学习模型*——没有比这更清楚的了。其中最受欢迎的功能是他们的现场实验图表；彗星。ML 为您提供了一个引人注目的仪表板，它将您的 ML 实验代码及其结果绑定在一起，还提供了一些功能，帮助从业者通过调整超参数来优化他们的模型。

NLP 项目在许多方面类似于传统的软件应用程序，但也有很大的不同。这是相似的，因为两个应用程序都是在受控的开发环境中制作的。这是不同的，因为 NLP 和机器学习项目通常还包括来自一个永无止境的来源，称为现实世界的数据，因此我们用来构建应用程序的数据也必须被跟踪。

这就是彗星。ML 进来了。彗星。ML 允许用户:

*   追踪数据集，
*   跟踪代码的更改，
*   跟踪实验历史和机器学习见解。

另外彗星。ML 为从业者更快地构建更好的模型提供了有价值的见解和数据，同时也提高了生产率、协作性和可解释性。

另请阅读:[最佳 Comet.ml 替代方案](/web/20221206133311/https://neptune.ai/blog/the-best-comet-ml-alternatives)

### 松弛的

想想 WhatsApp，Facebook Messenger，或者 iMessage……现在给它吃类固醇吧。那是懈怠。Slack 是一个面向团队和整个工作组织的消息应用程序。它可以跨各种不同的设备和平台使用。该应用程序具有许多强大的功能，可以让个人在各种聊天室以及一对一的房间中进行交流——自从全球疫情大受欢迎以来，Slack 已经成为企业和团队的一个宝贵工具。

为了让团队的所有成员保持一致，有各种功能，例如:

*   **频道**——对话的中心空间。各种主题可能有多个渠道(如资源、支持、项目 1)。
*   **Slack Connect**–与来自不同公司的团队合作(对于参与 B2B 服务的公司来说非常好)
*   **语音和视频通话**

Slack 有许多应用程序和集成，可以全面提高生产率。我个人最喜欢的是 Google Drive 集成，它允许用户共享和管理对文件的访问，以及接收更新等，所有这些都在 Slack 中完成。还集成了其他常见应用程序，如 OneDrive、Zoom 和 Outlook。

### 吉拉

吉拉是由 Atlassian 开发的，用于专有问题跟踪，使它成为团队以灵活和自动化的方式规划项目、跟踪项目和发布产品或软件的伟大工具。这个工具非常适合敏捷团队，因为它包含了项目管理。用户可以自由地管理他们的项目，给团队成员分配任务(包括给程序员分配 bug)，创建里程碑，计划有指定期限的任务。

吉拉的一些功能包括(在[吉拉功能](https://web.archive.org/web/20221206133311/https://www.atlassian.com/software/jira/features)页面上阅读关于这些功能的更多信息):

*   Scrum 板
*   看板板
*   路线图
*   敏捷报告

吉拉很受欢迎，是 NLP 项目非常合适的解决方案，因为它促进了协作以及简化、组织和结构化工作流。

## 最后一个音符

数据科学家、人工智能团队和企业可以使用大量优秀的工具来简化 NLP 项目。

重要的是，您找到了最适合您需求的工具，并且集成了让您的项目顺利完成所需的功能。

感谢您的阅读，祝您的项目好运！*