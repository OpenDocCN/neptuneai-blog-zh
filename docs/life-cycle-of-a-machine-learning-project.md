# 机器学习项目的生命周期:有哪些阶段？

> 原文：<https://web.archive.org/web/https://neptune.ai/blog/life-cycle-of-a-machine-learning-project>

机器学习及其生命周期是关于什么的？不同的人会给你不同的答案。

*   程序员可能会说，这是关于用 Python 和复杂的数学算法编程。
*   商业利益相关者通常将机器学习与数据和一点神秘感联系在一起。
*   机器学习工程师倾向于谈论模型训练和数据争论。

那么谁是对的呢？所有人。

机器学习是关于数据的——没有谎言。没有足够多的数据供机器学习，就没有机器学习。可用数据量呈指数级增长，这使得机器学习开发比以往任何时候都更容易。

机器学习和算法之间的联系也在一点上。的确，有复杂的数学方法迫使机器学习。没有数学——没有机器学习。

最后，模型训练和数据准备确实是每个 ML 项目的核心。机器学习工程师花费大量时间训练模型和准备数据集。这就是为什么它是 ML 工程师首先想到的。

机器学习是关于开发、操纵数据和建模的。所有这些独立的部分一起形成了一个**机器学习项目生命周期**，这正是我们在本文中要讨论的内容。

## ML 生命周期的高级视图

机器学习项目的生命周期可以表示为一个多组件流程，其中每个连续的步骤都会影响流程的其余部分。让我们从很高的层面来看一下流程中的步骤:

1.  问题理解(又名业务理解)。
2.  数据收集。
3.  数据标注。
4.  数据角力。
5.  模型开发、培训和评估。
6.  生产环境中的模型部署和维护。

如你所见，整个循环包括 6 个连续的步骤。每一步都是独特的，有其自身的性质。这些差异导致完成每个步骤所需的资源、时间和团队成员的变化。让我们详细看看生命周期中的每个组成部分，看看它是怎么回事。

## 详细的 ML 生命周期

### 第一步:理解问题

每个项目都从一个你需要解决的问题开始。理想情况下，清晰的问题定义应该用数字描述。数字不仅能让你知道你的起点在哪里，还能让你在以后追踪变化的效果。

例如，我工作的公司有显示每个手动操作给企业带来多少成本的计算。这种方法有助于我们对运营进行分层，并根据我们需要花费的金额对其进行优先排序。

我们的管理层最近启动了一个新的机器学习项目，旨在为目前我们支出清单上最重要的特定手动操作带来自动化。该团队还进行了研究，将运营成本与我们的竞争对手进行了对比。

结果令人失望:类似的手动操作比我们行业中的其他公司便宜 20%。为了在市场上成功竞争，我们必须降低成本。这就是我们启动自动化项目的原因。

这就是我们的全部问题吗？不完全是。知道成本并不意味着我们可以将这个问题交给我们的机器学习团队，并期望他们来解决它。

到目前为止，我们只从商业角度定义了这个问题。在任何机器学习发生之前，我们需要从货币单位转移到我们的机器学习团队可以理解的其他 KPI。

为此，我们的管理层发现，如果我们想将给定的手动操作成本降低 20%，我们应该将手动处理的数量从 100%减少到至少 70%。这意味着 30%的操作应该是自动处理的。知道这一点可以帮助我们缩小项目的范围，让我们明白我们只需要针对问题的一部分，而不是整个问题。

接下来，我们要针对的手动操作被分解成几个部分。知道了每件事在时间(和金钱)上的花费，团队就能够为可能自动化的任务提出一个建议列表。

在与机器学习团队讨论这个列表时，他们挑选了一些任务，如果有适当的数据，这些任务可以通过监督机器学习算法来解决。

**最后，问题理解完成**:公司的每个团队都知道他们的目标和原因。项目可以开始了。

### 步骤 2:数据收集

数据就是力量。当问题清楚了，建立了合适的机器学习方法，就该收集数据了。

数据可以来自多个来源。您可能有一个可以查询相关数据的内部数据库。你可以让数据工程师帮你提取数据，或者使用现有的服务，比如亚马逊 Mturk，或者自己动手。

其他人从他们的客户端接收数据。当你和客户一起解决问题时，这是典型的情况。客户对最终结果感兴趣，并且愿意共享数据资产。

另一个可以考虑的选择是从第三方提供商那里购买数据。[尼尔森媒介研究](https://web.archive.org/web/20221206004255/http://www.nielsen.com/)就是一个很好的例子。它专注于快速消费品市场。他们做了大量的研究，从不同的市场人群中收集数据。销售快速消费品的公司总是在了解他们的客户和他们的偏好，以便利用新兴趋势盈利。像 NMR 这样的第三方提供商是有价值数据的重要来源。

还有开源数据集。如果你在处理一个许多企业和行业都可能遇到的一般性问题，它们会特别方便。你需要的数据集很有可能已经在网上的某个地方了。一些数据集来自政府组织，一些来自上市公司和大学。

更酷的是，公共数据集通常带有注释(如果适用)，因此您和您的团队可以避免花费大量项目时间和成本的手动操作。请将这些文章视为指南，帮助您为您的项目找到合适的公开可用数据集:

你的目标是收集尽可能多的相关数据。如果我们谈论表格数据，这通常意味着获取大时间跨度的数据。记住:你的样本越多，你未来的模型就越好。

在生命周期的后期，您将经历数据准备步骤，这可能会显著减少数据集中的样本数量(稍后我将解释原因)。这就是为什么在项目生命周期的最开始，积累尽可能多的数据是至关重要的。

如果你收集的还不够，你有两个选择:

数据扩充会给现有数据集带来额外的变化，从而使模型更易于泛化。它并不真的添加更多的样本，它只是操纵当前的数据来充分利用它。

从个人经验来看，我可以说你应该仔细考虑你应用的数据增强的类型。您只需要寻找反映模型将被使用的真实生产环境的增强。没有必要“教导”模型为那些你肯定知道在现实生活中不会发生的情况做好准备。在本文的后面，我们将讨论探索性数据分析(EDA ),它可以揭示您处理哪种数据以及哪种类型的增强是合适的。

另一方面，合成数据集是可用作模型输入的新样本。这是全新的数据，你可以使用[无监督的深度学习](https://web.archive.org/web/20221206004255/https://towardsdatascience.com/image-generation-in-10-minutes-with-generative-adversarial-networks-c2afc56bfa3b)(例如，生成对抗网络)，或者使用图像库(例如，在 Python 中，你可以想到 OpenCV 或 PIL)人工生成。

生成对抗网络从现有的例子中生成新的例子。作为一个很好的例子，我们可以参考计算机视觉行业，工程师使用这种架构类型从现有的、通常很小的数据集创建新的独特图像。我个人可以说，GANs 生成的图像质量相当好，对于标注(ML 项目生命周期的第 4 步)和进一步的神经网络训练(生命周期的第 5 步)相当有用。

### 第三步:数据准备

收集的数据杂乱无章。机器学习工程师在处理原始数据时会面临很多问题。以下是最常见的问题:

*   应该过滤相关数据。无关数据要清理；
*   应识别并去除噪音、误导和错误的样本；
*   应识别并消除异常值；
*   缺失值应被发现，并通过适当的方法删除和估算；
*   数据应该转换成适当的格式。

正如你所看到的，当处理原始数据时，机器学习工程师可能会面临多个问题。就其带来的问题而言，每个数据集都是独特的。关于如何进行数据预处理，没有经验法则。这个过程是创造性的和多方面的。

让我们考虑缺失值。这是大多数数据集都存在的一个普遍问题。ML 工程师可以简单地丢弃这些值，只处理数据集中的有效记录。

或者，你可以进行插补，用 NaNs 填充记录。又在找经验法则？不幸的是，这里也没有。根据您选择的不同标准，可以通过多种方式进行估算。用于估算的数学算法也不同，同样你有多种选择要考虑。

从现有特征创建新特征是机器学习工程师应该考虑的另一个选项。这个过程被称为数据工程。我个人经常做的数据工程的一个很好的例子是通过主成分分析(PCA)进行降维。PCA 减少了数据集中的特征数量，只保留那些对未来决策最有价值的特征。

一旦您完成了数据准备的核心部分，您可能想要转移到数据处理。数据预处理是一个步骤，使你的数据可以被你正在训练的神经网络或算法所消化。它通常意味着数据规范化、标准化和缩放。

通常，数据准备步骤伴随着探索性数据分析(EDA ),它补充了整个准备过程。EDA 帮助工程师熟悉他们所处理的数据。这通常意味着构建一些可以从不同角度帮助数据的图表。工程师从这种分析中获得的直觉有助于以后为数据准备、模型架构/算法选择(ml 项目生命周期的步骤 5.2)以及正确的度量选择(项目生命周期的步骤 5.4)找到正确的方法和工具。

[数据准备](https://web.archive.org/web/20221206004255/https://machinelearningmastery.com/what-is-data-preparation-in-machine-learning/)(又名数据争论)是最耗时的步骤之一，但也是最重要的步骤之一，因为它直接影响将进入网络的数据的质量。

我通常以数据预处理步骤结束，将处理后的数据分成三个独立的子集:用于训练、验证和测试的数据。对于小数据集，我分配不超过 30 %的数据用于验证和测试，其余的数据用于训练。对于大数据集(大于 10k，我是一名计算机视觉工程师，所以我处理图像),我的个人实践使我得出以下分割比:

*   10%用于测试，
*   10 %用于培训期间的验证，
*   80%用于培训。

我强烈推荐的拆分策略是分层拆分，这有助于保持每个数据集中类的比例相等。这对正确的性能评估很重要。

### 步骤 4:数据注释

如果你的工作是在[监督学习](https://web.archive.org/web/20221206004255/https://www.ibm.com/cloud/learn/supervised-learning)领域，你需要为数据集中的每个样本添加一个标签。为数据样本分配标签的过程称为数据注释或数据标注。

[数据标注](https://web.archive.org/web/20221206004255/https://lionbridge.ai/articles/data-annotation-machine-learning/)是一项手动操作，非常耗时，而且通常由第三方执行。很少有机器学习工程师自己做标签的情况。考虑到您和您的团队很可能不会自己检查注释过程，您在这一步的主要目标是设计一个全面的注释指南。

指南将让注释者知道该做什么。这就是为什么要想出一个全面的指南来涵盖注释工作最基本的方面是至关重要的。不要忘记贴标过程中可能出现的边缘情况。您的注释团队应该为他们可能面临的每一个可能的场景做好准备。在注释工作中没有假设的空间。一切都必须清晰透明。您还应该指派一个人来协助注释团队。如果您不能处理一个特定的例子，注释者应该知道联系谁来解决他们的问题。

有一些很好的例子可以用来创建自己的注释指南。如果你对注释如何影响整个机器学习生命周期感到好奇，可以考虑阅读这篇研究论文。请记住，数据注释的质量会直接影响最终模型的性能。不要限制注释指南的工作时间。让它易于使用并且足够详细。例子总是有帮助的，并且通常很受注释者的欢迎。花在指南注释上的时间是对最终结果质量的投资。

### 第五步:建模

到这一步，您应该有一个完整的数据集，可以输入到模型中。下一步是什么？是时候对未来的模式做出决定，并组装它。

#### 5.1.尝试通过迁移学习来解决你的问题

机器学习工程师不会从零开始创建模型。他们倾向于重用已经在大型公共数据集上表现良好的模型。这些预先训练的模型可用于微调。这种方法已经在深度学习中广泛建立。例如，在计算机视觉中，微调工作得很好，因为 CNN 提取的低级特征对于大范围的任务是统一的。

你可以找到公共预训练模型的地方被称为模型动物园。 [Github](https://web.archive.org/web/20221206004255/https://github.com/) 是预训练模型的一个很好的来源，有数百个可能的选项。你只需要搜索你所使用的给定架构和框架的模型。

例如，TensorFlow 是一个机器学习框架，它提供了一个导入预训练模型的机会。[这里有一个由 TensorFlow 创建的带有检测模型的动物园](https://web.archive.org/web/20221206004255/https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)的例子。这些模型可用于计算机视觉中的[迁移学习](/web/20221206004255/https://neptune.ai/blog/transfer-learning-guide-examples-for-images-and-text-in-keras)。

您应该始终为您的项目寻找一个预先训练好的模型来开始工作。它将节省您的时间、计算资源，甚至提高最终结果的质量。

#### 5.2.相应地调整模型架构

需要注意的是，我们导入的预训练模型需要进行修改，以反映我们正在执行的特定任务。

如果你从事计算机视觉，你可能记得一个分类模型可以识别的类的数量取决于模型架构的顶部。最后一个密集图层的单元数量应等于您想要区分的类的数量。您的工作是准备一个适合您目标的最终模型架构设计。

#### 5.3.多做实验

机器学习工程师倾向于做大量实验。我们喜欢尝试多种模型配置、架构和参数。您可能不会接受您得到的基线结果，并将其转移到生产中。这个结果很少会成为最好的结果。寻找最佳模型配置的迭代训练过程是机器学习工程师的常见做法。

在这一点上，你应该尝试多种可供选择的假设，这些假设可能对你的任务有用。为了缩小可能选项的列表，您可以考虑使用大多数 ML 框架提供的[超参数调优](/web/20221206004255/https://neptune.ai/blog/hyperparameter-tuning-in-python-a-complete-guide-2020)方法。这些方法评估多种配置的性能，比较它们，并让您了解性能最佳的配置。您只需指定要采样的值和参数。

实验是我们工作的本质。如果你的计算资源不是有限的，你一定要利用它。你可能会得到意想不到的结果。谁知道呢，也许一个新的最先进的模型配置将来自你的一个实验。

如果你运行了大量的实验，检查一下如何很好地跟踪和组织它们。

#### 5.4.正确评估

评估总是和做实验联系在一起的。您需要了解每个模型的行为，以便选择性能最佳的模型。为了比较模型，需要定义一组度量标准。

根据您正在处理的问题，您的度量标准会有所不同。比如对于回归问题，我们通常看 MSE 或者 MAE。另一方面，要评估分类模型，准确性可能是平衡数据集的一个好选择。不平衡的集合需要更复杂的度量。对于这种情况，F1 分数是一个很好的指标。

训练期间的评估在单独的验证数据集上执行。它跟踪我们的模型在泛化方面有多好，避免了可能的偏差和过度拟合。

在培训工作中可视化模型进度始终是一个很好的实践。Tensorboard 是第一个也是最基本的选择。或者，Neptune.ai 是一个更高级的工具，它可以可视化模型随时间变化的性能，还可以进行[实验跟踪](/web/20221206004255/https://neptune.ai/experiment-tracking)。拥有合适的工具至关重要。花点时间去找一个符合你特殊需求的实验跟踪工具。当你得到一个的时候，你将会节省大量的时间并且改善你的整个工作流程。

### 步骤 6:模型部署

太棒了。你有一个出色的模型，准备投入生产。现在，工程师部署一个训练模型，并使其可用于外部推理请求。

这是机器学习生命周期的最后一步。但是工作还远没有结束，我们不能放松下来，等待新的项目。

**部署的模型需要监控**。您需要跟踪部署的模型性能，以确保它继续以业务所需的质量完成工作。我们都知道随着时间的推移可能会发生一些负面影响:模型退化是最常见的影响之一。

另一个好的做法是收集模型错误处理的样本，以找出其发生的根本原因，并使用它来重新训练模型，使其对此类样本更加稳健。这种小规模的持续研究将帮助你更好地理解可能的边缘情况和其他你当前的模型没有准备好的意外事件。

## 结论

到现在为止，你应该对整个机器学习项目的生命周期有了很好的理解。让我再次强调，一个周期中的每一个连续步骤都可能对后面的步骤产生重大影响，既有积极的一面，也有消极的一面。你必须仔细检查每一步。

我的个人实践表明**步骤#2(数据收集)、步骤#3(数据准备)和步骤#4(数据标注)是需要时间最多的**。

进入模型的数据质量是一个好模型的关键驱动因素。不要忽视这些步骤，并始终投入足够的时间和资源。