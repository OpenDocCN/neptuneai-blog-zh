<html>
<head>
<title>Deep Dive into ML Models in Production Using TensorFlow Extended (TFX) and Kubeflow </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>使用TensorFlow Extended (TFX)和Kubeflow深入研究生产中的ML模型</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/deep-dive-into-ml-models-in-production-using-tfx-and-kubeflow#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/deep-dive-into-ml-models-in-production-using-tfx-and-kubeflow#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<blockquote class="wp-block-quote is-style-default"><p>如果整个行业的Jupyter笔记本电脑中每浪费一个机器学习模型，我就会成为百万富翁。—我</p></blockquote>



<p>构建模型是一回事，将模型投入生产又是另一回事。机器学习最难的部分之一是有效地将模型投入生产。</p>



<p>这里强调的是<strong>有效地</strong>，因为虽然有很多方法可以将模型投入生产，但是很少有工具可以有效地部署、监控、跟踪和自动化这个过程。</p>



<p>在本教程中，我将向您介绍<strong> TensorFlow Extended，俗称TFX。</strong>你将使用TFX、谷歌人工智能平台管道和Kubeflow，将一个示例机器学习项目投入生产。</p>







<p>如果您是第一次学习这些工具，请不要担心，我将尽力正确地解释它们，同时也实际地实现它们。</p>



<p>要完成本教程或继续学习，你需要一个<a href="https://web.archive.org/web/20221201153827/https://cloud.google.com/gcp/?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=emea-emea-all-en-dr-bkws-all-all-trial-b-gcp-1009139&amp;utm_content=text-ad-none-any-DEV_c-CRE_380533847713-ADGP_Hybrid+%7C+AW+SEM+%7C+BKWS+~+BMM_M:1_EMEA_EN_General_Cloud_gcp-KWID_43700053286073021-kwd-20903505266-userloc_1029654&amp;utm_term=KW_%2Bgcp-NET_g-PLAC_&amp;ds_rl=1242853&amp;ds_rl=1245734&amp;ds_rl=1242853&amp;ds_rl=1245734&amp;gclid=Cj0KCQjw7sz6BRDYARIsAPHzrNLXt8SrFgZ1ZFiZXIwbxO1p3mcq5dXgDv2YcvgFmaSNQTAY8kBF9sYaAmrqEALw_wcB" target="_blank" rel="noreferrer noopener nofollow"> GCP账户</a>。如果你还没有，请到<a href="https://web.archive.org/web/20221201153827/https://cloud.google.com/gcp/?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=emea-emea-all-en-dr-bkws-all-all-trial-b-gcp-1009139&amp;utm_content=text-ad-none-any-DEV_c-CRE_380533847713-ADGP_Hybrid+%7C+AW+SEM+%7C+BKWS+~+BMM_M:1_EMEA_EN_General_Cloud_gcp-KWID_43700053286073021-kwd-20903505266-userloc_1029654&amp;utm_term=KW_%2Bgcp-NET_g-PLAC_&amp;ds_rl=1242853&amp;ds_rl=1245734&amp;ds_rl=1242853&amp;ds_rl=1245734&amp;gclid=Cj0KCQjw7sz6BRDYARIsAPHzrNLXt8SrFgZ1ZFiZXIwbxO1p3mcq5dXgDv2YcvgFmaSNQTAY8kBF9sYaAmrqEALw_wcB" target="_blank" rel="noreferrer noopener nofollow">这里</a>注册，你会得到300美元的注册积分，可以用来进行实验。除此之外，您还需要:</p>



<ul><li>对机器学习的基本理解</li><li>对<a href="/web/20221201153827/https://neptune.ai/integrations/tensorflow" target="_blank" rel="noreferrer noopener">张量流</a>的基本理解</li><li>对云平台有一点熟悉</li><li>显然，你也需要Python</li></ul>



<h2 id="Introduction">TFX和库伯弗洛简介</h2>



<p>TFX是一个基于Tensorflow的生产规模的机器学习平台。它由谷歌所有并积极维护，在谷歌内部使用。</p>







<p>TFX提供了一系列框架、库和组件，用于定义、启动和监控生产中的机器学习模型。</p>



<p>TFX提供的组件让您可以从一开始就构建专为扩展而设计的高效ML管道。这些组件包括:</p>



<ul><li>建模，</li><li>培养</li><li>上菜(推断)，</li><li>以及管理不同目标的部署，如web、移动或物联网设备。</li></ul>



<p>在下图中，您可以看到可用TFX库和可用管道组件之间的关系，您可以使用它们来实现这一点。</p>











<p>您会注意到，TFX库和组件涵盖了一个典型的端到端机器学习管道，从数据摄取开始，到模型服务结束。</p>



<p>Python中提供了用于实现上述不同任务的TFX库，这些库可以单独安装。但是建议只安装TFX，它带有所有的组件。</p>



<p>随着本教程的进行，你将会使用不同的TFX组件，在向你展示如何使用它之前，我将首先解释它的功能。</p>



<p id="separator-block_5f89523157abc" class="block-separator block-separator--5"> </p>



<h3><strong>幕后的TFX和指挥者</strong></h3>



<p>默认情况下，TFX会为您的ML管道创建一个有向无环图(DAG)。它使用<a href="https://web.archive.org/web/20221201153827/https://beam.apache.org/" target="_blank" rel="noreferrer noopener nofollow"> Apache-Beam </a>来管理和实现管道，这可以在分布式处理后端上轻松执行，如<a href="https://web.archive.org/web/20221201153827/https://spark.apache.org/" target="_blank" rel="noreferrer noopener nofollow"> Apache Spark </a>、<a href="https://web.archive.org/web/20221201153827/https://cloud.google.com/dataflow" target="_blank" rel="noreferrer noopener nofollow"> Google Cloud Dataflow、</a> <a href="https://web.archive.org/web/20221201153827/https://flink.apache.org/" target="_blank" rel="noreferrer noopener nofollow"> Apache Flink </a>等等。</p>



<p>值得一提的是，Beam附带了一个直接通道，因此它可以用于测试或小型部署等场景。</p>



<p>虽然运行Apache Beam的TFX很酷，但是很难配置、监控和维护定义的管道和工作流。这就产生了我们称之为管弦乐队的工具。</p>



<p>像Kubeflow或Apache Airflow这样的编排器使得配置、操作、监控和维护ML管道变得很容易。它们大多带有你容易理解的图形用户界面。</p>



<p><strong>以下是显示已定义任务的示例气流GUI:</strong></p>







<p><strong>这里有一个给Kubeflow: </strong></p>







<p>在本教程中，您将使用Kubeflow作为ML管道的编排器，所以让我们简单地谈谈Kubeflow。</p>







<p><a href="https://web.archive.org/web/20221201153827/https://www.kubeflow.org/" target="_blank" rel="noreferrer noopener nofollow"> Kubeflow </a>是一款开源<a href="https://web.archive.org/web/20221201153827/https://github.com/kubeflow/kubeflow" target="_blank" rel="noreferrer noopener nofollow">kubernetes</a>-专门为开发、编排、部署和运行可扩展ML工作负载而设计的原生平台。</p>



<p>它可以帮助您轻松管理端到端的ML管道流程编排，在内部或云等众多环境中运行工作流，并为工作流的可视化提供支持。</p>



<p>现在我们已经有了基本的介绍，让我们进入本教程的实践方面。在下一部分中，您将在GCP上设置您的项目。</p>



<p id="separator-block_5f89523a57abd" class="block-separator block-separator--5"> </p>



<h2 id="Setting">建立一个新的谷歌云项目</h2>



<p>如果您已经创建了一个Google Cloud帐户，那么您已经拥有了免费的GC积分。接下来，您将为本教程创建一个新项目。</p>



<section id="note-block_5f894e00d3c56" class="block-note c-box c-box--default c-box--dark c-box--no-hover c-box--standard ">

    

    <div class="block-note__content">
                    <div class="c-item c-item--text">

                <img decoding="async" loading="lazy" alt="" class="c-item__arrow lazyload" src="../Images/6ee4db9241456412a31ee02e477cd458.png" data-src="https://web.archive.org/web/20221201153827/https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg" data-original-src="https://web.archive.org/web/20221201153827/https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg"/>

                <div class="c-item__content">

                                            <p>如果你已经用完了你的免费积分，那么你的GC账户将会收费，所以记得在本教程结束时清理项目。</p>
                                    </div>

            </div>
            </div>


</section>



<p id="separator-block_6009c728634e2" class="block-separator block-separator--5"> </p>



<p>要设置新项目，请按照以下步骤操作:</p>











<ul><li>为您的项目命名。我会把我的叫做tfx-project。</li></ul>







<ul><li>点击<strong>创建</strong>新项目</li><li>创建完成后，再次单击项目下拉菜单，并选择您刚刚创建的新项目。</li></ul>



<p>如果操作正确，您应该会看到您的项目仪表板。</p>







<p id="separator-block_6009c735634e3" class="block-separator block-separator--5"> </p>



<h2 id="Configuring">配置AI平台管道并设置Kubeflow</h2>



<p>现在您已经创建了项目，您将设置Kubeflow。按照以下步骤实现这一点:</p>



<ul><li>点击汉堡菜单，显示GCP上可用的服务，滚动到你有<strong> AI平台</strong>的地方，选择<strong>管道。</strong></li></ul>







<ul><li>在pipelines页面中，单击<strong>新实例</strong>按钮。这将打开Kubeflow管道页面。您可以在这里配置Kubeflow引擎。</li><li>您可以为您的群集选择一个区域，或者保留默认值。</li><li><strong>确保选中允许访问框</strong>，因为这是您的集群访问其他云API所必需的。</li></ul>







<ul><li>点击<strong>创建集群</strong>按钮，等待几分钟直到集群创建完毕。</li><li>您可以选择一个名称空间，或者保留默认值。此外，如果您将为您的工件使用一个托管存储，那么您可以添加您的存储细节，或者留空。</li><li>最后点击<strong>部署</strong>，等待管道部署完成。</li></ul>







<p id="separator-block_5f89524e57ac0" class="block-separator block-separator--5"> </p>



<h2 id="Set">设置云人工智能平台笔记本</h2>



<p>接下来，您将在AI平台中设置一个笔记本。这让我们可以在熟悉的Jupyter笔记本环境中进行实验。要实例化这个新笔记本，请执行以下步骤:</p>



<ul><li>从GC汉堡菜单中选择<strong> AI平台</strong>选项，点击<strong>笔记本</strong>选项。</li><li>接下来，选择<strong>启用笔记本API </strong>，然后点击<strong>新建实例</strong>，在AI平台上创建一个新的笔记本实例。</li><li>根据您想要做的事情和您的预算，您可以选择一个自定义的启动库来添加到您的笔记本实例。对于本文，我将使用没有安装GPU的Tensorflow 2.1版本。</li></ul>







<ul><li>在弹出菜单中，点击底部的<strong>自定义</strong>。这将打开一个配置页面，如果向下滚动，您将看到一个减少计算实例的CPU和RAM数量的选项。为了降低成本，您将使用更小的产品。</li></ul>







<p>如果你有足够的预算，并且需要非常快或大的东西，你可以跳过上面的步骤。</p>



<ul><li>最后，滚动到最后，点击<strong>创建</strong>创建笔记本。</li></ul>



<p id="separator-block_5f89525657ac1" class="block-separator block-separator--5"> </p>



<h2 id="Experimenting">在云端体验笔记本电脑</h2>



<p>现在您已经设置了笔记本，您将打开它。按照以下步骤实现这一点:</p>



<ul><li>在AI平台仪表板中，再次单击管道。这一次您将看到刚刚创建的Kubeflow管道，在它旁边有一个<strong> OPEN PIPELINES DASHBOARD </strong>命令。点击它。</li></ul>







<p>这将在Kubeflow中打开您的管道，从这里您可以执行许多特定于Kubeflow的功能。</p>



<ul><li>接下来点击<strong>打开TF 2.1笔记本</strong>。这将打开<strong>笔记本</strong>页面，您可以在其中选择一个笔记本实例。单击您之前创建的笔记本实例，如下所示。</li></ul>







<ul><li>最后，点击<strong> Create </strong>来启动笔记本实例。这将打开一个熟悉的Jupyter笔记本，您将在其中进行实验。</li></ul>







<p>在打开的Jupyter笔记本中，<strong>导入的</strong>文件夹中提供了一个模板文件，帮助您执行一些重要的配置和设置，以及一个用于处理TFX组件的模板。</p>



<p>稍后我们将利用这种配置，但是现在让我们开始构建我们的项目。</p>



<p>在笔记本中，为您的项目创建一个新文件夹(<strong> advert-pred </strong>)。在那个文件夹中，创建一个新的Jupyter笔记本(<strong>广告-实验</strong>)并打开它。</p>







<p>在这个Jupyter笔记本中，您将单独并交互地浏览每个TFX组件。<strong>这将帮助你理解每个组件在做什么</strong>，然后在最后，你将把你的实验变成一个完整的管道并部署它。</p>



<p>你可以在这里得到完整的笔记本<a href="https://web.archive.org/web/20221201153827/https://github.com/risenW/tfx-adClickPrediction/blob/master/advert-experiment.ipynb" target="_blank" rel="noreferrer noopener nofollow">，在这里</a>得到完整的项目代码<a href="https://web.archive.org/web/20221201153827/https://github.com/risenW/tfx-adClickPrediction" target="_blank" rel="noreferrer noopener nofollow">。</a></p>



<h3><strong>设置</strong></h3>



<p>在笔记本的第一个单元中，你将安装TFX、库比弗洛(kfp)和一个名为skaffold的软件包:</p>



<pre class="hljs"># Install tfx <span class="hljs-keyword">and</span> kfp Python packages.
import sys
!{sys.executable} -m pip install --user --upgrade -q tfx==<span class="hljs-number">0.22</span><span class="hljs-number">.0</span>
!{sys.executable} -m pip install --user --upgrade -q kfp==<span class="hljs-number">1.0</span><span class="hljs-number">.0</span>
# Download skaffold <span class="hljs-keyword">and</span> <span class="hljs-keyword">set</span> it 
!curl ///skaffold//latest/ /home//.local//Import packages
</pre>



<p><a href="https://web.archive.org/web/20221201153827/https://skaffold.dev/" target="_blank" rel="noreferrer noopener nofollow"> <strong> Skaffold </strong> </a> <strong>是一个命令行工具，方便Kubernetes应用程序的持续开发</strong>。它帮助我们轻松管理和处理构建、推送和部署应用程序的工作流。以后你就会明白斯卡福德的用途了。</p>



<p>运行第一个单元后，您会得到一些警告——现在忽略它们。其中一个通知您您的安装不在您的env路径中。通过将它们添加到PATH中，您可以在下一个单元格中解决这个问题。</p>



<pre class="hljs"># <span class="hljs-keyword">Set</span> `PATH` to  ``
PATH=%env 
%env /home//.local/
</pre>



<p>接下来，设置一些重要的环境变量，Kubeflow稍后将使用这些变量来编排管道。将下面的代码复制到新的单元格中:</p>



<pre class="hljs"># <span class="hljs-keyword">Read</span> GCP <span class="hljs-keyword">project</span> id <span class="hljs-keyword">from</span> env.
shell_output=!gcloud config list --format <span class="hljs-string">'value(core.project)'</span> <span class="hljs-number">2</span>&gt;<span class="hljs-regexp">/dev/</span><span class="hljs-keyword">null</span>
GOOGLE_CLOUD_PROJECT=shell_output[<span class="hljs-number">0</span>]
%env GOOGLE_CLOUD_PROJECT={GOOGLE_CLOUD_PROJECT}
<span class="hljs-keyword">print</span>(<span class="hljs-string">"GCP project ID:"</span> + GOOGLE_CLOUD_PROJECT)
</pre>



<p>第一个变量是您的<strong> GCP项目ID </strong>。这可以从你的环境中访问，因为你在人工智能平台上。接下来是Kubeflow管道集群端点。</p>



<p>在部署管道时，<strong>端点URL </strong>用于访问KFP集群。要获得您的KFP端点，请从Kubeflow“入门”页面复制URL。</p>







<p>将复制的URL分配给变量<strong>端点</strong>:</p>



<pre class="hljs">ENDPOINT=<span class="hljs-string">'https://2adfdb83b477n893-dot-us-central2.pipelines.googleusercontent.com'</span>
</pre>



<p><strong>复制端点URL时，确保删除URL的最后一个路径，并在. com结尾停止复制。</strong></p>



<p>接下来，您将创建一个Docker名称，Skaffold将使用它来捆绑您的管道。</p>



<pre class="hljs">CUSTOM_TFX_IMAGE=<span class="hljs-string">'gcr.io/'</span> + GOOGLE_CLOUD_PROJECT + <span class="hljs-string">'/advert-pred-pipeline'</span>
</pre>



<p>最后，您将设置基本路径，并将当前工作目录设置为项目文件夹。</p>



<pre class="hljs">#<span class="hljs-keyword">set</span> base 
BASE_PATH  
%cd 
</pre>



<p><strong>您完成了设置</strong>。</p>



<p>接下来，您将开始对每个TFX组件进行交互式探索。</p>



<h2 id="Running">交互式运行TFX组件</h2>



<p>TFX附带了一个内置的orchestrator，允许您在Jupyter笔记本中交互式地运行每个组件。</p>



<p>这有助于您轻松探索每个组件，并可视化输出。在探索结束时，您可以将代码作为管道导出。</p>



<p>现在，让我们来看看实际情况。在新的代码单元格中，导入以下包:</p>



<pre class="hljs"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> pprint
<span class="hljs-keyword">import</span> absl
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> tensorflow_model_analysis <span class="hljs-keyword">as</span> tfma
tf.get_logger().propagate = <span class="hljs-keyword">False</span>
pp = pprint.PrettyPrinter()
<span class="hljs-keyword">import</span> tfx
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> CsvExampleGen
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> Evaluator
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> ExampleValidator
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> Pusher
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> ResolverNode
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> SchemaGen
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> StatisticsGen
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> Trainer
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> Transform
<span class="hljs-keyword">from</span> tfx.components.base <span class="hljs-keyword">import</span> executor_spec
<span class="hljs-keyword">from</span> tfx.components.trainer.executor <span class="hljs-keyword">import</span> GenericExecutor
<span class="hljs-keyword">from</span> tfx.dsl.experimental <span class="hljs-keyword">import</span> latest_blessed_model_resolver
<span class="hljs-keyword">from</span> tfx.orchestration <span class="hljs-keyword">import</span> metadata
<span class="hljs-keyword">from</span> tfx.orchestration <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">from</span> tfx.orchestration.experimental.interactive.interactive_context <span class="hljs-keyword">import</span> InteractiveContext
<span class="hljs-keyword">from</span> tfx.proto <span class="hljs-keyword">import</span> pusher_pb2
<span class="hljs-keyword">from</span> tfx.proto <span class="hljs-keyword">import</span> trainer_pb2
<span class="hljs-keyword">from</span> tfx.types <span class="hljs-keyword">import</span> Channel
<span class="hljs-keyword">from</span> tfx.types.standard_artifacts <span class="hljs-keyword">import</span> Model
<span class="hljs-keyword">from</span> tfx.types.standard_artifacts <span class="hljs-keyword">import</span> ModelBlessing
<span class="hljs-keyword">from</span> tfx.utils.dsl_utils <span class="hljs-keyword">import</span> external_input
%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip
</pre>



<p>在导入的包中，您会注意到您从tfx组件包中导入了不同的模块。这些组件将在ML流程的不同阶段按顺序用于定义管道。</p>



<p>最后一行代码(% <strong> load_ext </strong>)加载一个tfx notebook扩展，该扩展可用于标记从notebook自动生成管道时应该跳过的代码单元。</p>



<p>是啊！您可以自动将笔记本导出为管道，在Apache Beam或Airflow上运行。</p>



<h3><strong>上传您的数据</strong></h3>



<p>在你的广告预测目录中，创建一个名为data的新文件夹。您将在此上传数据，供实验阶段使用。</p>



<p>在您继续之前，请从<a href="https://web.archive.org/web/20221201153827/https://drive.google.com/file/d/1dvT89N1f6ecmDEsIqvY667PssAbk_juI/view?usp=sharing">这里</a>下载广告数据。</p>







<p>要将数据上传到您的笔记本实例，请打开您创建的数据文件夹，单击上传图标并选择您刚刚下载的数据文件。</p>



<p>上传完毕，让我们先来看一下最上面的几排。</p>



<pre class="hljs">dat<span class="hljs-built_in">a_root</span> = 'data'
dat<span class="hljs-built_in">a_filepath</span> = os.path.join(dat<span class="hljs-built_in">a_root</span>, <span class="hljs-string">"advertising.csv"</span>)
!head {dat<span class="hljs-built_in">a_filepath</span>}
</pre>



<p>//输出</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/54b2634e9fc5b71d99848270e796e04d.png" alt="TFX output 1" class="wp-image-28325" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201153827im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/TFX-output-1.png?resize=768%2C737&amp;ssl=1"/><figcaption><em>Sample data output</em></figcaption></figure></div>



<p><strong>数据集来自于本次挑战上的</strong><a href="https://web.archive.org/web/20221201153827/https://www.kaggle.com/fayomi/advertising#advertising.csv" target="_blank" rel="noreferrer noopener nofollow"><strong/></a><strong>。任务是预测客户是否会点击广告。所以这是一个二元分类任务。</strong></p>



<section id="note-block_5f88b66daf8a8" class="block-note c-box c-box--default c-box--dark c-box--no-hover c-box--standard ">

    

    <div class="block-note__content">
                    <div class="c-item c-item--text">

                <img decoding="async" loading="lazy" alt="" class="c-item__arrow lazyload" src="../Images/6ee4db9241456412a31ee02e477cd458.png" data-src="https://web.archive.org/web/20221201153827/https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg" data-original-src="https://web.archive.org/web/20221201153827/https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg"/>

                <div class="c-item__content">

                                            <p>这是一个关于构建ML管道的教程，因此，我不会涉及广泛的特征工程或分析。</p>
                                    </div>

            </div>
            </div>


</section>



<p id="separator-block_6009c773634e4" class="block-separator block-separator--5"> </p>



<p>让我们从TFX组件开始。</p>



<p>在您继续进行之前，首先您将创建一个叫做InteractiveContext的东西。InteractiveContext将允许您在笔记本中以交互方式运行TFX组件，以便您可以可视化其输出。这与生产环境不同，在生产环境中，您将使用orchestrator来运行您的组件。</p>



<p>在新单元格中，创建并运行InteractiveContext，如下所示:</p>



<pre class="hljs">context = InteractiveContext()
</pre>



<h3><strong>范例生成</strong></h3>



<p>您将使用的第一个组件是ExampleGen。ExampleGen通常位于ML管道的开头，因为它用于接收数据，分成训练集和评估集，将数据转换为高效的<a href="https://web.archive.org/web/20221201153827/https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank" rel="noreferrer noopener nofollow"> <strong> tf。示例</strong> </a>格式，并且还将数据复制到一个托管目录中，以便于管道中的其他组件访问。</p>



<p>在下面的代码单元格中，您将把数据源传递给ExampleGen输入参数，并使用上下文运行它:</p>



<pre class="hljs">example_gen = CsvExampleGen(input=external_input(_data_root))
context.run(example_gen)
</pre>







<p>上面，您可以查看ExampleGen输出的一个交互式小部件。这些输出被称为工件，ExampleGen通常产生两个工件——<strong>训练</strong>示例和<strong>评估</strong>示例。</p>



<p>默认情况下，ExampleGen将数据分成2/3的定型集，1/3用于评估集。</p>



<p>您还可以查看存储工件和URI的位置:</p>



<pre class="hljs">artifact = example_gen.outputs[<span class="hljs-string">'examples'</span>].get()[<span class="hljs-number">0</span>]
print(artifact.split_names, artifact.uri)

</pre>



<p>//输出</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/5151515a94aebf99ba712aebc561a60d.png" alt="TFX output 2" class="wp-image-28327" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201153827im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/TFX-output-2.png?ssl=1"/></figure>



<p>既然<strong> ExampleGen </strong>已经接收完数据，下一步就是数据分析。</p>



<h3><strong> StatisticsGen </strong></h3>



<p><strong> StatisticsGen </strong>组件用于计算数据集的统计数据。这些统计数据提供了数据的快速概览，包括形状、存在的要素以及值分布等详细信息。</p>



<p>为了计算数据的统计信息，您将把ExampleGen的输出作为输入传入。</p>



<pre class="hljs">statistics_gen = StatisticsGen(
   examples=example_gen.outputs[<span class="hljs-string">'examples'</span>])
context.run(statistics_gen)
</pre>







<p>这些统计数据可以使用上下文的show方法可视化，如下所示:</p>



<pre class="hljs">context.show(statistics_gen.outputs[<span class="hljs-string">'statistics'</span>])
</pre>



<p>下面您将看到为数字特征生成的统计数据:</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/0029028115d15d2bd70d4a47e22a6098.png" alt="numerical features statistics" class="wp-image-28249" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201153827im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/numerical-features-statistics.png?resize=768%2C520&amp;ssl=1"/><figcaption><em>Statistics for numerical features</em></figcaption></figure></div>



<p>如果您向下滚动，在statistics小部件中，您还会找到分类变量的描述。</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img decoding="async" loading="lazy" src="../Images/1a10c3dbf84606088e41e4e9a4c31d44.png" alt="categorical variables" class="wp-image-28251" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201153827im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/categorical-variables.png?resize=768%2C505&amp;ssl=1"/><figcaption><em>Statistics for categorical features</em></figcaption></figure></div>



<p>使用StatisticGen，您可以快速了解您的数据概况。您可以检查缺失、零的存在以及分布情况。</p>



<p>这些统计数据将被下游组件使用，如<strong> SchemaGen </strong>和<strong> ExampleValidator </strong>，用于在生产中接收新数据时检测异常、偏差和漂移。</p>



<h3><strong> SchemaGen </strong></h3>



<p><a href="https://web.archive.org/web/20221201153827/https://www.tensorflow.org/tfx/guide/schemagen" target="_blank" rel="noreferrer noopener nofollow"> SchemaGen </a>组件将从统计数据中为您的数据生成一个模式。模式只是数据的一个定义。它从数据特征中定义类型、期望的属性、界限等等。</p>



<p>在下面的代码单元格中，您将把StatisticsGen输出传递给SchemaGen输入，然后可视化输出。</p>



<pre class="hljs">schema_gen = SchemaGen(
   statistics=statistics_gen.outputs[<span class="hljs-string">'statistics'</span>],
   infer_feature_shape=<span class="hljs-keyword">False</span>)
context.run(schema_gen)
context.show(schema_gen.outputs[<span class="hljs-string">'schema'</span>])
</pre>







<p>数据集中的每个要素都被表示，以及预期的类型、存在、化合价和域。</p>



<h3><strong>示例验证器</strong></h3>



<p>ML管道中的下一个组件是ExampleValidator。该组件根据定义的模式验证您的数据并检测异常。</p>



<p>这可用于在生产中验证进入管道的任何新数据。在新数据输入到您的模型之前，它对于检测新数据中的漂移、变化和偏差非常有用。</p>



<p>在下面的代码单元格中，我们将StatisticsGen和SchemaGen输出传递给ExampleValidator:</p>



<pre class="hljs">example_validator = ExampleValidator(
   statistics=statistics_gen.outputs[<span class="hljs-string">'statistics'</span>],
   schema=schema_gen.outputs[<span class="hljs-string">'schema'</span>])
context.run(example_validator)
context.show(example_validator.outputs[<span class="hljs-string">'anomalies'</span>])
</pre>







<p>我们的数据目前没有异常。我们可以进入下一个部分。</p>



<h3><strong>变换</strong></h3>



<p>管道中的下一个组件是转换组件。该组件对训练和服务数据执行特征工程。</p>



<p>要对接收到的数据执行转换，需要从ExampleGen传入数据，从SchemaGen传入模式，最后传入包含转换代码的Python模块。</p>



<p>在您的项目目录(advert-pred)中，创建一个名为<strong> model </strong>的新文件夹。在这个文件夹中，您将定义您的转换代码以及模型代码。</p>



<p>在模型文件夹中，创建三个脚本— <strong> constants.py、advert-transform.py </strong>和<strong> __init__.py. </strong></p>



<p>要在Jupyter Lab中创建一个Python脚本，打开相应的文件夹，点击<strong> + </strong>图标，创建一个文本文件，然后将扩展名改为<strong> .py. </strong></p>



<p>在<strong> constants.py </strong>中，您将定义一些变量，如分类特征、数字特征以及需要编码的特征的名称。在我们的例子中，您将使用如下所示的一些选定功能:</p>



<pre class="hljs">DENSE_FLOAT_FEATURE_KEYS = [<span class="hljs-string">'DailyTimeSpentOnSite'</span>, <span class="hljs-string">'Age'</span>,                                     <span class="hljs-string">'AreaIncome'</span>, <span class="hljs-string">'DailyInternetUsage'</span> ]
VOCAB_FEATURE_KEYS = [<span class="hljs-string">'City'</span>, <span class="hljs-string">'Male'</span>, <span class="hljs-string">'Country'</span> ]

VOCAB_SIZE = <span class="hljs-number">1000</span>

OOV_SIZE = <span class="hljs-number">10</span>

LABEL_KEY = <span class="hljs-string">'ClickedOnAd'</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">transformed_name</span><span class="hljs-params">(key)</span>:</span>
   <span class="hljs-keyword">return</span> key + <span class="hljs-string">'_xf'</span>
</pre>



<p><strong> DENSE_FLOAT_FEATURE_KEYS </strong>代表所有数字特征，而<strong> VOCAB_FEATURE_KEYS </strong>特征包含所有你想要编码的字符串特征。</p>



<p>此外，您还添加了一个小的助手函数，它将把<strong> _xf </strong>附加到每个特性名称上。这在变换模块中用于区分变换后的要素和原始要素。</p>



<p>在advert-transform.py中，您将导入您的联系人，然后定义转换步骤。这是所有处理、清理、填充缺失值的代码所在的位置。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> tensorflow_transform <span class="hljs-keyword">as</span> tft
<span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> constants

_DENSE_FLOAT_FEATURE_KEYS = constants.DENSE_FLOAT_FEATURE_KEYS
_LABEL_KEY = constants.LABEL_KEY
_VOCAB_FEATURE_KEYS = constants.VOCAB_FEATURE_KEYS
_VOCAB_SIZE = constants.VOCAB_SIZE
_OOV_SIZE = constants.OOV_SIZE
_transformed_name = constants.transformed_name

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocessing_fn</span><span class="hljs-params">(inputs)</span>:</span>
 <span class="hljs-string">"""tf.transform's callback function for preprocessing inputs.
 Args:
   inputs: map from feature keys to raw not-yet-transformed features.
 Returns:
   Map from string feature key to transformed feature operations.
 """</span>
 outputs = {}
 <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> _DENSE_FLOAT_FEATURE_KEYS:
   
   outputs[_transformed_name(key)] = tft.scale_to_z_score(
       inputs[key])

 <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> _VOCAB_FEATURE_KEYS:
   
   outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(
       inputs[key],
       top_k=_VOCAB_SIZE,
       num_oov_buckets=_OOV_SIZE)
outputs[_transformed_name(_LABEL_KEY)] = inputs[_LABEL_KEY]
<span class="hljs-keyword">return</span> outputs
</pre>



<p>在<strong> advert-constants.py </strong>脚本的顶部，您初始化了在<strong> constants.py. </strong>中定义的常数。接下来，您定义了<strong>预处理_fn </strong>函数。该函数由<strong>转换</strong>组件调用，名字(<strong>预处理_fn </strong> ) <strong> </strong>要保留。</p>



<p>在<strong>预处理_fn </strong>函数中，您将根据每个特征的类型对其进行处理，对其进行重命名，然后将其追加到输出字典中。变换组件期望<strong>预处理_fn </strong>返回一个变换特征的字典。</p>



<p><strong>另外，注意我们的预处理代码是用纯Tensorflow </strong>编写的。建议这样做，以便您的操作能够以最佳方式分布并在集群中运行。如果您想使用纯Python代码，尽管不推荐，您可以使用“<a href="https://web.archive.org/web/20221201153827/https://www.tensorflow.org/api_docs/python/tf/function" target="_blank" rel="noreferrer noopener nofollow">@ TF _ function</a>”包装器将它们转换为Tensorflow的函数。</p>



<p>现在回到您的笔记本，在新的单元格中添加以下代码:</p>



<pre class="hljs">advert_transform = <span class="hljs-string">'model/advert-transform.py'</span>
transform = Transform(
   examples=example_gen.outputs[<span class="hljs-string">'examples'</span>],
   schema=schema_gen.outputs[<span class="hljs-string">'schema'</span>],
   module_file=advert_transform)
context.run(transform)
</pre>



<p>首先，定义转换代码的路径，然后传递示例和模式。当您运行这个程序时，您应该会看到一个非常长的输出，显示了一些转换后的特性，最后，您可以看到如下所示的工件小部件:</p>







<p id="separator-block_6009c7a2634e5" class="block-separator block-separator--5"> </p>







<p>转换组件将生成两个工件:一个<strong> transform_graph </strong>和<strong> transformed_examples </strong>。<strong> transform_graph </strong>将所有预处理步骤定义为一个有向无环图(DAG ),它可以用于任何摄取的新数据，而<strong> transformed_examples </strong>包含实际的预处理训练和评估数据。</p>



<p>您可以通过调用如下所示的转换输出来轻松查看这一点:</p>



<pre class="hljs">transform.outputs
</pre>



<p>//输出</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img decoding="async" src="../Images/3ab458f5c4bd8757ce46996fb9998be7.png" alt="TXF output 3" class="wp-image-28329" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201153827im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/TXF-output-3.png?ssl=1"/><figcaption><em>Transform component output</em></figcaption></figure></div>



<p>现在您已经获取、分析和转换了您的数据，您将定义下一个组件，称为<strong>训练器</strong>。</p>



<p id="separator-block_5f89529d57acb" class="block-separator block-separator--5"><strong>教练</strong></p>



<h3><strong>训练器</strong>组件用于训练Tensorflow/Keras中定义的模型。培训师将接受模式、转换后的数据和转换图、转换参数以及您的模型定义代码。</h3>



<p>在您的<strong> model </strong>文件夹中，创建一个名为<strong> advert-trainer.py、</strong>的新Python脚本，并添加以下代码。</p>



<p>上面的代码很长，所以我们将逐一介绍:</p>



<pre class="hljs"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> absl
<span class="hljs-keyword">import</span> datetime
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> tensorflow_transform <span class="hljs-keyword">as</span> tft
<span class="hljs-keyword">from</span> tfx.components.trainer.executor <span class="hljs-keyword">import</span> TrainerFnArgs
<span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> constants

_DENSE_FLOAT_FEATURE_KEYS = constants.DENSE_FLOAT_FEATURE_KEYS
_VOCAB_FEATURE_KEYS = constants.VOCAB_FEATURE_KEYS
_VOCAB_SIZE = constants.VOCAB_SIZE
_OOV_SIZE = constants.OOV_SIZE
_LABEL_KEY = constants.LABEL_KEY
_transformed_name = constants.transformed_name

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_transformed_names</span><span class="hljs-params">(keys)</span>:</span>
 <span class="hljs-keyword">return</span> [_transformed_name(key) <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> keys]

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_gzip_reader_fn</span><span class="hljs-params">(filenames)</span>:</span>
 <span class="hljs-string">"""Small utility returning a record reader that can read gzip'ed files."""</span>
 <span class="hljs-keyword">return</span> tf.data.TFRecordDataset(
     filenames,
     compression_type=<span class="hljs-string">'GZIP'</span>)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_get_serve_tf_examples_fn</span><span class="hljs-params">(model, tf_transform_output)</span>:</span>
 <span class="hljs-string">"""Returns a function that parses a serialized tf.Example and applies TFT."""</span>
model.tft_layer = tf_transform_output.transform_features_layer()
<span class="hljs-meta">@tf.function</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">serve_tf_examples_fn</span><span class="hljs-params">(serialized_tf_examples)</span>:</span>
   <span class="hljs-string">"""Returns the output to be used in the serving signature."""</span>
   feature_spec = tf_transform_output.raw_feature_spec()
   feature_spec.pop(_LABEL_KEY)
   parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)
   transformed_features = model.tft_layer(parsed_features)
   <span class="hljs-keyword">return</span> model(transformed_features)
<span class="hljs-keyword">return</span> serve_tf_examples_fn

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_input_fn</span><span class="hljs-params">(file_pattern, tf_transform_output,
             batch_size=<span class="hljs-number">100</span>)</span>:</span>
 <span class="hljs-string">"""Generates features and label for tuning/training.
Args:
   file_pattern: List of paths or patterns of input tfrecord files.
   tf_transform_output: A TFTransformOutput.
   batch_size: representing the number of consecutive elements of returned
     dataset to combine in a single batch
Returns:
   A dataset that contains (features, indices) tuple where features is a
     dictionary of Tensors, and indices is a single Tensor of label indices.
 """</span>
 transformed_feature_spec = (
     tf_transform_output.transformed_feature_spec().copy())
dataset = tf.data.experimental.make_batched_features_dataset(
     file_pattern=file_pattern,
     batch_size=batch_size,
     features=transformed_feature_spec,
     reader=_gzip_reader_fn,
     label_key=_transformed_name(_LABEL_KEY))
<span class="hljs-keyword">return</span> dataset

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_build_keras_model</span><span class="hljs-params">(hidden_units)</span>:</span>
 <span class="hljs-string">"""Creates a DNN Keras model for classifying taxi data.
 """</span>
 real_valued_columns = [
     tf.feature_column.numeric_column(key, shape=())
     <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)
 ]
 categorical_columns = [
     tf.feature_column.categorical_column_with_identity(
         key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=<span class="hljs-number">0</span>)
     <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> _transformed_names(_VOCAB_FEATURE_KEYS)
 ]
 indicator_column = [
     tf.feature_column.indicator_column(categorical_column)
     <span class="hljs-keyword">for</span> categorical_column <span class="hljs-keyword">in</span> categorical_columns
 ]
model = _wide_and_deep_classifier(
     wide_columns=indicator_column,
     deep_columns=real_valued_columns,
     dnn_hidden_units=hidden_units <span class="hljs-keyword">or</span> [<span class="hljs-number">100</span>, <span class="hljs-number">70</span>, <span class="hljs-number">60</span>, <span class="hljs-number">50</span>])
 <span class="hljs-keyword">return</span> model

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_wide_and_deep_classifier</span><span class="hljs-params">(wide_columns, deep_columns, dnn_hidden_units)</span>:</span>
 <span class="hljs-string">"""returns a simple keras wide and deep model.
 """</span>
 input_layers = {
     colname: tf.keras.layers.Input(name=colname, shape=(), dtype=tf.float32)
     <span class="hljs-keyword">for</span> colname <span class="hljs-keyword">in</span> _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)
 }

 input_layers.update({
     colname: tf.keras.layers.Input(name=colname, shape=(), dtype=<span class="hljs-string">'int32'</span>)
     <span class="hljs-keyword">for</span> colname <span class="hljs-keyword">in</span> _transformed_names(_VOCAB_FEATURE_KEYS)
 })
deep = tf.keras.layers.DenseFeatures(deep_columns)(input_layers)
 <span class="hljs-keyword">for</span> numnodes <span class="hljs-keyword">in</span> dnn_hidden_units:
   deep = tf.keras.layers.Dense(numnodes)(deep)

 wide = tf.keras.layers.DenseFeatures(wide_columns)(input_layers)
output = tf.keras.layers.Dense(
     <span class="hljs-number">1</span>, activation=<span class="hljs-string">'sigmoid'</span>)(
         tf.keras.layers.concatenate([deep, wide]))
model = tf.keras.Model(input_layers, output)
 model.compile(
     loss=<span class="hljs-string">'binary_crossentropy'</span>,
     optimizer=tf.keras.optimizers.Adam(lr=<span class="hljs-number">0.01</span>),
     metrics=[tf.keras.metrics.BinaryAccuracy()])
 model.summary(print_fn=absl.logging.info)
 <span class="hljs-keyword">return</span> model



<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run_fn</span><span class="hljs-params">(fn_args: TrainerFnArgs)</span>:</span>
 <span class="hljs-string">"""Train the model based on given args.
 Args:
   fn_args: Holds args used to train the model as name/value pairs.
 """</span>
 
 first_dnn_layer_size = <span class="hljs-number">150</span>
 num_dnn_layers = <span class="hljs-number">4</span>
 dnn_decay_factor = <span class="hljs-number">0.7</span>
tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)
train_dataset = _input_fn(fn_args.train_files, tf_transform_output, <span class="hljs-number">40</span>)
 eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output, <span class="hljs-number">40</span>)
model = _build_keras_model(
     
     hidden_units=[
         max(<span class="hljs-number">2</span>, int(first_dnn_layer_size * dnn_decay_factor**i))
         <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_dnn_layers)
     ])
log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), <span class="hljs-string">'logs'</span>)
 tensorboard_callback = tf.keras.callbacks.TensorBoard(
     log_dir=log_dir, update_freq=<span class="hljs-string">'batch'</span>)
 model.fit(
     train_dataset,
     steps_per_epoch=fn_args.train_steps,
     validation_data=eval_dataset,
     validation_steps=fn_args.eval_steps,
     callbacks=[tensorboard_callback])
signatures = {
     <span class="hljs-string">'serving_default'</span>:
         _get_serve_tf_examples_fn(model,
                                   tf_transform_output).get_concrete_function(
                                       tf.TensorSpec(
                                           shape=[<span class="hljs-keyword">None</span>],
                                           dtype=tf.string,
                                           name=<span class="hljs-string">'examples'</span>)),
 }
model.save(fn_args.serving_model_dir, save_format=<span class="hljs-string">'tf'</span>, signatures=signatures)
</pre>



<p>在导入部分，我们从常量模块导入一些您将使用的常量。</p>



<ul><li>接下来，定义三个实用函数。第一个<strong> _transformed_names </strong>只是为每个特性返回一个修改后的名称。<strong> _gzip_reader_fn </strong>用于读取TFRecordDataset格式的文件。这就是我们的数据由<strong> ExampleGen </strong>表示的格式。最后是<strong>_ get _ serve _ TF _ examples _ fn</strong>，它解析每个<em> tf。示例</em>并应用转换函数。</li><li>接下来，在<strong> _input_fn </strong>函数中，您只需生成一个tf。来自变换要素的数据集文件。这是用于训练我们的模型的有效数据格式。</li><li>接下来的两个函数<strong> _build_keras_model </strong>和<strong>_ wide _ and _ deep _ classifier</strong>使用函数式API构建keras模型。这个函数式API在这里很有用，因为我们正在定义一个可以编排的静态图，因此，在编译模型之前，必须正确定义每个特性。</li><li>接下来，也是最重要的，您将定义<strong> run_fn </strong>。这个函数由训练器组件调用，因此名称不应该更改。在此函数中，您将从转换后的输出中初始化训练和评估数据集，初始化模型，为模型输出和张量板定义记录目录，最后拟合模型。</li></ul>







<ul><li>接下来，您定义服务签名，它被下一个组件<strong>推送器</strong>用于服务您的模型。</li><li>最后，您使用定义的签名将模型保存到服务目录中。</li><li>当您完成教练脚本的定义后，返回到您的笔记本并添加教练组件，如下所示:</li></ul>



<p>培训师接受培训师模块、来自转换输出的转换示例、转换图、模式以及用于培训和评估步骤的培训师参数。</p>



<pre class="hljs">advert_trainer = <span class="hljs-string">'model/advert-trainer.py'</span>
trainer = Trainer(
   module_file=advert_trainer,
   custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),
   examples=transform.outputs[<span class="hljs-string">'transformed_examples'</span>],
   transform_graph=transform.outputs[<span class="hljs-string">'transform_graph'</span>],
   schema=schema_gen.outputs[<span class="hljs-string">'schema'</span>],
   train_args=trainer_pb2.TrainArgs(num_steps=<span class="hljs-number">1000</span>),
   eval_args=trainer_pb2.EvalArgs(num_steps=<span class="hljs-number">500</span>))
context.run(trainer)
</pre>







<p>现在您已经完成了培训，您将添加下一个组件——评估员。</p>



<p>求值程序</p>



<h3>评估器组件计算评估集中的模型性能度量。它还可以用于验证任何新训练的模型。</h3>



<p>当您在生产中改进和测试新型号时，这很有用。要设置评估器，您需要定义一个配置。</p>



<p>该配置只是指示评估者报告什么指标，在评估新模型时使用什么阈值，等等。更多关于这个<a href="https://web.archive.org/web/20221201153827/https://www.tensorflow.org/tfx/model_analysis/get_started" target="_blank" rel="noreferrer noopener nofollow">的内容请看这里</a>。</p>



<p>将以下配置代码添加到您的笔记本中:</p>



<p>接下来，您将把此配置以及示例和训练模型输出传递给评估者，如下所示:</p>



<pre class="hljs">eval_config = tfma.EvalConfig(
   model_specs=[tfma.ModelSpec(label_key=<span class="hljs-string">'ClickedOnAd'</span>)],
   metrics_specs=[
       tfma.MetricsSpec(
           metrics=[
               tfma.MetricConfig(class_name=<span class="hljs-string">'ExampleCount'</span>),
               tfma.MetricConfig(class_name=<span class="hljs-string">'BinaryAccuracy'</span>,
                 threshold=tfma.MetricThreshold(
                     value_threshold=tfma.GenericValueThreshold(
                         lower_bound={<span class="hljs-string">'value'</span>: <span class="hljs-number">0.5</span>}),
                     change_threshold=tfma.GenericChangeThreshold(
                         direction=tfma.MetricDirection.HIGHER_IS_BETTER,
                         absolute={<span class="hljs-string">'value'</span>: <span class="hljs-number">-1e-10</span>})))
           ]
       )
   ])
model_resolver = ResolverNode(
     instance_name=<span class="hljs-string">'latest_blessed_model_resolver'</span>,
     resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,
     model=Channel(type=Model),
     model_blessing=Channel(type=ModelBlessing))
context.run(model_resolver)
</pre>







<p>要可视化评估器的输出，请使用如下所示的show方法:</p>



<pre class="hljs">evaluator = Evaluator(
   examples=example_gen.outputs[<span class="hljs-string">'examples'</span>],
   model=trainer.outputs[<span class="hljs-string">'model'</span>],
   baseline_model=model_resolver.outputs[<span class="hljs-string">'model'</span>],
   eval_config=eval_config)
context.run(evaluator)
</pre>



<p>上面，您可以看到评估者报告的指标。如果你训练一个新的模型，性能将与基线模型进行比较，在我们的例子中，基线模型不存在，因为这是我们的第一个模型。</p>



<pre class="hljs">context.show(evaluator.outputs[<span class="hljs-string">'evaluation'</span>])
</pre>







<p>此外，评价者可以告诉我们一个模特是<strong>被祝福的</strong>还是<strong>没有被祝福的</strong>。一款<strong>加持的</strong>车型<strong> </strong>已经顺利通过所有评测标准，比现在的车型更好。然后这可以由<strong>推动器</strong>组件推动和服务，否则它抛出一个错误。这意味着您可以轻松地自动化模型部署。</p>



<p>要检查我们的当前模型是否得到了评估者的认可，请获取评估者的输出，如下所示:</p>



<p>//输出</p>



<pre class="hljs">blessing_uri = evaluator<span class="hljs-selector-class">.outputs</span><span class="hljs-selector-class">.blessing</span><span class="hljs-selector-class">.get</span>()[<span class="hljs-number">0</span>]<span class="hljs-selector-class">.uri</span>
!ls -l {blessing_uri}
</pre>



<p>我们的模型被自动地祝福，因为它是我们管道中的第一个模型。如果您训练另一个模型，并重新运行评估器管道，那么它将与当前模型进行比较，并变得有福气或没有福气。</p>



<figure class="wp-block-image size-large"><img decoding="async" src="../Images/a2823604f59a21425a2667d3bc24ef6f.png" alt="TFX output 4" class="wp-image-28332" data-recalc-dims="1" data-original-src="https://web.archive.org/web/20221201153827im_/https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/TFX-output-4.png?ssl=1"/></figure>



<section id="note-block_5f88ba69af8aa" class="block-note c-box c-box--default c-box--dark c-box--no-hover c-box--standard ">

    

    <div class="block-note__content">
                    <div class="c-item c-item--wysiwyg_editor">

                <img decoding="async" loading="lazy" alt="" class="c-item__arrow lazyload" src="../Images/6ee4db9241456412a31ee02e477cd458.png" data-src="https://web.archive.org/web/20221201153827/https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg" data-original-src="https://web.archive.org/web/20221201153827/https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg"/>

                <div class="c-item__content">

                                            <p> </p>
                                    </div>

            </div>
            </div>


</section>



<p id="separator-block_6009c7bd634e6" class="block-separator block-separator--5">既然您的模型已经被训练和认可，您可以使用Pusher组件轻松地将它导出到服务模型目录中。</p>



<p><strong>推动器</strong></p>



<h3>在管道中总是排在最后的Pusher组件用于将一个受祝福的模型导出到服务目录。</h3>



<p>要添加这个组件，您需要传入训练器输出、评估器输出以及服务目录。如下所示:</p>



<p>首先，您可以指定服务模型目录，您的训练模型将被推送到该目录。这可以是云存储或本地文件系统。</p>



<pre class="hljs">serving_model_dir = <span class="hljs-string">'serving_model/advert-pred'</span>
pusher = Pusher(
    model=trainer.outputs[<span class="hljs-string">'model'</span>],
    model_blessing=evaluator.outputs[<span class="hljs-string">'blessing'</span>],
    push_destination=pusher_pb2.PushDestination(
    filesystem=pusher_pb2.PushDestination.Filesystem(
    base_directory=serving_model_dir)))
    context.run(pusher)
</pre>



<p><strong>就这样！您已经成功实现了所有的TFX组件</strong>，从获取数据到生成统计数据到生成模式，再到转换、模型训练、评估以及最终的模型保存。您可以轻松地导出笔记本，以便在Apache Beam、Kubeflow或Apache Airflow等流程编排中运行。</p>



<p>在下一节中，我将向您展示如何使用Kubeflow来编排您的管道。</p>



<p> </p>



<p id="separator-block_5f8952b957acf" class="block-separator block-separator--5">设置您的Kubeflow管道</p>



<h2 id="Setting-up">要使用Kubeflow运行或编排您的管道，您需要编写一些配置代码。这有助于设置Kubeflow以及定义要添加的TFX管道组件。按照以下步骤实现这一点:</h2>



<p>首先，在项目目录中创建一个名为<strong> pipeline.py. </strong>的新Python脚本</p>



<ul><li>在您的<strong> pipeline.py </strong>文件中，您将像我们在交互探索阶段所做的那样添加所有组件。</li></ul>



<p>该文件定义了TFX管道和管道中的各种组件。</p>



<p>如果您注意到，上面的代码类似于您在交互式探索阶段编写的代码，这里您只需删除InteractiveContext，并将每个组件添加到组件列表中。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> ml_metadata.proto <span class="hljs-keyword">import</span> metadata_store_pb2
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> CsvExampleGen
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> Evaluator
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> ExampleValidator
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> Pusher
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> ResolverNode
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> SchemaGen
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> StatisticsGen
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> Trainer
<span class="hljs-keyword">from</span> tfx.components <span class="hljs-keyword">import</span> Transform
<span class="hljs-keyword">from</span> tfx.components.base <span class="hljs-keyword">import</span> executor_spec
<span class="hljs-keyword">from</span> tfx.components.trainer <span class="hljs-keyword">import</span> executor <span class="hljs-keyword">as</span> trainer_executor
<span class="hljs-keyword">from</span> tfx.dsl.experimental <span class="hljs-keyword">import</span> latest_blessed_model_resolver
<span class="hljs-keyword">from</span> tfx.extensions.google_cloud_ai_platform.pusher <span class="hljs-keyword">import</span> executor <span class="hljs-keyword">as</span> ai_platform_pusher_executor
<span class="hljs-keyword">from</span> tfx.extensions.google_cloud_ai_platform.trainer <span class="hljs-keyword">import</span> executor <span class="hljs-keyword">as</span> ai_platform_trainer_executor
<span class="hljs-keyword">from</span> tfx.extensions.google_cloud_big_query.example_gen <span class="hljs-keyword">import</span> component <span class="hljs-keyword">as</span> big_query_example_gen_component
<span class="hljs-keyword">from</span> tfx.orchestration <span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">from</span> tfx.proto <span class="hljs-keyword">import</span> pusher_pb2
<span class="hljs-keyword">from</span> tfx.proto <span class="hljs-keyword">import</span> trainer_pb2
<span class="hljs-keyword">from</span> tfx.types <span class="hljs-keyword">import</span> Channel
<span class="hljs-keyword">from</span> tfx.types.standard_artifacts <span class="hljs-keyword">import</span> Model
<span class="hljs-keyword">from</span> tfx.types.standard_artifacts <span class="hljs-keyword">import</span> ModelBlessing
<span class="hljs-keyword">from</span> tfx.utils.dsl_utils <span class="hljs-keyword">import</span> external_input
<span class="hljs-keyword">import</span> tensorflow_model_analysis <span class="hljs-keyword">as</span> tfma

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_pipeline</span><span class="hljs-params">(pipeline_name,
                   pipeline_root,
                   data_path,
                   preprocessing_fn,
                   run_fn,
                   train_args,
                   eval_args,
                   eval_accuracy_threshold,
                   serving_model_dir,
                   metadata_connection_config=None,
                   beam_pipeline_args=None,
                   ai_platform_training_args=None,
                   ai_platform_serving_args=None)</span>:</span>
components = []
example_gen = CsvExampleGen(input=external_input(data_path))
 components.append(example_gen)
statistics_gen = StatisticsGen(examples=example_gen.outputs[<span class="hljs-string">'examples'</span>])
 components.append(statistics_gen)
schema_gen = SchemaGen(
     statistics=statistics_gen.outputs[<span class="hljs-string">'statistics'</span>],
     infer_feature_shape=<span class="hljs-keyword">True</span>)
 components.append(schema_gen)
example_validator = ExampleValidator(
     statistics=statistics_gen.outputs[<span class="hljs-string">'statistics'</span>],
     schema=schema_gen.outputs[<span class="hljs-string">'schema'</span>])
 components.append(example_validator)
transform = Transform(
     examples=example_gen.outputs[<span class="hljs-string">'examples'</span>],
     schema=schema_gen.outputs[<span class="hljs-string">'schema'</span>],
     preprocessing_fn=preprocessing_fn)
 components.append(transform)
trainer_args = {
     <span class="hljs-string">'run_fn'</span>: run_fn,
     <span class="hljs-string">'transformed_examples'</span>: transform.outputs[<span class="hljs-string">'transformed_examples'</span>],
     <span class="hljs-string">'schema'</span>: schema_gen.outputs[<span class="hljs-string">'schema'</span>],
     <span class="hljs-string">'transform_graph'</span>: transform.outputs[<span class="hljs-string">'transform_graph'</span>],
     <span class="hljs-string">'train_args'</span>: train_args,
     <span class="hljs-string">'eval_args'</span>: eval_args,
     <span class="hljs-string">'custom_executor_spec'</span>:
         executor_spec.ExecutorClassSpec(trainer_executor.GenericExecutor),
 }

 <span class="hljs-keyword">if</span> ai_platform_training_args <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
   trainer_args.update({
       <span class="hljs-string">'custom_executor_spec'</span>:
           executor_spec.ExecutorClassSpec(
               ai_platform_trainer_executor.GenericExecutor
           ),
       <span class="hljs-string">'custom_config'</span>: {
           ai_platform_trainer_executor.TRAINING_ARGS_KEY:
               ai_platform_training_args,
       }
   })

 trainer = Trainer(**trainer_args)
 components.append(trainer)
model_resolver = ResolverNode(
     instance_name=<span class="hljs-string">'latest_blessed_model_resolver'</span>,
     resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,
     model=Channel(type=Model),
     model_blessing=Channel(type=ModelBlessing))
 components.append(model_resolver)
eval_config = tfma.EvalConfig(
       model_specs=[tfma.ModelSpec(label_key=<span class="hljs-string">'ClickedOnAd'</span>)],
       metrics_specs=[
           tfma.MetricsSpec(
               metrics=[
                   tfma.MetricConfig(class_name=<span class="hljs-string">'ExampleCount'</span>),
                   tfma.MetricConfig(class_name=<span class="hljs-string">'BinaryAccuracy'</span>,
                   threshold=tfma.MetricThreshold(
                       value_threshold=tfma.GenericValueThreshold(
                           lower_bound={<span class="hljs-string">'value'</span>: <span class="hljs-number">0.5</span>}),
                       change_threshold=tfma.GenericChangeThreshold(
                           direction=tfma.MetricDirection.HIGHER_IS_BETTER,
                           absolute={<span class="hljs-string">'value'</span>: <span class="hljs-number">-1e-10</span>})))
               ]
           )
       ])
 evaluator = Evaluator(
     examples=example_gen.outputs[<span class="hljs-string">'examples'</span>],
     model=trainer.outputs[<span class="hljs-string">'model'</span>],
     baseline_model=model_resolver.outputs[<span class="hljs-string">'model'</span>],
     eval_config=eval_config)
 components.append(evaluator)

 
 pusher_args = {
     <span class="hljs-string">'model'</span>:
         trainer.outputs[<span class="hljs-string">'model'</span>],
     <span class="hljs-string">'model_blessing'</span>:
         evaluator.outputs[<span class="hljs-string">'blessing'</span>],
     <span class="hljs-string">'push_destination'</span>:
         pusher_pb2.PushDestination(
             filesystem=pusher_pb2.PushDestination.Filesystem(
                 base_directory=serving_model_dir)),
 }
 <span class="hljs-keyword">if</span> ai_platform_serving_args <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
   pusher_args.update({
       <span class="hljs-string">'custom_executor_spec'</span>:
           executor_spec.ExecutorClassSpec(ai_platform_pusher_executor.Executor
                                          ),
       <span class="hljs-string">'custom_config'</span>: {
           ai_platform_pusher_executor.SERVING_ARGS_KEY:
               ai_platform_serving_args
       },
   })
 pusher = Pusher(**pusher_args)  
 components.append(pusher)
<span class="hljs-keyword">return</span> pipeline.Pipeline(
     pipeline_name=pipeline_name,
     pipeline_root=pipeline_root,
     components=components,
     metadata_connection_config=metadata_connection_config,
     beam_pipeline_args=beam_pipeline_args,
 )
</pre>



<p>为了创建管道，您从<strong> tfx.orchestrator </strong>导入管道，并传递所需的参数，这些参数只是管道名称、将存储所有输出的根目录、组件列表和元数据配置。</p>



<p>接下来，创建一个Kubeflow runner脚本(<strong> kubeflow_dag_runner.py </strong>)并粘贴下面的代码:</p>



<p><em>定义KubeflowDagRunner以使用Kubeflow运行管道。</em></p>



<p>这个脚本是特定于Kubeflow的，是通用的，所以你可以在你的项目中使用它。在这里，您可以定义所有变量，例如数据路径、输出的存储位置、管道名称以及训练和评估参数。</p>



<pre class="hljs"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> absl <span class="hljs-keyword">import</span> logging
<span class="hljs-keyword">import</span> pipeline
<span class="hljs-keyword">from</span> tfx.orchestration.kubeflow <span class="hljs-keyword">import</span> kubeflow_dag_runner
<span class="hljs-keyword">from</span> tfx.proto <span class="hljs-keyword">import</span> trainer_pb2
<span class="hljs-keyword">from</span> tfx.utils <span class="hljs-keyword">import</span> telemetry_utils



<span class="hljs-keyword">try</span>:
 <span class="hljs-keyword">import</span> google.auth
 <span class="hljs-keyword">try</span>:
   _, GOOGLE_CLOUD_PROJECT = google.auth.default()
 <span class="hljs-keyword">except</span> google.auth.exceptions.DefaultCredentialsError:
   GOOGLE_CLOUD_PROJECT = <span class="hljs-string">''</span>
<span class="hljs-keyword">except</span> ImportError:
 GOOGLE_CLOUD_PROJECT = <span class="hljs-string">''</span>
PIPELINE_NAME = <span class="hljs-string">'advert_pred_pipeline'</span>

GCS_BUCKET_NAME = GOOGLE_CLOUD_PROJECT + <span class="hljs-string">'-kubeflowpipelines-default'</span>
PREPROCESSING_FN = <span class="hljs-string">'model.advert-transform.preprocessing_fn'</span>
RUN_FN = <span class="hljs-string">'model.advert-trainer.run_fn'</span>
TRAIN_NUM_STEPS = <span class="hljs-number">1000</span>
EVAL_NUM_STEPS = <span class="hljs-number">500</span>
EVAL_ACCURACY_THRESHOLD = <span class="hljs-number">0.5</span>


OUTPUT_DIR = os.path.join(<span class="hljs-string">'gs://'</span>, GCS_BUCKET_NAME)


PIPELINE_ROOT = os.path.join(OUTPUT_DIR, <span class="hljs-string">'advert_pred_pipeline_output'</span>,
                            PIPELINE_NAME)


SERVING_MODEL_DIR = os.path.join(PIPELINE_ROOT, <span class="hljs-string">'serving_model'</span>)
DATA_PATH = <span class="hljs-string">'gs://{}/advert-pred/data/'</span>.format(GCS_BUCKET_NAME)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">()</span>:</span>
 <span class="hljs-string">"""Define a kubeflow pipeline."""</span>
metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()
 tfx_image = os.environ.get(<span class="hljs-string">'KUBEFLOW_TFX_IMAGE'</span>, <span class="hljs-keyword">None</span>)
runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(
     kubeflow_metadata_config=metadata_config, tfx_image=tfx_image)

 pod_labels = kubeflow_dag_runner.get_default_pod_labels()
 pod_labels.update({telemetry_utils.LABEL_KFP_SDK_ENV: <span class="hljs-string">'advert-pred'</span>})
 kubeflow_dag_runner.KubeflowDagRunner(
     config=runner_config, pod_labels_to_attach=pod_labels
 ).run(
     pipeline.create_pipeline(
         pipeline_name=PIPELINE_NAME,
         pipeline_root=PIPELINE_ROOT,
         data_path=DATA_PATH,
         preprocessing_fn=PREPROCESSING_FN,
         run_fn=RUN_FN,
         train_args=trainer_pb2.TrainArgs(num_steps=TRAIN_NUM_STEPS),
         eval_args=trainer_pb2.EvalArgs(num_steps=EVAL_NUM_STEPS),
         eval_accuracy_threshold=EVAL_ACCURACY_THRESHOLD,
         serving_model_dir=SERVING_MODEL_DIR,
     ))
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
 logging.set_verbosity(logging.INFO)
 run()
</pre>



<p>这个脚本还包含一个叫做<strong> run的重要函数。</strong><strong>运行</strong>函数定义了成功执行Kubeflow管道的配置。它根据指定的参数实例化一个管道对象，然后执行它。</p>



<p>现在，再次回到您的笔记本实例。在你的互动探索后，在一个新的单元格中，将广告数据复制到你的谷歌云存储中。</p>



<p>如果您的数据已经在GCS中，请忽略这一点，只需在pipeline.py文件中指定路径。</p>



<section id="note-block_5f88bb1eaf8ad" class="block-note c-box c-box--default c-box--dark c-box--no-hover c-box--standard ">

    

    <div class="block-note__content">
                    <div class="c-item c-item--wysiwyg_editor">

                <img decoding="async" loading="lazy" alt="" class="c-item__arrow lazyload" src="../Images/6ee4db9241456412a31ee02e477cd458.png" data-src="https://web.archive.org/web/20221201153827/https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg" data-original-src="https://web.archive.org/web/20221201153827/https://neptune.ai/wp-content/themes/neptune/img/blocks/note/list-arrow.svg"/>

                <div class="c-item__content">

                                            <p> </p>
                                    </div>

            </div>
            </div>


</section>



<p id="separator-block_6033882b875eb" class="block-separator block-separator--0">默认情况下，当您实例化Kubeflow时，已经为您的管道创建了一个云桶。您将在复制数据集时指定此路径。</p>



<p>可以导航到云存储<a href="https://web.archive.org/web/20221201153827/https://console.cloud.google.com/storage/browser" target="_blank" rel="noreferrer noopener nofollow">浏览器</a>确认文件已经上传。</p>



<pre class="hljs"><span class="hljs-meta">## copy data to cloud storage for easy access from Kubeflow</span>
!gsutil cp <span class="hljs-class"><span class="hljs-keyword">data</span>/advertising.csv gs://{<span class="hljs-type">GOOGLE_CLOUD_PROJECT</span>}-kubeflowpipelines-default/advert-pred/<span class="hljs-keyword">data</span>/<span class="hljs-keyword">data</span>.csv</span>
</pre>



<p>接下来，设置<strong>管道</strong>变量名。这与<strong> Kubeflow_dag_runner.py </strong>脚本中的相同:</p>



<p>管道名称= '广告预测管道'</p>



<p>接下来，在新单元中，您将使用tfx pipeline create命令创建管道，如下所示:</p>



<p>注意，您指定了Kubeflow runner脚本、Kubeflow实例的端点以及Docker图像名称。</p>



<p>运行上面的命令需要几分钟才能完成。这是因为TFX使用我们之前安装的<strong> skaffold </strong>包来构建管道的docker映像。</p>



<pre class="hljs">!tfx pipeline create
-<span class="ruby">-pipeline-path=kubeflow_dag_runner.py
</span>-<span class="ruby">-endpoint={ENDPOINT}
</span>-<span class="ruby">-build-target-image={CUSTOM_TFX_IMAGE}
</span></pre>



<p>成功构建后，您会发现两个新文件(Dockerfile和build.yaml)。接下来，您将使用tfx run命令向Kubeflow提交这个管道作业。如下所示:</p>



<p>您的Kubeflow管道已成功推出！要对此进行监控，请转到您的Kubeflow实例页面(从这里复制端点URL)，单击<strong> Experiments，</strong>，然后选择您的管道名称。</p>



<pre class="hljs">!tfx run create --pipeline-name={PIPELINE_NAME} --endpoint={ENDPOINT}</pre>







<p>在执行时，您应该会看到一个管道图。如果有任何错误，它显示一个红色的失败图标，管道停止，否则它显示绿色，所有组件都被执行。</p>



<p><strong>您还可以在Kubeflow中查看每个输出的可视化效果。</strong>这是从每个组件的输出中自动生成的。</p>







<p>例如，下面我们检查<strong> statisticsgen </strong>的输出。点击<strong> statisticsgen </strong>节点，选择可视化。</p>



<p>要查看生成的输出和保存的模型，您可以导航到您的<a href="https://web.archive.org/web/20221201153827/https://console.cloud.google.com/storage/" target="_blank" rel="noreferrer noopener nofollow"> GCS </a> bucket。</p>







<p>如果您对您的管道进行更新，您可以使用下面的代码轻松地更新和运行它:</p>







<p><strong>就这样！您已经使用TFX和Kubeflow </strong>成功地编排了一个端到端的ML管道。结合本教程中使用的工具，您可以轻松有效地构建整个ML工作流。</p>



<pre class="hljs">!tfx pipeline <span class="hljs-keyword">update</span>


!tfx run <span class="hljs-keyword">create</span> 
</pre>



<p>摘要</p>



<p id="separator-block_5f8952c957ad1" class="block-separator block-separator--5">在本教程中，您学习了如何使用TFX构建ML组件，如何在AI云平台上创建笔记本实例，如何交互式运行TFX组件，以及如何使用Kubeflow协调您的管道。</p>



<h2 id="Cleaning">这是非常重要的知识，你可以开始在你的下一个公司或个人项目中使用。</h2>



<p>希望对你有帮助。我等不及要看你造的东西了！</p>



<p><strong>本教程完整课程代码的链接可在<a href="https://web.archive.org/web/20221201153827/https://github.com/risenW/tfx-adClickPrediction" target="_blank" rel="noreferrer noopener nofollow">此处</a>找到</strong>。</p>



<p>参考</p>



<p>本教程旨在介绍TensorFlow Extended (TFX)和Cloud AI平台管道，帮助你学会|<a href="https://web.archive.org/web/20221201153827/http://www.tensorflow.org/" target="_blank" rel="noreferrer noopener nofollow">www.tensorflow.org</a></p>



<p id="separator-block_5f8952cc57ad2" class="block-separator block-separator--5">TFX是一个基于TensorFlow的谷歌生产规模的机器学习(ML)平台。它提供了一个配置|<a href="https://web.archive.org/web/20221201153827/http://www.tensorflow.org/" target="_blank" rel="noreferrer noopener nofollow">www.tensorflow.org</a></p>



<h2 id="h-references">从命令行。对于这个特定的管道，查找带有前缀workflow1(它的前缀)的服务，并注意|<a href="https://web.archive.org/web/20221201153827/http://cloud.google.com/" target="_blank" rel="noreferrer noopener nofollow">cloud.google.com</a></h2>







<p>Apache Beam为运行批处理和流数据处理作业提供了一个框架，这些作业可以在各种|<a href="https://web.archive.org/web/20221201153827/http://www.tensorflow.org/" target="_blank" rel="noreferrer noopener nofollow">www.tensorflow.org</a>上运行</p>







<p>TFX is a Google-production-scale machine learning (ML) platform based on TensorFlow. It provides a configuration | <a href="https://web.archive.org/web/20221201153827/http://www.tensorflow.org/" target="_blank" rel="noreferrer noopener nofollow">www.tensorflow.org</a></p>







<p>From the command line. For this particular pipeline, look for the services with prefix workflow1 (its prefix), and note | <a href="https://web.archive.org/web/20221201153827/http://cloud.google.com/" target="_blank" rel="noreferrer noopener nofollow">cloud.google.com</a></p>







<p>Apache Beam provides a framework for running batch and streaming data processing jobs that run on a variety of | <a href="https://web.archive.org/web/20221201153827/http://www.tensorflow.org/" target="_blank" rel="noreferrer noopener nofollow">www.tensorflow.org</a> </p>
        </div>
        
    </div>    
</body>
</html>