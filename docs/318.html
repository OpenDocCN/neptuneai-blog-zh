<html>
<head>
<title>How to Keep Track of PyTorch Lightning Experiments With Neptune </title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>如何跟踪海王星的PyTorch闪电实验</h1>
<blockquote>原文：<a href="https://web.archive.org/web/https://neptune.ai/blog/pytorch-lightning-neptune-integration#0001-01-01">https://web.archive.org/web/https://neptune.ai/blog/pytorch-lightning-neptune-integration#0001-01-01</a></blockquote><div><div class="l-content content-wrapper js-content">
            
<p>使用PyTorch Lightning并想知道您应该选择哪个记录器来<a href="/web/20221206015925/https://neptune.ai/experiment-tracking" target="_blank" rel="noreferrer noopener">跟踪您的实验</a>？</p>



<p>想要找到保存超参数、指标和其他建模元数据的好方法吗？</p>



<p>考虑使用PyTorch Lightning来构建您的深度学习代码，并且不介意了解它的日志记录功能？</p>



<p>不知道闪电有一个相当可怕的海王星积分？</p>



<p>这篇文章(很可能)适合你。</p>



<h2 id="h-why-pytorch-lightning-and-neptune">为什么是PyTorch闪电和海王星？</h2>



<p>如果你从未听说过，PyTorch Lightning 是PyTorch之上的一个非常轻量级的包装器，它更像是一个编码标准而不是框架。这种格式可以让你摆脱大量的样板代码，同时保持简单易懂。</p>



<p>其结果是一个框架，为研究人员、学生和生产团队提供了尝试疯狂想法的终极灵活性，而不必学习另一个框架，同时自动化掉所有的工程细节。</p>



<p>您可以获得的一些出色功能包括:</p>



<ul><li>在不改变代码的情况下，在CPU、GPU或TPUs上进行训练，</li><li>琐碎的多GPU和多节点训练</li><li>微不足道的16位精度支持</li><li>内置性能分析器(训练器(profile=True))</li></ul>



<p>以及一大堆其他伟大的功能。</p>







<p>但是，伴随着这种轻松运行实验的强大功能和随意调整的灵活性，出现了一个问题。</p>



<p>如何跟踪所有变化，例如:</p>



<ul><li>损失和指标，</li><li>超参数</li><li>模型二进制</li><li>验证预测</li></ul>



<p>和其他能帮助你组织实验过程的东西？</p>



<h3>PyTorch闪电记录器</h3>



<p>幸运的是，PyTorch Lightning为您提供了一个将记录器轻松连接到pl的选项。训练器和一个<a href="https://web.archive.org/web/20221206015925/https://pytorch-lightning.readthedocs.io/en/latest/api_references.html#loggers" target="_blank" rel="noreferrer noopener nofollow">支持的记录器</a>可以跟踪之前提到的所有东西(和许多其他东西)是NeptuneLogger，它保存你的实验在…你猜对了，<a href="https://web.archive.org/web/20221206015925/https://docs.neptune.ai/integrations-and-supported-tools/model-training/pytorch-lightning" target="_blank" rel="noreferrer noopener">海王星</a>。</p>



<p>海王星不仅跟踪你的实验文物，而且:</p>







<p>最好的部分是，这种集成使用起来真的很简单。</p>



<p>让我给你看看它是什么样子的。</p>



<section id="blog-intext-cta-block_61cade7df0a30" class="block-blog-intext-cta  c-box c-box--default c-box--dark c-box--no-hover c-box--standard ">

            
    
            <p>你也可以看看这个<a href="https://web.archive.org/web/20221206015925/https://colab.research.google.com/drive/1EThGG9EbN6rjMITFUKNtUwQdth_Zuu36?usp=sharing" target="_blank" rel="noreferrer noopener nofollow"> colab笔记本</a>，玩玩我们将要谈到的你自己的例子。</p>
    
    </section>



<h2 id="h-pytorch-lightning-logging-basic-integration-save-hyperparameters-metrics-and-more">PyTorch闪电日志:基本集成(保存超参数、指标等)</h2>



<p>在最简单的情况下，您只需创建<code>NeptuneLogger</code>:</p>



<pre class="hljs"><span class="hljs-keyword">from</span> pytorch_lightning.loggers <span class="hljs-keyword">import</span> NeptuneLogger

neptune_logger = NeptuneLogger(
    api_key=<span class="hljs-string">"ANONYMOUS"</span>,
    project_name=<span class="hljs-string">"shared/pytorch-lightning-integration"</span>)</pre>



<p>并将其传递给<code>Trainer</code>的logger参数，以符合您的模型。</p>



<pre class="hljs"><span class="hljs-keyword">from</span> pytorch_lightning <span class="hljs-keyword">import</span> Trainer

trainer = Trainer(logger=neptune_logger)
trainer.fit(model)
</pre>



<p>通过这样做，您可以自动:</p>



<ul><li>记录指标和损失(并创建图表)，</li><li>记录并保存超参数(如果通过lightning hparams定义)，</li><li>记录硬件利用率</li><li>记录Git信息和执行脚本</li></ul>



<p>看看这个实验。</p>







<p>你可以监控你的实验，比较它们，并与他人分享。</p>



<p>对一辆四缸车来说还不错。</p>



<p>但是只要多一点努力，你就能得到更多。</p>



<h2 id="h-pytorch-lightning-logging-advanced-options">PyTorch闪电测井:高级选项</h2>



<p>Neptune为您提供了许多定制选项，您可以简单地记录更多特定于实验的内容，如图像预测、模型权重、性能图表等等。</p>



<p>所有这些功能对Lightning用户都是可用的，在下一节中，我将向您展示如何充分利用Neptune。</p>



<h3>创建NeptuneLogger时记录额外信息</h3>



<p>创建记录器时，您可以记录其他有用的信息:</p>



<ul><li><a href="https://web.archive.org/web/20221206015925/https://docs.neptune.ai/you-should-know/what-can-you-log-and-display#code" target="_blank" rel="noreferrer noopener">代码</a>:快照脚本、jupyter笔记本、配置文件等等，</li><li>超参数:记录学习率、历元数和其他东西(如果你正在使用lightning的lightning <code>hparams</code>对象，它将被自动记录)</li><li><a href="https://web.archive.org/web/20221206015925/https://docs.neptune.ai/you-should-know/what-can-you-log-and-display#data-versions" target="_blank" rel="noreferrer noopener">属性</a>:日志数据位置、数据版本或其他</li><li><a href="https://web.archive.org/web/20221206015925/https://docs.neptune.ai/you-should-know/what-can-you-log-and-display#tags" target="_blank" rel="noreferrer noopener">标签</a>:添加“resnet50”或“无增强”等标签来组织您的跑步。</li></ul>



<p>只需将这些信息传递给你的记录器:</p>



<pre class="hljs">neptune_logger = NeptuneLogger(
    api_key=<span class="hljs-string">"ANONYMOUS"</span>,
    project=<span class="hljs-string">"shared/pytorch-lightning-integration"</span>,
    tags=[<span class="hljs-string">"pytorch-lightning"</span>, <span class="hljs-string">"mlp"</span>],
)
</pre>



<h3>用PyTorch Lightning记录训练中的额外事情</h3>



<p>训练中可以记录很多有趣的信息。</p>



<p>您可能对监控以下内容感兴趣:</p>



<ul><li>每个时期后的模型预测(考虑预测遮罩或覆盖的边界框)</li><li>诊断图表，如ROC AUC曲线或混淆矩阵</li><li><a href="https://web.archive.org/web/20221206015925/https://docs.neptune.ai/you-should-know/what-can-you-log-and-display#model-checkpoints" target="_blank" rel="noreferrer noopener">模型检查点</a>，或其他对象</li></ul>



<p>这真的很简单。只需转到您的<code>LightningModule</code>并调用作为<code>self.logger.experiment</code>可用的Neptune实验的方法。</p>



<p>例如，我们可以记录每个时期后的损失直方图:</p>



<pre class="hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CoolSystem</span><span class="hljs-params">(pl.LightningModule)</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">validation_epoch_end</span><span class="hljs-params">(self, outputs)</span>:</span>
        
        avg_loss = torch.stack([x[<span class="hljs-string">'val_loss'</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> outputs]).mean()
        
        fig = plt.figure()
        losses = np.stack([x[<span class="hljs-string">'val_loss'</span>].numpy() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> outputs])
        plt.hist(losses)
        neptune_logger.experiments[<span class="hljs-string">'loss_histograms'</span>].log(File.as_image(fig))
        plt.close(fig)

        <span class="hljs-keyword">return</span> {<span class="hljs-string">'avg_val_loss'</span>: avg_loss}</pre>



<p><a href="https://web.archive.org/web/20221206015925/https://app.neptune.ai/shared/pytorch-lightning-integration/e/PYTOR-173293/all?path=imgs&amp;attribute=loss_histograms" target="_blank" rel="noreferrer noopener">自己探索它们</a>。</p>







<p><a href="https://web.archive.org/web/20221206015925/https://docs.neptune.ai/you-should-know/what-can-you-log-and-display" target="_blank" rel="noreferrer noopener">在培训期间，您可能希望记录的其他事情</a>有:</p>



<ul><li><code>neptune_logger.experiment["your/metadata/metric"].log(metric)</code> #记录自定义指标</li><li><code>neptune_logger.experiment["your/metadata/text"].log(text)</code> #日志文本值</li><li><code>neptune_logger.experiment["your/metadata/file"].upload(artifact)</code> #日志文件</li><li><code>neptune_logger.experiment["your/metadata/figure"].upload(File.as_image(artifact))</code> #日志图片、图表</li><li><code>neptune_logger.experiment["properties/key"] = value</code> #添加键值对</li><li><code>neptune_logger.experiment["sys/tags"].add(['tag1', 'tag2'])</code> #为组织添加标签</li></ul>



<p>很酷吧？</p>



<p>但是…这不是你能做的全部！</p>



<h3>PyTorch闪电训练结束后记录东西</h3>



<p>跟踪你的实验不一定要在你做完后才结束。安装循环末端。</p>



<p>您可能想要跟踪<code>trainer.test(model)</code>的指标，或者计算一些额外的验证指标并记录下来。</p>



<p>要做到这一点，你只需要告诉<code>NeptuneLogger</code>不要在安装后关闭:</p>



<pre class="hljs">neptune_logger = NeptuneLogger(
    api_key=<span class="hljs-string">"ANONYMOUS"</span>,
    project_name=<span class="hljs-string">"shared/pytorch-lightning-integration"</span>,
    ...
)
</pre>



<p>…您可以继续记录🙂</p>



<p><strong>测试指标:</strong></p>



<pre class="hljs">trainer.test(model)</pre>



<p><strong>其他(外部)指标:</strong></p>



<pre class="hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score
...
accuracy = accuracy_score(y_true, y_pred)
neptune_logger.experiment[<span class="hljs-string">'test/accuracy'</span>].log(accuracy)</pre>



<p><strong>测试集上的性能图表:</strong></p>



<pre class="hljs"><span class="hljs-keyword">from</span> scikitplot.metrics <span class="hljs-keyword">import</span> plot_confusion_matrix
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
...
fig, ax = plt.subplots(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">12</span>))
plot_confusion_matrix(y_true, y_pred, ax=ax)
neptune_logger.experiment[<span class="hljs-string">'test/confusion_matrix'</span>].upload(File.as_image(fig))</pre>



<p><strong>整个模型检查点目录:</strong></p>



<pre class="hljs">neptune_logger.experiment(<span class="hljs-string">'checkpoints'</span>).upload(<span class="hljs-string">'my/checkpoints'</span>)
</pre>



<p><a href="https://web.archive.org/web/20221206015925/https://app.neptune.ai/shared/pytorch-lightning-integration/e/PYTOR-173293/all?path=&amp;attribute=confusion_matrix" target="_blank" rel="noreferrer noopener">转到本实验</a>查看这些对象是如何被记录的:</p>







<p>但是…还有更多！</p>



<p>海王星让你在训练后获取实验。</p>



<p>让我告诉你怎么做。</p>



<h3>把你的PyTorch闪电实验信息直接拿到笔记本上</h3>



<p>您可以在实验完成后获取实验，分析结果，并更新度量、工件或其他东西。</p>



<p>例如，让我们将实验仪表板提取到熊猫数据帧:</p>



<pre class="hljs"><span class="hljs-keyword">import</span> neptune.new <span class="hljs-keyword">as</span> neptune

project = neptune.init(<span class="hljs-string">'shared/pytorch-lightning-integration'</span>)
project.fetch_runs_table().to_pandas()
</pre>



<p>或者获取一个单独的实验并用训练后计算的一些外部度量来更新它:</p>



<pre class="hljs">exp = neptune.init(project=<span class="hljs-string">'shared/pytorch-lightning-integration'</span>, id=<span class="hljs-string">'PYTOR-63'</span>)
exp[<span class="hljs-string">'some_external_metric'</span>].log(<span class="hljs-number">0.92</span>)</pre>



<p>或者获取一个单独的实验并用训练后计算的一些外部度量来更新它:</p>



<pre class="hljs">exp = project.get_experiments(id=<span class="hljs-string">'PYTOR-63'</span>)[<span class="hljs-number">0</span>]
exp.log_metric(<span class="hljs-string">'some_external_metric'</span>, <span class="hljs-number">0.92</span>)
</pre>



<p>如你所见，你可以从Pytorch Lightning将很多东西记录到Neptune。</p>



<p>如果你想深入了解这个问题:</p>







<h2 id="h-final-thoughts">最后的想法</h2>



<p>Pytorch Lightning是一个很棒的库，可以帮助您:</p>



<ul><li>组织你的深度学习代码，让其他人容易理解，</li><li>将开发样板外包给经验丰富的工程师团队，</li><li>访问大量最先进的功能，几乎不需要修改您的代码</li></ul>



<p>借助Neptune integration，您可以免费获得一些额外的东西:</p>



<ul><li>你可以监控和跟踪你的深度学习实验</li><li>你可以很容易地与其他人分享你的研究</li><li>您和您的团队可以访问实验元数据并更有效地协作。</li></ul>



<p>希望有了这种力量，你将确切地知道你(和其他人)尝试了什么，你的深度学习研究将以闪电般的速度前进</p>



<h2 id="h-full-pytorch-lightning-tracking-script">完整的PyTorch闪电追踪脚本</h2>



<pre class="hljs">pip install --upgrade torch pytorch-lightning&gt;=<span class="hljs-number">1.5</span><span class="hljs-number">.0</span>
    neptune-client
    matplotlib scikit-plot
</pre>



<pre class="hljs"><span class="hljs-keyword">import</span> os

<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> neptune.new <span class="hljs-keyword">as</span> neptune
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-keyword">from</span> torchvision.datasets <span class="hljs-keyword">import</span> MNIST
<span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-keyword">import</span> pytorch_lightning <span class="hljs-keyword">as</span> pl

MAX_EPOCHS=<span class="hljs-number">15</span>
LR=<span class="hljs-number">0.02</span>
BATCHSIZE=<span class="hljs-number">32</span>
CHECKPOINTS_DIR = <span class="hljs-string">'my_models/checkpoints'</span>

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CoolSystem</span><span class="hljs-params">(pl.LightningModule)</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(CoolSystem, self).__init__()
        
        self.l1 = torch.nn.Linear(<span class="hljs-number">28</span> * <span class="hljs-number">28</span>, <span class="hljs-number">10</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-keyword">return</span> torch.relu(self.l1(x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)))

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">training_step</span><span class="hljs-params">(self, batch, batch_idx)</span>:</span>
        
        x, y = batch
        y_hat = self.forward(x)
        loss = F.cross_entropy(y_hat, y)
        self.log(<span class="hljs-string">'train/loss'</span>, loss)
        <span class="hljs-keyword">return</span> {<span class="hljs-string">'loss'</span>: loss}

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">validation_step</span><span class="hljs-params">(self, batch, batch_idx)</span>:</span>
        
        x, y = batch
        y_hat = self.forward(x)
        loss = F.cross_entropy(y_hat, y)
        self.log(<span class="hljs-string">'val/loss'</span>, loss)
        <span class="hljs-keyword">return</span> {<span class="hljs-string">'val_loss'</span>: loss}

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">validation_epoch_end</span><span class="hljs-params">(self, outputs)</span>:</span>
        
        avg_loss = torch.stack([x[<span class="hljs-string">'val_loss'</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> outputs]).mean()

        fig = plt.figure()
        losses = np.stack([x[<span class="hljs-string">'val_loss'</span>].numpy() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> outputs])
        plt.hist(losses)
        neptune_logger.experiment[<span class="hljs-string">'imgs/loss_histograms'</span>].upload(neptune.types.File.as_image(fig))

        <span class="hljs-keyword">return</span> {<span class="hljs-string">'avg_val_loss'</span>: avg_loss}

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_step</span><span class="hljs-params">(self, batch, batch_idx)</span>:</span>
        
        x, y = batch
        y_hat = self.forward(x)
        loss = F.cross_entropy(y_hat, y)
        self.log(<span class="hljs-string">'test/loss'</span>, loss)
        <span class="hljs-keyword">return</span> {<span class="hljs-string">'test_loss'</span>: loss}

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_end</span><span class="hljs-params">(self, outputs)</span>:</span>
        
        avg_loss = torch.stack([x[<span class="hljs-string">'test_loss'</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> outputs]).mean()
        <span class="hljs-keyword">return</span> {<span class="hljs-string">'avg_test_loss'</span>: avg_loss}

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">configure_optimizers</span><span class="hljs-params">(self)</span>:</span>
        
        
        
        <span class="hljs-keyword">return</span> torch.optim.Adam(self.parameters(), lr=LR)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_dataloader</span><span class="hljs-params">(self)</span>:</span>
        
        <span class="hljs-keyword">return</span> DataLoader(MNIST(os.getcwd(), train=<span class="hljs-keyword">True</span>, download=<span class="hljs-keyword">True</span>, transform=transforms.ToTensor()), batch_size=BATCHSIZE)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">val_dataloader</span><span class="hljs-params">(self)</span>:</span>
        
        <span class="hljs-keyword">return</span> DataLoader(MNIST(os.getcwd(), train=<span class="hljs-keyword">True</span>, download=<span class="hljs-keyword">True</span>, transform=transforms.ToTensor()), batch_size=BATCHSIZE)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_dataloader</span><span class="hljs-params">(self)</span>:</span>
        
        <span class="hljs-keyword">return</span> DataLoader(MNIST(os.getcwd(), train=<span class="hljs-keyword">False</span>, download=<span class="hljs-keyword">True</span>, transform=transforms.ToTensor()), batch_size=BATCHSIZE)
<span class="hljs-keyword">from</span> pytorch_lightning.loggers.neptune <span class="hljs-keyword">import</span> NeptuneLogger

neptune_logger = NeptuneLogger(
    api_key=<span class="hljs-string">"ANONYMOUS"</span>,
    project_name=<span class="hljs-string">"shared/pytorch-lightning-integration"</span>,
    tags=[<span class="hljs-string">"pytorch-lightning"</span>, <span class="hljs-string">"mlp"</span>],
)
model_checkpoint = pl.callbacks.ModelCheckpoint(filepath=CHECKPOINTS_DIR)

<span class="hljs-keyword">from</span> pytorch_lightning <span class="hljs-keyword">import</span> Trainer

model = CoolSystem()
trainer = Trainer(max_epochs=MAX_EPOCHS,
                  logger=neptune_logger,
                  checkpoint_callback=model_checkpoint,
                  )
trainer.fit(model)
trainer.test(model)


<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

model.freeze()
test_loader = DataLoader(MNIST(os.getcwd(), train=<span class="hljs-keyword">False</span>, download=<span class="hljs-keyword">True</span>, transform=transforms.ToTensor()), batch_size=<span class="hljs-number">256</span>)

y_true, y_pred = [],[]
<span class="hljs-keyword">for</span> i, (x, y) <span class="hljs-keyword">in</span> enumerate(test_loader):
    y_hat = model.forward(x).argmax(axis=<span class="hljs-number">1</span>).cpu().detach().numpy()
    y = y.cpu().detach().numpy()

    y_true.append(y)
    y_pred.append(y_hat)

    <span class="hljs-keyword">if</span> i == len(test_loader):
        <span class="hljs-keyword">break</span>
y_true = np.hstack(y_true)
y_pred = np.hstack(y_pred)


<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score

accuracy = accuracy_score(y_true, y_pred)
neptune_logger.experiment[<span class="hljs-string">'test/accuracy'</span>].log(accuracy)


<span class="hljs-keyword">from</span> scikitplot.metrics <span class="hljs-keyword">import</span> plot_confusion_matrix
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

fig, ax = plt.subplots(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">12</span>))
plot_confusion_matrix(y_true, y_pred, ax=ax)
neptune_logger.experiment[<span class="hljs-string">'confusion_matrix'</span>].log(File.as_image(fig))


neptune_logger.experiment(<span class="hljs-string">'checkpoints'</span>).upload(CHECKPOINTS_DIR)

neptune_logger.experiment.stop()
</pre>
        </div>
        
    </div>    
</body>
</html>